{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ad85b03-163f-49a0-8765-55a25b48c224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "from ase.io import read\n",
    "import xcquinox as xce\n",
    "import torch, jax, optax\n",
    "import numpy as np\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import pyscfad as psa\n",
    "import os, sys\n",
    "from pyscfad import dft, scf, gto, df\n",
    "from pyscfad.pbc import scf as scfp\n",
    "from pyscfad.pbc import gto as gtop\n",
    "from pyscfad.pbc import dft as dftp\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE']='false'\n",
    "os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'\n",
    "\n",
    "from mp_api.client import MPRester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9adc4407-1bb5-441f-ac34-380de1dda5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpr = MPRester(api_key = 'UutJcvAlT6PETlthXKpvFNDU3VjztR1c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f17a47f7-ed34-4feb-beaf-9a530274da62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b587ac23bd964f368307e1916a33506f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Retrieving ElectronicStructureDoc documents:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret = mpr.get_bandstructure_by_material_id('mp-66')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f2dc572b-090a-4f54-a03a-4a6e6aebd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "struc = ret.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "028549e3-cfaf-4323-9da3-a9a04c6dca20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 2.526994574994177 2.526994574994177 2.526994574994177\n",
       " angles : 60.00000000000001 60.00000000000001 60.00000000000001\n",
       " volume : 11.410322800393955\n",
       "      A : -1.786855 -1.786855 0.0\n",
       "      B : -1.786855 0.0 -1.786855\n",
       "      C : 0.0 -1.786855 -1.786855\n",
       "    pbc : True True True\n",
       "PeriodicSite: C (-2.68, -2.68, -2.68) [0.75, 0.75, 0.75]\n",
       "PeriodicSite: C (0.0, 0.0, 0.0) [0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struc.get_reduced_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "75fc35da-42e0-4107-8b0e-d54271ec16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = ret.structure.as_dict()\n",
    "at_coor_xyz = [ (i['species'][0]['element'], i['xyz']) for i in rets['sites']]\n",
    "\n",
    "at_coor_abc = [ (i['species'][0]['element'], [rets['lattice']['a']*j for j in i['abc']]) for i in rets['sites']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9f86742b-f266-4183-81b0-f52ccb238032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', [1.8952459312456327, 1.8952459312456327, 1.8952459312456327]),\n",
       " ('C', [0.0, 0.0, 0.0])]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_coor_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dc61ea45-65ad-4433-be2f-c10019506d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C', [-2.6802825, -2.6802825, -2.6802825]), ('C', [0.0, 0.0, 0.0])]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "at_coor_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2d32b46-c26d-4498-87ec-10abc8d99c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cella = -np.asarray(rets['lattice']['matrix'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6550e949-8105-4a47-8b27-85ba0ddbeb4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "The leading minor of order 2 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m kpts \u001b[38;5;241m=\u001b[39m cell\u001b[38;5;241m.\u001b[39mmake_kpts([\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m      9\u001b[0m mf \u001b[38;5;241m=\u001b[39m scfp\u001b[38;5;241m.\u001b[39mKRHF(cell, kpts\u001b[38;5;241m=\u001b[39mkpts)\n\u001b[0;32m---> 10\u001b[0m e \u001b[38;5;241m=\u001b[39m \u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/scf/hf.py:395\u001b[0m, in \u001b[0;36mSCF.kernel\u001b[0;34m(self, dm0, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernel\u001b[39m(\u001b[38;5;28mself\u001b[39m, dm0\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmol)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverged, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me_tot, \\\n\u001b[1;32m    394\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmo_energy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmo_coeff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmo_occ \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 395\u001b[0m             \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_tol_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mdm0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdm0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39me_tot\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/scf/hf.py:168\u001b[0m, in \u001b[0;36mkernel\u001b[0;34m(mf, conv_tol, conv_tol_grad, dump_chk, dm0, callback, conv_check, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     chkfile\u001b[38;5;241m.\u001b[39msave_mol(mol, mf\u001b[38;5;241m.\u001b[39mchkfile)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;66;03m# A preprocessing hook before the SCF iteration\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m#mf.pre_kernel(locals())\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \u001b[38;5;66;03m# SCF iteration\u001b[39;00m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# NOTE if use implicit differentiation, only dm will have gradient.\u001b[39;00m\n\u001b[1;32m    167\u001b[0m dm, scf_conv, e_tot, mo_energy, mo_coeff, mo_occ \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 168\u001b[0m         \u001b[43mmake_implicit_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_scf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscf_implicit_diff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimality_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_scf_optimality_cond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgen_gmres\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh1e\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m             \u001b[49m\u001b[43mconv_tol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_tol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconv_tol_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconv_tol_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdiis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmf_diis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdump_chk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdump_chk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m run_extra_cycle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mscf_implicit_diff \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m conv_check \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m scf_conv):\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/scf/hf.py:64\u001b[0m, in \u001b[0;36m_scf\u001b[0;34m(dm, mf, s1e, h1e, conv_tol, conv_tol_grad, diis, dump_chk, callback, log)\u001b[0m\n\u001b[1;32m     61\u001b[0m last_hf_e \u001b[38;5;241m=\u001b[39m e_tot\n\u001b[1;32m     63\u001b[0m fock \u001b[38;5;241m=\u001b[39m mf\u001b[38;5;241m.\u001b[39mget_fock(h1e, s1e, vhf, dm, cycle, diis)\n\u001b[0;32m---> 64\u001b[0m mo_energy, mo_coeff \u001b[38;5;241m=\u001b[39m \u001b[43mmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms1e\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m mo_occ \u001b[38;5;241m=\u001b[39m stop_trace(mf\u001b[38;5;241m.\u001b[39mget_occ)(mo_energy, mo_coeff)\n\u001b[1;32m     66\u001b[0m dm \u001b[38;5;241m=\u001b[39m mf\u001b[38;5;241m.\u001b[39mmake_rdm1(mo_coeff, mo_occ)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/pbc/scf/khf.py:147\u001b[0m, in \u001b[0;36mKSCF.eig\u001b[0;34m(self, h_kpts, s_kpts)\u001b[0m\n\u001b[1;32m    144\u001b[0m mo_coeff_kpts \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nkpts):\n\u001b[0;32m--> 147\u001b[0m     e, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh_kpts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_kpts\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     eig_kpts\u001b[38;5;241m.\u001b[39mappend(e)\n\u001b[1;32m    149\u001b[0m     mo_coeff_kpts\u001b[38;5;241m.\u001b[39mappend(c)\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/scf/hf.py:400\u001b[0m, in \u001b[0;36mSCF._eigh\u001b[0;34m(self, h, s)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eigh\u001b[39m(\u001b[38;5;28mself\u001b[39m, h, s):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/_src/scipy/linalg.py:28\u001b[0m, in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver, deg_thresh)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (b \u001b[38;5;241m+\u001b[39m b\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mconj())\n\u001b[0;32m---> 28\u001b[0m w, v \u001b[38;5;241m=\u001b[39m \u001b[43m_eigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeg_thresh\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeg_thresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eigvals_only:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m w\n",
      "    \u001b[0;31m[... skipping hidden 5 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/_src/scipy/linalg.py:37\u001b[0m, in \u001b[0;36m_eigh\u001b[0;34m(a, b, deg_thresh)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@partial\u001b[39m(custom_jvp, nondiff_argnums\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m,))\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_eigh\u001b[39m(a, b, deg_thresh\u001b[38;5;241m=\u001b[39mDEG_THRESH):\n\u001b[0;32m---> 37\u001b[0m     w, v \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigh\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(w, dtype\u001b[38;5;241m=\u001b[39mv\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m w, v\n",
      "File \u001b[0;32m~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/scipy/linalg/_decomp.py:593\u001b[0m, in \u001b[0;36meigh\u001b[0;34m(a, b, lower, eigvals_only, overwrite_a, overwrite_b, turbo, eigvals, type, check_finite, subset_by_index, subset_by_value, driver)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIllegal value in argument \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of internal \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    591\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m-\u001b[39minfo, drv\u001b[38;5;241m.\u001b[39mtypecode \u001b[38;5;241m+\u001b[39m pfx \u001b[38;5;241m+\u001b[39m driver))\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m n:\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe leading minor of order \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m of B is not \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive definite. The factorization of B \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    595\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcould not be completed and no eigenvalues \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    596\u001b[0m                       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mor eigenvectors were computed.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(info\u001b[38;5;241m-\u001b[39mn))\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    598\u001b[0m     drv_err \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mev\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe algorithm failed to converge; \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    599\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff-diagonal elements of an intermediate \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    600\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtridiagonal form did not converge to zero.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    605\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInternal Error.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    606\u001b[0m                }\n",
      "\u001b[0;31mLinAlgError\u001b[0m: The leading minor of order 2 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed."
     ]
    }
   ],
   "source": [
    "tcell = gtop.Cell()\n",
    "cell.atom = at_coor_xyz\n",
    "cell.a = cella\n",
    "cell.basis = 'gth-szv'\n",
    "cell.pseudo = 'gth-pade'\n",
    "cell.exp_to_discard = 0.1\n",
    "cell.build(trace_lattice_vectors=True)\n",
    "kpts = cell.make_kpts([2,2,2])\n",
    "mf = scfp.KRHF(cell, kpts=kpts)\n",
    "e = mf.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94938dd-9c2b-4b5f-a8dc-2ab9cb7895f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "55b5d21b-595b-4774-b551-825225c228bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species': [{'element': 'Si', 'occu': 1}],\n",
       " 'abc': [0.75, 0.75, 0.75],\n",
       " 'xyz': [-4.1016945, -4.1016945, -4.1016945],\n",
       " 'properties': {},\n",
       " 'label': 'Si'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets['sites'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cf7c6a8a-3e1d-4953-a4a3-4ff4cefb037a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'band_index': defaultdict(list, {<Spin.up: 1>: [1, 2, 3]}),\n",
       " 'kpoint_index': [0, 72, 73],\n",
       " 'kpoint': <pymatgen.electronic_structure.bandstructure.Kpoint at 0x748e25c9f8e0>,\n",
       " 'energy': 5.6165,\n",
       " 'projections': {<Spin.up: 1>: array([[0.    , 0.    ],\n",
       "         [0.0066, 0.0066],\n",
       "         [0.1974, 0.1974],\n",
       "         [0.0098, 0.0098],\n",
       "         [0.    , 0.    ],\n",
       "         [0.    , 0.    ],\n",
       "         [0.    , 0.    ],\n",
       "         [0.    , 0.    ],\n",
       "         [0.    , 0.    ]])}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.get_vbm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7fccd885-d912-4701-99de-ea6863e57cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_band_gap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mget_band_gap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34mr\"\"\"Returns band gap data.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            A dict {\"energy\",\"direct\",\"transition\"}:\u001b[0m\n",
       "\u001b[0;34m            \"energy\": band gap energy\u001b[0m\n",
       "\u001b[0;34m            \"direct\": A boolean telling if the gap is direct or not\u001b[0m\n",
       "\u001b[0;34m            \"transition\": kpoint labels of the transition (e.g., \"\\\\Gamma-X\")\u001b[0m\n",
       "\u001b[0;34m        \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_metal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"direct\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transition\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mvbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vbm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"direct\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"transition\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mcbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcart_coords\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mvbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcart_coords\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"direct\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transition\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"-\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m[\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mf\"({','.join(f'{c.frac_coords[i]:.3f}' for i in range(3))})\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pymatgen/electronic_structure/bandstructure.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ret.get_band_gap??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9690b3-30be-403a-abc3-f88a969f0b36",
   "metadata": {},
   "source": [
    "Non-local descriptor package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12554bff-1f83-4adf-a53e-7d61b22bceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mldftdat.density import *\n",
    "from mldftdat.density import _get_x_helper_c\n",
    "from mldftdat.pyscf_utils import get_mgga_data\n",
    "from mldftdat.analyzers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c512a82-36be-4a46-b7ab-42b784f61c2a",
   "metadata": {},
   "source": [
    "Utility function requiring torch to load old models, but we won't require torch as a prerequisite. Eventually want to have a self-contained folder of translated models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f315b50-8bf3-48ea-997f-fdb45a6fe351",
   "metadata": {},
   "source": [
    "Torch structure for loading old models below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2f6383-a523-42f0-b1ba-dcd0a8ae3caf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# #relevant functions from dpyscfl to see if it can be self-contained here in the notebook\n",
    "# #xcdiff has this named XC_L, not X_L. keep for consistency's sake\n",
    "\n",
    "# class LOB(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, limit=1.804):\n",
    "#         \"\"\" Utility function to squash output to [-1, limit-1] inteval.\n",
    "#             Can be used to enforce non-negativity and Lieb-Oxford bound.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.sig = torch.nn.Sigmoid()\n",
    "#         self.limit = limit\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.limit*self.sig(x-np.log(self.limit-1))-1\n",
    "\n",
    "\n",
    "# class X_L(torch.nn.Module):\n",
    "#     def __init__(self, n_input, n_hidden=16, use=[], device='cpu', ueg_limit=False, lob=1.804, one_e=False):\n",
    "#         \"\"\"Local exchange model based on MLP\n",
    "#         Receives density descriptors in this order : [rho, s, alpha, nl],\n",
    "#         input may be truncated depending on level of approximation\n",
    "\n",
    "#         Args:\n",
    "#             n_input (int): Input dimensions (LDA: 1, GGA: 2, meta-GGA: 3, ...)\n",
    "#             n_hidden (int, optional): Number of hidden nodes (three hidden layers used by default). Defaults to 16.\n",
    "#             use (list of ints, optional): Only these indices are used as input to the model (can be used to omit density as input to enforce uniform density scaling). These indices are also used to enforce UEG where the assumed order is [s, alpha, ...].. Defaults to [].\n",
    "#             device (str, optional): {'cpu','cuda'}. Defaults to 'cpu'.\n",
    "#             ueg_limit (bool, optional): Enforce uniform homoegeneous electron gas limit. Defaults to False.\n",
    "#             lob (float, optional): Enforce this value as local Lieb-Oxford bound (don't enforce if set to 0). Defaults to 1.804.\n",
    "#             one_e (bool, optional): _description_. Defaults to False.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.ueg_limit = ueg_limit\n",
    "#         self.spin_scaling = True\n",
    "#         self.lob = lob\n",
    "\n",
    "#         if not use:\n",
    "#             self.use = torch.Tensor(np.arange(n_input)).long().to(device)\n",
    "#         else:\n",
    "#             self.use = torch.Tensor(use).long().to(device)\n",
    "#         #xcdiff includes double flag on net\n",
    "#         self.net =  torch.nn.Sequential(\n",
    "#                 torch.nn.Linear(n_input, n_hidden),\n",
    "#                 torch.nn.GELU(),\n",
    "#                 torch.nn.Linear(n_hidden, n_hidden),\n",
    "#                 torch.nn.GELU(),\n",
    "#                 torch.nn.Linear(n_hidden, n_hidden),\n",
    "#                 torch.nn.GELU(),\n",
    "#                 torch.nn.Linear(n_hidden, 1),\n",
    "#             ).double().to(device)\n",
    "\n",
    "#         #to device not declared in xcdiff\n",
    "#         self.tanh = torch.nn.Tanh().to(device)\n",
    "#         self.lobf = LOB(lob).to(device)\n",
    "#         #below declared in xcdiff\n",
    "#         self.sig = torch.nn.Sigmoid()\n",
    "#         self.shift = 1/(1+np.exp(-1e-3))\n",
    "\n",
    "#     def forward(self, rho, **kwargs):\n",
    "#         \"\"\"Forward pass\n",
    "\n",
    "#         Args:\n",
    "#             rho (_type_): _description_\n",
    "\n",
    "#         Returns:\n",
    "#             _type_: _description_\n",
    "#         \"\"\"\n",
    "#         # print(rho.size, rho.shape, rho.dtype)\n",
    "#         # print('x call -- rho shape', rho.shape)\n",
    "#         # print('x call -- rho[...,self.use] shape', rho[...,self.use].shape)\n",
    "#         squeezed = self.net(rho[...,self.use]).squeeze()\n",
    "#         # print('x call -- squeezed shape', squeezed.shape)\n",
    "#         # print('x call -- squeezed', squeezed)\n",
    "\n",
    "#         if self.ueg_limit:\n",
    "#             ueg_lim = rho[...,self.use[0]]\n",
    "#             if len(self.use) > 1:\n",
    "#                 ueg_lim_a = torch.pow(self.tanh(rho[...,self.use[1]]),2)\n",
    "#             else:\n",
    "#                 ueg_lim_a = 0\n",
    "#             #below comparison not in xcdiff\n",
    "#             if len(self.use) > 2:\n",
    "#                 ueg_lim_nl = torch.sum(rho[...,self.use[2:]],dim=-1)\n",
    "#             else:\n",
    "#                 ueg_lim_nl = 0\n",
    "#         else:\n",
    "#             ueg_lim = 1\n",
    "#             ueg_lim_a = 0\n",
    "#             ueg_lim_nl = 0\n",
    "\n",
    "#         if self.lob:\n",
    "#             result = self.lobf(squeezed*(ueg_lim + ueg_lim_a + ueg_lim_nl))\n",
    "#         else:\n",
    "#             result = squeezed*(ueg_lim + ueg_lim_a + ueg_lim_nl)\n",
    "\n",
    "#         return result\n",
    "\n",
    "# class C_L(torch.nn.Module):\n",
    "#     def __init__(self, n_input=2,n_hidden=16, device='cpu', ueg_limit=False, lob=2.0, use = []):\n",
    "#         \"\"\"Local correlation model based on MLP\n",
    "#         Receives density descriptors in this order : [rho, spinscale, s, alpha, nl]\n",
    "#         input may be truncated depending on level of approximation\n",
    "\n",
    "#         Args:\n",
    "#             n_input (int, optional): Input dimensions (LDA: 2, GGA: 3 , meta-GGA: 4). Defaults to 2.\n",
    "#             n_hidden (int, optional): Number of hidden nodes (three hidden layers used by default). Defaults to 16.\n",
    "#             device (str, optional): {'cpu','cuda'}. Defaults to 'cpu'.\n",
    "#             ueg_limit (bool, optional): Enforce uniform homoegeneous electron gas limit. Defaults to False.\n",
    "#             lob (float, optional): Technically Lieb-Oxford bound but used here to enforce non-negativity. Should be kept at 2.0 in most instances. Defaults to 2.0.\n",
    "#             use (list of ints, optional): Indices for [s, alpha] (in that order) in input, to determine UEG limit. Defaults to [].\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.spin_scaling = False\n",
    "#         self.lob = False\n",
    "#         self.ueg_limit = ueg_limit\n",
    "#         self.n_input=n_input\n",
    "\n",
    "#         if not use:\n",
    "#             self.use = torch.Tensor(np.arange(n_input)).long().to(device)\n",
    "#         else:\n",
    "#             self.use = torch.Tensor(use).long().to(device)\n",
    "#         self.net = torch.nn.Sequential(\n",
    "#                 torch.nn.Linear(n_input, n_hidden),\n",
    "#                 torch.nn.GELU(),\n",
    "#                 torch.nn.Linear(n_hidden, n_hidden),\n",
    "#                 torch.nn.GELU(),\n",
    "#                 torch.nn.Linear(n_hidden, n_hidden),\n",
    "#                 torch.nn.GELU(),\n",
    "#                 torch.nn.Linear(n_hidden, 1),\n",
    "#                 torch.nn.Softplus()\n",
    "#             ).double().to(device)\n",
    "#         self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "#         self.tanh = torch.nn.Tanh()\n",
    "#         #self.lob section allows for different values here, default=2. xcdiff doesn't have this,\n",
    "#         #assumes 2 always\n",
    "#         self.lob = lob\n",
    "#         if self.lob:\n",
    "#             self.lobf = LOB(self.lob)\n",
    "#         else:\n",
    "#             self.lob =  1000.0\n",
    "#             self.lobf = LOB(self.lob)\n",
    "\n",
    "\n",
    "#     def forward(self, rho, **kwargs):\n",
    "#         \"\"\"Forward pass in network\n",
    "\n",
    "#         Args:\n",
    "#             rho (torch.Tensor): density\n",
    "\n",
    "#         Returns:\n",
    "#             _type_: _description_\n",
    "#         \"\"\"\n",
    "#         inp = rho\n",
    "#         # print(rho.size, rho.shape, rho.dtype)\n",
    "#         # print('c call -- rho shape', rho.shape)\n",
    "#         # print('c call, rho[...,self.use] shape', rho.shape)\n",
    "#         # print('c call, rho[...,self.use]', rho)        \n",
    "#         squeezed = -self.net(inp).squeeze()\n",
    "#         # print('c call -- squeezed shape', squeezed.shape)\n",
    "#         # print('c call -- squeezed', squeezed)\n",
    "        \n",
    "#         if self.ueg_limit:\n",
    "#             #below not form used in xcdiff\n",
    "# #            ueg_lim = rho[...,self.use[0]]\n",
    "#             #below form used in xcdiff,\n",
    "#             ueg_lim = self.tanh(rho[...,self.use[0]])\n",
    "#             if len(self.use) > 1:\n",
    "#                 ueg_lim_a = torch.pow(self.tanh(rho[...,self.use[1]]),2)\n",
    "#             else:\n",
    "#                 ueg_lim_a = 0\n",
    "#             #xcdiff does not include this next comparison\n",
    "#             if len(self.use) > 2:\n",
    "#                 ueg_lim_nl = torch.sum(self.tanh(rho[...,self.use[2:]])**2,dim=-1)\n",
    "#             else:\n",
    "#                 ueg_lim_nl = 0\n",
    "\n",
    "#             ueg_factor = ueg_lim + ueg_lim_a + ueg_lim_nl\n",
    "#         else:\n",
    "#             ueg_factor = 1\n",
    "#         #xcdiff below returns the negative of the negative inputs\n",
    "#         #lob is sigmoid, so odd function, negatives cancel, so not needed\n",
    "#         if self.lob:\n",
    "#             return self.lobf(squeezed*ueg_factor)\n",
    "#         else:\n",
    "#             return squeezed*ueg_factor\n",
    "# class LDA_X(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         \"\"\" UEG exchange\"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, rho, **kwargs):\n",
    "#         return -3/4*(3/np.pi)**(1/3)*rho**(1/3)\n",
    "# params_a_pp     = [1,  1,  1]\n",
    "# params_a_alpha1 = [0.21370,  0.20548,  0.11125]\n",
    "# params_a_a      = [0.031091, 0.015545, 0.016887]\n",
    "# params_a_beta1  = [7.5957, 14.1189, 10.357]\n",
    "# params_a_beta2  = [3.5876, 6.1977, 3.6231]\n",
    "# params_a_beta3  = [1.6382, 3.3662,  0.88026]\n",
    "# params_a_beta4  = [0.49294, 0.62517, 0.49671]\n",
    "# params_a_fz20   = 1.709921\n",
    "       \n",
    "# class PW_C(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         \"\"\" UEG correlation, Perdew & Wang\"\"\"\n",
    "#         super().__init__()\n",
    "#     def forward(self, rs, zeta):\n",
    "#         def g_aux(k, rs):\n",
    "#             return params_a_beta1[k]*torch.sqrt(rs) + params_a_beta2[k]*rs\\\n",
    "#           + params_a_beta3[k]*rs**1.5 + params_a_beta4[k]*rs**(params_a_pp[k] + 1)\n",
    "\n",
    "#         def g(k, rs):\n",
    "#             return -2*params_a_a[k]*(1 + params_a_alpha1[k]*rs)\\\n",
    "#           * torch.log(1 +  1/(2*params_a_a[k]*g_aux(k, rs)))\n",
    "\n",
    "#         def f_zeta(zeta):\n",
    "#             return ((1+zeta)**(4/3) + (1-zeta)**(4/3) - 2)/(2**(4/3)-2)\n",
    "\n",
    "#         def f_pw(rs, zeta):\n",
    "#             return g(0, rs) + zeta**4*f_zeta(zeta)*(g(1, rs) - g(0, rs) + g(2, rs)/params_a_fz20)\\\n",
    "#           - f_zeta(zeta)*g(2, rs)/params_a_fz20\n",
    "\n",
    "#         return f_pw(rs, zeta)\n",
    "\n",
    "# class XC(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, grid_models=None, heg_mult=True, pw_mult=True,\n",
    "#                     level = 1, exx_a=None, epsilon=1e-8):\n",
    "#         \"\"\"Defines the XC functional on a grid\n",
    "\n",
    "#         Args:\n",
    "#             grid_models (list, optional): list of X_L (local exchange) or C_L (local correlation). Defines the xc-models/enhancement factors. Defaults to None.\n",
    "#             heg_mult (bool, optional): Use homoegeneous electron gas exchange (multiplicative if grid_models is not empty). Defaults to True.\n",
    "#             pw_mult (bool, optional): Use homoegeneous electron gas correlation (Perdew & Wang). Defaults to True.\n",
    "#             level (int, optional): Controls the number of density \"descriptors\" generated. 1: LDA, 2: GGA, 3:meta-GGA, 4: meta-GGA + electrostatic (nonlocal). Defaults to 1.\n",
    "#             exx_a (_type_, optional): Exact exchange mixing parameter. Defaults to None.\n",
    "#             epsilon (float, optional): Offset to avoid div/0 in calculations. Defaults to 1e-8.\n",
    "#         \"\"\"\n",
    "\n",
    "#         super().__init__()\n",
    "#         self.heg_mult = heg_mult\n",
    "#         self.pw_mult = pw_mult\n",
    "#         self.grid_coords = None\n",
    "#         self.training = True\n",
    "#         self.level = level\n",
    "#         self.epsilon = epsilon\n",
    "#         if level > 3:\n",
    "#             print('WARNING: Non-local models highly experimental and likely will not work ')\n",
    "#         self.loge = 1e-5\n",
    "#         self.s_gam = 1\n",
    "\n",
    "#         if heg_mult:\n",
    "#             self.heg_model = LDA_X()\n",
    "#         if pw_mult:\n",
    "#             self.pw_model = PW_C()\n",
    "#         self.grid_models = list(grid_models)\n",
    "#         if self.grid_models:\n",
    "#             self.grid_models = torch.nn.ModuleList(self.grid_models)\n",
    "#         self.model_mult = [1 for m in self.grid_models]\n",
    "\n",
    "#         if exx_a is not None:\n",
    "#             self.exx_a = torch.nn.Parameter(torch.Tensor([exx_a]))\n",
    "#             self.exx_a.requires_grad = True\n",
    "#         else:\n",
    "#             self.exx_a = 0\n",
    "\n",
    "#     def evaluate(self):\n",
    "#         \"\"\"Switches self.training flag to False\n",
    "#         \"\"\"\n",
    "#         self.training=False\n",
    "#     def train(self):\n",
    "#         \"\"\"Switches self.training flag to True\n",
    "#         \"\"\"\n",
    "#         self.training=True\n",
    "\n",
    "#     def add_model_mult(self, model_mult):\n",
    "#         \"\"\"_summary_\n",
    "\n",
    "#         .. todo:: \n",
    "#             Unclear what the purpose of this is\n",
    "\n",
    "#         Args:\n",
    "#             model_mult (_type_): _description_\n",
    "#         \"\"\"\n",
    "#         del(self.model_mult)\n",
    "#         self.register_buffer('model_mult',torch.Tensor(model_mult))\n",
    "\n",
    "#     def add_exx_a(self, exx_a):\n",
    "#         \"\"\"Adds exact-exchange mixing parameter after initialization\n",
    "\n",
    "#         Args:\n",
    "#             exx_a (float): Exchange mixing parameter\n",
    "#         \"\"\"\n",
    "#         self.exx_a = torch.nn.Parameter(torch.Tensor([exx_a]))\n",
    "#         self.exx_a.requires_grad = True\n",
    "\n",
    "#     # Density (rho)\n",
    "#     def l_1(self, rho):\n",
    "#         \"\"\"Level 1 Descriptor -- Creates dimensionless quantity from rho.\n",
    "#         Eq. 3 in `base paper <https://link.aps.org/doi/10.1103/PhysRevB.104.L161109>`_\n",
    "\n",
    "#         .. math:: x_0 = \\\\rho^{1/3}\n",
    "\n",
    "#         Args:\n",
    "#             rho (torch.Tensor): density\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: dimensionless density\n",
    "#         \"\"\"\n",
    "#         return rho**(1/3)\n",
    "\n",
    "#     # Reduced density gradient s\n",
    "#     def l_2(self, rho, gamma):\n",
    "#         \"\"\"Level 2 Descriptor -- Reduced gradient density\n",
    "#         Eq. 5 in `base paper <https://link.aps.org/doi/10.1103/PhysRevB.104.L161109>`_\n",
    "\n",
    "#         .. math:: x_2=s=\\\\frac{1}{2(3\\\\pi^2)^{1/3}} \\\\frac{|\\\\nabla \\\\rho|}{\\\\rho^{4/3}}\n",
    "\n",
    "#         Args:\n",
    "#             rho (torch.Tensor): density\n",
    "#             gamma (torch.Tensor): squared density gradient\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: reduced density gradient s\n",
    "#         \"\"\"\n",
    "#         return torch.sqrt(gamma)/(2*(3*np.pi**2)**(1/3)*rho**(4/3)+self.epsilon)\n",
    "\n",
    "#     # Reduced kinetic energy density alpha\n",
    "#     def l_3(self, rho, gamma, tau):\n",
    "#         \"\"\"Level 3 Descriptor -- Reduced kinetic energy density\n",
    "#         Eq. 6 in `base paper <https://link.aps.org/doi/10.1103/PhysRevB.104.L161109>`_\n",
    "\n",
    "#         .. math:: x_3 = \\\\alpha = \\\\frac{\\\\tau-\\\\tau^W}{\\\\tau^{unif}},\n",
    "\n",
    "#         where\n",
    "\n",
    "#         .. math:: \\\\tau^W = \\\\frac{|\\\\nabla \\\\rho|^2}{8\\\\rho}, \\\\tau^{unif} = \\\\frac{3}{10} (3\\\\pi^2)^{2/3}\\\\rho^{5/3}.\n",
    "\n",
    "#         Args:\n",
    "#             rho (torch.Tensor): density\n",
    "#             gamma (torch.Tensor): squared density gradient\n",
    "#             tau (torch.Tensor): kinetic energy density\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: reduced kinetic energy density\n",
    "#         \"\"\"\n",
    "#         uniform_factor = (3/10)*(3*np.pi**2)**(2/3)\n",
    "#         tw = gamma/(8*(rho+self.epsilon))\n",
    "#         #commented is dpyscflite version, uncommented is xcdiff version\n",
    "#         #return torch.nn.functional.relu((tau - tw)/(uniform_factor*rho**(5/3)+tw*1e-3 + 1e-12))\n",
    "#         return (tau - gamma/(8*(rho+self.epsilon)))/(uniform_factor*rho**(5/3)+self.epsilon)\n",
    "\n",
    "#     # Unit-less electrostatic potential\n",
    "#     def l_4(self, rho, nl):\n",
    "#         \"\"\"Level 4 Descriptor -- Unitless electrostatic potential\n",
    "\n",
    "#         .. todo:: Figure out what exactly this part is\n",
    "\n",
    "#         Args:\n",
    "#             rho (torch.Tensor): density\n",
    "#             nl (torch.Tensor): some non-local descriptor\n",
    "\n",
    "#         Returns:\n",
    "#             torch.nn.functional.relu: _description_\n",
    "#         \"\"\"\n",
    "#         u = nl[:,:1]/((rho.unsqueeze(-1)**(1/3))*self.nl_ueg[:,:1] + self.epsilon)\n",
    "#         wu = nl[:,1:]/((rho.unsqueeze(-1))*self.nl_ueg[:,1:] + self.epsilon)\n",
    "#         return torch.nn.functional.relu(torch.cat([u,wu],dim=-1))\n",
    "\n",
    "#     def get_descriptors(self, rho0_a, rho0_b, gamma_a, gamma_b, gamma_ab,nl_a,nl_b, tau_a, tau_b, spin_scaling = False):\n",
    "#         \"\"\"Creates 'ML-compatible' descriptors from the electron density and its gradients, a & b correspond to spin channels\n",
    "\n",
    "#         Args:\n",
    "#             rho0_a (torch.Tensor): :math:`\\\\rho` in spin-channel a\n",
    "#             rho0_b (torch.Tensor): :math:`\\\\rho` in spin-channel b\n",
    "#             gamma_a (torch.Tensor): :math:`|\\\\nabla \\\\rho|^2` in spin-channel a \n",
    "#             gamma_b (torch.Tensor): :math:`|\\\\nabla \\\\rho|^2` in spin-channel b\n",
    "#             gamma_ab (torch.Tensor): _description_\n",
    "#             nl_a (torch.Tensor): _description_\n",
    "#             nl_b (torch.Tensor): _description_\n",
    "#             tau_a (torch.Tensor): KE density in spin-channel a\n",
    "#             tau_b (torch.Tensor): KE density in spin-channel b\n",
    "#             spin_scaling (bool, optional): Flag for spin-scaling. Defaults to False.\n",
    "\n",
    "#         Returns:\n",
    "#             _type_: _description_\n",
    "#         \"\"\"\n",
    "\n",
    "#         if not spin_scaling:\n",
    "#             #If no spin-scaling, calculate polarization and use for X1\n",
    "#             zeta = (rho0_a - rho0_b)/(rho0_a + rho0_b + self.epsilon)\n",
    "#             spinscale = 0.5*((1+zeta)**(4/3) + (1-zeta)**(4/3)) # zeta\n",
    "\n",
    "#         if self.level > 0:  #  LDA\n",
    "#             if spin_scaling:\n",
    "#                 descr1 = torch.log(self.l_1(2*rho0_a) + self.loge)\n",
    "#                 descr2 = torch.log(self.l_1(2*rho0_b) + self.loge)\n",
    "#             else:\n",
    "#                 descr1 = torch.log(self.l_1(rho0_a + rho0_b) + self.loge)# rho\n",
    "#                 descr2 = torch.log(spinscale) # zeta\n",
    "#             descr = torch.cat([descr1.unsqueeze(-1), descr2.unsqueeze(-1)],dim=-1)\n",
    "#         if self.level > 1: # GGA\n",
    "#             if spin_scaling:\n",
    "#                 descr3a = self.l_2(2*rho0_a, 4*gamma_a) # s\n",
    "#                 descr3b = self.l_2(2*rho0_b, 4*gamma_b) # s\n",
    "#                 descr3 = torch.cat([descr3a.unsqueeze(-1), descr3b.unsqueeze(-1)],dim=-1)\n",
    "#                 descr3 = (1-torch.exp(-descr3**2/self.s_gam))*torch.log(descr3 + 1)\n",
    "#             else:\n",
    "#                 descr3 = self.l_2(rho0_a + rho0_b, gamma_a + gamma_b + 2*gamma_ab) # s\n",
    "#                 #line below in xcdiff, not dpyscfl\n",
    "#                 descr3 = descr3/((1+zeta)**(2/3) + (1-zeta)**2/3)\n",
    "#                 descr3 = descr3.unsqueeze(-1)\n",
    "#                 descr3 = (1-torch.exp(-descr3**2/self.s_gam))*torch.log(descr3 + 1)\n",
    "#             descr = torch.cat([descr, descr3],dim=-1)\n",
    "#         if self.level > 2: # meta-GGA\n",
    "#             if spin_scaling:\n",
    "#                 descr4a = self.l_3(2*rho0_a, 4*gamma_a, 2*tau_a)\n",
    "#                 descr4b = self.l_3(2*rho0_b, 4*gamma_b, 2*tau_b)\n",
    "#                 descr4 = torch.cat([descr4a.unsqueeze(-1), descr4b.unsqueeze(-1)],dim=-1)\n",
    "#                 #below in xcdiff, not dpyscfl\n",
    "#                 descr4 = descr4**3/(descr4**2+self.epsilon)\n",
    "#             else:\n",
    "#                 descr4 = self.l_3(rho0_a + rho0_b, gamma_a + gamma_b + 2*gamma_ab, tau_a + tau_b)\n",
    "#                 #next 2 in xcdiff, not dpyscfl\n",
    "#                 descr4 = 2*descr4/((1+zeta)**(5/3) + (1-zeta)**(5/3))\n",
    "#                 descr4 = descr4**3/(descr4**2+self.epsilon)\n",
    "\n",
    "#                 descr4 = descr4.unsqueeze(-1)\n",
    "#             descr4 = torch.log((descr4 + 1)/2)\n",
    "#             descr = torch.cat([descr, descr4],dim=-1)\n",
    "#         if self.level > 3: # meta-GGA + V_estat\n",
    "#             if spin_scaling:\n",
    "#                 descr5a = self.l_4(2*rho0_a, 2*nl_a)\n",
    "#                 descr5b = self.l_4(2*rho0_b, 2*nl_b)\n",
    "#                 descr5 = torch.log(torch.stack([descr5a, descr5b],dim=-1) + self.loge)\n",
    "#                 descr5 = descr5.view(descr5.size()[0],-1)\n",
    "#             else:\n",
    "#                 descr5= torch.log(self.l_4(rho0_a + rho0_b, nl_a + nl_b) + self.loge)\n",
    "\n",
    "#             descr = torch.cat([descr, descr5],dim=-1)\n",
    "#         if spin_scaling:\n",
    "#             print('spin_scaling')\n",
    "#             print('descr size -- ', descr.size())\n",
    "#             descr = descr.view(descr.size()[0],-1,2).permute(2,0,1)\n",
    "#             print('reshaped descr size --', descr.size())\n",
    "#         return descr\n",
    "\n",
    "\n",
    "#     def forward(self, dm):\n",
    "#         \"\"\"_summary_\n",
    "\n",
    "#         Args:\n",
    "#             dm (torch.Tensor): density matrix\n",
    "\n",
    "#         Returns:\n",
    "#             _type_: _description_\n",
    "#         \"\"\"\n",
    "#         Exc = 0\n",
    "#         if self.grid_models or self.heg_mult:\n",
    "#             if self.ao_eval.dim()==2:\n",
    "#                 ao_eval = self.ao_eval.unsqueeze(0)\n",
    "#             else:\n",
    "#                 ao_eval = self.ao_eval\n",
    "\n",
    "#             # Create density (and gradients) from atomic orbitals evaluated on grid\n",
    "#             # and density matrix\n",
    "#             # rho[ijsp]: del_i phi del_j phi dm (s: spin, p: grid point index)\n",
    "#             #print(\"FORWARD PASS IN XC. AO_EVAL SHAPE, DM SHAPE: \", ao_eval.shape, dm.shape)\n",
    "#             rho = contract('xij,yik,...jk->xy...i', ao_eval, ao_eval, dm)+1e-10\n",
    "#             rho0 = rho[0,0]\n",
    "#             drho = rho[0,1:4] + rho[1:4,0]\n",
    "#             tau = 0.5*(rho[1,1] + rho[2,2] + rho[3,3])\n",
    "\n",
    "#             # Non-local electrostatic potential\n",
    "#             if self.level > 3:\n",
    "#                 non_loc = contract('mnQ, QP, Pki, ...mn-> ...ki', self.df_3c, self.df_2c_inv, self.vh_on_grid, dm)\n",
    "#             else:\n",
    "#                 non_loc = torch.zeros_like(tau).unsqueeze(-1)\n",
    "\n",
    "#             if dm.dim() == 3: # If unrestricted (open-shell) calculation\n",
    "\n",
    "#                 # Density\n",
    "#                 rho0_a = rho0[0]\n",
    "#                 rho0_b = rho0[1]\n",
    "\n",
    "#                 # Contracted density gradient\n",
    "#                 gamma_a, gamma_b = contract('ij,ij->j',drho[:,0],drho[:,0]), contract('ij,ij->j',drho[:,1],drho[:,1])\n",
    "#                 gamma_ab = contract('ij,ij->j',drho[:,0],drho[:,1])\n",
    "\n",
    "#                 # Kinetic energy density\n",
    "#                 tau_a, tau_b = tau\n",
    "\n",
    "#                 # E.-static\n",
    "#                 non_loc_a, non_loc_b = non_loc\n",
    "#             else:\n",
    "#                 rho0_a = rho0_b = rho0*0.5\n",
    "#                 gamma_a=gamma_b=gamma_ab= contract('ij,ij->j',drho[:],drho[:])*0.25\n",
    "#                 tau_a = tau_b = tau*0.5\n",
    "#                 non_loc_a=non_loc_b = non_loc*0.5\n",
    "\n",
    "#             # xc-energy per unit particle\n",
    "#             exc = self.eval_grid_models(torch.cat([rho0_a.unsqueeze(-1),\n",
    "#                                                     rho0_b.unsqueeze(-1),\n",
    "#                                                     gamma_a.unsqueeze(-1),\n",
    "#                                                     gamma_ab.unsqueeze(-1),\n",
    "#                                                     gamma_b.unsqueeze(-1),\n",
    "#                                                     torch.zeros_like(rho0_a).unsqueeze(-1), #Dummy for laplacian\n",
    "#                                                     torch.zeros_like(rho0_a).unsqueeze(-1), #Dummy for laplacian\n",
    "#                                                     tau_a.unsqueeze(-1),\n",
    "#                                                     tau_b.unsqueeze(-1),\n",
    "#                                                     non_loc_a,\n",
    "#                                                     non_loc_b],dim=-1))\n",
    "#             print('xc call, exc.shape', exc.shape)\n",
    "#             #inplace modification throws MulBackwards0 error sometimes?\n",
    "#             Exc += torch.sum(((rho0_a + rho0_b)*exc.clone()[:,0])*self.grid_weights)\n",
    "#             #Exc = torch.sum(((rho0_a + rho0_b)*exc[:,0])*self.grid_weights)\n",
    "#             # try:\n",
    "#             #     Exc = torch.sum(((rho0_a + rho0_b)*exc[:,0])*self.grid_weights)\n",
    "#             # except:\n",
    "#             #     e = sys.exc_info()[0]\n",
    "#             #     Exc = torch.sum(((rho0_a + rho0_b)*exc[:,0])*self.grid_weights)\n",
    "#             #     print(\"Error detected\")\n",
    "#             #     print(e)                \n",
    "\n",
    "#         #Below in xcdiff, not in dpyscfl\n",
    "#         #However, keep commented out -- self.nxc_models not implemented\n",
    "#         #if self.nxc_models:\n",
    "#         #    for nxc_model in self.nxc_models:\n",
    "#         #        Exc += nxc_model(dm, self.ml_ovlp)\n",
    "\n",
    "#         # print('XC.FORWARD: Exc = ', Exc)\n",
    "        \n",
    "#         return Exc\n",
    "\n",
    "#     def eval_grid_models(self, rho, debug=False):\n",
    "#         \"\"\"Evaluates all models stored in self.grid_models along with HEG exchange and correlation\n",
    "\n",
    "\n",
    "#         Args:\n",
    "#             rho ([list of torch.Tensors]): List with [rho0_a,rho0_b,gamma_a,gamma_ab,gamma_b, dummy for laplacian, dummy for laplacian, tau_a, tau_b, non_loc_a, non_loc_b]\n",
    "\n",
    "#         Returns:\n",
    "#             _type_: _description_\n",
    "#         \"\"\"\n",
    "#         Exc = 0\n",
    "#         rho0_a = rho[:, 0]\n",
    "#         rho0_b = rho[:, 1]\n",
    "#         gamma_a = rho[:, 2]\n",
    "#         gamma_ab = rho[:, 3]\n",
    "#         gamma_b = rho[:, 4]\n",
    "#         tau_a = rho[:, 7]\n",
    "#         tau_b = rho[:, 8]\n",
    "#         nl = rho[:,9:]\n",
    "#         nl_size = nl.size()[-1]//2\n",
    "#         nl_a = nl[:,:nl_size]\n",
    "#         nl_b = nl[:,nl_size:]\n",
    "\n",
    "#         C_F= 3/10*(3*np.pi**2)**(2/3)\n",
    "#         #in xcdiff, self.meta_local would change below assignments\n",
    "#         #not used here\n",
    "#         rho0_a_ueg = rho0_a\n",
    "#         rho0_b_ueg = rho0_b\n",
    "\n",
    "#         zeta = (rho0_a_ueg - rho0_b_ueg)/(rho0_a_ueg + rho0_b_ueg + 1e-8)\n",
    "#         rs = (4*np.pi/3*(rho0_a_ueg+rho0_b_ueg + 1e-8))**(-1/3)\n",
    "#         rs_a = (4*np.pi/3*(rho0_a_ueg + 1e-8))**(-1/3)\n",
    "#         rs_b = (4*np.pi/3*(rho0_b_ueg + 1e-8))**(-1/3)\n",
    "\n",
    "\n",
    "#         exc_a = torch.zeros_like(rho0_a)\n",
    "#         exc_b = torch.zeros_like(rho0_a)\n",
    "#         exc_ab = torch.zeros_like(rho0_a)\n",
    "\n",
    "#         if debug:\n",
    "#             print('eval_grid_models nan summary:')\n",
    "#             print('zeta, rs, rs_a, rs_b, exc_a, exc_b, exc_ab')\n",
    "#             print('{}, {}, {}, {}, {}, {}, {}'.format(\n",
    "#                 torch.isnan(zeta).any().sum(),\n",
    "#                 torch.isnan(rs).any().sum(),\n",
    "#                 torch.isnan(rs_a).any().sum(),\n",
    "#                 torch.isnan(rs_b).any().sum(),\n",
    "#                 torch.isnan(exc_a).any().sum(),\n",
    "#                 torch.isnan(exc_b).any().sum(),\n",
    "#                 torch.isnan(exc_ab).any().sum(),                \n",
    "#             ))\n",
    "\n",
    "#         descr_method = self.get_descriptors\n",
    "\n",
    "\n",
    "#         descr_dict = {}\n",
    "#         rho_tot = rho0_a + rho0_b\n",
    "#         if self.grid_models:\n",
    "\n",
    "#             for grid_model in self.grid_models:\n",
    "#                 if not grid_model.spin_scaling:\n",
    "#                     if not 'c' in descr_dict:\n",
    "#                         descr_dict['c'] = descr_method(rho0_a, rho0_b, gamma_a, gamma_b,\n",
    "#                                                                          gamma_ab, nl_a, nl_b, tau_a, tau_b, spin_scaling = False)\n",
    "#                         descr_dict['c'] = descr_method(rho0_a, rho0_b, gamma_a, gamma_b,\n",
    "#                                                                          gamma_ab, nl_a, nl_b, tau_a, tau_b, spin_scaling = False)\n",
    "#                     descr = descr_dict['c']\n",
    "#                     #print(\"DESCR: \", descr)\n",
    "#                     #print(\"DESCR MAX:\", torch.max(descr))\n",
    "#                     #print(\"DESCR MIN: \", torch.min(descr))\n",
    "#                     #print(\"GRID MODEL: \", grid_model)\n",
    "#                     for name, param in grid_model.named_parameters():\n",
    "#                         if torch.isnan(param).any():\n",
    "#                             print(\"NANS IN NETWORK WEIGHT -- {}\".format(name))\n",
    "#                             raise ValueError(\"NaNs in Network Weights.\")\n",
    "\n",
    "#                     #Evaluate network with descriptors on grid\n",
    "#                     #in xcdiff, edge_index is passed here, not in dpyscfl\n",
    "#                     exc = grid_model(descr,\n",
    "#                                       grid_coords = self.grid_coords)\n",
    "#                     #print(\"EXC GRID_MODEL C: \", exc)\n",
    "\n",
    "#                     #Included from xcdiff, 2dim exc -> spin polarized\n",
    "#                     if exc.dim() == 2: #If using spin decomposition\n",
    "#                         pw_alpha = self.pw_model(rs_a, torch.ones_like(rs_a))\n",
    "#                         pw_beta = self.pw_model(rs_b, torch.ones_like(rs_b))\n",
    "#                         pw = self.pw_model(rs, zeta)\n",
    "#                         ec_alpha = (1 + exc[:,0])*pw_alpha*rho0_a/(rho_tot+1e-8)\n",
    "#                         ec_beta =  (1 + exc[:,1])*pw_beta*rho0_b/(rho_tot+1e-8)\n",
    "#                         ec_mixed = (1 + exc[:,2])*(pw*rho_tot - pw_alpha*rho0_a - pw_beta*rho0_b)/(rho_tot+1e-8)\n",
    "#                         exc_ab = ec_alpha + ec_beta + ec_mixed\n",
    "#                     else:\n",
    "#                         if self.pw_mult:\n",
    "#                             exc_ab += (1 + exc)*self.pw_model(rs, zeta)\n",
    "#                         else:\n",
    "#                             exc_ab += exc\n",
    "# #                    if self.pw_mult:\n",
    "# #                        exc_ab += (1 + exc)*self.pw_model(rs, zeta)\n",
    "# #                    else:\n",
    "# #                        exc_ab += exc\n",
    "#                 else:\n",
    "#                     if not 'x' in descr_dict:\n",
    "#                         descr_dict['x'] = descr_method(rho0_a, rho0_b, gamma_a, gamma_b,\n",
    "#                                                                          gamma_ab, nl_a, nl_b, tau_a, tau_b, spin_scaling = True)\n",
    "#                     descr = descr_dict['x']\n",
    "\n",
    "#                     #in xcdiff, edge_index is passed here, not in dpyscfl\n",
    "#                     exc = grid_model(descr,\n",
    "#                                   grid_coords = self.grid_coords)\n",
    "\n",
    "#                     #print(\"EXC GRID_MODEL X: \", exc)\n",
    "\n",
    "#                     if self.heg_mult:\n",
    "#                         exc_a += (1 + exc[0])*self.heg_model(2*rho0_a_ueg)*(1-self.exx_a)\n",
    "#                     else:\n",
    "#                         exc_a += exc[0]*(1-self.exx_a)\n",
    "\n",
    "#                     if torch.all(rho0_b == torch.zeros_like(rho0_b)): #Otherwise produces NaN's\n",
    "#                         exc_b += exc[0]*0\n",
    "#                     else:\n",
    "#                         if self.heg_mult:\n",
    "#                             exc_b += (1 + exc[1])*self.heg_model(2*rho0_b_ueg)*(1-self.exx_a)\n",
    "#                         else:\n",
    "#                             exc_b += exc[1]*(1-self.exx_a)\n",
    "\n",
    "#         else:\n",
    "#             if self.heg_mult:\n",
    "#                 exc_a = self.heg_model(2*rho0_a_ueg)\n",
    "#                 exc_b = self.heg_model(2*rho0_b_ueg)\n",
    "#             if self.pw_mult:\n",
    "#                 exc_ab = self.pw_model(rs, zeta)\n",
    "\n",
    "\n",
    "#         # exc = rho0_a_ueg/rho_tot*exc_a + rho0_b_ueg/rho_tot*exc_b + exc_ab\n",
    "#         exc = exc_a * (rho0_a_ueg/ (rho_tot + self.epsilon)) + exc_b*(rho0_b_ueg / (rho_tot + self.epsilon)) + exc_ab\n",
    "#         if debug:\n",
    "#             print('eval_grid_models nan summary:')\n",
    "#             print('zeta, rs, rs_a, rs_b, exc_a, exc_b, exc_ab')\n",
    "#             print('{}, {}, {}, {}, {}, {}, {}'.format(\n",
    "#                 torch.isnan(zeta).any().sum(),\n",
    "#                 torch.isnan(rs).any().sum(),\n",
    "#                 torch.isnan(rs_a).any().sum(),\n",
    "#                 torch.isnan(rs_b).any().sum(),\n",
    "#                 torch.isnan(exc_a).any().sum(),\n",
    "#                 torch.isnan(exc_b).any().sum(),\n",
    "#                 torch.isnan(exc_ab).any().sum(),                \n",
    "#             ))\n",
    "\n",
    "#         return exc.unsqueeze(-1)\n",
    "# class make_rdm1(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         \"\"\" Generate one-particle reduced density matrix\"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, mo_coeff, mo_occ):\n",
    "#         \"\"\"Forward pass calculating one-particle reduced density matrix.\n",
    "\n",
    "#         Args:\n",
    "#             mo_coeff (torch.Tensor/np.array(?)): Molecular orbital coefficients\n",
    "#             mo_occ (torch.Tensor/np.array(?)): Molecular orbital occupation numbers\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor/np.array(?): The RDM1\n",
    "#         \"\"\"\n",
    "#         if mo_coeff.ndim == 3:\n",
    "#             mocc_a = mo_coeff[0, :, mo_occ[0]>0]\n",
    "#             mocc_b = mo_coeff[1, :, mo_occ[1]>0]\n",
    "#             if torch.sum(mo_occ[1]) > 0:\n",
    "#                 return torch.stack([contract('ij,jk->ik', mocc_a*mo_occ[0,mo_occ[0]>0], mocc_a.T),\n",
    "#                                     contract('ij,jk->ik', mocc_b*mo_occ[1,mo_occ[1]>0], mocc_b.T)],dim=0)\n",
    "#             else:\n",
    "#                 return torch.stack([contract('ij,jk->ik', mocc_a*mo_occ[0,mo_occ[0]>0], mocc_a.T),\n",
    "#                                     torch.zeros_like(mo_coeff)[0]],dim=0)\n",
    "#         else:\n",
    "#             mocc = mo_coeff[:, mo_occ>0]\n",
    "#             return contract('ij,jk->ik', mocc*mo_occ[mo_occ>0], mocc.T)\n",
    "\n",
    "# class get_rho(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "\n",
    "#     def forward(self, dm, results):\n",
    "#         ao_eval = results['ao_eval'][0]\n",
    "#         print(\"AO_EVAL, DM SHAPES: {}. {}.\".format(ao_eval.shape, dm.shape))\n",
    "#         if dm.ndim == 2:\n",
    "#             print(\"2D DM.\")\n",
    "#             print(\"RESULTS N_ELEC: \", results['n_elec'])\n",
    "#             rho = contract('ij,ik,jk->i',\n",
    "#                                ao_eval, ao_eval, dm)\n",
    "#         else:\n",
    "#             print(\"NON-2D DM\")\n",
    "#             rho = contract('ij,ik,xjk->xi',\n",
    "#                                ao_eval, ao_eval, dm)\n",
    "#         return rho\n",
    "\n",
    "# class energy_tot(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         Total energy (electron-electron + electron-ion; ion-ion not included)\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, dm, hcore, veff):\n",
    "#         \"\"\"Tensor contraction to find total electron energy (e-e + e-ion)\n",
    "\n",
    "#         Args:\n",
    "#             dm (torch.Tensor): Density matrix\n",
    "#             hcore (torch.Tensor): Core Hamiltonian\n",
    "#             veff (torch.Tensor): Effective Potential\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: The electronic energy\n",
    "#         \"\"\"\n",
    "#         return torch.sum((contract('...ij,ij', dm, hcore) + .5*contract('...ij,...ij', dm, veff))).unsqueeze(0)\n",
    "\n",
    "# class get_veff(torch.nn.Module):\n",
    "#     def __init__(self, exx=False, model=None, req_grad=False):\n",
    "#         \"\"\"Builds the one-electron effective potential (not including local xc-potential)\n",
    "\n",
    "#         Args:\n",
    "#             exx (bool, optional): Exact exchange flag. Defaults to False.\n",
    "#             model (xc-model): Only used for exact exchange mixing parameter. Defaults to None.\n",
    "#             df (bool, optional): Use density fitting flag. Defaults to False.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.exx = exx\n",
    "#         self.model = model\n",
    "#         self.req_grad = req_grad\n",
    "        \n",
    "#     def forward(self, dm, eri):\n",
    "#         \"\"\"Forward pass if no density fitting\n",
    "\n",
    "#         Args:\n",
    "#             dm (torch.Tensor): Density matrix\n",
    "#             eri (torch.Tensor(?)): Electron repulsion integral tensor\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: The \"effective\" potential\n",
    "#         \"\"\"\n",
    "#         J = contract('...ij,ijkl->...kl',dm, eri)\n",
    "#         if self.exx:\n",
    "#             K = self.model.exx_a * contract('...ij,ikjl->...kl',dm, eri)\n",
    "#         else:\n",
    "#             K =  torch.zeros_like(J)\n",
    "\n",
    "#         if J.ndim == 3:\n",
    "#             return J[0] + J[1] - K\n",
    "#         else:\n",
    "#             return J-0.5*K\n",
    "#     def forward2(self, dm, eri):\n",
    "#         ''' reimplementation of hf.dot_eri_dm '''\n",
    "#         nao = dm.shape[-1]\n",
    "#         if eri.nelement() == nao**4:\n",
    "#             vj = contract('...ij,ijkl->...kl',dm, eri)\n",
    "#             if self.exx:\n",
    "#                 vk = self.model.exx_a * contract('...ij,ikjl->...kl',dm, eri)\n",
    "#             else:\n",
    "#                 vk =  torch.zeros_like(vj)\n",
    "    \n",
    "#         else:\n",
    "#             # raise ValueError('eri elements != nao**4')\n",
    "#             vj, vk = scf._vhf.incore(eri.detach().numpy(), dm.detach().numpy(), 0, with_j = True, with_k = self.exx)\n",
    "\n",
    "#         if not self.exx:\n",
    "#             vk = np.zeros_like(vj)\n",
    "#         if vj.ndim == 3:\n",
    "#             veff =  vj[0] + vj[1] - vk\n",
    "#         else:\n",
    "#             veff =  vj-0.5*vk\n",
    "\n",
    "#         return torch.tensor(veff, requires_grad=self.req_grad)\n",
    "#         # if vj.ndim == 3:\n",
    "#         #     return vj[0] + vj[1] - vk\n",
    "#         # else:\n",
    "#         #     return vj - 0.5*vk    \n",
    "        \n",
    "        \n",
    "\n",
    "# def get_veff_np(dm, eri):\n",
    "#         \"\"\"Forward pass if no density fitting\n",
    "\n",
    "#         Args:\n",
    "#             dm (torch.Tensor): Density matrix\n",
    "#             eri (torch.Tensor(?)): Electron repulsion integral tensor\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: The \"effective\" potential\n",
    "#         \"\"\"\n",
    "#         J = contract('...ij,ijkl->...kl',dm, eri)\n",
    "#         K =  torch.zeros_like(J)\n",
    "#         if J.ndim == 3:\n",
    "#             return J[0] + J[1] - K\n",
    "#         else:\n",
    "#             return J-0.5*K\n",
    "# def energy_tot_np(dm, hcore, veff):\n",
    "#         \"\"\"Tensor contraction to find total electron energy (e-e + e-ion)\n",
    "\n",
    "#         Args:\n",
    "#             dm (torch.Tensor): Density matrix\n",
    "#             hcore (torch.Tensor): Core Hamiltonian\n",
    "#             veff (torch.Tensor): Effective Potential\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor: The electronic energy\n",
    "#         \"\"\"\n",
    "#         return torch.sum((contract('...ij,ij', dm, hcore) + .5*contract('...ij,...ij', dm, veff))).unsqueeze(0)\n",
    "# def make_rdm1_np(mo_coeff, mo_occ):\n",
    "#         \"\"\"Forward pass calculating one-particle reduced density matrix.\n",
    "\n",
    "#         Args:\n",
    "#             mo_coeff (torch.Tensor/np.array(?)): Molecular orbital coefficients\n",
    "#             mo_occ (torch.Tensor/np.array(?)): Molecular orbital occupation numbers\n",
    "\n",
    "#         Returns:\n",
    "#             torch.Tensor/np.array(?): The RDM1\n",
    "#         \"\"\"\n",
    "#         if mo_coeff.ndim == 3:\n",
    "#             mocc_a = mo_coeff[0, :, mo_occ[0]>0]\n",
    "#             mocc_b = mo_coeff[1, :, mo_occ[1]>0]\n",
    "#             if torch.sum(mo_occ[1]) > 0:\n",
    "#                 return torch.stack([contract('ij,jk->ik', mocc_a*mo_occ[0,mo_occ[0]>0], mocc_a.T),\n",
    "#                                     contract('ij,jk->ik', mocc_b*mo_occ[1,mo_occ[1]>0], mocc_b.T)],dim=0)\n",
    "#             else:\n",
    "#                 return torch.stack([contract('ij,jk->ik', mocc_a*mo_occ[0,mo_occ[0]>0], mocc_a.T),\n",
    "#                                     torch.zeros_like(mo_coeff)[0]],dim=0)\n",
    "#         else:\n",
    "#             mocc = mo_coeff[:, mo_occ>0]\n",
    "#             return contract('ij,jk->ik', mocc*mo_occ[mo_occ>0], mocc.T)\n",
    "\n",
    "\n",
    "\n",
    "# def get_fock(hc, veff):\n",
    "#     \"\"\"Get the Fock matrix\n",
    "\n",
    "#     Args:\n",
    "#         hc (torch.Tensor): Core Hamiltonian\n",
    "#         veff (torch.Tensor): Effective Potential\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: hc+veff\n",
    "#     \"\"\"\n",
    "#     return hc + veff\n",
    "# def get_hcore(v, t):\n",
    "#     \"\"\" \"Core\" Hamiltionian, includes ion-electron and kinetic contributions\n",
    "\n",
    "#     .. math:: H_{core} = T + V_{nuc-elec}\n",
    "\n",
    "#     Args:\n",
    "#         v (torch.Tensor, np.array): Electron-ion interaction energy\n",
    "#         t (torch.Tensor, np.array): Kinetic energy\n",
    "\n",
    "#     Returns:\n",
    "#         torch.Tensor: v + t\n",
    "#     \"\"\"\n",
    "#     return v + t\n",
    "\n",
    "\n",
    "# class eig(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         \"\"\"Solves generalized eigenvalue problem using Cholesky decomposition\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, h, s_chol):\n",
    "#         \"\"\"Solver for generalized eigenvalue problem\n",
    "\n",
    "#         .. todo:: torch.symeig is deprecated for torch.linalg.eigh, replace\n",
    "\n",
    "#         Args:\n",
    "#             h (torch.Tensor): Hamiltionian\n",
    "#             s_chol (torch.Tensor): (Inverse) Cholesky decomp. of overlap matrix S\n",
    "#                                     s_chol = np.linalg.inv(np.linalg.cholesky(S))\n",
    "\n",
    "#         Returns:\n",
    "#             (torch.Tensor, torch.Tensor): Eigenvalues (MO energies), eigenvectors (MO coeffs)\n",
    "#         \"\"\"\n",
    "#         #e, c = torch.symeig(contract('ij,...jk,kl->...il',s_chol, h, s_chol.T), eigenvectors=True,upper=False)\n",
    "#         upper=False\n",
    "#         UPLO = \"U\" if upper else \"L\"\n",
    "#         e, c = torch.linalg.eigh(contract('ij,...jk,kl->...il',s_chol, h, s_chol.T), UPLO=UPLO)\n",
    "#         c = contract('ij,...jk ->...ik',s_chol.T, c.clone())\n",
    "#         return e, c\n",
    "# torch._C._debug_only_display_vmap_fallback_warnings(True)\n",
    "# class SCF(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self, alpha=0.8, nsteps=10, xc=None, device='cpu', exx=False):\n",
    "#         \"\"\"This class implements the self-consistent field (SCF) equations\n",
    "\n",
    "#         Args:\n",
    "#             alpha (float, optional): Linear mixing parameter. Defaults to 0.8.\n",
    "#             nsteps (int, optional): Number of scf steps. Defaults to 10.\n",
    "#             xc (dpyscfl.net.XC, optional): Class containing the exchange-correlation models. Defaults to None.\n",
    "#             device (str, optional): {'cpu','cuda'}, which device to use. Defaults to 'cpu'.\n",
    "#             exx (bool, optional): Use exact exchange flag. Defaults to False.\n",
    "#         \"\"\"\n",
    "#         super().__init__()\n",
    "#         self.nsteps = nsteps\n",
    "#         self.alpha = alpha\n",
    "#         self.get_veff = get_veff(exx, xc, req_grad=REQ_GRAD).to(device) # Include Fock (exact) exchange?\n",
    "\n",
    "#         self.eig = eig().to(device)\n",
    "#         self.energy_tot = energy_tot().to(device)\n",
    "#         self.make_rdm1 = make_rdm1().to(device)\n",
    "#         self.xc = xc\n",
    "#         #ncore parameter used in xcdiff, not here\n",
    "\n",
    "#     def forward(self, dm, matrices, sc=True, **kwargs):\n",
    "#         \"\"\"Forward pass SCF cycle\n",
    "\n",
    "#         Args:\n",
    "#             dm (torch.Tensor): Initial density matrix\n",
    "#             matrices (dict of torch.Tensors): Contains all other matrices that are considered fixed during SCF calculations (e-integrals etc.)\n",
    "#             sc (bool, optional): If True does self-consistent calculations, else single-pass. Defaults to True.\n",
    "\n",
    "#         Returns:\n",
    "#             dict of torch.Tensors: results: E, dm, and mo_energies\n",
    "#         \"\"\"\n",
    "#         dm = dm[0]\n",
    "\n",
    "#         # Required matrices\n",
    "#         # ===================\n",
    "#         # v: Electron-ion pot.\n",
    "#         # t: Kinetic\n",
    "#         # mo_occ: MO occupations\n",
    "#         # e_nuc: Ion-Ion energy contribution\n",
    "#         # s: overlap matrix\n",
    "#         # s_chol: inverse Cholesky decomposition of overlap matrix\n",
    "#         v, t, mo_occ, e_nuc, s, s_chol = [matrices[key][0] for key in \\\n",
    "#                                              ['v','t','mo_occ',\n",
    "#                                              'e_nuc','s','s_chol']]\n",
    "#         hc = get_hcore(v,t)\n",
    "\n",
    "#         # Optional matrices\n",
    "#         # ====================\n",
    "\n",
    "#         # Electron repulsion integrals\n",
    "#         eri = matrices.get('eri',[None])[0]\n",
    "\n",
    "#         grid_weights = matrices.get('grid_weights',[None])[0]\n",
    "#         grid_coords = matrices.get('grid_coords',[None])[0]\n",
    "#         #edge index called for here in xcdiff, not here\n",
    "\n",
    "#         # Atomic orbitals evaluated on grid\n",
    "#         ao_eval = matrices.get('ao_eval',[None])[0]\n",
    "\n",
    "#         # Used to restore correct potential after symmetrization:\n",
    "#         L = matrices.get('L', [torch.eye(dm.size()[-1])])[0]\n",
    "#         scaling = matrices.get('scaling',[torch.ones([dm.size()[-1]]*2)])[0]\n",
    "\n",
    "#         # Density fitting integrals\n",
    "#         df_2c_inv = matrices.get('df_2c_inv',[None])[0]\n",
    "#         df_3c = matrices.get('df_3c',[None])[0]\n",
    "\n",
    "#         # Electrostatic potential on grid\n",
    "#         vh_on_grid = matrices.get('vh_on_grid',[None])[0]\n",
    "\n",
    "#         dm_old = dm\n",
    "\n",
    "#         E = []\n",
    "#         deltadm = []\n",
    "#         nsteps = self.nsteps\n",
    "\n",
    "#         # if not self.xc.training:\n",
    "#         #     #if not training, backpropagation doesn't happen so don't need derivatives beyond\n",
    "#         #     #calculation at a given step\n",
    "#         #     create_graph = False\n",
    "#         # else:\n",
    "#         #     create_graph = True\n",
    "#         vvv = kwargs.get('verbose', False)\n",
    "#         if vvv:\n",
    "#             print('SCF Loop Beginning: {} Steps'.format(nsteps))\n",
    "\n",
    "#         # SCF iteration loop\n",
    "#         for step in range(nsteps):\n",
    "#             #some diis happens here in xcdiff, not implemented here\n",
    "#             if vvv:\n",
    "#                 print('Step {}'.format(step))\n",
    "#             alpha = (self.alpha)**(step)+0.3\n",
    "#             beta = (1-alpha)\n",
    "#             dm = alpha * dm + beta * dm_old\n",
    "\n",
    "#             dm_old = dm\n",
    "#             if vvv:\n",
    "#                 print(\"Density Matrix stats: \")\n",
    "#                 print(\"Mean: \", torch.mean(dm))\n",
    "#                 print(\"Min/Max: \", torch.min(dm), torch.max(dm))\n",
    "#                 print(\"Select Indices: dm.flatten()[[0, 5, 10, 100]]\", dm.flatten()[[0,5,10,100]])\n",
    "\n",
    "#             if df_3c is not None:\n",
    "#                 veff = self.get_veff.forward_df(dm, df_3c, df_2c_inv, eri)\n",
    "#             elif kwargs.get('erisym_veff', False):\n",
    "#                 veff = self.get_veff.forward2(dm, eri)\n",
    "#             else:\n",
    "#                 veff = self.get_veff(dm, eri)\n",
    "\n",
    "#             if kwargs.get('debug', False):\n",
    "#                 print('STEP-{}/VEFF: '.format(step), veff)\n",
    "            \n",
    "#             if self.xc: #If using xc-functional (not Hartree-Fock)\n",
    "#                 self.xc.ao_eval = ao_eval\n",
    "#                 self.xc.grid_weights = grid_weights\n",
    "#                 self.xc.grid_coords = grid_coords\n",
    "#                 #edge index, ml_ovlp called for here in xcdiff\n",
    "#                 if vh_on_grid is not None:\n",
    "#                     self.xc.vh_on_grid = vh_on_grid\n",
    "#                     self.xc.df_2c_inv = df_2c_inv\n",
    "#                     self.xc.df_3c = df_3c\n",
    "\n",
    "#                 if torch.sum(mo_occ) == 1:   # Otherwise H produces NaNs\n",
    "#                     dm[1] = dm.clone()[0]*1e-12\n",
    "#                     dm_old[1] = dm.clone()[0]*1e-12\n",
    "\n",
    "#                 exc = self.xc(dm)\n",
    "\n",
    "#                 if kwargs.get('debug', False):\n",
    "#                     print('STEP-{}/exc: '.format(step), exc)\n",
    "\n",
    "                \n",
    "#                 # vxc = torch.autograd.functional.jacobian(self.xc, dm, create_graph=True)\n",
    "#                 vxc = torch.autograd.functional.jacobian(self.xc, dm, create_graph=False,\n",
    "#                                                          vectorize=False)\n",
    "#                 vxc1 = torch.autograd.grad(exc, dm)[0]\n",
    "#                 print('vxc/vxc1 shapes,', vxc.shape, vxc1.shape)\n",
    "#                 if kwargs.get('debug', False):\n",
    "#                     msize = vxc.element_size() * vxc.nelement()\n",
    "#                     msize1 = vxc1.element_size() * vxc1.nelement()\n",
    "#                     print('vxc: SHAPE = {}. SIZE = {} KB / {} MB / {} GB'.format(k, vxc.shape, msize/(1000), msize/(1000**2), msize/(1000**3)))\n",
    "#                     print('vxc1: SHAPE = {}. SIZE = {} KB / {} MB / {} GB'.format(k, vxc1.shape, msize1/(1000), msize1/(1000**2), msize1/(1000**3)))\n",
    "#                     print('|vxc - vxc1|.max(): ', abs(vxc-vxc1).max())\n",
    "#                 # Restore correct symmetry for vxc\n",
    "#                 if vxc.dim() > 2:\n",
    "#                     vxc = contract('ij,xjk,kl->xil',L,vxc.clone(),L.T)\n",
    "#                     vxc = torch.where(scaling.unsqueeze(0) > 0 , vxc.clone(), scaling.unsqueeze(0))\n",
    "#                 else:\n",
    "#                     vxc = torch.mm(L,torch.mm(vxc.clone(),L.T))\n",
    "#                     vxc = torch.where(scaling > 0 , vxc.clone(), scaling)\n",
    "\n",
    "#                 if torch.sum(mo_occ) == 1:   # Otherwise H produces NaNs\n",
    "#                     vxc[1] = torch.zeros_like(vxc.clone()[1])\n",
    "\n",
    "#                 veff += vxc\n",
    "\n",
    "#                 if kwargs.get('debug', False):\n",
    "#                     print('STEP-{}/VEFF+VXC: '.format(step), veff)\n",
    "\n",
    "\n",
    "#                 #Add random noise to potential to avoid degeneracies in EVs\n",
    "#                 if self.xc.training:#: and sc:\n",
    "#                     if step == 0:\n",
    "#                         print(\"Noise generation to avoid potential degeneracies\")\n",
    "#                     noise = torch.abs(torch.randn(vxc.size(),device=vxc.device)*1e-4)\n",
    "#                     noise = noise + torch.transpose(noise,-1,-2)\n",
    "#                     veff = veff.clone() + noise\n",
    "#                 if kwargs.get('debug', False):\n",
    "#                     print('STEP-{}/VEFF+VXC+NOISE: '.format(step), veff)\n",
    "\n",
    "#             else:\n",
    "#                 exc=0\n",
    "#                 vxc=torch.zeros_like(veff)\n",
    "#             f = get_fock(hc, veff)\n",
    "#             if kwargs.get('debug', False):\n",
    "#                 print('STEP-{}/FOCK: '.format(step), f)\n",
    "\n",
    "#             mo_e, mo_coeff = self.eig(f, s_chol)\n",
    "#             dm = self.make_rdm1(mo_coeff, mo_occ)\n",
    "\n",
    "#             # e_tot = self.energy_tot(dm_old, hc, veff-vxc)+ e_nuc + exc\n",
    "#             e_tot = self.energy_tot(dm, hc, veff-vxc)+ e_nuc + exc\n",
    "#             E.append(e_tot)\n",
    "#             if vvv:\n",
    "#                 print(\"{} Energy: {}\".format(step, e_tot))\n",
    "#                 print(\"History: {}\".format(E))\n",
    "#             if not sc:\n",
    "#                 break\n",
    "\n",
    "#         #in xcdiff, things happen here with mo_occ[:self.ncore], e_ip etc. not implemented here\n",
    "        \n",
    "#         results = {'E': torch.cat(E), 'dm':dm, 'mo_energy':mo_e}\n",
    "\n",
    "#         return results\n",
    "\n",
    "# def get_optimizer(model, path='', hybrid=None, lr=1e-3, l2=1e-6):\n",
    "#     if hybrid:\n",
    "#             optimizer = torch.optim.Adam(list(model.parameters()) + [model.xc.exx_a],\n",
    "#                                     lr=lr, weight_decay=l2)\n",
    "#     else:\n",
    "#         optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                                     lr=lr, weight_decay=l2)\n",
    "\n",
    "#     MIN_RATE = 1e-7\n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min',\n",
    "#                                                             verbose=True, patience=int(10/PRINT_EVERY),\n",
    "#                                                             factor=0.1, min_lr=MIN_RATE)\n",
    "\n",
    "#     if path:\n",
    "#         optimizer.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "#     return optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "499207f4-29fc-41b0-8983-4822d7fc13cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_torch_xc(xctype, pretrain_loc='', hyb_par=0, path='', DEVICE='cpu', ueg_limit=True, meta_x=None, freec=False,\n",
    "            inserts = 0, nhidden = 16):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        xctype (_type_): _description_\n",
    "        pretrain_loc (_type_): _description_\n",
    "        hyb_par (int, optional): _description_. Defaults to 0.\n",
    "        path (str, optional): _description_. Defaults to ''.\n",
    "        DEVICE (str, optional): _description_. Defaults to 'cpu'.\n",
    "        ueg_limit (bool, optional): _description_. Defaults to True.\n",
    "        meta_x (_type_, optional): _description_. Defaults to None.\n",
    "        freec (bool, optional): _description_. Defaults to False.\n",
    "    \"\"\"\n",
    "    print('FREEC', freec)\n",
    "    if xctype == 'GGA':\n",
    "        lob = 1.804 if ueg_limit else 0\n",
    "        x = X_L(device=DEVICE,n_input=1, n_hidden=nhidden, use=[1], lob=lob, ueg_limit=ueg_limit) # PBE_X\n",
    "        c = C_L(device=DEVICE,n_input=3, n_hidden=nhidden, use=[2], ueg_limit=ueg_limit and not freec)\n",
    "        xc_level = 2\n",
    "    elif xctype == 'MGGA':\n",
    "        lob = 1.174 if ueg_limit else 0\n",
    "        x = X_L(device=DEVICE,n_input=2, n_hidden=nhidden, use=[1,2], lob=1.174, ueg_limit=ueg_limit) # PBE_X\n",
    "        c = C_L(device=DEVICE,n_input=4, n_hidden=nhidden, use=[2,3], ueg_limit=ueg_limit and not freec)\n",
    "        xc_level = 3\n",
    "    if pretrain_loc:\n",
    "        print(\"Loading pre-trained models from \" + pretrain_loc)\n",
    "        x.load_state_dict(torch.load(pretrain_loc + '/x'))\n",
    "        c.load_state_dict(torch.load(pretrain_loc + '/c'))\n",
    "    EXX = bool(hyb_par)\n",
    "    EXX_A = hyb_par if hyb_par else None\n",
    "\n",
    "    xc = XC(grid_models=[x, c], heg_mult=True, level=xc_level)\n",
    "    if path:\n",
    "        try:\n",
    "            xcp = torch.load(path, map_location=torch.device('cpu')).xc\n",
    "            xc.load_state_dict(xcp.state_dict())\n",
    "        except AttributeError:\n",
    "            # AttributeError: 'RecursiveScriptModule' object has no attribute 'copy'\n",
    "            #occurs when loading finished xc from xcdiff\n",
    "            xcp = torch.jit.load(path)\n",
    "            xc.load_state_dict(xcp.state_dict())\n",
    "\n",
    "    return xc\n",
    "def get_torch_weights_and_biases(torch_net):\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for nidx, net in enumerate(torch_net):\n",
    "        try:\n",
    "            w = jnp.array(net.weight.data)\n",
    "            b = jnp.array(net.bias.data)\n",
    "            weights.append(w)\n",
    "            biases.append(b)\n",
    "        except:\n",
    "            print('This torch layer is not a Linear model.')\n",
    "            continue\n",
    "    return (weights, biases)\n",
    "    \n",
    "#per https://docs.kidger.site/equinox/tricks/\n",
    "def trunc_init(weight: jax.Array, key: jax.random.PRNGKey) -> jax.Array:\n",
    "    out, in_ = weight.shape\n",
    "    stddev = math.sqrt(1 / in_)\n",
    "    return stddev * jax.random.truncated_normal(key, shape=(out, in_), lower=-2, upper=2)\n",
    "\n",
    "def init_linear_weight(model, seed, new_weights, new_bias):\n",
    "    jax.random.PRNGKey(seed)\n",
    "    is_linear = lambda x: isinstance(x, eqx.nn.Linear)\n",
    "    get_weights = lambda m: [x.weight\n",
    "                           for x in jax.tree_util.tree_leaves(m, is_leaf=is_linear)\n",
    "                           if is_linear(x)]\n",
    "    get_bias = lambda m: [x.bias\n",
    "                           for x in jax.tree_util.tree_leaves(m, is_leaf=is_linear)\n",
    "                           if is_linear(x)]\n",
    "\n",
    "    weights = get_weights(model)\n",
    "    bias = get_bias(model)\n",
    "    new_model = eqx.tree_at(get_weights, model, new_weights)\n",
    "    new_model = eqx.tree_at(get_bias, new_model, new_bias)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a969b2be-584c-4ca5-b46b-d5ad23a8a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jax_exc_func(model, ao_eval, gw):\n",
    "    def ret_func(inp):\n",
    "        return model(inp, ao_eval, gw)\n",
    "    return ret_func\n",
    "\n",
    "def jax_loss_func(loss_func, model, en, ao, gw, eri, mooc, hc, s):\n",
    "    def ret_func(dm):\n",
    "        return loss_func(model, dm, en, ao, gw, eri, mooc, hc, s)\n",
    "    return ret_func\n",
    "\n",
    "# @eqx.filter_jit\n",
    "def jax_dm(dm, eri, vxc_grad_func, mo_occ, hc, s, ogd, alpha0=0.7):\n",
    "    L = jnp.eye(dm.shape[-1])\n",
    "    scaling = jnp.ones([dm.shape[-1]]*2)\n",
    "    dm_old = dm\n",
    "    def true_func(vxc):\n",
    "        vxc.at[1].set(jnp.zeros_like(vxc[1]))\n",
    "        return vxc\n",
    "    def false_func(vxc):\n",
    "        return vxc\n",
    "    alpha = jnp.power(alpha0, 0)+0.3\n",
    "    beta = (1-alpha)\n",
    "    dm = alpha * dm + beta * dm_old\n",
    "    dm_old = dm\n",
    "    veff = xce.utils.get_veff()(dm, eri)\n",
    "    vxc = jax.grad(vxc_grad_func)(dm)\n",
    "    if vxc.ndim > 2:\n",
    "        vxc = jnp.einsum('ij,xjk,kl->xil',L,vxc,L.T)\n",
    "        vxc = jnp.where(jnp.expand_dims(scaling, 0) > 0 , vxc, jnp.expand_dims(scaling,0))\n",
    "    else:\n",
    "        vxc = jnp.matmul(L,jnp.matmul(vxc ,L.T))\n",
    "        vxc = jnp.where(scaling > 0 , vxc, scaling)\n",
    "    \n",
    "    jax.lax.cond(jnp.sum(mo_occ) == 1, true_func, false_func, vxc)\n",
    "    \n",
    "    veff += vxc\n",
    "    f = xce.utils.get_fock()(hc, veff)\n",
    "    mo_e, mo_c = xce.utils.eig()(f+1e-6*jax.random.uniform(key=jax.random.PRNGKey(92017), shape=f.shape), s, ogd)\n",
    "    dm = xce.utils.make_rdm1()(mo_c, mo_occ)\n",
    "    return dm, mo_e, mo_c\n",
    "    \n",
    "# @eqx.filter_grad\n",
    "def e_loss(model, inp_dm, ref_en, ao_eval, grid_weights, *args):\n",
    "    print(f\"e_loss; input stats. inp_dm.shape = {inp_dm.shape}, ref_en = {ref_en}, ao_eval.shape = {ao_eval.shape}, grid_weights.shape = {grid_weights.shape}\")\n",
    "    e_pred = model(inp_dm, ao_eval, grid_weights)\n",
    "    eL = jnp.sqrt( np.mean((e_pred-ref_en)**2))\n",
    "    # print('energy loss', eL)\n",
    "    return eL\n",
    "\n",
    "class E_loss(eqx.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, model, inp_dm, ref_en, ao_eval, grid_weights):\n",
    "\n",
    "        e_pred = model(inp_dm, ao_eval, grid_weights)\n",
    "        eL = jnp.sqrt( jnp.mean((e_pred-ref_en)**2))\n",
    "        return eL\n",
    "\n",
    "def holo_loss(model, inp_dm, ref_en, ao_eval, grid_weights, vxc_grad_func, mo_occ, hc, s, eri, ogd, alpha0):\n",
    "    dm, mo_e, mo_c = jax_dm(inp_dm, eri, vxc_grad_func, mo_occ, hc, s, ogd, alpha0)\n",
    "    homo_i = jnp.max(jnp.nonzero(mo_occ, size=dm.shape[0])[0])\n",
    "    homo_e = mo_e[homo_i]\n",
    "    lumo_e = mo_e[homo_i+1]\n",
    "    pred_holo = lumo_e - homo_e\n",
    "    print('pred_holo', pred_holo)\n",
    "    return jnp.sqrt( np.mean ((pred_holo - ref_en)**2))\n",
    "\n",
    "def loop_e_loss(model, inp_dms, ref_ens, ao_evals, grid_weights):\n",
    "    e_preds = []\n",
    "    for idx in range(len(ref_ens)):\n",
    "        ep = model(inp_dms[idx], ao_evals[idx], grid_weights[idx])\n",
    "        e_preds.append(ep)\n",
    "    e_preds = jnp.array(e_preds)\n",
    "    e_refs = jnp.array(ref_ens)\n",
    "    eL = jnp.sqrt( jnp.mean( (e_refs-e_preds)**2))\n",
    "    return eL\n",
    "# @eqx.filter_grad\n",
    "\n",
    "def dm_loss(model, inp_dm, ref_en, ao_eval, gw, eri, mo_occ, hc, s, ogd, *args):\n",
    "    dmp, moe, moc = jax_dm(inp_dm, eri, jax_exc_func(model, ao_eval, gw), mo_occ, hc, s, ogd)\n",
    "    dmL = jnp.sqrt(jnp.sum( (dmp - inp_dm)**2))\n",
    "    return dmL\n",
    "\n",
    "\n",
    "def loop_dm_loss(model, inp_dms, eris, mo_occs, hcs, ss, ao_evals, gws):\n",
    "    dmL = 0\n",
    "    for idx, dm in enumerate(inp_dms):\n",
    "        dmp = jax_dm(inp_dms[idx], eris[idx], jax_exc_func(model, ao_evals[idx], gws[idx]), mo_occs[idx], hcs[idx], ss[idx])\n",
    "        dmL += jnp.mean((dmp - inp_dms[idx])**2)\n",
    "    dmL = jnp.sqrt(dmL)\n",
    "    return dmL\n",
    "    \n",
    "# @eqx.filter_value_and_grad\n",
    "def total_loss(model, inp_dms, ref_ens, ref_holos, ao_evals, grid_weights, eris, mo_occs, hcs, ss, ogd):\n",
    "    # eL = e_loss(model, inp_dms, ref_ens, ao_evals, grid_weights, ogd)\n",
    "    # dmL = dm_loss(model, inp_dms, ref_ens, ao_eval, grid_weights, eris, mo_occs, hcs, ss, ogd)\n",
    "    vxcgf = jax_exc_func(model, ao_eval, grid_weights)\n",
    "    holoL = holo_loss(model, inp_dms, ref_holos, ao_evals, grid_weights, vxcgf, mo_occs, hcs, ss, eris, ogd, alpha0=0.7)\n",
    "    # return jnp.sqrt( eL**2 + holoL**2)\n",
    "    return jnp.sqrt( holoL**2 )\n",
    "\n",
    "def total_loop_loss(model, inp_dms, ref_ens, ao_evals, grid_weights, eris, mo_occs, hcs, ss):\n",
    "    eL = loop_e_loss(model, inp_dms, ref_ens, ao_evals, grid_weights)\n",
    "    dmL = loop_dm_loss(model, inp_dms, eris, mo_occs, hcs, ss, ao_evals, grid_weights)\n",
    "    return jnp.sqrt(eL**2 + dmL**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fd714-90e4-4ba2-aa6b-36b83a22ac10",
   "metadata": {},
   "source": [
    "Dev for multi-NL input networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0899be14-65e9-4a2e-b58a-2aca51a1ad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class eX(eqx.Module):\n",
    "    n_input: int\n",
    "    n_hidden: int\n",
    "    ueg_limit: jax.Array\n",
    "    spin_scaling: bool\n",
    "    lob: jax.Array\n",
    "    use: list\n",
    "    net: eqx.Module\n",
    "    tanh: jax.named_call\n",
    "    lobf: jax.named_call\n",
    "    sig: jax.named_call\n",
    "    shift: jax.Array\n",
    "    lobf: eqx.Module\n",
    "    seed: int\n",
    "    depth: int\n",
    "\n",
    "    def __init__(self, n_input, n_hidden=16, depth=3, use=[], ueg_limit=False, lob=1.804, seed=92017):\n",
    "        \"\"\"\n",
    "        __init__ Local exchange model based on MLP.\n",
    "\n",
    "        Receives density descriptors in this order : [rho, s, alpha, nl], where the input may be truncated depending on XC-level of approximation.\n",
    "\n",
    "        The MLP generated is hard-coded to have one output value -- the predicted exchange energy given a specific input from the grid.\n",
    "\n",
    "        :param n_input: Input dimensions (LDA: 1, GGA: 2, meta-GGA: 3, ...)\n",
    "        :type n_input: int\n",
    "        :param n_hidden: Number of hidden nodes (three hidden layers used by default), defaults to 16\n",
    "        :type n_hidden: int, optional\n",
    "        :param depth: Depth of the MLP, defaults to 3\n",
    "        :type depth: int, optional\n",
    "        :param use: Only these indices are used as input to the model (can be used to omit density as input to enforce uniform density scaling). These indices are also used to enforce UEG where the assumed order is [s, alpha, ...], defaults to []\n",
    "        :type use: list, optional\n",
    "        :param ueg_limit: Flag to determine whether or not to enforce uniform homoegeneous electron gas limit, defaults to False\n",
    "        :type ueg_limit: bool, optional\n",
    "        :param lob: Enforce this value as local Lieb-Oxford bound (don't enforce if set to 0), defaults to 1.804\n",
    "        :type lob: float, optional\n",
    "        :param seed: Random seed used to generate initial weights and biases for the MLP, defaults to 92017\n",
    "        :type seed: int, optional\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.ueg_limit = ueg_limit\n",
    "        self.spin_scaling = True\n",
    "        self.lob = lob\n",
    "        self.n_input = n_input\n",
    "        self.n_hidden = n_hidden\n",
    "        self.seed = seed\n",
    "        self.depth = depth\n",
    "\n",
    "        if not use:\n",
    "            self.use = jnp.arange(n_input)\n",
    "        else:\n",
    "            self.use = use\n",
    "        self.net =  eqx.nn.MLP(in_size = self.n_input,\n",
    "                               out_size = 1,\n",
    "                               width_size = self.n_hidden,\n",
    "                               depth = self.depth,\n",
    "                               activation = jax.nn.gelu,\n",
    "                              key=jax.random.PRNGKey(self.seed))\n",
    "        \n",
    "        self.tanh = jnp.tanh\n",
    "        self.lobf = xce.net.LOB(limit=self.lob)\n",
    "        self.sig = jax.nn.sigmoid\n",
    "        self.shift = 1/(1+jnp.exp(-1e-3))\n",
    "\n",
    "    def __call__(self, rho, **kwargs):\n",
    "        \"\"\"\n",
    "        __call__ Forward pass for the exchange network.\n",
    "\n",
    "        Uses :jax.vmap: to vectorize evaluation of the MLP on the descriptors, assuming a shape [batch, *, n_input]\n",
    "\n",
    "        .. todo: Make sure the :vmap: call can work with specific :use: values beyond the defaults assumed in the previous implementation.\n",
    "\n",
    "        :param rho: The descriptors to the MLP -- transformed densities and gradients appropriate to the XC-level. This network will only use the dimensions specified in self.use.\n",
    "        :type rho: jax.Array\n",
    "        :return: The exchange energy on the grid\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        if self.n_input < 4:\n",
    "            squeezed = jnp.squeeze(jax.vmap(jax.vmap(self.net), in_axes=1)(rho[...,self.use])).T\n",
    "        else:\n",
    "            print(f\"eX.__call__, rho shape: {rho.shape}\")\n",
    "            squeezed = jnp.squeeze(jax.vmap(self.net)(rho))\n",
    "\n",
    "        if self.ueg_limit:\n",
    "            ueg_lim = rho[...,self.use[0]]\n",
    "            if len(self.use) > 1:\n",
    "                ueg_lim_a = jnp.power(self.tanh(rho[...,self.use[1]]),2)\n",
    "            else:\n",
    "                ueg_lim_a = 0\n",
    "            if len(self.use) > 2:\n",
    "                ueg_lim_nl = jnp.sum(rho[...,self.use[2:]],axis=-1)\n",
    "            else:\n",
    "                ueg_lim_nl = 0\n",
    "        else:\n",
    "            ueg_lim = 1\n",
    "            ueg_lim_a = 0\n",
    "            ueg_lim_nl = 0\n",
    "\n",
    "        if self.lob:\n",
    "            result = self.lobf(squeezed*(ueg_lim + ueg_lim_a + ueg_lim_nl))\n",
    "        else:\n",
    "            result = squeezed*(ueg_lim + ueg_lim_a + ueg_lim_nl)\n",
    "\n",
    "        return result\n",
    "\n",
    "class eC(eqx.Module):\n",
    "    n_input: int\n",
    "    n_hidden: int\n",
    "    ueg_limit: jax.Array\n",
    "    spin_scaling: bool\n",
    "    lob: jax.Array\n",
    "    use: list\n",
    "    net: eqx.Module\n",
    "    tanh: jax.named_call\n",
    "    lobf: jax.named_call\n",
    "    sig: jax.named_call\n",
    "    lobf: eqx.Module\n",
    "    seed: int\n",
    "    depth: int\n",
    "\n",
    "    def __init__(self, n_input=2,n_hidden=16, depth=3, use = [], ueg_limit=False, lob=2.0, seed=92017):\n",
    "        \"\"\"\n",
    "        __init__ Local correlation model based on MLP.\n",
    "\n",
    "        Receives density descriptors in this order : [rho, spinscale, s, alpha, nl], where the input may be truncated depending on XC-level of approximation\n",
    "\n",
    "        .. todo: Make sure the :vmap: call can work with specific :use: values beyond the defaults assumed in the previous implementation.\n",
    "\n",
    "        :param n_input: Input dimensions (LDA: 2, GGA: 3 , meta-GGA: 4), defaults to 2.\n",
    "        :type n_input: int\n",
    "        :param n_hidden: Number of hidden nodes (three hidden layers used by default), defaults to 16\n",
    "        :type n_hidden: int, optional\n",
    "        :param depth: Depth of the MLP, defaults to 3\n",
    "        :type depth: int, optional\n",
    "        :param use: Only these indices are used as input to the model. These indices are also used to enforce UEG where the assumed order is [s, alpha, ...], defaults to []\n",
    "        :type use: list, optional\n",
    "        :param ueg_limit: Flag to determine whether or not to enforce uniform homoegeneous electron gas limit, defaults to False\n",
    "        :type ueg_limit: bool, optional\n",
    "        :param lob: Enforce this value as local Lieb-Oxford bound (don't enforce if set to 0), defaults to 2.0\n",
    "        :type lob: float, optional\n",
    "        :param seed: Random seed used to generate initial weights and biases for the MLP, defaults to 92017\n",
    "        :type seed: int, optional\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.spin_scaling = False\n",
    "        self.lob = False\n",
    "        self.ueg_limit = ueg_limit\n",
    "        self.n_input=n_input\n",
    "        self.n_hidden=n_hidden\n",
    "        self.seed = seed\n",
    "        self.depth = depth\n",
    "\n",
    "        if not use:\n",
    "            self.use = jnp.arange(n_input)\n",
    "        else:\n",
    "            self.use = use\n",
    "        self.net =  eqx.nn.MLP(in_size = self.n_input,\n",
    "                               out_size = 1,\n",
    "                               width_size = self.n_hidden,\n",
    "                               depth = self.depth,\n",
    "                               activation = jax.nn.gelu,\n",
    "                               final_activation = jax.nn.softplus,\n",
    "                               key=jax.random.PRNGKey(self.seed))\n",
    "        self.sig = jax.nn.sigmoid\n",
    "        self.tanh = jnp.tanh\n",
    "        self.lob = lob\n",
    "        if self.lob:\n",
    "            self.lobf = xce.net.LOB(self.lob)\n",
    "        else:\n",
    "            self.lob =  1000.0\n",
    "            self.lobf = xce.net.LOB(self.lob)\n",
    "\n",
    "\n",
    "    def __call__(self, rho, **kwargs):\n",
    "        \"\"\"\n",
    "        __call__ Forward pass for the correlation network.\n",
    "\n",
    "        Uses :jax.vmap: to vectorize evaluation of the MLP on the descriptors, assuming a shape [*, n_input]\n",
    "\n",
    "        :param rho: The descriptors to the MLP -- transformed densities and gradients appropriate to the XC-level. This network will only use the dimensions specified in self.use in determining the UEG limits.\n",
    "        :type rho: jax.Array\n",
    "        :return: The exchange energy on the grid\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        print(f\"eC.__call__, rho shape: {rho.shape}\")\n",
    "        squeezed = jnp.squeeze(-jax.vmap(self.net)(rho))\n",
    "\n",
    "        if self.ueg_limit:\n",
    "            ueg_lim = self.tanh(rho[...,self.use[0]])\n",
    "            if len(self.use) > 1:\n",
    "                ueg_lim_a = jnp.pow(self.tanh(rho[...,self.use[1]]),2)\n",
    "            else:\n",
    "                ueg_lim_a = 0\n",
    "            if len(self.use) > 2:\n",
    "                ueg_lim_nl = jnp.sum(self.tanh(rho[...,self.use[2:]])**2,axis=-1)\n",
    "            else:\n",
    "                ueg_lim_nl = 0\n",
    "\n",
    "            ueg_factor = ueg_lim + ueg_lim_a + ueg_lim_nl\n",
    "        else:\n",
    "            ueg_factor = 1\n",
    "        if self.lob:\n",
    "            return self.lobf(squeezed*ueg_factor)\n",
    "        else:\n",
    "            return squeezed*ueg_factor\n",
    "\n",
    "class eXC(eqx.Module):\n",
    "    grid_models: list\n",
    "    heg_mult: bool\n",
    "    pw_mult: bool\n",
    "    level: int\n",
    "    exx_a: jax.Array\n",
    "    epsilon: jax.Array\n",
    "    loge: jax.Array\n",
    "    s_gam: jax.Array\n",
    "    heg_model: eqx.Module\n",
    "    pw_model: eqx.Module\n",
    "    model_mult: list\n",
    "    debug: bool\n",
    "    nlstart_i: int\n",
    "    nlend_i: int\n",
    "    \n",
    "    def __init__(self, grid_models=[], heg_mult=True, pw_mult=True,\n",
    "                    level = 1, exx_a=None, epsilon=1e-8, debug=False,\n",
    "                nlstart_i = 3, nlend_i = 12):\n",
    "        \"\"\"\n",
    "        __init__ Defines the XC functional\n",
    "\n",
    "        Constructed with two MLPs -- one for the local exchange energy on the grid, the other for the local correlation energy.\n",
    "\n",
    "        :param grid_models: list of eX (local exchange) or eC (local correlation). Defines the xc-models/enhancement factors, defaults to []\n",
    "        :type grid_models: list, optional\n",
    "        :param heg_mult: Use homoegeneous electron gas exchange (multiplicative if grid_models is not empty), defaults to True\n",
    "        :type heg_mult: bool, optional\n",
    "        :param pw_mult: Use homoegeneous electron gas correlation (Perdew & Wang), defaults to True\n",
    "        :type pw_mult: bool, optional\n",
    "        :param level: Controls the number of density \"descriptors\" generated. 1: LDA, 2: GGA, 3:meta-GGA, 4: meta-GGA + electrostatic (nonlocal), defaults to 1\n",
    "        :type level: int, optional\n",
    "        :param exx_a: Exact exchange mixing parameter, defaults to None\n",
    "        :type exx_a: float, optional\n",
    "        :param epsilon: Offset to avoid div/0 in calculations, defaults to 1e-8\n",
    "        :type epsilon: float, optional\n",
    "        :param debug: Controls printing of various stats throughout, defaults to False\n",
    "        :type debug: bool, optional\n",
    "        :param nlstart_i: If level > 3, this controls the number of CIDER Nonlocal parameters are selected, defaults to 3 as the first nonlocal CIDER descriptor\n",
    "        :type nlstart_i: int, optional\n",
    "        :param nlend_i: If level > 3, this controls the number of CIDER Nonlocal parameters are selected, defaults to 12 as the last nonlocal CIDER descriptor\n",
    "        :type nlend_i: int, optional\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.heg_mult = heg_mult\n",
    "        self.pw_mult = pw_mult\n",
    "        self.level = level\n",
    "        self.grid_models = grid_models\n",
    "        self.epsilon = epsilon\n",
    "        if level > 3:\n",
    "            print('WARNING: Non-local models highly experimental and likely will not work ')\n",
    "        self.loge = 1e-5\n",
    "        self.s_gam = 1\n",
    "        self.debug = debug\n",
    "        self.nlstart_i = 3\n",
    "        self.nlend_i = 12\n",
    "\n",
    "        if heg_mult:\n",
    "            self.heg_model = xce.xc.LDA_X()\n",
    "        if pw_mult:\n",
    "            self.pw_model = xce.xc.PW_C()\n",
    "        self.model_mult = [1 for m in self.grid_models]\n",
    "        if not exx_a:\n",
    "            self.exx_a = 0\n",
    "        else:\n",
    "            self.exx_a = exx_a\n",
    "\n",
    "    def __call__(self, dm, ao_eval, grid_weights, mf = None):\n",
    "        \"\"\"\n",
    "        __call__ Forward call for the XC network to get the grid point e_xc\n",
    "\n",
    "        Generates the density-on-grid from the density matrix, atomic orbital evaluation, and the grid weights from a :pyscfad: calculation.\n",
    "\n",
    "\n",
    "        :param dm: Density matrix\n",
    "        :type dm: jax.Array\n",
    "        :param ao_eval: Atomic orbitals evaluated on the grid\n",
    "        :type ao_eval: jax.Array\n",
    "        :param grid_weights: Grid weights associated to the grid on which the atomic orbitals are evaluated\n",
    "        :type grid_weights: jax.Array\n",
    "        :return: Exc, exchange-correlation energy from integrating the network calls across the grid\n",
    "        :rtype: float\n",
    "        \"\"\"\n",
    "        Exc = 0\n",
    "        if self.level > 3:\n",
    "            assert mf is not None\n",
    "        if self.grid_models or self.heg_mult:\n",
    "            if ao_eval.ndim==2:\n",
    "                ao_eval = jnp.expand_dims(ao_eval,0)\n",
    "            else:\n",
    "                ao_eval = ao_eval\n",
    "\n",
    "            # Create density (and gradients) from atomic orbitals evaluated on grid\n",
    "            # and density matrix\n",
    "            # rho[ijsp]: del_i phi del_j phi dm (s: spin, p: grid point index)\n",
    "            rho = jnp.einsum('xij,yik,...jk->xy...i', ao_eval, ao_eval, dm)+1e-10\n",
    "            \n",
    "            rho0 = rho[0,0]\n",
    "            drho = rho[0,1:4] + rho[1:4,0]\n",
    "            tau = 0.5*(rho[1,1] + rho[2,2] + rho[3,3])\n",
    "\n",
    "            non_loc = jnp.zeros_like(tau)\n",
    "\n",
    "            if dm.ndim == 3: # If unrestricted (open-shell) calculation\n",
    "\n",
    "                # Density\n",
    "                rho0_a = rho0[0]\n",
    "                rho0_b = rho0[1]\n",
    "\n",
    "                # jnp.einsumed density gradient\n",
    "                gamma_a, gamma_b = jnp.einsum('ij,ij->j',drho[:,0],drho[:,0]), jnp.einsum('ij,ij->j',drho[:,1],drho[:,1])\n",
    "                gamma_ab = jnp.einsum('ij,ij->j',drho[:,0],drho[:,1])\n",
    "\n",
    "                # Kinetic energy density\n",
    "                tau_a, tau_b = tau\n",
    "\n",
    "                # E.-static\n",
    "                non_loc_a, non_loc_b = non_loc\n",
    "            else:\n",
    "                rho0_a = rho0_b = rho0*0.5\n",
    "                gamma_a=gamma_b=gamma_ab= jnp.einsum('ij,ij->j',drho[:],drho[:])*0.25\n",
    "                tau_a = tau_b = tau*0.5\n",
    "                non_loc_a=non_loc_b = non_loc*0.5\n",
    "\n",
    "            # xc-energy per unit particle\n",
    "            exc = self.eval_grid_models(jnp.concatenate([jnp.expand_dims(rho0_a,-1),\n",
    "                                                    jnp.expand_dims(rho0_b,-1),\n",
    "                                                    jnp.expand_dims(gamma_a,-1),\n",
    "                                                    jnp.expand_dims(gamma_ab,-1),\n",
    "                                                    jnp.expand_dims(gamma_b,-1),\n",
    "                                                    jnp.expand_dims(jnp.zeros_like(rho0_a),-1), #Dummy for laplacian\n",
    "                                                    jnp.expand_dims(jnp.zeros_like(rho0_a),-1), #Dummy for laplacian\n",
    "                                                    jnp.expand_dims(tau_a,-1),\n",
    "                                                    jnp.expand_dims(tau_b,-1),\n",
    "                                                    jnp.expand_dims(non_loc_a,-1),\n",
    "                                                    jnp.expand_dims(non_loc_b,-1)],axis=-1),\n",
    "                                       mf = mf, dm = dm)\n",
    "            Exc += jnp.sum(((rho0_a + rho0_b)*exc[:,0])*grid_weights)\n",
    "        return Exc\n",
    "            \n",
    "    # Density (rho)\n",
    "    def l_1(self, rho):\n",
    "        \"\"\"\n",
    "        l_1 Level 1 (LDA-level) Descriptor -- Creates dimensionless quantity from rho.\n",
    "\n",
    "        Equation 3 from the `base paper`_.\n",
    "\n",
    "        .. _base paper: https://link.aps.org/doi/10.1103/PhysRevB.104.L161109\n",
    "\n",
    "        .. math:: x_0 = \\\\rho^{1/3}\n",
    "\n",
    "\n",
    "        :param rho: density\n",
    "        :type rho: jax.Array\n",
    "        :return: Scaled density\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        return rho**(1/3)\n",
    "\n",
    "    # Reduced density gradient s\n",
    "    def l_2(self, rho, gamma):\n",
    "        \"\"\"\n",
    "        l_2 Level 2 (GGA-level) Descriptor -- Reduced gradient density\n",
    "\n",
    "        Equation 5 from the `base paper`_.\n",
    "\n",
    "        .. _base paper: https://link.aps.org/doi/10.1103/PhysRevB.104.L161109\n",
    "\n",
    "        .. math:: x_2=s=\\\\frac{1}{2(3\\\\pi^2)^{1/3}} \\\\frac{|\\\\nabla \\\\rho|}{\\\\rho^{4/3}}\n",
    "\n",
    "        \n",
    "        :param rho: density\n",
    "        :type rho: jax.Array\n",
    "        :param gamma: squared density gradient\n",
    "        :type gamma: jax.Array\n",
    "        :return: reduced density gradient s\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        return jnp.sqrt(gamma)/(2*(3*np.pi**2)**(1/3)*rho**(4/3)+self.epsilon)\n",
    "\n",
    "    # Reduced kinetic energy density alpha\n",
    "    def l_3(self, rho, gamma, tau):\n",
    "        \"\"\"\n",
    "        l_3 Level 3 (MGGA-level) Descriptor -- Reduced kinetic energy density\n",
    "\n",
    "        Equation 6 from the `base paper`_.\n",
    "\n",
    "        .. _base paper: https://link.aps.org/doi/10.1103/PhysRevB.104.L161109\n",
    "\n",
    "        .. math:: \\\\tau^W = \\\\frac{|\\\\nabla \\\\rho|^2}{8\\\\rho}, \\\\tau^{unif} = \\\\frac{3}{10} (3\\\\pi^2)^{2/3}\\\\rho^{5/3}.\n",
    "\n",
    "\n",
    "        :param rho: density\n",
    "        :type rho: jax.Array\n",
    "        :param gamma: squared density gradient\n",
    "        :type gamma: jax.Array\n",
    "        :param tau: kinetic energy density\n",
    "        :type tau: jax.Array\n",
    "        :return: reduced kinetic energy density\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        uniform_factor = (3/10)*(3*np.pi**2)**(2/3)\n",
    "        tw = gamma/(8*(rho+self.epsilon))\n",
    "        return (tau - tw)/(uniform_factor*rho**(5/3)+self.epsilon)\n",
    "\n",
    "    # Unit-less electrostatic potential\n",
    "    def l_4(self, rho, nl):\n",
    "        \"\"\"\n",
    "        l_4 Level 4 (Non-local level) Descriptor -- Unitless electrostatic potential\n",
    "\n",
    "        .. todo:: document/implement in a more descriptive manner\n",
    "\n",
    "        :param rho: density\n",
    "        :type rho: jax.Array\n",
    "        :param nl: non-local values arising from density contractions\n",
    "        :type nl: jax.Array\n",
    "        :return: the non-local descriptors\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        u = nl[:,:1]/((jnp.expand_dims(rho, -1)**(1/3))*self.nl_ueg[:,:1] + self.epsilon)\n",
    "        wu = nl[:,1:]/((jnp.expand_dims(rho, -1))*self.nl_ueg[:,1:] + self.epsilon)\n",
    "        return jax.nn.relu(jnp.concatenate([u,wu],axis=-1))\n",
    "\n",
    "    def nl_4(self, mf, dm):\n",
    "        an = RKSAnalyzer(mf)\n",
    "        descr5 = jnp.asarray(get_exchange_descriptors2(an, restricted=True, version='c', auxbasis=mf.mol.basis,\n",
    "                                   rdm1=True, dm=np.asarray(dm), inmol=True, mol=mf.mol, ingrid=True, grid=mf.grids))\n",
    "        descr5 = descr5[self.nlstart_i:self.nlend_i]\n",
    "        return descr5\n",
    "        \n",
    "    # @eqx.filter_jit\n",
    "    def get_descriptors(self, rho0_a, rho0_b, gamma_a, gamma_b, gamma_ab,nl_a,nl_b, tau_a, tau_b, spin_scaling = False,\n",
    "                       mf = None, dm = None):\n",
    "        \"\"\"\n",
    "        get_descriptors Creates 'ML-compatible' descriptors from the electron density and its gradients, a & b correspond to spin channels\n",
    "\n",
    "        :param rho0_a: :math:`\\\\rho` in spin-channel a\n",
    "        :type rho0_a: jax.Array\n",
    "        :param rho0_b: :math:`\\\\rho` in spin-channel b\n",
    "        :type rho0_b: jax.Array\n",
    "        :param gamma_a: :math:`|\\\\nabla \\\\rho|^2` in spin-channel b\n",
    "        :type gamma_a: jax.Array\n",
    "        :param gamma_b: :math:`|\\\\nabla \\\\rho|^2` in spin-channel b\n",
    "        :type gamma_b: jax.Array\n",
    "        :param gamma_ab: :math:`|\\\\nabla \\\\rho|^2`, contracted from both spin channels\n",
    "        :type gamma_ab: jax.Array\n",
    "        :param nl_a: Non-local descriptors in spin-channel a, not currently used.\n",
    "        :type nl_a: jax.Array\n",
    "        :param nl_b: Non-local descriptors in spin-channel b, not currently used.\n",
    "        :type nl_b: jax.Array\n",
    "        :param tau_a: KE density in spin-channel a\n",
    "        :type tau_a: jax.Array\n",
    "        :param tau_b: KE density in spin-channel b\n",
    "        :type tau_b: jax.Array\n",
    "        :param spin_scaling: Flag for spin-scaling, defaults to False\n",
    "        :type spin_scaling: bool, optional\n",
    "        :return: Array of the machine-learning descriptors on the grid\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        if not spin_scaling:\n",
    "            #If no spin-scaling, calculate polarization and use for X1\n",
    "            zeta = (rho0_a - rho0_b)/(rho0_a + rho0_b + self.epsilon)\n",
    "            spinscale = 0.5*((1+zeta)**(4/3) + (1-zeta)**(4/3)) # zeta\n",
    "\n",
    "        if self.level > 0:  #  LDA\n",
    "            if spin_scaling:\n",
    "                descr1 = jnp.log(self.l_1(2*rho0_a) + self.loge)\n",
    "                descr2 = jnp.log(self.l_1(2*rho0_b) + self.loge)\n",
    "            else:\n",
    "                descr1 = jnp.log(self.l_1(rho0_a + rho0_b) + self.loge)# rho\n",
    "                descr2 = jnp.log(spinscale) # zeta\n",
    "            descr = jnp.concatenate([jnp.expand_dims(descr1, -1), jnp.expand_dims(descr2, -1)],axis=-1)\n",
    "        if self.level > 1: # GGA\n",
    "            if spin_scaling:\n",
    "                descr3a = self.l_2(2*rho0_a, 4*gamma_a) # s\n",
    "                descr3b = self.l_2(2*rho0_b, 4*gamma_b) # s\n",
    "                descr3 = jnp.concatenate([jnp.expand_dims(descr3a,-1), jnp.expand_dims(descr3b,-1)],axis=-1)\n",
    "                descr3 = (1-jnp.exp(-descr3**2/self.s_gam))*jnp.log(descr3 + 1)\n",
    "            else:\n",
    "                descr3 = self.l_2(rho0_a + rho0_b, gamma_a + gamma_b + 2*gamma_ab) # s\n",
    "                descr3 = descr3/((1+zeta)**(2/3) + (1-zeta)**2/3)\n",
    "                descr3 = jnp.expand_dims(descr3,-1)\n",
    "                descr3 = (1-jnp.exp(-descr3**2/self.s_gam))*jnp.log(descr3 + 1)\n",
    "            descr = jnp.concatenate([descr, descr3],axis=-1)\n",
    "        if self.level > 2: # meta-GGA\n",
    "            if spin_scaling:\n",
    "                descr4a = self.l_3(2*rho0_a, 4*gamma_a, 2*tau_a)\n",
    "                descr4b = self.l_3(2*rho0_b, 4*gamma_b, 2*tau_b)\n",
    "                descr4 = jnp.concatenate([jnp.expand_dims(descr4a,-1), jnp.expand_dims(descr4b,-1)],axis=-1)\n",
    "                descr4 = descr4**3/(descr4**2+self.epsilon)\n",
    "            else:\n",
    "                descr4 = self.l_3(rho0_a + rho0_b, gamma_a + gamma_b + 2*gamma_ab, tau_a + tau_b)\n",
    "                descr4 = 2*descr4/((1+zeta)**(5/3) + (1-zeta)**(5/3))\n",
    "                descr4 = descr4**3/(descr4**2+self.epsilon)\n",
    "\n",
    "                descr4 = jnp.expand_dims(descr4,-1)\n",
    "            descr4 = jnp.log((descr4 + 1)/2)\n",
    "            descr = jnp.concatenate([descr, descr4],axis=-1)\n",
    "        if self.level > 3: # meta-GGA + V_estat\n",
    "            # if spin_scaling:\n",
    "            #     descr5a = self.l_4(2*rho0_a, 2*nl_a)\n",
    "            #     descr5b = self.l_4(2*rho0_b, 2*nl_b)\n",
    "            #     descr5 = jnp.log(jnp.stack([descr5a, descr5b],axis=-1) + self.loge)\n",
    "            #     descr5 = descr5.view(descr5.size()[0],-1)\n",
    "            # else:\n",
    "            #     descr5= jnp.log(self.l_4(rho0_a + rho0_b, nl_a + nl_b) + self.loge)\n",
    "\n",
    "            # descr = jnp.concatenate([descr, descr5],axis=-1)\n",
    "            descr5 = self.nl_4(mf, dm).T\n",
    "                \n",
    "            descr = jnp.concatenate([descr, descr5], axis=-1)\n",
    "        if spin_scaling and self.level <= 3:\n",
    "            descr = jnp.transpose(jnp.reshape(descr,(jnp.shape(descr)[0],-1,2)), (2,0,1)) \n",
    "        return descr\n",
    "\n",
    "    def eval_grid_models(self, rho, mf=None, dm=None):\n",
    "        \"\"\"\n",
    "        eval_grid_models Evaluates all models stored in self.grid_models along with HEG exchange and correlation\n",
    "\n",
    "        :param rho: List/array with [rho0_a,rho0_b,gamma_a,gamma_ab,gamma_b, dummy for laplacian, dummy for laplacian, tau_a, tau_b, non_loc_a, non_loc_b]\n",
    "                    Shape assumes, for instance, that rho0_a = rho[:, 0], etc.\n",
    "        :type rho: jax.Array\n",
    "        :return: The exchange-correlation energy density (on the grid)\n",
    "        :rtype: jax.Array\n",
    "        \"\"\"\n",
    "        Exc = 0\n",
    "        rho0_a = rho[:, 0]\n",
    "        rho0_b = rho[:, 1]\n",
    "        gamma_a = rho[:, 2]\n",
    "        gamma_ab = rho[:, 3]\n",
    "        gamma_b = rho[:, 4]\n",
    "        tau_a = rho[:, 7]\n",
    "        tau_b = rho[:, 8]\n",
    "        nl = rho[:,9:]\n",
    "        nl_size = jnp.size(nl, -1)//2\n",
    "        nl_a = nl[:,:nl_size]\n",
    "        nl_b = nl[:,nl_size:]\n",
    "\n",
    "        C_F= 3/10*(3*np.pi**2)**(2/3)\n",
    "        rho0_a_ueg = rho0_a\n",
    "        rho0_b_ueg = rho0_b\n",
    "\n",
    "        zeta = (rho0_a_ueg - rho0_b_ueg)/(rho0_a_ueg + rho0_b_ueg + 1e-8)\n",
    "        rs = (4*np.pi/3*(rho0_a_ueg+rho0_b_ueg + 1e-8))**(-1/3)\n",
    "        rs_a = (4*np.pi/3*(rho0_a_ueg + 1e-8))**(-1/3)\n",
    "        rs_b = (4*np.pi/3*(rho0_b_ueg + 1e-8))**(-1/3)\n",
    "\n",
    "        #initialize zero values for the ex/ec/grid values\n",
    "        exc_a = jnp.zeros_like(rho0_a)\n",
    "        exc_b = jnp.zeros_like(rho0_a)\n",
    "        exc_ab = jnp.zeros_like(rho0_a)\n",
    "\n",
    "        if self.debug:\n",
    "            print('eval_grid_models nan summary:')\n",
    "            print('zeta, rs, rs_a, rs_b, exc_a, exc_b, exc_ab')\n",
    "            print('{}, {}, {}, {}, {}, {}, {}'.format(\n",
    "                jnp.sum(jnp.any(jnp.isnan(zeta))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(rs))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(rs_a))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(rs_b))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(exc_a))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(exc_b))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(exc_ab))),                \n",
    "            ))\n",
    "\n",
    "        descr_dict = {}\n",
    "        rho_tot = rho0_a + rho0_b\n",
    "        #spin scaling false descriptors\n",
    "        descr_dict[False] = self.get_descriptors(rho0_a, rho0_b, gamma_a, gamma_b,\n",
    "                                                         gamma_ab, nl_a, nl_b, tau_a, tau_b, spin_scaling = False,\n",
    "                                                mf = mf, dm = dm)\n",
    "        #spin scaling true descriptors\n",
    "        descr_dict[True] = self.get_descriptors(rho0_a, rho0_b, gamma_a, gamma_b,\n",
    "                                                         gamma_ab, nl_a, nl_b, tau_a, tau_b, spin_scaling = True,\n",
    "                                               mf = mf, dm = dm)\n",
    "\n",
    "        def else_test_fun(exc, exc_b):\n",
    "            if self.heg_mult:\n",
    "                exc_b += (1 + exc[1])*self.heg_model(2*rho0_b_ueg)*(1-self.exx_a)\n",
    "            else:\n",
    "                exc_b += exc[1]*(1-self.exx_a)\n",
    "            return exc_b\n",
    "            \n",
    "        def if_not_test_fun(exc, exc_b):\n",
    "            exc_b += exc[0]*0\n",
    "            return exc_b\n",
    "\n",
    "        def gm_eval_func(grid_model, exc_a, exc_b, exc_ab):\n",
    "            if not grid_model.spin_scaling:\n",
    "                descr = descr_dict[False]\n",
    "                print(f\"spin_scaling = False; input descr to exc shape: {descr.shape}\")\n",
    "                exc = grid_model(descr)\n",
    "                if jnp.ndim(exc) == 2: #If using spin decomposition\n",
    "                    pw_alpha = self.pw_model(rs_a, jnp.ones_like(rs_a))\n",
    "                    pw_beta = self.pw_model(rs_b, jnp.ones_like(rs_b))\n",
    "                    pw = self.pw_model(rs, zeta)\n",
    "                    ec_alpha = (1 + exc[:,0])*pw_alpha*rho0_a/(rho_tot+1e-8)\n",
    "                    ec_beta =  (1 + exc[:,1])*pw_beta*rho0_b/(rho_tot+1e-8)\n",
    "                    ec_mixed = (1 + exc[:,2])*(pw*rho_tot - pw_alpha*rho0_a - pw_beta*rho0_b)/(rho_tot+1e-8)\n",
    "                    exc_ab += ec_alpha + ec_beta + ec_mixed\n",
    "                else:\n",
    "                    if self.pw_mult:\n",
    "                        exc_ab += (1 + exc)*self.pw_model(rs, zeta)\n",
    "                    else:\n",
    "                        exc_ab += exc\n",
    "            else:\n",
    "                descr = descr_dict[True]\n",
    "                print(f\"spin_scaling = True; input descr to exc shape: {descr.shape}\")\n",
    "                exc = grid_model(descr)\n",
    "\n",
    "\n",
    "                if self.heg_mult:\n",
    "                    exc_a += (1 + exc[0])*self.heg_model(2*rho0_a_ueg)*(1-self.exx_a)\n",
    "                else:\n",
    "                    exc_a += exc[0]*(1-self.exx_a)\n",
    "                test = jnp.sum(jnp.abs(rho0_b))\n",
    "                exc_b = jax.lax.cond(test, else_test_fun, if_not_test_fun, exc, exc_b)\n",
    "\n",
    "            return (exc_a, exc_b, exc_ab)\n",
    "\n",
    "        if self.grid_models:\n",
    "            exc_a, exc_b, exc_ab = gm_eval_func(self.grid_models[0], exc_a, exc_b, exc_ab)\n",
    "            exc_a, exc_b, exc_ab = gm_eval_func(self.grid_models[1], exc_a, exc_b, exc_ab)                    \n",
    "        else:\n",
    "            if self.heg_mult:\n",
    "                exc_a = self.heg_model(2*rho0_a_ueg)\n",
    "                exc_b = self.heg_model(2*rho0_b_ueg)\n",
    "            if self.pw_mult:\n",
    "                exc_ab = self.pw_model(rs, zeta)\n",
    "\n",
    "\n",
    "        exc = exc_a * (rho0_a_ueg/ (rho_tot + self.epsilon)) + exc_b*(rho0_b_ueg / (rho_tot + self.epsilon)) + exc_ab\n",
    "        if self.debug:\n",
    "            print('eval_grid_models nan summary:')\n",
    "            print('zeta, rs, rs_a, rs_b, exc_a, exc_b, exc_ab')\n",
    "            print('{}, {}, {}, {}, {}, {}, {}'.format(\n",
    "                jnp.sum(jnp.any(jnp.isnan(zeta))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(rs))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(rs_a))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(rs_b))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(exc_a))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(exc_b))),\n",
    "                jnp.sum(jnp.any(jnp.isnan(exc_ab))),                \n",
    "            ))\n",
    "\n",
    "        return jnp.expand_dims(exc, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9d64854-d562-4a95-ba78-205e9f3a98bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update docs, only input =2 ??? for MGGA? holdover from sebastian for some reason\n",
    "xnet = xce.net.eX(n_input = 2, use = [1, 2], ueg_limit=True, lob=1.174)\n",
    "# I guess use default LOB\n",
    "cnet = xce.net.eC(n_input = 4, use = [2, 3], ueg_limit=True)\n",
    "blankxc = xce.xc.eXC(grid_models = [xnet, cnet], level=3)\n",
    "p = '/home/awills/Documents/Research/xcquinox/models/pretrained/scan'\n",
    "# xc = eqx.tree_deserialise_leaves(os.path.join(p, 'xc.eqx'), blankxc)\n",
    "xc = blankxc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff290535-cea2-4978-a0ed-4b835a93d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Non-local models highly experimental and likely will not work \n"
     ]
    }
   ],
   "source": [
    "nlxnet = eX(n_input = 15, use = [], ueg_limit=True, lob=1.174)\n",
    "nlcnet = eC(n_input = 13, use = [], ueg_limit=True)\n",
    "\n",
    "nlxc = eXC(grid_models = [nlxnet, nlcnet], level=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9b816618-1efa-4c63-9c89-8d44503156fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NL_E_loss(eqx.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        The standard energy loss module, RMSE loss of predicted vs. reference energies.\n",
    "        '''\n",
    "        super().__init__()\n",
    "\n",
    "    def __call__(self, model, inp_dm, ref_en, ao_eval, grid_weights, mf):\n",
    "        '''\n",
    "        Computes the energy loss for a given model and associated input density matrix, atomic orbitals on the grid, and grid weights\n",
    "\n",
    "        Loss is the RMSE energy, so predicted energy can potentially be a jax.Array of SCF guesses.\n",
    "\n",
    "        :param model: The XC object whose forward pass predicts the XC energy based on the inputs here.\n",
    "        :type model: xcquinox.xc.eXC\n",
    "        :param inp_dm: The density matrix to pass into the network for density creation on the grid.\n",
    "        :type inp_dm: jax.Array\n",
    "        :param ref_en: The reference energy to take the loss with respect to.\n",
    "        :type ref_en: jax.Array\n",
    "        :param ao_eval: Atomic orbitals evaluated on the grid\n",
    "        :type ao_eval: jax.Array\n",
    "        :param grid_weights: pyscfad's grid weights for the reference calculation\n",
    "        :type grid_weights: jax.Array\n",
    "        :return: The RMSE error.\n",
    "        :rtype: jax.Array\n",
    "        '''\n",
    "        e_pred = model(inp_dm, ao_eval, grid_weights, mf)\n",
    "        eL = jnp.sqrt( jnp.mean((e_pred-ref_en)**2))\n",
    "        return eL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc33e1f8-f680-4a5f-a3a1-c077b614e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awills/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/pbc/gto/cell.py:243: UserWarning: Function cell.dumps drops attribute coords because it is not JSON-serializable\n",
      "  warnings.warn(msg)\n",
      "/home/awills/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/pbc/gto/cell.py:243: UserWarning: Function cell.dumps drops attribute a because it is not JSON-serializable\n",
      "  warnings.warn(msg)\n",
      "/home/awills/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/pbc/gto/cell.py:243: UserWarning: Function cell.dumps drops attribute abc because it is not JSON-serializable\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "cell = gtop.Cell()\n",
    "a = 5.43\n",
    "cell.atom = [['Si', [0,0,0]],\n",
    "              ['Si', [a/4,a/4,a/4]]]\n",
    "cell.a = jnp.asarray([[0, a/2, a/2],\n",
    "                     [a/2, 0, a/2],\n",
    "                     [a/2, a/2, 0]])\n",
    "cell.basis = 'gth-szv'\n",
    "cell.pseudo = 'gth-pade'\n",
    "cell.exp_to_discard = 0.1\n",
    "cell.build(trace_lattice_vectors=True)\n",
    "kpts = cell.make_kpts([2,2,2])\n",
    "mf = scfp.KRHF(cell, kpts=kpts)\n",
    "e = mf.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cce8d7a-6883-4130-97c0-59e17f7604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = mf.get_bands(kpts, cell=cell, kpts=kpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b0f78e2-e5eb-4cec-ac0d-ba58fa8ea090",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3855865464.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    hcc = mf.get_hcore(cell, kpts)??\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "hcc = mf.get_hcore(cell, kpts)??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b781a1c-4f6a-4c8b-a12b-eb824e88d7fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0b77f9a-df82-42f8-9a3f-921d18019c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hcore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Get the core Hamiltonian AO matrices at sampled k-points.\n",
       "\n",
       "Args:\n",
       "    kpts : (nkpts, 3) ndarray\n",
       "\n",
       "Returns:\n",
       "    hcore : (nkpts, nao, nao) ndarray\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0mget_hcore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mkpts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkpts\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpseudo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mnuc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ecpbas\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbc_intor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int1e_kin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhermi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkpts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0mnuc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/pbc/scf/khf.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf.get_hcore??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a5fd4b0-f3ce-4f42-b7e1-b9ddc2a89601",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkpts = cell.pbc_intor('int1e_kin', comp=1, hermi=1, kpts=kpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d19ffde-2a2c-4551-9d8c-027dcec6ed96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tkpts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e777a8a-f9e4-4a7b-9e9c-37bfba29c250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m        list\n",
       "\u001b[0;31mString form:\u001b[0m\n",
       "[array([[-5.11785471e-01+8.11619500e-19j, -9.18410647e-16-3.05577232e-17j,\n",
       "           -8.54822546e-1 <...> -01+6.18995023e-02j,\n",
       "           -2.74367362e-01-5.82588369e-01j, -7.07003474e-01+1.49945011e-15j]])]\n",
       "\u001b[0;31mLength:\u001b[0m      8\n",
       "\u001b[0;31mDocstring:\u001b[0m  \n",
       "Built-in mutable sequence.\n",
       "\n",
       "If no argument is given, the constructor creates a new empty list.\n",
       "The argument must be an iterable if specified."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf.mo_coeff?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8e58e42-14b7-4ddb-8bd7-6724372fcdc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_rdm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmo_coeff_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo_occ_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "One-particle density matrix in AO representation\n",
       "\n",
       "Args:\n",
       "    mo_coeff : 2D ndarray\n",
       "        Orbital coefficients. Each column is one orbital.\n",
       "    mo_occ : 1D ndarray\n",
       "        Occupancy\n",
       "Returns:\n",
       "    One-particle density matrix, 2D ndarray\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mmake_rdm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo_coeff_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo_occ_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmo_coeff_kpts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmo_coeff_kpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmo_coeff\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mmo_occ_kpts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmo_occ_kpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmo_occ\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmake_rdm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmo_coeff_kpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo_occ_kpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscfad/pbc/scf/khf.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf.make_rdm1??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a281180a-f8a6-43d4-80b7-f0a3b88b5830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyscfad.pbc.scf.khf.KSCF"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d87cd3-6f88-4c6a-8a9c-f068bfcd85ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkpts_band\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mget_bands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts_band\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm_kpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m'''Get energy bands at the given (arbitrary) 'band' k-points.\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m        Returns:\u001b[0m\n",
       "\u001b[0;34m            mo_energy : (nmo,) ndarray or a list of (nmo,) ndarray\u001b[0m\n",
       "\u001b[0;34m                Bands energies E_n(k)\u001b[0m\n",
       "\u001b[0;34m            mo_coeff : (nao, nmo) ndarray or a list of (nao,nmo) ndarray\u001b[0m\n",
       "\u001b[0;34m                Band orbitals psi_n(k)\u001b[0m\n",
       "\u001b[0;34m        '''\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mdm_kpts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdm_kpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_rdm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mkpts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkpts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkpts\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkpts_band\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkpts_band\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0msingle_kpt_band\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkpts_band\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkpts_band\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkpts_band\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_hcore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts_band\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mfock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfock\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_veff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm_kpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkpts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts_band\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkpts_band\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0ms1e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ovlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkpts_band\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmo_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo_coeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1e\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0msingle_kpt_band\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmo_energy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmo_energy\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mmo_coeff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmo_coeff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mmo_energy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmo_coeff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/pbc/scf/khf.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mf.get_bands??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "153018d6-9bb2-4732-91c3-8bf8ed435b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.30616192,  0.30616192, -0.30616192],\n",
       "       [ 0.30616192, -0.30616192,  0.30616192],\n",
       "       [ 0.61232384,  0.        ,  0.        ],\n",
       "       [-0.30616192,  0.30616192,  0.30616192],\n",
       "       [ 0.        ,  0.61232384,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.61232384],\n",
       "       [ 0.30616192,  0.30616192,  0.30616192]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d84583e8-a0b9-4b9b-b7c1-c9bbc5429b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_kn = bands[0]\n",
    "vbmax = -99\n",
    "for en in e_kn:\n",
    "    vb_k = en[cell.nelectron//2-1]\n",
    "    if vb_k > vbmax:\n",
    "        vbmax = vb_k\n",
    "e_kn = [en - vbmax for en in e_kn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5487074-a90c-4981-9c93-8d5b55c7d0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([-6.14187342e-01+0.j, -1.82144603e-11+0.j, -7.58227015e-12+0.j,\n",
       "         0.00000000e+00+0.j,  5.50609333e-01+0.j,  5.50609333e-01+0.j,\n",
       "         5.50609333e-01+0.j,  5.95700834e-01+0.j], dtype=complex128),\n",
       " Array([-0.49454436+0.j, -0.34280689+0.j, -0.07186577+0.j, -0.07186577+0.j,\n",
       "         0.56397967+0.j,  0.66943433+0.j,  0.66943433+0.j,  0.93730272+0.j],      dtype=complex128),\n",
       " Array([-0.49454436+0.j, -0.34280689+0.j, -0.07186577+0.j, -0.07186577+0.j,\n",
       "         0.56397967+0.j,  0.66943433+0.j,  0.66943433+0.j,  0.93730272+0.j],      dtype=complex128),\n",
       " Array([-0.39825575+0.j, -0.39825575+0.j, -0.15064707+0.j, -0.15064707+0.j,\n",
       "         0.6127736 +0.j,  0.6127736 +0.j,  0.88688775+0.j,  0.88688775+0.j],      dtype=complex128),\n",
       " Array([-0.49454436+0.j, -0.34280689+0.j, -0.07186577+0.j, -0.07186577+0.j,\n",
       "         0.56397967+0.j,  0.66943433+0.j,  0.66943433+0.j,  0.93730272+0.j],      dtype=complex128),\n",
       " Array([-0.39825575+0.j, -0.39825575+0.j, -0.15064707+0.j, -0.15064707+0.j,\n",
       "         0.6127736 +0.j,  0.6127736 +0.j,  0.88688775+0.j,  0.88688775+0.j],      dtype=complex128),\n",
       " Array([-0.39825575+0.j, -0.39825575+0.j, -0.15064707+0.j, -0.15064707+0.j,\n",
       "         0.6127736 +0.j,  0.6127736 +0.j,  0.88688775+0.j,  0.88688775+0.j],      dtype=complex128),\n",
       " Array([-0.49454436+0.j, -0.34280689+0.j, -0.07186577+0.j, -0.07186577+0.j,\n",
       "         0.56397967+0.j,  0.66943433+0.j,  0.66943433+0.j,  0.93730272+0.j],      dtype=complex128)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_kn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e368be14-122e-4c78-b98e-c4a94815684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Array([-6.14566376e-01+0.j, -3.79034099e-04+0.j, -3.79034089e-04+0.j,\n",
       "        -3.79034081e-04+0.j,  5.50230299e-01+0.j,  5.50230299e-01+0.j,\n",
       "         5.50230299e-01+0.j,  5.95321800e-01+0.j], dtype=complex128),\n",
       " Array([-0.49492339+0.j, -0.34318592+0.j, -0.0722448 +0.j, -0.0722448 +0.j,\n",
       "         0.56360064+0.j,  0.66905529+0.j,  0.66905529+0.j,  0.93692368+0.j],      dtype=complex128),\n",
       " Array([-0.49492339+0.j, -0.34318592+0.j, -0.0722448 +0.j, -0.0722448 +0.j,\n",
       "         0.56360064+0.j,  0.66905529+0.j,  0.66905529+0.j,  0.93692368+0.j],      dtype=complex128),\n",
       " Array([-0.39863479+0.j, -0.39863479+0.j, -0.1510261 +0.j, -0.1510261 +0.j,\n",
       "         0.61239457+0.j,  0.61239457+0.j,  0.88650872+0.j,  0.88650872+0.j],      dtype=complex128),\n",
       " Array([-0.49492339+0.j, -0.34318592+0.j, -0.0722448 +0.j, -0.0722448 +0.j,\n",
       "         0.56360064+0.j,  0.66905529+0.j,  0.66905529+0.j,  0.93692368+0.j],      dtype=complex128),\n",
       " Array([-0.39863479+0.j, -0.39863479+0.j, -0.1510261 +0.j, -0.1510261 +0.j,\n",
       "         0.61239457+0.j,  0.61239457+0.j,  0.88650872+0.j,  0.88650872+0.j],      dtype=complex128),\n",
       " Array([-0.39863479+0.j, -0.39863479+0.j, -0.1510261 +0.j, -0.1510261 +0.j,\n",
       "         0.61239457+0.j,  0.61239457+0.j,  0.88650872+0.j,  0.88650872+0.j],      dtype=complex128),\n",
       " Array([-0.49492339+0.j, -0.34318592+0.j, -0.0722448 +0.j, -0.0722448 +0.j,\n",
       "         0.56360064+0.j,  0.66905529+0.j,  0.66905529+0.j,  0.93692368+0.j],      dtype=complex128)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65312b28-8c51-47c2-8127-efef5b0f7946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bands[0]), len(bands[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f90722e4-90e9-43e7-953b-9b8f9c270a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIOR TO POST PROCESS 25274.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25274.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24114.0\n",
      "MO VELE MAT 1127092224 23008.0\n",
      "FINISHED POST PROCESS 23008.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25250.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25255.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24121.0\n",
      "MO VELE MAT 1127092224 23000.0\n",
      "FINISHED POST PROCESS 23000.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Array(-13.92249356, dtype=float64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlxc(dm, ao_eval, mf.grids.weights, mf=mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6cf09f2c-968e-4cc6-ba4c-b43a98391ca3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Epoch 0 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25261.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25261.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24129.0\n",
      "MO VELE MAT 1127092224 23012.0\n",
      "FINISHED POST PROCESS 23012.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25267.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25270.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24137.0\n",
      "MO VELE MAT 1127092224 23007.0\n",
      "FINISHED POST PROCESS 23007.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25269.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25269.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24133.0\n",
      "MO VELE MAT 1127092224 23008.0\n",
      "FINISHED POST PROCESS 23008.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25262.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25264.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24135.0\n",
      "MO VELE MAT 1127092224 23031.0\n",
      "FINISHED POST PROCESS 23031.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.2650463341350964\n",
      "step=0, epoch_train_loss=0.2650463341350964\n",
      "Epoch 1\n",
      "Epoch 1 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25294.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25294.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24131.0\n",
      "MO VELE MAT 1127092224 23003.0\n",
      "FINISHED POST PROCESS 23003.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25271.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25271.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24146.0\n",
      "MO VELE MAT 1127092224 23020.0\n",
      "FINISHED POST PROCESS 23020.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25297.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25297.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24149.0\n",
      "MO VELE MAT 1127092224 23036.0\n",
      "FINISHED POST PROCESS 23036.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25277.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25277.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24166.0\n",
      "MO VELE MAT 1127092224 23022.0\n",
      "FINISHED POST PROCESS 23022.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.2628795395406751\n",
      "step=1, epoch_train_loss=0.2628795395406751\n",
      "Epoch 2\n",
      "Epoch 2 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25294.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25294.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24131.0\n",
      "MO VELE MAT 1127092224 23001.0\n",
      "FINISHED POST PROCESS 23001.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25269.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25269.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24126.0\n",
      "MO VELE MAT 1127092224 23024.0\n",
      "FINISHED POST PROCESS 23024.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25291.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25291.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24140.0\n",
      "MO VELE MAT 1127092224 23015.0\n",
      "FINISHED POST PROCESS 23015.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25284.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25283.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24155.0\n",
      "MO VELE MAT 1127092224 23037.0\n",
      "FINISHED POST PROCESS 23037.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.26060511630729266\n",
      "step=2, epoch_train_loss=0.26060511630729266\n",
      "Epoch 3\n",
      "Epoch 3 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25316.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25316.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24152.0\n",
      "MO VELE MAT 1127092224 23016.0\n",
      "FINISHED POST PROCESS 23016.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25278.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25278.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24155.0\n",
      "MO VELE MAT 1127092224 23022.0\n",
      "FINISHED POST PROCESS 23022.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25274.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25274.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24139.0\n",
      "MO VELE MAT 1127092224 23015.0\n",
      "FINISHED POST PROCESS 23015.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25269.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25269.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24121.0\n",
      "MO VELE MAT 1127092224 22996.0\n",
      "FINISHED POST PROCESS 22996.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.2582163611488788\n",
      "step=3, epoch_train_loss=0.2582163611488788\n",
      "Epoch 4\n",
      "Epoch 4 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25266.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25266.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24111.0\n",
      "MO VELE MAT 1127092224 22992.0\n",
      "FINISHED POST PROCESS 22992.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25268.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25268.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24127.0\n",
      "MO VELE MAT 1127092224 22995.0\n",
      "FINISHED POST PROCESS 22995.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25272.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25272.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24127.0\n",
      "MO VELE MAT 1127092224 23005.0\n",
      "FINISHED POST PROCESS 23005.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25264.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25264.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24124.0\n",
      "MO VELE MAT 1127092224 23003.0\n",
      "FINISHED POST PROCESS 23003.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.2557060416681729\n",
      "step=4, epoch_train_loss=0.2557060416681729\n",
      "Epoch 5\n",
      "Epoch 5 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25270.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25270.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24113.0\n",
      "MO VELE MAT 1127092224 22988.0\n",
      "FINISHED POST PROCESS 22988.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25240.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25239.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24122.0\n",
      "MO VELE MAT 1127092224 23007.0\n",
      "FINISHED POST PROCESS 23007.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25273.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25273.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24120.0\n",
      "MO VELE MAT 1127092224 22984.0\n",
      "FINISHED POST PROCESS 22984.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25235.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25235.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24113.0\n",
      "MO VELE MAT 1127092224 23001.0\n",
      "FINISHED POST PROCESS 23001.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.25306635391473087\n",
      "step=5, epoch_train_loss=0.25306635391473087\n",
      "Epoch 6\n",
      "Epoch 6 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25270.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25270.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24101.0\n",
      "MO VELE MAT 1127092224 22977.0\n",
      "FINISHED POST PROCESS 22977.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25238.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25244.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24105.0\n",
      "MO VELE MAT 1127092224 22973.0\n",
      "FINISHED POST PROCESS 22973.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25254.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25254.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24118.0\n",
      "MO VELE MAT 1127092224 22994.0\n",
      "FINISHED POST PROCESS 22994.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25257.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25258.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24112.0\n",
      "MO VELE MAT 1127092224 23008.0\n",
      "FINISHED POST PROCESS 23008.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.25028887573473213\n",
      "step=6, epoch_train_loss=0.25028887573473213\n",
      "Epoch 7\n",
      "Epoch 7 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25262.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25266.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24098.0\n",
      "MO VELE MAT 1127092224 22985.0\n",
      "FINISHED POST PROCESS 22985.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25241.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25241.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24115.0\n",
      "MO VELE MAT 1127092224 22989.0\n",
      "FINISHED POST PROCESS 22989.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25281.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25281.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24113.0\n",
      "MO VELE MAT 1127092224 22999.0\n",
      "FINISHED POST PROCESS 22999.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25256.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25256.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24120.0\n",
      "MO VELE MAT 1127092224 22999.0\n",
      "FINISHED POST PROCESS 22999.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.2473645151592727\n",
      "step=7, epoch_train_loss=0.2473645151592727\n",
      "Epoch 8\n",
      "Epoch 8 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25271.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25271.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24128.0\n",
      "MO VELE MAT 1127092224 22980.0\n",
      "FINISHED POST PROCESS 22980.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25244.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25244.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24121.0\n",
      "MO VELE MAT 1127092224 22993.0\n",
      "FINISHED POST PROCESS 22993.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25268.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25268.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24137.0\n",
      "MO VELE MAT 1127092224 23018.0\n",
      "FINISHED POST PROCESS 23018.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25280.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25280.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24149.0\n",
      "MO VELE MAT 1127092224 23035.0\n",
      "FINISHED POST PROCESS 23035.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Loss = 0.24428345292365172\n",
      "step=8, epoch_train_loss=0.24428345292365172\n",
      "Epoch 9\n",
      "Epoch 9 :: Batch 0/1\n",
      "PRIOR TO POST PROCESS 25295.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25295.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24132.0\n",
      "MO VELE MAT 1127092224 23009.0\n",
      "FINISHED POST PROCESS 23009.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25272.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25275.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24141.0\n",
      "MO VELE MAT 1127092224 23021.0\n",
      "FINISHED POST PROCESS 23021.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25277.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25276.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24143.0\n",
      "MO VELE MAT 1127092224 23023.0\n",
      "FINISHED POST PROCESS 23023.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25280.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25279.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24145.0\n",
      "MO VELE MAT 1127092224 23031.0\n",
      "FINISHED POST PROCESS 23031.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "Batch Loss = 0.24103507812610836\n",
      "step=9, epoch_train_loss=0.24103507812610836\n"
     ]
    }
   ],
   "source": [
    "trainer = xce.train.xcTrainer(model=nlxc, optim=optax.adamw(1e-4), steps=10, loss = NL_E_loss(), do_jit=False)\n",
    "newm = trainer(1, trainer.model, dms, energies, ao_evals, gws, mfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "55b52220-37e4-4646-8927-bff4917f1669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:CUDA backend failed to initialize: Found CUDA version 12010, but JAX was built against version 12030, which is newer. The copy of CUDA that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIOR TO POST PROCESS 25220.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25220.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24072.0\n",
      "MO VELE MAT 1127092224 22950.0\n",
      "FINISHED POST PROCESS 22950.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25211.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25211.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24076.0\n",
      "MO VELE MAT 1127092224 22938.0\n",
      "FINISHED POST PROCESS 22938.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n",
      "PRIOR TO POST PROCESS 25216.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25216.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24062.0\n",
      "MO VELE MAT 1127092224 22932.0\n",
      "FINISHED POST PROCESS 22932.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "PRIOR TO POST PROCESS 25183.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 25183.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 24051.0\n",
      "MO VELE MAT 1127092224 22928.0\n",
      "FINISHED POST PROCESS 22928.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n",
      "spin_scaling = True; input descr to exc shape: (25728, 15)\n",
      "eX.__call__, rho shape: (25728, 15)\n",
      "spin_scaling = False; input descr to exc shape: (25728, 13)\n",
      "eC.__call__, rho shape: (25728, 13)\n"
     ]
    }
   ],
   "source": [
    "en1 = nlxc(dms[0], ao_evals[0], gws[0], mfs[0])\n",
    "en2 = newm(dms[0], ao_evals[0], gws[0], mfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "de5ae189-6d95-4930-b0dc-083e9b85fc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(0.26504633, dtype=float64), Array(0.23760792, dtype=float64))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(en1-energies[0]), abs(en2-energies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2c533-e349-4140-9a62-c8c2708793b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db599d3e-8a58-4edc-94c6-ee4d78ed8e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ptscan = get_torch_xc(xctype='MGGA', pretrain_loc='/home/awills/Documents/Research/dpyscfl/models/pretrained/scan',\n",
    "#                 nhidden=16)\n",
    "# tgms = ptscan.grid_models\n",
    "# t_x_w, t_x_b = get_torch_weights_and_biases(tgms[0].net)\n",
    "# t_c_w, t_c_b = get_torch_weights_and_biases(tgms[1].net)\n",
    "\n",
    "# xnet = init_linear_weight(xnet, seed=92017, new_weights = t_x_w, new_bias = t_x_b)\n",
    "# cnet = init_linear_weight(cnet, seed=92017, new_weights = t_c_w, new_bias = t_c_b)\n",
    "# gms = [xnet, cnet]\n",
    "# xc = xce.xc.eXC(grid_models = gms, level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776c0275-d16e-4c04-a0f6-6b3e273be21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xcd = get_torch_xc(xctype='MGGA', path='/home/awills/Documents/Research/torch_dpy/models/xcdiff/MODEL_MGGA/xc')\n",
    "# tgms = xcd.grid_models\n",
    "# t_x_w, t_x_b = get_torch_weights_and_biases(tgms[0].net)\n",
    "# t_c_w, t_c_b = get_torch_weights_and_biases(tgms[1].net)\n",
    "\n",
    "# xnet = init_linear_weight(xnet, seed=92017, new_weights = t_x_w, new_bias = t_x_b)\n",
    "# cnet = init_linear_weight(cnet, seed=92017, new_weights = t_c_w, new_bias = t_c_b)\n",
    "# gms = [xnet, cnet]\n",
    "# xceqx = xce.xc.eXC(grid_models = gms, level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a6a71-e226-4b0c-b69d-f30fe33f83cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xcdp = '/home/awills/Documents/Research/xcquinox/models/xcdiff'\n",
    "# eqx.tree_serialise_leaves(os.path.join(xcdp, 'xc.eqx'), xceqx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41362b-346a-4109-b197-2ad96aa1d3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xc.grid_models[0].net.layers[0].weight - xceqx.grid_models[0].net.layers[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebe944d-de21-47c7-9c1b-265ee137d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = '/home/awills/Documents/Research/xcquinox/models/pretrained/scan'\n",
    "# eqx.tree_serialise_leaves(os.path.join(p, 'xc.eqx'), xc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa151a52-1a98-4651-9dd5-62c12a76030f",
   "metadata": {},
   "source": [
    "Test molecule with pyscfad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92697109-fac8-48ae-8282-5b8d556bc694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awills/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/gto/mole.py:1215: UserWarning: Function mol.dumps drops attribute coords because it is not JSON-serializable\n",
      "  warnings.warn(msg)\n",
      "/home/awills/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/gto/mole.py:1215: UserWarning: Function mol.dumps drops attribute exp because it is not JSON-serializable\n",
      "  warnings.warn(msg)\n",
      "/home/awills/anaconda3/envs/pyscfad/lib/python3.10/site-packages/pyscf/gto/mole.py:1215: UserWarning: Function mol.dumps drops attribute ctr_coeff because it is not JSON-serializable\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -109.525964831721\n"
     ]
    }
   ],
   "source": [
    "trainms = read('/home/awills/Documents/Research/torch_dpy/subset09_nf/subat_ref_corrected.traj', ':')\n",
    "mfs = []\n",
    "mols = []\n",
    "energies = []\n",
    "dms = []\n",
    "ao_evals = []\n",
    "gws = []\n",
    "eris = []\n",
    "mo_occs = []\n",
    "hcs = []\n",
    "vs = []\n",
    "ts = []\n",
    "ss = []\n",
    "hologaps = []\n",
    "ogds = []\n",
    "for idx, at in enumerate(trainms[1:2]):\n",
    "    name, mol = xce.utils.ase_atoms_to_mol(at, basis='def2tzvpd')\n",
    "    mol.build()\n",
    "    mols.append(mol)\n",
    "    mf = dft.RKS(mol, xc='SCAN')\n",
    "    e_tot = mf.kernel()\n",
    "    mfs.append(mf)\n",
    "    dm = mf.make_rdm1()\n",
    "    ao_eval = jnp.array(mf._numint.eval_ao(mol, mf.grids.coords, deriv=2))\n",
    "    energies.append(mf.get_veff().exc)\n",
    "    dms.append(dm)\n",
    "    ogds.append(dm.shape)\n",
    "    ao_evals.append(ao_eval)\n",
    "    gws.append(mf.grids.weights)\n",
    "    ts.append(mol.intor('int1e_kin'))\n",
    "    vs.append(mol.intor('int1e_nuc'))\n",
    "    mo_occs.append(mf.mo_occ)\n",
    "    hcs.append(mf.get_hcore())\n",
    "    eris.append(mol.intor('int2e'))\n",
    "    ss.append(jnp.linalg.inv(jnp.linalg.cholesky(mol.intor('int1e_ovlp'))))\n",
    "    hologaps.append(mf.mo_energy[mf.mo_occ == 0][0] - mf.mo_energy[mf.mo_occ > 1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbf3b3ce-1cad-493d-84bb-28c27cfb7357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc.grid_models[0].spin_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82391e24-5e3a-4b8d-bbe2-3974a2439cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array(-12.76261576, dtype=float64), -13.657447221972637)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc(dm, ao_eval, mf.grids.weights), mf.get_veff().exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b438509e-3976-48ca-a357-41f26fec8890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIOR TO POST PROCESS 27858.0\n",
      "post_process, self.grid shape: (25728, 3)\n",
      "NUMBER OF CHUNKS RHF 1 float64 27830.0\n",
      "get_vele_mat, returned shape: (74, 74, 25728)\n",
      "get_vele_mat, points shape: (25728, 3)\n",
      "AO VELE MAT 1127092224 (25728, 74, 74)\n",
      "MEM NOW 26674.0\n",
      "MO VELE MAT 1127092224 25510.0\n",
      "FINISHED POST PROCESS 25510.0\n",
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n"
     ]
    }
   ],
   "source": [
    "an = RKSAnalyzer(calc=mf)\n",
    "#these are the OUTPUTs from contract_exchange_descriptors, which ARE the rotationally invariant quantities.\n",
    "#per the final call in _get_x_helper\n",
    "#the return quantities are indexed as\n",
    "# res\n",
    "# 0:  rho\n",
    "# 1:  s\n",
    "# 2:  alpha\n",
    "# 3:  g0\n",
    "# 4:  norm(g1)**2\n",
    "# 5:  g1 dot svec\n",
    "# 6:  norm(g2)**2\n",
    "# 7:  svec dot g2 dot svec\n",
    "# 8:  g1 dot g2 dot svec\n",
    "# 9:  g1 dot g2 dot g1\n",
    "# 10: g0-r^2\n",
    "# 11: g0-r^4\n",
    "descr = get_exchange_descriptors2(an, restricted=True, version='c', auxbasis='def2tzvp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dae3d0f9-09ee-4533-ad4d-2dbe6c72ba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 25728)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52efc3d9-8f5c-420e-bb4e-4f122d069f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74] (74,)\n",
      "(74, 74) (74, 74)\n",
      "Spin unpolarized make_rdm1()\n"
     ]
    }
   ],
   "source": [
    "vgf = lambda x: xc(x, ao_evals[0], gws[0])\n",
    "dmp, moe, moc = xce.utils.get_dm_moe(dms[0], eris[0], vgf, mo_occs[0], hcs[0],ss[0], ogds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f003146-68d0-485a-a92a-a867d99e01ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nao in get_exchange_descriptors2: 74\n",
      "naux in get_exchange_descriptors2: 74\n",
      "ao_to_aux shape: (74, 74, 74)\n"
     ]
    }
   ],
   "source": [
    "descr3 = jnp.asarray(get_exchange_descriptors2(an, restricted=True, version='c', auxbasis='def2tzvp',\n",
    "                                   rdm1=True, dm=np.asarray(dmp), inmol=True, mol=mol, ingrid=True, grid=mf.grids))\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876b3920-b417-4545-ab08-f3fa647d7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlstart_i, nlend_i = (3,12)\n",
    "nldesc = descr3[nlstart_i:nlend_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26464774-26ca-4073-b44d-dba00e6a19e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 25728)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nldesc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33d98e1-1512-4328-829e-4930a226927c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "169d6c18-6c41-49fd-b8f1-e8bf494602f4",
   "metadata": {},
   "source": [
    "Create silicon cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecf4efd-e924-4751-93b0-e35b432c3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = gtop.Cell()\n",
    "a = 5.43\n",
    "cell.atom = [['Si', [0,0,0]],\n",
    "              ['Si', [a/4,a/4,a/4]]]\n",
    "cell.a = jnp.asarray([[0, a/2, a/2],\n",
    "                     [a/2, 0, a/2],\n",
    "                     [a/2, a/2, 0]])\n",
    "cell.basis = 'gth-szv'\n",
    "cell.pseudo = 'gth-pade'\n",
    "cell.exp_to_discard = 0.1\n",
    "cell.build(trace_lattice_vectors=True)\n",
    "kpts = cell.make_kpts([2,2,2])\n",
    "mf = scfp.KRHF(cell, kpts=kpts)\n",
    "e = mf.kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd40a2a-4f3d-4d32-be14-31ad5e29efb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
