no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/condabin/conda
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/bin/conda
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/bin/conda-env
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/bin/activate
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/bin/deactivate
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/etc/profile.d/conda.sh
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/etc/fish/conf.d/conda.fish
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/shell/condabin/Conda.psm1
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/shell/condabin/conda-hook.ps1
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/lib/python3.9/site-packages/xontrib/conda.xsh
no change     /gpfs/projects/FernandezGroup/Alec/miniconda3/etc/profile.d/conda.csh
no change     /gpfs/home/jofranklin/.bashrc
No action taken.
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165240> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165240> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeac165240> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac164a30> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1661a0> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac166350> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac167c70> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1648e0> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac164790> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1640d0> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1666b0> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac164880> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac165030> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac165990> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1655a0> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac165a20> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac166560> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac164670> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac165270> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1649d0> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1667a0> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac167040> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac166200> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac165f90> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac167640> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeac165cc0> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac164d00> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac164a30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac164a30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051022 -0.00019156 -0.00051334 ... -0.02830887 -0.02830887
 -0.02830887] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046675  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1661a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1661a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-3.60081838e-04 -1.08775305e-04 -1.31917160e-05 ... -2.74817476e-02
 -2.74817476e-02 -2.74817476e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 4)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac166350> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac166350> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.92637366e-09 -1.31700807e-07 -9.61527370e-06 ... -7.49400542e-16
 -7.49400542e-16 -7.49400542e-16] = ,SCAN
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 4)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac167c70> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac167c70> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.31884219e-04 -2.81911891e-04 -2.81911891e-04 ... -1.27154711e-05
 -2.64861768e-02 -2.64861768e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 4)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033802925117  <S^2> = 2.0027445  2S+1 = 3.0018291
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1648e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1648e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.15932790e-04 -4.01406609e-05 -2.14200586e-06 ... -2.76158582e-02
 -2.76158582e-02 -2.76158582e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 4)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121363  <S^2> = 0.7516194  2S+1 = 2.0016187
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac164790> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac164790> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.99635391e-04 -2.40573891e-04 -8.22204485e-05 ... -2.84484386e-02
 -2.84484386e-02 -2.84484386e-02] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 4)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560996169  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1640d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1640d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.38889972e-03 -1.49563075e-03 -7.58545002e-04 ... -2.49766509e-05
 -2.46575515e-04 -2.01535656e-05] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 4)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786812725  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1666b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1666b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00023988 -0.00019459 -0.0002011  ... -0.02838402 -0.02838402
 -0.02838402] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 3.5527137e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac164880> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac164880> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00043469 -0.00024024 -0.00035532 ... -0.00047537 -0.03728133
 -0.03728133] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 4)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.3377924465131  <S^2> = 4.0073278e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165030> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165030> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-9.02468888e-05 -7.92694658e-06 -9.80568469e-06 ... -4.33714150e-02
 -4.33714150e-02 -4.33714150e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 4)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322844  <S^2> = 1.4210855e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165990> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165990> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.48187338e-05 -6.19475249e-05 -2.61742784e-04 ... -8.70042314e-07
 -2.73391097e-02 -2.73391097e-02] = ,SCAN
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 4)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888959  <S^2> = 4.9737992e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1655a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1655a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051559 -0.00027432 -0.00088583 ... -0.00027432 -0.04174728
 -0.04174728] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 4)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.2079227e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165a20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165a20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.53951178e-05 -5.93507199e-06 -3.10072916e-04 ... -5.94325581e-02
 -5.94325581e-02 -5.94325581e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 4)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894506571  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac166560> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac166560> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.62975568e-04 -3.05570008e-05 -1.65913910e-06 ... -4.22396766e-02
 -4.22396766e-02 -4.22396766e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 4)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346373  <S^2> = 1.687539e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac164670> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac164670> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.72190712e-05 -2.72190712e-05 -2.84904833e-04 ... -1.08108260e-05
 -1.03072478e-05 -1.03072478e-05] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 4)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5369932e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165270> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165270> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00015688 -0.00024669 -0.00068269 ... -0.03791166 -0.03791166
 -0.03791166] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 4)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374077  <S^2> = 6.9277917e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1649d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1649d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.28500681e-05 -5.65091132e-06 -7.37932132e-06 ... -4.76689214e-02
 -4.76689214e-02 -4.76689214e-02] = ,SCAN
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 4)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.5495166e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1667a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1667a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003863  -0.00040095 -0.00040095 ... -0.0213199  -0.0213199
 -0.0213199 ] = ,SCAN
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 4)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5862867e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac167040> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac167040> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00088473 -0.00088473 -0.00116894 ... -0.00088473 -0.00088473
 -0.00116894] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 4)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.3844043e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac166200> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac166200> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.91408540e-05 -1.46971271e-04 -1.08734417e-03 ... -2.81566369e-02
 -2.81566369e-02 -2.81566369e-02] = ,SCAN
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 4)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5385916e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165f90> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165f90> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.39373335e-04 -1.31641332e-04 -1.15950750e-05 ... -7.32416564e-02
 -7.32416564e-02 -7.32416564e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 4)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336091276  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac167640> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac167640> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.84679716e-05 -7.80527089e-05 -7.80560616e-05 ... -2.92531309e-02
 -2.92531309e-02 -2.92531309e-02] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 4)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864075  <S^2> = 3.1530334e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac165cc0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac165cc0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.56165538e-04 -7.34744214e-05 -5.30574304e-06 ... -7.93995702e-06
 -7.93995702e-06 -7.93995702e-06] = ,SCAN
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 4)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.2030381e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac164d00> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac164d00> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.28290753e-04 -1.41305449e-05 -6.13700492e-05 ... -2.47993463e-02
 -2.47993463e-02 -2.47993463e-02] = ,SCAN
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 4)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3155699e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.45512011e-04 -7.12775692e-05 -5.48666345e-06 ... -6.02613084e-06
 -6.02613084e-06 -6.02613084e-06] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 4)
PRE NAN FILT: tFxc.shape=(224161,), tdrho.shape=(224161, 4)
nan_filt_rho.shape=(224161,)
nan_filt_fxc.shape=(224161,)
tFxc.shape=(224161,), tdrho.shape=(224161, 4)
inp[0].shape = (224161, 2)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 0.5662259917556933
0, epoch_train_loss=0.5662259917556933
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 0.38587325060581495
1, epoch_train_loss=0.38587325060581495
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 0.2163165503027258
2, epoch_train_loss=0.2163165503027258
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 0.07242103620996607
3, epoch_train_loss=0.07242103620996607
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 0.011168997137299916
4, epoch_train_loss=0.011168997137299916
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 0.0016998981137998008
5, epoch_train_loss=0.0016998981137998008
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 0.0008327745308585165
6, epoch_train_loss=0.0008327745308585165
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.0007443632809919822
7, epoch_train_loss=0.0007443632809919822
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.000736057841624464
8, epoch_train_loss=0.000736057841624464
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.0007354163805696214
9, epoch_train_loss=0.0007354163805696214
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.0007353736408453673
10, epoch_train_loss=0.0007353736408453673
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.0007353709987404782
11, epoch_train_loss=0.0007353709987404782
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.0007353708369512648
12, epoch_train_loss=0.0007353708369512648
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.0007353708266208606
13, epoch_train_loss=0.0007353708266208606
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.0007353708259081356
14, epoch_train_loss=0.0007353708259081356
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.0007353708258538233
15, epoch_train_loss=0.0007353708258538233
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.0007353708258491957
16, epoch_train_loss=0.0007353708258491957
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.0007353708258487522
17, epoch_train_loss=0.0007353708258487522
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.000735370825848704
18, epoch_train_loss=0.000735370825848704
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.0007353708258486982
19, epoch_train_loss=0.0007353708258486982
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.0007353708258486974
20, epoch_train_loss=0.0007353708258486974
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.0007353708258486971
21, epoch_train_loss=0.0007353708258486971
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.0007353708258486971
22, epoch_train_loss=0.0007353708258486971
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.0007353708258486971
23, epoch_train_loss=0.0007353708258486971
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.0007353708258486971
24, epoch_train_loss=0.0007353708258486971
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.0007353708258486971
25, epoch_train_loss=0.0007353708258486971
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.0007353708258486971
26, epoch_train_loss=0.0007353708258486971
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0007353708258486971
27, epoch_train_loss=0.0007353708258486971
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.0007353708258486971
28, epoch_train_loss=0.0007353708258486971
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.0007353708258486971
29, epoch_train_loss=0.0007353708258486971
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0007353708258486971
30, epoch_train_loss=0.0007353708258486971
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.0007353708258486971
31, epoch_train_loss=0.0007353708258486971
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.0007353708258486971
32, epoch_train_loss=0.0007353708258486971
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.0007353708258486971
33, epoch_train_loss=0.0007353708258486971
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.0007353708258486971
34, epoch_train_loss=0.0007353708258486971
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.0007353708258486971
35, epoch_train_loss=0.0007353708258486971
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.0007353708258486971
36, epoch_train_loss=0.0007353708258486971
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.0007353708258486971
37, epoch_train_loss=0.0007353708258486971
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.0007353708258486971
38, epoch_train_loss=0.0007353708258486971
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.0007353708258486971
39, epoch_train_loss=0.0007353708258486971
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.0007353708258486971
40, epoch_train_loss=0.0007353708258486971
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.0007353708258486971
41, epoch_train_loss=0.0007353708258486971
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.0007353708258486971
42, epoch_train_loss=0.0007353708258486971
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.0007353708258486971
43, epoch_train_loss=0.0007353708258486971
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.0007353708258486971
44, epoch_train_loss=0.0007353708258486971
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.0007353708258486971
45, epoch_train_loss=0.0007353708258486971
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.0007353708258486971
46, epoch_train_loss=0.0007353708258486971
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.0007353708258486971
47, epoch_train_loss=0.0007353708258486971
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.0007353708258486971
48, epoch_train_loss=0.0007353708258486971
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.0007353708258486971
49, epoch_train_loss=0.0007353708258486971
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.0007353708258486971
50, epoch_train_loss=0.0007353708258486971
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.0007353708258486971
51, epoch_train_loss=0.0007353708258486971
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.0007353708258486971
52, epoch_train_loss=0.0007353708258486971
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.0007353708258486971
53, epoch_train_loss=0.0007353708258486971
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.0007353708258486971
54, epoch_train_loss=0.0007353708258486971
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.0007353708258486971
55, epoch_train_loss=0.0007353708258486971
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.0007353708258486971
56, epoch_train_loss=0.0007353708258486971
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.0007353708258486971
57, epoch_train_loss=0.0007353708258486971
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0007353708258486971
58, epoch_train_loss=0.0007353708258486971
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.0007353708258486971
59, epoch_train_loss=0.0007353708258486971
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.0007353708258486971
60, epoch_train_loss=0.0007353708258486971
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.0007353708258486971
61, epoch_train_loss=0.0007353708258486971
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.0007353708258486971
62, epoch_train_loss=0.0007353708258486971
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.0007353708258486971
63, epoch_train_loss=0.0007353708258486971
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.0007353708258486971
64, epoch_train_loss=0.0007353708258486971
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0007353708258486971
65, epoch_train_loss=0.0007353708258486971
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.0007353708258486971
66, epoch_train_loss=0.0007353708258486971
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0007353708258486971
67, epoch_train_loss=0.0007353708258486971
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.0007353708258486971
68, epoch_train_loss=0.0007353708258486971
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0007353708258486971
69, epoch_train_loss=0.0007353708258486971
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0007353708258486971
70, epoch_train_loss=0.0007353708258486971
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0007353708258486971
71, epoch_train_loss=0.0007353708258486971
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0007353708258486971
72, epoch_train_loss=0.0007353708258486971
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0007353708258486971
73, epoch_train_loss=0.0007353708258486971
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0007353708258486971
74, epoch_train_loss=0.0007353708258486971
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0007353708258486971
75, epoch_train_loss=0.0007353708258486971
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0007353708258486971
76, epoch_train_loss=0.0007353708258486971
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0007353708258486971
77, epoch_train_loss=0.0007353708258486971
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.0007353708258486971
78, epoch_train_loss=0.0007353708258486971
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0007353708258486971
79, epoch_train_loss=0.0007353708258486971
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0007353708258486971
80, epoch_train_loss=0.0007353708258486971
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.0007353708258486971
81, epoch_train_loss=0.0007353708258486971
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0007353708258486971
82, epoch_train_loss=0.0007353708258486971
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.0007353708258486971
83, epoch_train_loss=0.0007353708258486971
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0007353708258486971
84, epoch_train_loss=0.0007353708258486971
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0007353708258486971
85, epoch_train_loss=0.0007353708258486971
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.0007353708258486971
86, epoch_train_loss=0.0007353708258486971
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.0007353708258486971
87, epoch_train_loss=0.0007353708258486971
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0007353708258486971
88, epoch_train_loss=0.0007353708258486971
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0007353708258486971
89, epoch_train_loss=0.0007353708258486971
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0007353708258486971
90, epoch_train_loss=0.0007353708258486971
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0007353708258486971
91, epoch_train_loss=0.0007353708258486971
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0007353708258486971
92, epoch_train_loss=0.0007353708258486971
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0007353708258486971
93, epoch_train_loss=0.0007353708258486971
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.0007353708258486971
94, epoch_train_loss=0.0007353708258486971
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0007353708258486971
95, epoch_train_loss=0.0007353708258486971
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0007353708258486971
96, epoch_train_loss=0.0007353708258486971
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.0007353708258486971
97, epoch_train_loss=0.0007353708258486971
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0007353708258486971
98, epoch_train_loss=0.0007353708258486971
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0007353708258486971
99, epoch_train_loss=0.0007353708258486971
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0007353708258486971
100, epoch_train_loss=0.0007353708258486971
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.0007353708258486971
101, epoch_train_loss=0.0007353708258486971
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0007353708258486971
102, epoch_train_loss=0.0007353708258486971
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.0007353708258486971
103, epoch_train_loss=0.0007353708258486971
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0007353708258486971
104, epoch_train_loss=0.0007353708258486971
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0007353708258486971
105, epoch_train_loss=0.0007353708258486971
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0007353708258486971
106, epoch_train_loss=0.0007353708258486971
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0007353708258486971
107, epoch_train_loss=0.0007353708258486971
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0007353708258486971
108, epoch_train_loss=0.0007353708258486971
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0007353708258486971
109, epoch_train_loss=0.0007353708258486971
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0007353708258486971
110, epoch_train_loss=0.0007353708258486971
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0007353708258486971
111, epoch_train_loss=0.0007353708258486971
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0007353708258486971
112, epoch_train_loss=0.0007353708258486971
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0007353708258486971
113, epoch_train_loss=0.0007353708258486971
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0007353708258486971
114, epoch_train_loss=0.0007353708258486971
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0007353708258486971
115, epoch_train_loss=0.0007353708258486971
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0007353708258486971
116, epoch_train_loss=0.0007353708258486971
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007353708258486971
117, epoch_train_loss=0.0007353708258486971
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0007353708258486971
118, epoch_train_loss=0.0007353708258486971
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007353708258486971
119, epoch_train_loss=0.0007353708258486971
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.0007353708258486971
120, epoch_train_loss=0.0007353708258486971
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007353708258486971
121, epoch_train_loss=0.0007353708258486971
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007353708258486971
122, epoch_train_loss=0.0007353708258486971
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0007353708258486971
123, epoch_train_loss=0.0007353708258486971
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0007353708258486971
124, epoch_train_loss=0.0007353708258486971
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0007353708258486971
125, epoch_train_loss=0.0007353708258486971
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0007353708258486971
126, epoch_train_loss=0.0007353708258486971
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0007353708258486971
127, epoch_train_loss=0.0007353708258486971
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0007353708258486971
128, epoch_train_loss=0.0007353708258486971
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0007353708258486971
129, epoch_train_loss=0.0007353708258486971
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0007353708258486971
130, epoch_train_loss=0.0007353708258486971
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0007353708258486971
131, epoch_train_loss=0.0007353708258486971
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007353708258486971
132, epoch_train_loss=0.0007353708258486971
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007353708258486971
133, epoch_train_loss=0.0007353708258486971
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007353708258486971
134, epoch_train_loss=0.0007353708258486971
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0007353708258486971
135, epoch_train_loss=0.0007353708258486971
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007353708258486971
136, epoch_train_loss=0.0007353708258486971
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007353708258486971
137, epoch_train_loss=0.0007353708258486971
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0007353708258486971
138, epoch_train_loss=0.0007353708258486971
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007353708258486971
139, epoch_train_loss=0.0007353708258486971
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007353708258486971
140, epoch_train_loss=0.0007353708258486971
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007353708258486971
141, epoch_train_loss=0.0007353708258486971
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0007353708258486971
142, epoch_train_loss=0.0007353708258486971
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0007353708258486971
143, epoch_train_loss=0.0007353708258486971
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0007353708258486971
144, epoch_train_loss=0.0007353708258486971
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.0007353708258486971
145, epoch_train_loss=0.0007353708258486971
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0007353708258486971
146, epoch_train_loss=0.0007353708258486971
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0007353708258486971
147, epoch_train_loss=0.0007353708258486971
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0007353708258486971
148, epoch_train_loss=0.0007353708258486971
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0007353708258486971
149, epoch_train_loss=0.0007353708258486971
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0007353708258486971
150, epoch_train_loss=0.0007353708258486971
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.0007353708258486971
151, epoch_train_loss=0.0007353708258486971
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0007353708258486971
152, epoch_train_loss=0.0007353708258486971
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0007353708258486971
153, epoch_train_loss=0.0007353708258486971
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0007353708258486971
154, epoch_train_loss=0.0007353708258486971
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.0007353708258486971
155, epoch_train_loss=0.0007353708258486971
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0007353708258486971
156, epoch_train_loss=0.0007353708258486971
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.0007353708258486971
157, epoch_train_loss=0.0007353708258486971
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0007353708258486971
158, epoch_train_loss=0.0007353708258486971
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0007353708258486971
159, epoch_train_loss=0.0007353708258486971
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.0007353708258486971
160, epoch_train_loss=0.0007353708258486971
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0007353708258486971
161, epoch_train_loss=0.0007353708258486971
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.0007353708258486971
162, epoch_train_loss=0.0007353708258486971
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0007353708258486971
163, epoch_train_loss=0.0007353708258486971
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.0007353708258486971
164, epoch_train_loss=0.0007353708258486971
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0007353708258486971
165, epoch_train_loss=0.0007353708258486971
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0007353708258486971
166, epoch_train_loss=0.0007353708258486971
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0007353708258486971
167, epoch_train_loss=0.0007353708258486971
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0007353708258486971
168, epoch_train_loss=0.0007353708258486971
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0007353708258486971
169, epoch_train_loss=0.0007353708258486971
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0007353708258486971
170, epoch_train_loss=0.0007353708258486971
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0007353708258486971
171, epoch_train_loss=0.0007353708258486971
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.0007353708258486971
172, epoch_train_loss=0.0007353708258486971
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0007353708258486971
173, epoch_train_loss=0.0007353708258486971
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.0007353708258486971
174, epoch_train_loss=0.0007353708258486971
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0007353708258486971
175, epoch_train_loss=0.0007353708258486971
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0007353708258486971
176, epoch_train_loss=0.0007353708258486971
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.0007353708258486971
177, epoch_train_loss=0.0007353708258486971
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0007353708258486971
178, epoch_train_loss=0.0007353708258486971
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.0007353708258486971
179, epoch_train_loss=0.0007353708258486971
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0007353708258486971
180, epoch_train_loss=0.0007353708258486971
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0007353708258486971
181, epoch_train_loss=0.0007353708258486971
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.0007353708258486971
182, epoch_train_loss=0.0007353708258486971
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0007353708258486971
183, epoch_train_loss=0.0007353708258486971
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0007353708258486971
184, epoch_train_loss=0.0007353708258486971
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0007353708258486971
185, epoch_train_loss=0.0007353708258486971
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0007353708258486971
186, epoch_train_loss=0.0007353708258486971
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0007353708258486971
187, epoch_train_loss=0.0007353708258486971
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0007353708258486971
188, epoch_train_loss=0.0007353708258486971
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.0007353708258486971
189, epoch_train_loss=0.0007353708258486971
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0007353708258486971
190, epoch_train_loss=0.0007353708258486971
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0007353708258486971
191, epoch_train_loss=0.0007353708258486971
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.0007353708258486971
192, epoch_train_loss=0.0007353708258486971
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0007353708258486971
193, epoch_train_loss=0.0007353708258486971
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.0007353708258486971
194, epoch_train_loss=0.0007353708258486971
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0007353708258486971
195, epoch_train_loss=0.0007353708258486971
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.0007353708258486971
196, epoch_train_loss=0.0007353708258486971
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.0007353708258486971
197, epoch_train_loss=0.0007353708258486971
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.0007353708258486971
198, epoch_train_loss=0.0007353708258486971
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.0007353708258486971
199, epoch_train_loss=0.0007353708258486971
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0007353708258486971
200, epoch_train_loss=0.0007353708258486971
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.0007353708258486971
201, epoch_train_loss=0.0007353708258486971
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0007353708258486971
202, epoch_train_loss=0.0007353708258486971
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0007353708258486971
203, epoch_train_loss=0.0007353708258486971
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.0007353708258486971
204, epoch_train_loss=0.0007353708258486971
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0007353708258486971
205, epoch_train_loss=0.0007353708258486971
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0007353708258486971
206, epoch_train_loss=0.0007353708258486971
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0007353708258486971
207, epoch_train_loss=0.0007353708258486971
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.0007353708258486971
208, epoch_train_loss=0.0007353708258486971
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0007353708258486971
209, epoch_train_loss=0.0007353708258486971
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0007353708258486971
210, epoch_train_loss=0.0007353708258486971
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.0007353708258486971
211, epoch_train_loss=0.0007353708258486971
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.0007353708258486971
212, epoch_train_loss=0.0007353708258486971
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.0007353708258486971
213, epoch_train_loss=0.0007353708258486971
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0007353708258486971
214, epoch_train_loss=0.0007353708258486971
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0007353708258486971
215, epoch_train_loss=0.0007353708258486971
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.0007353708258486971
216, epoch_train_loss=0.0007353708258486971
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.0007353708258486971
217, epoch_train_loss=0.0007353708258486971
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0007353708258486971
218, epoch_train_loss=0.0007353708258486971
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0007353708258486971
219, epoch_train_loss=0.0007353708258486971
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.0007353708258486971
220, epoch_train_loss=0.0007353708258486971
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0007353708258486971
221, epoch_train_loss=0.0007353708258486971
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.0007353708258486971
222, epoch_train_loss=0.0007353708258486971
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.0007353708258486971
223, epoch_train_loss=0.0007353708258486971
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0007353708258486971
224, epoch_train_loss=0.0007353708258486971
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0007353708258486971
225, epoch_train_loss=0.0007353708258486971
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.0007353708258486971
226, epoch_train_loss=0.0007353708258486971
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.0007353708258486971
227, epoch_train_loss=0.0007353708258486971
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.0007353708258486971
228, epoch_train_loss=0.0007353708258486971
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0007353708258486971
229, epoch_train_loss=0.0007353708258486971
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.0007353708258486971
230, epoch_train_loss=0.0007353708258486971
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.0007353708258486971
231, epoch_train_loss=0.0007353708258486971
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.0007353708258486971
232, epoch_train_loss=0.0007353708258486971
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0007353708258486971
233, epoch_train_loss=0.0007353708258486971
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0007353708258486971
234, epoch_train_loss=0.0007353708258486971
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0007353708258486971
235, epoch_train_loss=0.0007353708258486971
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.0007353708258486971
236, epoch_train_loss=0.0007353708258486971
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0007353708258486971
237, epoch_train_loss=0.0007353708258486971
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.0007353708258486971
238, epoch_train_loss=0.0007353708258486971
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.0007353708258486971
239, epoch_train_loss=0.0007353708258486971
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.0007353708258486971
240, epoch_train_loss=0.0007353708258486971
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.0007353708258486971
241, epoch_train_loss=0.0007353708258486971
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0007353708258486971
242, epoch_train_loss=0.0007353708258486971
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.0007353708258486971
243, epoch_train_loss=0.0007353708258486971
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0007353708258486971
244, epoch_train_loss=0.0007353708258486971
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.0007353708258486971
245, epoch_train_loss=0.0007353708258486971
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.0007353708258486971
246, epoch_train_loss=0.0007353708258486971
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0007353708258486971
247, epoch_train_loss=0.0007353708258486971
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.0007353708258486971
248, epoch_train_loss=0.0007353708258486971
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.0007353708258486971
249, epoch_train_loss=0.0007353708258486971
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0007353708258486971
250, epoch_train_loss=0.0007353708258486971
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0007353708258486971
251, epoch_train_loss=0.0007353708258486971
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0007353708258486971
252, epoch_train_loss=0.0007353708258486971
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.0007353708258486971
253, epoch_train_loss=0.0007353708258486971
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.0007353708258486971
254, epoch_train_loss=0.0007353708258486971
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0007353708258486971
255, epoch_train_loss=0.0007353708258486971
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.0007353708258486971
256, epoch_train_loss=0.0007353708258486971
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0007353708258486971
257, epoch_train_loss=0.0007353708258486971
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.0007353708258486971
258, epoch_train_loss=0.0007353708258486971
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0007353708258486971
259, epoch_train_loss=0.0007353708258486971
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.0007353708258486971
260, epoch_train_loss=0.0007353708258486971
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.0007353708258486971
261, epoch_train_loss=0.0007353708258486971
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.0007353708258486971
262, epoch_train_loss=0.0007353708258486971
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.0007353708258486971
263, epoch_train_loss=0.0007353708258486971
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.0007353708258486971
264, epoch_train_loss=0.0007353708258486971
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.0007353708258486971
265, epoch_train_loss=0.0007353708258486971
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0007353708258486971
266, epoch_train_loss=0.0007353708258486971
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.0007353708258486971
267, epoch_train_loss=0.0007353708258486971
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0007353708258486971
268, epoch_train_loss=0.0007353708258486971
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.0007353708258486971
269, epoch_train_loss=0.0007353708258486971
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.0007353708258486971
270, epoch_train_loss=0.0007353708258486971
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.0007353708258486971
271, epoch_train_loss=0.0007353708258486971
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0007353708258486971
272, epoch_train_loss=0.0007353708258486971
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.0007353708258486971
273, epoch_train_loss=0.0007353708258486971
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0007353708258486971
274, epoch_train_loss=0.0007353708258486971
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0007353708258486971
275, epoch_train_loss=0.0007353708258486971
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.0007353708258486971
276, epoch_train_loss=0.0007353708258486971
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.0007353708258486971
277, epoch_train_loss=0.0007353708258486971
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0007353708258486971
278, epoch_train_loss=0.0007353708258486971
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.0007353708258486971
279, epoch_train_loss=0.0007353708258486971
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.0007353708258486971
280, epoch_train_loss=0.0007353708258486971
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.0007353708258486971
281, epoch_train_loss=0.0007353708258486971
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.0007353708258486971
282, epoch_train_loss=0.0007353708258486971
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.0007353708258486971
283, epoch_train_loss=0.0007353708258486971
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0007353708258486971
284, epoch_train_loss=0.0007353708258486971
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0007353708258486971
285, epoch_train_loss=0.0007353708258486971
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.0007353708258486971
286, epoch_train_loss=0.0007353708258486971
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.0007353708258486971
287, epoch_train_loss=0.0007353708258486971
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.0007353708258486971
288, epoch_train_loss=0.0007353708258486971
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0007353708258486971
289, epoch_train_loss=0.0007353708258486971
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.0007353708258486971
290, epoch_train_loss=0.0007353708258486971
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.0007353708258486971
291, epoch_train_loss=0.0007353708258486971
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.0007353708258486971
292, epoch_train_loss=0.0007353708258486971
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.0007353708258486971
293, epoch_train_loss=0.0007353708258486971
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.0007353708258486971
294, epoch_train_loss=0.0007353708258486971
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.0007353708258486971
295, epoch_train_loss=0.0007353708258486971
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.0007353708258486971
296, epoch_train_loss=0.0007353708258486971
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.0007353708258486971
297, epoch_train_loss=0.0007353708258486971
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.0007353708258486971
298, epoch_train_loss=0.0007353708258486971
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.0007353708258486971
299, epoch_train_loss=0.0007353708258486971
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.0007353708258486971
300, epoch_train_loss=0.0007353708258486971
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0007353708258486971
301, epoch_train_loss=0.0007353708258486971
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.0007353708258486971
302, epoch_train_loss=0.0007353708258486971
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.0007353708258486971
303, epoch_train_loss=0.0007353708258486971
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.0007353708258486971
304, epoch_train_loss=0.0007353708258486971
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.0007353708258486971
305, epoch_train_loss=0.0007353708258486971
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.0007353708258486971
306, epoch_train_loss=0.0007353708258486971
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.0007353708258486971
307, epoch_train_loss=0.0007353708258486971
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.0007353708258486971
308, epoch_train_loss=0.0007353708258486971
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.0007353708258486971
309, epoch_train_loss=0.0007353708258486971
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0007353708258486971
310, epoch_train_loss=0.0007353708258486971
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0007353708258486971
311, epoch_train_loss=0.0007353708258486971
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.0007353708258486971
312, epoch_train_loss=0.0007353708258486971
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.0007353708258486971
313, epoch_train_loss=0.0007353708258486971
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.0007353708258486971
314, epoch_train_loss=0.0007353708258486971
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.0007353708258486971
315, epoch_train_loss=0.0007353708258486971
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0007353708258486971
316, epoch_train_loss=0.0007353708258486971
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.0007353708258486971
317, epoch_train_loss=0.0007353708258486971
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.0007353708258486971
318, epoch_train_loss=0.0007353708258486971
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.0007353708258486971
319, epoch_train_loss=0.0007353708258486971
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.0007353708258486971
320, epoch_train_loss=0.0007353708258486971
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.0007353708258486971
321, epoch_train_loss=0.0007353708258486971
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.0007353708258486971
322, epoch_train_loss=0.0007353708258486971
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0007353708258486971
323, epoch_train_loss=0.0007353708258486971
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.0007353708258486971
324, epoch_train_loss=0.0007353708258486971
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.0007353708258486971
325, epoch_train_loss=0.0007353708258486971
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.0007353708258486971
326, epoch_train_loss=0.0007353708258486971
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.0007353708258486971
327, epoch_train_loss=0.0007353708258486971
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.0007353708258486971
328, epoch_train_loss=0.0007353708258486971
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.0007353708258486971
329, epoch_train_loss=0.0007353708258486971
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.0007353708258486971
330, epoch_train_loss=0.0007353708258486971
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0007353708258486971
331, epoch_train_loss=0.0007353708258486971
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0007353708258486971
332, epoch_train_loss=0.0007353708258486971
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0007353708258486971
333, epoch_train_loss=0.0007353708258486971
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.0007353708258486971
334, epoch_train_loss=0.0007353708258486971
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.0007353708258486971
335, epoch_train_loss=0.0007353708258486971
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.0007353708258486971
336, epoch_train_loss=0.0007353708258486971
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0007353708258486971
337, epoch_train_loss=0.0007353708258486971
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.0007353708258486971
338, epoch_train_loss=0.0007353708258486971
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0007353708258486971
339, epoch_train_loss=0.0007353708258486971
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.0007353708258486971
340, epoch_train_loss=0.0007353708258486971
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0007353708258486971
341, epoch_train_loss=0.0007353708258486971
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.0007353708258486971
342, epoch_train_loss=0.0007353708258486971
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.0007353708258486971
343, epoch_train_loss=0.0007353708258486971
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.0007353708258486971
344, epoch_train_loss=0.0007353708258486971
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.0007353708258486971
345, epoch_train_loss=0.0007353708258486971
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.0007353708258486971
346, epoch_train_loss=0.0007353708258486971
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0007353708258486971
347, epoch_train_loss=0.0007353708258486971
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0007353708258486971
348, epoch_train_loss=0.0007353708258486971
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.0007353708258486971
349, epoch_train_loss=0.0007353708258486971
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.0007353708258486971
350, epoch_train_loss=0.0007353708258486971
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0007353708258486971
351, epoch_train_loss=0.0007353708258486971
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.0007353708258486971
352, epoch_train_loss=0.0007353708258486971
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.0007353708258486971
353, epoch_train_loss=0.0007353708258486971
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.0007353708258486971
354, epoch_train_loss=0.0007353708258486971
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.0007353708258486971
355, epoch_train_loss=0.0007353708258486971
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.0007353708258486971
356, epoch_train_loss=0.0007353708258486971
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0007353708258486971
357, epoch_train_loss=0.0007353708258486971
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.0007353708258486971
358, epoch_train_loss=0.0007353708258486971
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.0007353708258486971
359, epoch_train_loss=0.0007353708258486971
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.0007353708258486971
360, epoch_train_loss=0.0007353708258486971
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.0007353708258486971
361, epoch_train_loss=0.0007353708258486971
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.0007353708258486971
362, epoch_train_loss=0.0007353708258486971
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0007353708258486971
363, epoch_train_loss=0.0007353708258486971
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.0007353708258486971
364, epoch_train_loss=0.0007353708258486971
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.0007353708258486971
365, epoch_train_loss=0.0007353708258486971
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007353708258486971
366, epoch_train_loss=0.0007353708258486971
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0007353708258486971
367, epoch_train_loss=0.0007353708258486971
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0007353708258486971
368, epoch_train_loss=0.0007353708258486971
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0007353708258486971
369, epoch_train_loss=0.0007353708258486971
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.0007353708258486971
370, epoch_train_loss=0.0007353708258486971
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.0007353708258486971
371, epoch_train_loss=0.0007353708258486971
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.0007353708258486971
372, epoch_train_loss=0.0007353708258486971
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.0007353708258486971
373, epoch_train_loss=0.0007353708258486971
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0007353708258486971
374, epoch_train_loss=0.0007353708258486971
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0007353708258486971
375, epoch_train_loss=0.0007353708258486971
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.0007353708258486971
376, epoch_train_loss=0.0007353708258486971
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.0007353708258486971
377, epoch_train_loss=0.0007353708258486971
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0007353708258486971
378, epoch_train_loss=0.0007353708258486971
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0007353708258486971
379, epoch_train_loss=0.0007353708258486971
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.0007353708258486971
380, epoch_train_loss=0.0007353708258486971
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.0007353708258486971
381, epoch_train_loss=0.0007353708258486971
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0007353708258486971
382, epoch_train_loss=0.0007353708258486971
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0007353708258486971
383, epoch_train_loss=0.0007353708258486971
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0007353708258486971
384, epoch_train_loss=0.0007353708258486971
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0007353708258486971
385, epoch_train_loss=0.0007353708258486971
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.0007353708258486971
386, epoch_train_loss=0.0007353708258486971
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0007353708258486971
387, epoch_train_loss=0.0007353708258486971
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.0007353708258486971
388, epoch_train_loss=0.0007353708258486971
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0007353708258486971
389, epoch_train_loss=0.0007353708258486971
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0007353708258486971
390, epoch_train_loss=0.0007353708258486971
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0007353708258486971
391, epoch_train_loss=0.0007353708258486971
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.0007353708258486971
392, epoch_train_loss=0.0007353708258486971
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.0007353708258486971
393, epoch_train_loss=0.0007353708258486971
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007353708258486971
394, epoch_train_loss=0.0007353708258486971
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0007353708258486971
395, epoch_train_loss=0.0007353708258486971
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.0007353708258486971
396, epoch_train_loss=0.0007353708258486971
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.0007353708258486971
397, epoch_train_loss=0.0007353708258486971
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.0007353708258486971
398, epoch_train_loss=0.0007353708258486971
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0007353708258486971
399, epoch_train_loss=0.0007353708258486971
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0007353708258486971
400, epoch_train_loss=0.0007353708258486971
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0007353708258486971
401, epoch_train_loss=0.0007353708258486971
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0007353708258486971
402, epoch_train_loss=0.0007353708258486971
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.0007353708258486971
403, epoch_train_loss=0.0007353708258486971
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.0007353708258486971
404, epoch_train_loss=0.0007353708258486971
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.0007353708258486971
405, epoch_train_loss=0.0007353708258486971
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0007353708258486971
406, epoch_train_loss=0.0007353708258486971
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.0007353708258486971
407, epoch_train_loss=0.0007353708258486971
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0007353708258486971
408, epoch_train_loss=0.0007353708258486971
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0007353708258486971
409, epoch_train_loss=0.0007353708258486971
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0007353708258486971
410, epoch_train_loss=0.0007353708258486971
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.0007353708258486971
411, epoch_train_loss=0.0007353708258486971
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.0007353708258486971
412, epoch_train_loss=0.0007353708258486971
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0007353708258486971
413, epoch_train_loss=0.0007353708258486971
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0007353708258486971
414, epoch_train_loss=0.0007353708258486971
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0007353708258486971
415, epoch_train_loss=0.0007353708258486971
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0007353708258486971
416, epoch_train_loss=0.0007353708258486971
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.0007353708258486971
417, epoch_train_loss=0.0007353708258486971
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.0007353708258486971
418, epoch_train_loss=0.0007353708258486971
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.0007353708258486971
419, epoch_train_loss=0.0007353708258486971
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.0007353708258486971
420, epoch_train_loss=0.0007353708258486971
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.0007353708258486971
421, epoch_train_loss=0.0007353708258486971
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.0007353708258486971
422, epoch_train_loss=0.0007353708258486971
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0007353708258486971
423, epoch_train_loss=0.0007353708258486971
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.0007353708258486971
424, epoch_train_loss=0.0007353708258486971
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.0007353708258486971
425, epoch_train_loss=0.0007353708258486971
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0007353708258486971
426, epoch_train_loss=0.0007353708258486971
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.0007353708258486971
427, epoch_train_loss=0.0007353708258486971
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.0007353708258486971
428, epoch_train_loss=0.0007353708258486971
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.0007353708258486971
429, epoch_train_loss=0.0007353708258486971
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.0007353708258486971
430, epoch_train_loss=0.0007353708258486971
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.0007353708258486971
431, epoch_train_loss=0.0007353708258486971
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.0007353708258486971
432, epoch_train_loss=0.0007353708258486971
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.0007353708258486971
433, epoch_train_loss=0.0007353708258486971
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0007353708258486971
434, epoch_train_loss=0.0007353708258486971
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.0007353708258486971
435, epoch_train_loss=0.0007353708258486971
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.0007353708258486971
436, epoch_train_loss=0.0007353708258486971
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.0007353708258486971
437, epoch_train_loss=0.0007353708258486971
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0007353708258486971
438, epoch_train_loss=0.0007353708258486971
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0007353708258486971
439, epoch_train_loss=0.0007353708258486971
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0007353708258486971
440, epoch_train_loss=0.0007353708258486971
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.0007353708258486971
441, epoch_train_loss=0.0007353708258486971
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0007353708258486971
442, epoch_train_loss=0.0007353708258486971
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0007353708258486971
443, epoch_train_loss=0.0007353708258486971
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.0007353708258486971
444, epoch_train_loss=0.0007353708258486971
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.0007353708258486971
445, epoch_train_loss=0.0007353708258486971
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0007353708258486971
446, epoch_train_loss=0.0007353708258486971
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.0007353708258486971
447, epoch_train_loss=0.0007353708258486971
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.0007353708258486971
448, epoch_train_loss=0.0007353708258486971
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.0007353708258486971
449, epoch_train_loss=0.0007353708258486971
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.0007353708258486971
450, epoch_train_loss=0.0007353708258486971
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0007353708258486971
451, epoch_train_loss=0.0007353708258486971
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.0007353708258486971
452, epoch_train_loss=0.0007353708258486971
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0007353708258486971
453, epoch_train_loss=0.0007353708258486971
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0007353708258486971
454, epoch_train_loss=0.0007353708258486971
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0007353708258486971
455, epoch_train_loss=0.0007353708258486971
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.0007353708258486971
456, epoch_train_loss=0.0007353708258486971
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0007353708258486971
457, epoch_train_loss=0.0007353708258486971
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.0007353708258486971
458, epoch_train_loss=0.0007353708258486971
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.0007353708258486971
459, epoch_train_loss=0.0007353708258486971
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.0007353708258486971
460, epoch_train_loss=0.0007353708258486971
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.0007353708258486971
461, epoch_train_loss=0.0007353708258486971
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0007353708258486971
462, epoch_train_loss=0.0007353708258486971
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0007353708258486971
463, epoch_train_loss=0.0007353708258486971
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.0007353708258486971
464, epoch_train_loss=0.0007353708258486971
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0007353708258486971
465, epoch_train_loss=0.0007353708258486971
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0007353708258486971
466, epoch_train_loss=0.0007353708258486971
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.0007353708258486971
467, epoch_train_loss=0.0007353708258486971
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.0007353708258486971
468, epoch_train_loss=0.0007353708258486971
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0007353708258486971
469, epoch_train_loss=0.0007353708258486971
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.0007353708258486971
470, epoch_train_loss=0.0007353708258486971
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.0007353708258486971
471, epoch_train_loss=0.0007353708258486971
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.0007353708258486971
472, epoch_train_loss=0.0007353708258486971
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.0007353708258486971
473, epoch_train_loss=0.0007353708258486971
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0007353708258486971
474, epoch_train_loss=0.0007353708258486971
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.0007353708258486971
475, epoch_train_loss=0.0007353708258486971
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.0007353708258486971
476, epoch_train_loss=0.0007353708258486971
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.0007353708258486971
477, epoch_train_loss=0.0007353708258486971
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.0007353708258486971
478, epoch_train_loss=0.0007353708258486971
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.0007353708258486971
479, epoch_train_loss=0.0007353708258486971
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.0007353708258486971
480, epoch_train_loss=0.0007353708258486971
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.0007353708258486971
481, epoch_train_loss=0.0007353708258486971
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.0007353708258486971
482, epoch_train_loss=0.0007353708258486971
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.0007353708258486971
483, epoch_train_loss=0.0007353708258486971
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.0007353708258486971
484, epoch_train_loss=0.0007353708258486971
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.0007353708258486971
485, epoch_train_loss=0.0007353708258486971
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.0007353708258486971
486, epoch_train_loss=0.0007353708258486971
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0007353708258486971
487, epoch_train_loss=0.0007353708258486971
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0007353708258486971
488, epoch_train_loss=0.0007353708258486971
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.0007353708258486971
489, epoch_train_loss=0.0007353708258486971
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0007353708258486971
490, epoch_train_loss=0.0007353708258486971
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0007353708258486971
491, epoch_train_loss=0.0007353708258486971
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.0007353708258486971
492, epoch_train_loss=0.0007353708258486971
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0007353708258486971
493, epoch_train_loss=0.0007353708258486971
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0007353708258486971
494, epoch_train_loss=0.0007353708258486971
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.0007353708258486971
495, epoch_train_loss=0.0007353708258486971
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0007353708258486971
496, epoch_train_loss=0.0007353708258486971
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0007353708258486971
497, epoch_train_loss=0.0007353708258486971
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.0007353708258486971
498, epoch_train_loss=0.0007353708258486971
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.0007353708258486971
499, epoch_train_loss=0.0007353708258486971
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.0007353708258486971
500, epoch_train_loss=0.0007353708258486971
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.0007353708258486971
501, epoch_train_loss=0.0007353708258486971
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.0007353708258486971
502, epoch_train_loss=0.0007353708258486971
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.0007353708258486971
503, epoch_train_loss=0.0007353708258486971
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0007353708258486971
504, epoch_train_loss=0.0007353708258486971
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.0007353708258486971
505, epoch_train_loss=0.0007353708258486971
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.0007353708258486971
506, epoch_train_loss=0.0007353708258486971
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.0007353708258486971
507, epoch_train_loss=0.0007353708258486971
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.0007353708258486971
508, epoch_train_loss=0.0007353708258486971
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.0007353708258486971
509, epoch_train_loss=0.0007353708258486971
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.0007353708258486971
510, epoch_train_loss=0.0007353708258486971
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.0007353708258486971
511, epoch_train_loss=0.0007353708258486971
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.0007353708258486971
512, epoch_train_loss=0.0007353708258486971
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.0007353708258486971
513, epoch_train_loss=0.0007353708258486971
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0007353708258486971
514, epoch_train_loss=0.0007353708258486971
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.0007353708258486971
515, epoch_train_loss=0.0007353708258486971
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.0007353708258486971
516, epoch_train_loss=0.0007353708258486971
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0007353708258486971
517, epoch_train_loss=0.0007353708258486971
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.0007353708258486971
518, epoch_train_loss=0.0007353708258486971
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.0007353708258486971
519, epoch_train_loss=0.0007353708258486971
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.0007353708258486971
520, epoch_train_loss=0.0007353708258486971
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.0007353708258486971
521, epoch_train_loss=0.0007353708258486971
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.0007353708258486971
522, epoch_train_loss=0.0007353708258486971
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0007353708258486971
523, epoch_train_loss=0.0007353708258486971
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.0007353708258486971
524, epoch_train_loss=0.0007353708258486971
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0007353708258486971
525, epoch_train_loss=0.0007353708258486971
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.0007353708258486971
526, epoch_train_loss=0.0007353708258486971
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.0007353708258486971
527, epoch_train_loss=0.0007353708258486971
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.0007353708258486971
528, epoch_train_loss=0.0007353708258486971
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0007353708258486971
529, epoch_train_loss=0.0007353708258486971
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.0007353708258486971
530, epoch_train_loss=0.0007353708258486971
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.0007353708258486971
531, epoch_train_loss=0.0007353708258486971
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.0007353708258486971
532, epoch_train_loss=0.0007353708258486971
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.0007353708258486971
533, epoch_train_loss=0.0007353708258486971
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.0007353708258486971
534, epoch_train_loss=0.0007353708258486971
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.0007353708258486971
535, epoch_train_loss=0.0007353708258486971
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0007353708258486971
536, epoch_train_loss=0.0007353708258486971
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.0007353708258486971
537, epoch_train_loss=0.0007353708258486971
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.0007353708258486971
538, epoch_train_loss=0.0007353708258486971
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.0007353708258486971
539, epoch_train_loss=0.0007353708258486971
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.0007353708258486971
540, epoch_train_loss=0.0007353708258486971
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.0007353708258486971
541, epoch_train_loss=0.0007353708258486971
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.0007353708258486971
542, epoch_train_loss=0.0007353708258486971
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0007353708258486971
543, epoch_train_loss=0.0007353708258486971
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.0007353708258486971
544, epoch_train_loss=0.0007353708258486971
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.0007353708258486971
545, epoch_train_loss=0.0007353708258486971
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.0007353708258486971
546, epoch_train_loss=0.0007353708258486971
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.0007353708258486971
547, epoch_train_loss=0.0007353708258486971
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.0007353708258486971
548, epoch_train_loss=0.0007353708258486971
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.0007353708258486971
549, epoch_train_loss=0.0007353708258486971
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.0007353708258486971
550, epoch_train_loss=0.0007353708258486971
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0007353708258486971
551, epoch_train_loss=0.0007353708258486971
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.0007353708258486971
552, epoch_train_loss=0.0007353708258486971
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0007353708258486971
553, epoch_train_loss=0.0007353708258486971
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.0007353708258486971
554, epoch_train_loss=0.0007353708258486971
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.0007353708258486971
555, epoch_train_loss=0.0007353708258486971
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0007353708258486971
556, epoch_train_loss=0.0007353708258486971
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.0007353708258486971
557, epoch_train_loss=0.0007353708258486971
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.0007353708258486971
558, epoch_train_loss=0.0007353708258486971
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.0007353708258486971
559, epoch_train_loss=0.0007353708258486971
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.0007353708258486971
560, epoch_train_loss=0.0007353708258486971
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.0007353708258486971
561, epoch_train_loss=0.0007353708258486971
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.0007353708258486971
562, epoch_train_loss=0.0007353708258486971
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.0007353708258486971
563, epoch_train_loss=0.0007353708258486971
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.0007353708258486971
564, epoch_train_loss=0.0007353708258486971
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.0007353708258486971
565, epoch_train_loss=0.0007353708258486971
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.0007353708258486971
566, epoch_train_loss=0.0007353708258486971
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0007353708258486971
567, epoch_train_loss=0.0007353708258486971
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0007353708258486971
568, epoch_train_loss=0.0007353708258486971
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.0007353708258486971
569, epoch_train_loss=0.0007353708258486971
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0007353708258486971
570, epoch_train_loss=0.0007353708258486971
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.0007353708258486971
571, epoch_train_loss=0.0007353708258486971
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.0007353708258486971
572, epoch_train_loss=0.0007353708258486971
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.0007353708258486971
573, epoch_train_loss=0.0007353708258486971
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.0007353708258486971
574, epoch_train_loss=0.0007353708258486971
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.0007353708258486971
575, epoch_train_loss=0.0007353708258486971
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.0007353708258486971
576, epoch_train_loss=0.0007353708258486971
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.0007353708258486971
577, epoch_train_loss=0.0007353708258486971
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.0007353708258486971
578, epoch_train_loss=0.0007353708258486971
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.0007353708258486971
579, epoch_train_loss=0.0007353708258486971
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0007353708258486971
580, epoch_train_loss=0.0007353708258486971
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.0007353708258486971
581, epoch_train_loss=0.0007353708258486971
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.0007353708258486971
582, epoch_train_loss=0.0007353708258486971
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.0007353708258486971
583, epoch_train_loss=0.0007353708258486971
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.0007353708258486971
584, epoch_train_loss=0.0007353708258486971
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.0007353708258486971
585, epoch_train_loss=0.0007353708258486971
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.0007353708258486971
586, epoch_train_loss=0.0007353708258486971
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.0007353708258486971
587, epoch_train_loss=0.0007353708258486971
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.0007353708258486971
588, epoch_train_loss=0.0007353708258486971
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.0007353708258486971
589, epoch_train_loss=0.0007353708258486971
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.0007353708258486971
590, epoch_train_loss=0.0007353708258486971
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0007353708258486971
591, epoch_train_loss=0.0007353708258486971
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.0007353708258486971
592, epoch_train_loss=0.0007353708258486971
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.0007353708258486971
593, epoch_train_loss=0.0007353708258486971
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.0007353708258486971
594, epoch_train_loss=0.0007353708258486971
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.0007353708258486971
595, epoch_train_loss=0.0007353708258486971
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.0007353708258486971
596, epoch_train_loss=0.0007353708258486971
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0007353708258486971
597, epoch_train_loss=0.0007353708258486971
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.0007353708258486971
598, epoch_train_loss=0.0007353708258486971
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.0007353708258486971
599, epoch_train_loss=0.0007353708258486971
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.0007353708258486971
600, epoch_train_loss=0.0007353708258486971
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.0007353708258486971
601, epoch_train_loss=0.0007353708258486971
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0007353708258486971
602, epoch_train_loss=0.0007353708258486971
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.0007353708258486971
603, epoch_train_loss=0.0007353708258486971
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.0007353708258486971
604, epoch_train_loss=0.0007353708258486971
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.0007353708258486971
605, epoch_train_loss=0.0007353708258486971
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.0007353708258486971
606, epoch_train_loss=0.0007353708258486971
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.0007353708258486971
607, epoch_train_loss=0.0007353708258486971
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.0007353708258486971
608, epoch_train_loss=0.0007353708258486971
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.0007353708258486971
609, epoch_train_loss=0.0007353708258486971
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.0007353708258486971
610, epoch_train_loss=0.0007353708258486971
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0007353708258486971
611, epoch_train_loss=0.0007353708258486971
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.0007353708258486971
612, epoch_train_loss=0.0007353708258486971
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.0007353708258486971
613, epoch_train_loss=0.0007353708258486971
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.0007353708258486971
614, epoch_train_loss=0.0007353708258486971
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.0007353708258486971
615, epoch_train_loss=0.0007353708258486971
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.0007353708258486971
616, epoch_train_loss=0.0007353708258486971
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.0007353708258486971
617, epoch_train_loss=0.0007353708258486971
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.0007353708258486971
618, epoch_train_loss=0.0007353708258486971
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.0007353708258486971
619, epoch_train_loss=0.0007353708258486971
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.0007353708258486971
620, epoch_train_loss=0.0007353708258486971
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.0007353708258486971
621, epoch_train_loss=0.0007353708258486971
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.0007353708258486971
622, epoch_train_loss=0.0007353708258486971
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.0007353708258486971
623, epoch_train_loss=0.0007353708258486971
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.0007353708258486971
624, epoch_train_loss=0.0007353708258486971
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.0007353708258486971
625, epoch_train_loss=0.0007353708258486971
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.0007353708258486971
626, epoch_train_loss=0.0007353708258486971
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.0007353708258486971
627, epoch_train_loss=0.0007353708258486971
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0007353708258486971
628, epoch_train_loss=0.0007353708258486971
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0007353708258486971
629, epoch_train_loss=0.0007353708258486971
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.0007353708258486971
630, epoch_train_loss=0.0007353708258486971
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.0007353708258486971
631, epoch_train_loss=0.0007353708258486971
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.0007353708258486971
632, epoch_train_loss=0.0007353708258486971
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.0007353708258486971
633, epoch_train_loss=0.0007353708258486971
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.0007353708258486971
634, epoch_train_loss=0.0007353708258486971
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.0007353708258486971
635, epoch_train_loss=0.0007353708258486971
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.0007353708258486971
636, epoch_train_loss=0.0007353708258486971
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.0007353708258486971
637, epoch_train_loss=0.0007353708258486971
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.0007353708258486971
638, epoch_train_loss=0.0007353708258486971
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.0007353708258486971
639, epoch_train_loss=0.0007353708258486971
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.0007353708258486971
640, epoch_train_loss=0.0007353708258486971
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.0007353708258486971
641, epoch_train_loss=0.0007353708258486971
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.0007353708258486971
642, epoch_train_loss=0.0007353708258486971
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.0007353708258486971
643, epoch_train_loss=0.0007353708258486971
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.0007353708258486971
644, epoch_train_loss=0.0007353708258486971
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0007353708258486971
645, epoch_train_loss=0.0007353708258486971
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0007353708258486971
646, epoch_train_loss=0.0007353708258486971
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.0007353708258486971
647, epoch_train_loss=0.0007353708258486971
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0007353708258486971
648, epoch_train_loss=0.0007353708258486971
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.0007353708258486971
649, epoch_train_loss=0.0007353708258486971
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.0007353708258486971
650, epoch_train_loss=0.0007353708258486971
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.0007353708258486971
651, epoch_train_loss=0.0007353708258486971
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.0007353708258486971
652, epoch_train_loss=0.0007353708258486971
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.0007353708258486971
653, epoch_train_loss=0.0007353708258486971
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.0007353708258486971
654, epoch_train_loss=0.0007353708258486971
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0007353708258486971
655, epoch_train_loss=0.0007353708258486971
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.0007353708258486971
656, epoch_train_loss=0.0007353708258486971
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.0007353708258486971
657, epoch_train_loss=0.0007353708258486971
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.0007353708258486971
658, epoch_train_loss=0.0007353708258486971
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.0007353708258486971
659, epoch_train_loss=0.0007353708258486971
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.0007353708258486971
660, epoch_train_loss=0.0007353708258486971
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0007353708258486971
661, epoch_train_loss=0.0007353708258486971
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.0007353708258486971
662, epoch_train_loss=0.0007353708258486971
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0007353708258486971
663, epoch_train_loss=0.0007353708258486971
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0007353708258486971
664, epoch_train_loss=0.0007353708258486971
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.0007353708258486971
665, epoch_train_loss=0.0007353708258486971
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.0007353708258486971
666, epoch_train_loss=0.0007353708258486971
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0007353708258486971
667, epoch_train_loss=0.0007353708258486971
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.0007353708258486971
668, epoch_train_loss=0.0007353708258486971
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.0007353708258486971
669, epoch_train_loss=0.0007353708258486971
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.0007353708258486971
670, epoch_train_loss=0.0007353708258486971
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.0007353708258486971
671, epoch_train_loss=0.0007353708258486971
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.0007353708258486971
672, epoch_train_loss=0.0007353708258486971
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.0007353708258486971
673, epoch_train_loss=0.0007353708258486971
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.0007353708258486971
674, epoch_train_loss=0.0007353708258486971
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.0007353708258486971
675, epoch_train_loss=0.0007353708258486971
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0007353708258486971
676, epoch_train_loss=0.0007353708258486971
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.0007353708258486971
677, epoch_train_loss=0.0007353708258486971
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.0007353708258486971
678, epoch_train_loss=0.0007353708258486971
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.0007353708258486971
679, epoch_train_loss=0.0007353708258486971
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0007353708258486971
680, epoch_train_loss=0.0007353708258486971
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0007353708258486971
681, epoch_train_loss=0.0007353708258486971
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0007353708258486971
682, epoch_train_loss=0.0007353708258486971
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.0007353708258486971
683, epoch_train_loss=0.0007353708258486971
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0007353708258486971
684, epoch_train_loss=0.0007353708258486971
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.0007353708258486971
685, epoch_train_loss=0.0007353708258486971
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.0007353708258486971
686, epoch_train_loss=0.0007353708258486971
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0007353708258486971
687, epoch_train_loss=0.0007353708258486971
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.0007353708258486971
688, epoch_train_loss=0.0007353708258486971
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.0007353708258486971
689, epoch_train_loss=0.0007353708258486971
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0007353708258486971
690, epoch_train_loss=0.0007353708258486971
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0007353708258486971
691, epoch_train_loss=0.0007353708258486971
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.0007353708258486971
692, epoch_train_loss=0.0007353708258486971
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.0007353708258486971
693, epoch_train_loss=0.0007353708258486971
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.0007353708258486971
694, epoch_train_loss=0.0007353708258486971
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0007353708258486971
695, epoch_train_loss=0.0007353708258486971
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0007353708258486971
696, epoch_train_loss=0.0007353708258486971
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.0007353708258486971
697, epoch_train_loss=0.0007353708258486971
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.0007353708258486971
698, epoch_train_loss=0.0007353708258486971
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0007353708258486971
699, epoch_train_loss=0.0007353708258486971
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0007353708258486971
700, epoch_train_loss=0.0007353708258486971
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.0007353708258486971
701, epoch_train_loss=0.0007353708258486971
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.0007353708258486971
702, epoch_train_loss=0.0007353708258486971
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0007353708258486971
703, epoch_train_loss=0.0007353708258486971
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.0007353708258486971
704, epoch_train_loss=0.0007353708258486971
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.0007353708258486971
705, epoch_train_loss=0.0007353708258486971
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0007353708258486971
706, epoch_train_loss=0.0007353708258486971
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0007353708258486971
707, epoch_train_loss=0.0007353708258486971
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0007353708258486971
708, epoch_train_loss=0.0007353708258486971
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0007353708258486971
709, epoch_train_loss=0.0007353708258486971
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.0007353708258486971
710, epoch_train_loss=0.0007353708258486971
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.0007353708258486971
711, epoch_train_loss=0.0007353708258486971
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0007353708258486971
712, epoch_train_loss=0.0007353708258486971
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.0007353708258486971
713, epoch_train_loss=0.0007353708258486971
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.0007353708258486971
714, epoch_train_loss=0.0007353708258486971
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.0007353708258486971
715, epoch_train_loss=0.0007353708258486971
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.0007353708258486971
716, epoch_train_loss=0.0007353708258486971
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0007353708258486971
717, epoch_train_loss=0.0007353708258486971
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.0007353708258486971
718, epoch_train_loss=0.0007353708258486971
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0007353708258486971
719, epoch_train_loss=0.0007353708258486971
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.0007353708258486971
720, epoch_train_loss=0.0007353708258486971
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0007353708258486971
721, epoch_train_loss=0.0007353708258486971
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.0007353708258486971
722, epoch_train_loss=0.0007353708258486971
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.0007353708258486971
723, epoch_train_loss=0.0007353708258486971
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.0007353708258486971
724, epoch_train_loss=0.0007353708258486971
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.0007353708258486971
725, epoch_train_loss=0.0007353708258486971
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0007353708258486971
726, epoch_train_loss=0.0007353708258486971
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.0007353708258486971
727, epoch_train_loss=0.0007353708258486971
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0007353708258486971
728, epoch_train_loss=0.0007353708258486971
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0007353708258486971
729, epoch_train_loss=0.0007353708258486971
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.0007353708258486971
730, epoch_train_loss=0.0007353708258486971
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.0007353708258486971
731, epoch_train_loss=0.0007353708258486971
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.0007353708258486971
732, epoch_train_loss=0.0007353708258486971
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.0007353708258486971
733, epoch_train_loss=0.0007353708258486971
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.0007353708258486971
734, epoch_train_loss=0.0007353708258486971
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.0007353708258486971
735, epoch_train_loss=0.0007353708258486971
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.0007353708258486971
736, epoch_train_loss=0.0007353708258486971
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0007353708258486971
737, epoch_train_loss=0.0007353708258486971
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.0007353708258486971
738, epoch_train_loss=0.0007353708258486971
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.0007353708258486971
739, epoch_train_loss=0.0007353708258486971
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.0007353708258486971
740, epoch_train_loss=0.0007353708258486971
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.0007353708258486971
741, epoch_train_loss=0.0007353708258486971
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.0007353708258486971
742, epoch_train_loss=0.0007353708258486971
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.0007353708258486971
743, epoch_train_loss=0.0007353708258486971
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.0007353708258486971
744, epoch_train_loss=0.0007353708258486971
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.0007353708258486971
745, epoch_train_loss=0.0007353708258486971
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.0007353708258486971
746, epoch_train_loss=0.0007353708258486971
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.0007353708258486971
747, epoch_train_loss=0.0007353708258486971
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.0007353708258486971
748, epoch_train_loss=0.0007353708258486971
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0007353708258486971
749, epoch_train_loss=0.0007353708258486971
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0007353708258486971
750, epoch_train_loss=0.0007353708258486971
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0007353708258486971
751, epoch_train_loss=0.0007353708258486971
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.0007353708258486971
752, epoch_train_loss=0.0007353708258486971
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.0007353708258486971
753, epoch_train_loss=0.0007353708258486971
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.0007353708258486971
754, epoch_train_loss=0.0007353708258486971
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.0007353708258486971
755, epoch_train_loss=0.0007353708258486971
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.0007353708258486971
756, epoch_train_loss=0.0007353708258486971
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.0007353708258486971
757, epoch_train_loss=0.0007353708258486971
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.0007353708258486971
758, epoch_train_loss=0.0007353708258486971
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.0007353708258486971
759, epoch_train_loss=0.0007353708258486971
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.0007353708258486971
760, epoch_train_loss=0.0007353708258486971
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.0007353708258486971
761, epoch_train_loss=0.0007353708258486971
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.0007353708258486971
762, epoch_train_loss=0.0007353708258486971
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 0.0007353708258486971
763, epoch_train_loss=0.0007353708258486971
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 0.0007353708258486971
764, epoch_train_loss=0.0007353708258486971
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.0007353708258486971
765, epoch_train_loss=0.0007353708258486971
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 0.0007353708258486971
766, epoch_train_loss=0.0007353708258486971
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 0.0007353708258486971
767, epoch_train_loss=0.0007353708258486971
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 0.0007353708258486971
768, epoch_train_loss=0.0007353708258486971
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 0.0007353708258486971
769, epoch_train_loss=0.0007353708258486971
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 0.0007353708258486971
770, epoch_train_loss=0.0007353708258486971
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 0.0007353708258486971
771, epoch_train_loss=0.0007353708258486971
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 0.0007353708258486971
772, epoch_train_loss=0.0007353708258486971
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 0.0007353708258486971
773, epoch_train_loss=0.0007353708258486971
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 0.0007353708258486971
774, epoch_train_loss=0.0007353708258486971
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 0.0007353708258486971
775, epoch_train_loss=0.0007353708258486971
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 0.0007353708258486971
776, epoch_train_loss=0.0007353708258486971
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 0.0007353708258486971
777, epoch_train_loss=0.0007353708258486971
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 0.0007353708258486971
778, epoch_train_loss=0.0007353708258486971
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 0.0007353708258486971
779, epoch_train_loss=0.0007353708258486971
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 0.0007353708258486971
780, epoch_train_loss=0.0007353708258486971
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 0.0007353708258486971
781, epoch_train_loss=0.0007353708258486971
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 0.0007353708258486971
782, epoch_train_loss=0.0007353708258486971
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 0.0007353708258486971
783, epoch_train_loss=0.0007353708258486971
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 0.0007353708258486971
784, epoch_train_loss=0.0007353708258486971
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 0.0007353708258486971
785, epoch_train_loss=0.0007353708258486971
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 0.0007353708258486971
786, epoch_train_loss=0.0007353708258486971
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 0.0007353708258486971
787, epoch_train_loss=0.0007353708258486971
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 0.0007353708258486971
788, epoch_train_loss=0.0007353708258486971
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 0.0007353708258486971
789, epoch_train_loss=0.0007353708258486971
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 0.0007353708258486971
790, epoch_train_loss=0.0007353708258486971
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 0.0007353708258486971
791, epoch_train_loss=0.0007353708258486971
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 0.0007353708258486971
792, epoch_train_loss=0.0007353708258486971
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 0.0007353708258486971
793, epoch_train_loss=0.0007353708258486971
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 0.0007353708258486971
794, epoch_train_loss=0.0007353708258486971
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 0.0007353708258486971
795, epoch_train_loss=0.0007353708258486971
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 0.0007353708258486971
796, epoch_train_loss=0.0007353708258486971
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 0.0007353708258486971
797, epoch_train_loss=0.0007353708258486971
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 0.0007353708258486971
798, epoch_train_loss=0.0007353708258486971
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 0.0007353708258486971
799, epoch_train_loss=0.0007353708258486971
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 0.0007353708258486971
800, epoch_train_loss=0.0007353708258486971
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 0.0007353708258486971
801, epoch_train_loss=0.0007353708258486971
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 0.0007353708258486971
802, epoch_train_loss=0.0007353708258486971
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 0.0007353708258486971
803, epoch_train_loss=0.0007353708258486971
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 0.0007353708258486971
804, epoch_train_loss=0.0007353708258486971
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 0.0007353708258486971
805, epoch_train_loss=0.0007353708258486971
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 0.0007353708258486971
806, epoch_train_loss=0.0007353708258486971
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 0.0007353708258486971
807, epoch_train_loss=0.0007353708258486971
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 0.0007353708258486971
808, epoch_train_loss=0.0007353708258486971
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 0.0007353708258486971
809, epoch_train_loss=0.0007353708258486971
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 0.0007353708258486971
810, epoch_train_loss=0.0007353708258486971
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 0.0007353708258486971
811, epoch_train_loss=0.0007353708258486971
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 0.0007353708258486971
812, epoch_train_loss=0.0007353708258486971
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 0.0007353708258486971
813, epoch_train_loss=0.0007353708258486971
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 0.0007353708258486971
814, epoch_train_loss=0.0007353708258486971
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 0.0007353708258486971
815, epoch_train_loss=0.0007353708258486971
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 0.0007353708258486971
816, epoch_train_loss=0.0007353708258486971
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 0.0007353708258486971
817, epoch_train_loss=0.0007353708258486971
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 0.0007353708258486971
818, epoch_train_loss=0.0007353708258486971
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 0.0007353708258486971
819, epoch_train_loss=0.0007353708258486971
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 0.0007353708258486971
820, epoch_train_loss=0.0007353708258486971
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 0.0007353708258486971
821, epoch_train_loss=0.0007353708258486971
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 0.0007353708258486971
822, epoch_train_loss=0.0007353708258486971
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 0.0007353708258486971
823, epoch_train_loss=0.0007353708258486971
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 0.0007353708258486971
824, epoch_train_loss=0.0007353708258486971
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 0.0007353708258486971
825, epoch_train_loss=0.0007353708258486971
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 0.0007353708258486971
826, epoch_train_loss=0.0007353708258486971
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 0.0007353708258486971
827, epoch_train_loss=0.0007353708258486971
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 0.0007353708258486971
828, epoch_train_loss=0.0007353708258486971
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 0.0007353708258486971
829, epoch_train_loss=0.0007353708258486971
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 0.0007353708258486971
830, epoch_train_loss=0.0007353708258486971
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 0.0007353708258486971
831, epoch_train_loss=0.0007353708258486971
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 0.0007353708258486971
832, epoch_train_loss=0.0007353708258486971
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 0.0007353708258486971
833, epoch_train_loss=0.0007353708258486971
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 0.0007353708258486971
834, epoch_train_loss=0.0007353708258486971
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 0.0007353708258486971
835, epoch_train_loss=0.0007353708258486971
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 0.0007353708258486971
836, epoch_train_loss=0.0007353708258486971
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 0.0007353708258486971
837, epoch_train_loss=0.0007353708258486971
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 0.0007353708258486971
838, epoch_train_loss=0.0007353708258486971
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 0.0007353708258486971
839, epoch_train_loss=0.0007353708258486971
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 0.0007353708258486971
840, epoch_train_loss=0.0007353708258486971
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 0.0007353708258486971
841, epoch_train_loss=0.0007353708258486971
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 0.0007353708258486971
842, epoch_train_loss=0.0007353708258486971
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 0.0007353708258486971
843, epoch_train_loss=0.0007353708258486971
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 0.0007353708258486971
844, epoch_train_loss=0.0007353708258486971
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 0.0007353708258486971
845, epoch_train_loss=0.0007353708258486971
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 0.0007353708258486971
846, epoch_train_loss=0.0007353708258486971
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.0007353708258486971
847, epoch_train_loss=0.0007353708258486971
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.0007353708258486971
848, epoch_train_loss=0.0007353708258486971
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0007353708258486971
849, epoch_train_loss=0.0007353708258486971
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.0007353708258486971
850, epoch_train_loss=0.0007353708258486971
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0007353708258486971
851, epoch_train_loss=0.0007353708258486971
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.0007353708258486971
852, epoch_train_loss=0.0007353708258486971
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.0007353708258486971
853, epoch_train_loss=0.0007353708258486971
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.0007353708258486971
854, epoch_train_loss=0.0007353708258486971
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.0007353708258486971
855, epoch_train_loss=0.0007353708258486971
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.0007353708258486971
856, epoch_train_loss=0.0007353708258486971
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.0007353708258486971
857, epoch_train_loss=0.0007353708258486971
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.0007353708258486971
858, epoch_train_loss=0.0007353708258486971
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.0007353708258486971
859, epoch_train_loss=0.0007353708258486971
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.0007353708258486971
860, epoch_train_loss=0.0007353708258486971
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.0007353708258486971
861, epoch_train_loss=0.0007353708258486971
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.0007353708258486971
862, epoch_train_loss=0.0007353708258486971
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.0007353708258486971
863, epoch_train_loss=0.0007353708258486971
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.0007353708258486971
864, epoch_train_loss=0.0007353708258486971
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.0007353708258486971
865, epoch_train_loss=0.0007353708258486971
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.0007353708258486971
866, epoch_train_loss=0.0007353708258486971
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.0007353708258486971
867, epoch_train_loss=0.0007353708258486971
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.0007353708258486971
868, epoch_train_loss=0.0007353708258486971
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.0007353708258486971
869, epoch_train_loss=0.0007353708258486971
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0007353708258486971
870, epoch_train_loss=0.0007353708258486971
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.0007353708258486971
871, epoch_train_loss=0.0007353708258486971
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.0007353708258486971
872, epoch_train_loss=0.0007353708258486971
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0007353708258486971
873, epoch_train_loss=0.0007353708258486971
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.0007353708258486971
874, epoch_train_loss=0.0007353708258486971
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.0007353708258486971
875, epoch_train_loss=0.0007353708258486971
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.0007353708258486971
876, epoch_train_loss=0.0007353708258486971
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.0007353708258486971
877, epoch_train_loss=0.0007353708258486971
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.0007353708258486971
878, epoch_train_loss=0.0007353708258486971
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.0007353708258486971
879, epoch_train_loss=0.0007353708258486971
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.0007353708258486971
880, epoch_train_loss=0.0007353708258486971
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.0007353708258486971
881, epoch_train_loss=0.0007353708258486971
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.0007353708258486971
882, epoch_train_loss=0.0007353708258486971
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0007353708258486971
883, epoch_train_loss=0.0007353708258486971
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0007353708258486971
884, epoch_train_loss=0.0007353708258486971
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0007353708258486971
885, epoch_train_loss=0.0007353708258486971
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.0007353708258486971
886, epoch_train_loss=0.0007353708258486971
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0007353708258486971
887, epoch_train_loss=0.0007353708258486971
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0007353708258486971
888, epoch_train_loss=0.0007353708258486971
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0007353708258486971
889, epoch_train_loss=0.0007353708258486971
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.0007353708258486971
890, epoch_train_loss=0.0007353708258486971
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0007353708258486971
891, epoch_train_loss=0.0007353708258486971
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0007353708258486971
892, epoch_train_loss=0.0007353708258486971
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.0007353708258486971
893, epoch_train_loss=0.0007353708258486971
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.0007353708258486971
894, epoch_train_loss=0.0007353708258486971
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0007353708258486971
895, epoch_train_loss=0.0007353708258486971
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.0007353708258486971
896, epoch_train_loss=0.0007353708258486971
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.0007353708258486971
897, epoch_train_loss=0.0007353708258486971
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0007353708258486971
898, epoch_train_loss=0.0007353708258486971
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0007353708258486971
899, epoch_train_loss=0.0007353708258486971
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0007353708258486971
900, epoch_train_loss=0.0007353708258486971
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.0007353708258486971
901, epoch_train_loss=0.0007353708258486971
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0007353708258486971
902, epoch_train_loss=0.0007353708258486971
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.0007353708258486971
903, epoch_train_loss=0.0007353708258486971
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0007353708258486971
904, epoch_train_loss=0.0007353708258486971
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007353708258486971
905, epoch_train_loss=0.0007353708258486971
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.0007353708258486971
906, epoch_train_loss=0.0007353708258486971
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.0007353708258486971
907, epoch_train_loss=0.0007353708258486971
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.0007353708258486971
908, epoch_train_loss=0.0007353708258486971
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.0007353708258486971
909, epoch_train_loss=0.0007353708258486971
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.0007353708258486971
910, epoch_train_loss=0.0007353708258486971
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0007353708258486971
911, epoch_train_loss=0.0007353708258486971
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.0007353708258486971
912, epoch_train_loss=0.0007353708258486971
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.0007353708258486971
913, epoch_train_loss=0.0007353708258486971
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.0007353708258486971
914, epoch_train_loss=0.0007353708258486971
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0007353708258486971
915, epoch_train_loss=0.0007353708258486971
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.0007353708258486971
916, epoch_train_loss=0.0007353708258486971
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.0007353708258486971
917, epoch_train_loss=0.0007353708258486971
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.0007353708258486971
918, epoch_train_loss=0.0007353708258486971
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0007353708258486971
919, epoch_train_loss=0.0007353708258486971
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.0007353708258486971
920, epoch_train_loss=0.0007353708258486971
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.0007353708258486971
921, epoch_train_loss=0.0007353708258486971
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.0007353708258486971
922, epoch_train_loss=0.0007353708258486971
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.0007353708258486971
923, epoch_train_loss=0.0007353708258486971
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.0007353708258486971
924, epoch_train_loss=0.0007353708258486971
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.0007353708258486971
925, epoch_train_loss=0.0007353708258486971
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0007353708258486971
926, epoch_train_loss=0.0007353708258486971
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.0007353708258486971
927, epoch_train_loss=0.0007353708258486971
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.0007353708258486971
928, epoch_train_loss=0.0007353708258486971
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0007353708258486971
929, epoch_train_loss=0.0007353708258486971
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.0007353708258486971
930, epoch_train_loss=0.0007353708258486971
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.0007353708258486971
931, epoch_train_loss=0.0007353708258486971
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.0007353708258486971
932, epoch_train_loss=0.0007353708258486971
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.0007353708258486971
933, epoch_train_loss=0.0007353708258486971
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.0007353708258486971
934, epoch_train_loss=0.0007353708258486971
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.0007353708258486971
935, epoch_train_loss=0.0007353708258486971
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.0007353708258486971
936, epoch_train_loss=0.0007353708258486971
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.0007353708258486971
937, epoch_train_loss=0.0007353708258486971
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.0007353708258486971
938, epoch_train_loss=0.0007353708258486971
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.0007353708258486971
939, epoch_train_loss=0.0007353708258486971
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.0007353708258486971
940, epoch_train_loss=0.0007353708258486971
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.0007353708258486971
941, epoch_train_loss=0.0007353708258486971
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.0007353708258486971
942, epoch_train_loss=0.0007353708258486971
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.0007353708258486971
943, epoch_train_loss=0.0007353708258486971
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.0007353708258486971
944, epoch_train_loss=0.0007353708258486971
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.0007353708258486971
945, epoch_train_loss=0.0007353708258486971
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.0007353708258486971
946, epoch_train_loss=0.0007353708258486971
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.0007353708258486971
947, epoch_train_loss=0.0007353708258486971
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.0007353708258486971
948, epoch_train_loss=0.0007353708258486971
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.0007353708258486971
949, epoch_train_loss=0.0007353708258486971
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.0007353708258486971
950, epoch_train_loss=0.0007353708258486971
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0007353708258486971
951, epoch_train_loss=0.0007353708258486971
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.0007353708258486971
952, epoch_train_loss=0.0007353708258486971
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.0007353708258486971
953, epoch_train_loss=0.0007353708258486971
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.0007353708258486971
954, epoch_train_loss=0.0007353708258486971
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.0007353708258486971
955, epoch_train_loss=0.0007353708258486971
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.0007353708258486971
956, epoch_train_loss=0.0007353708258486971
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.0007353708258486971
957, epoch_train_loss=0.0007353708258486971
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.0007353708258486971
958, epoch_train_loss=0.0007353708258486971
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.0007353708258486971
959, epoch_train_loss=0.0007353708258486971
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0007353708258486971
960, epoch_train_loss=0.0007353708258486971
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0007353708258486971
961, epoch_train_loss=0.0007353708258486971
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.0007353708258486971
962, epoch_train_loss=0.0007353708258486971
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0007353708258486971
963, epoch_train_loss=0.0007353708258486971
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.0007353708258486971
964, epoch_train_loss=0.0007353708258486971
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.0007353708258486971
965, epoch_train_loss=0.0007353708258486971
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.0007353708258486971
966, epoch_train_loss=0.0007353708258486971
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.0007353708258486971
967, epoch_train_loss=0.0007353708258486971
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.0007353708258486971
968, epoch_train_loss=0.0007353708258486971
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0007353708258486971
969, epoch_train_loss=0.0007353708258486971
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.0007353708258486971
970, epoch_train_loss=0.0007353708258486971
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.0007353708258486971
971, epoch_train_loss=0.0007353708258486971
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.0007353708258486971
972, epoch_train_loss=0.0007353708258486971
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.0007353708258486971
973, epoch_train_loss=0.0007353708258486971
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.0007353708258486971
974, epoch_train_loss=0.0007353708258486971
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.0007353708258486971
975, epoch_train_loss=0.0007353708258486971
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.0007353708258486971
976, epoch_train_loss=0.0007353708258486971
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0007353708258486971
977, epoch_train_loss=0.0007353708258486971
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.0007353708258486971
978, epoch_train_loss=0.0007353708258486971
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.0007353708258486971
979, epoch_train_loss=0.0007353708258486971
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.0007353708258486971
980, epoch_train_loss=0.0007353708258486971
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0007353708258486971
981, epoch_train_loss=0.0007353708258486971
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.0007353708258486971
982, epoch_train_loss=0.0007353708258486971
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.0007353708258486971
983, epoch_train_loss=0.0007353708258486971
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0007353708258486971
984, epoch_train_loss=0.0007353708258486971
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.0007353708258486971
985, epoch_train_loss=0.0007353708258486971
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.0007353708258486971
986, epoch_train_loss=0.0007353708258486971
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.0007353708258486971
987, epoch_train_loss=0.0007353708258486971
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.0007353708258486971
988, epoch_train_loss=0.0007353708258486971
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.0007353708258486971
989, epoch_train_loss=0.0007353708258486971
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.0007353708258486971
990, epoch_train_loss=0.0007353708258486971
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0007353708258486971
991, epoch_train_loss=0.0007353708258486971
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0007353708258486971
992, epoch_train_loss=0.0007353708258486971
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0007353708258486971
993, epoch_train_loss=0.0007353708258486971
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.0007353708258486971
994, epoch_train_loss=0.0007353708258486971
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0007353708258486971
995, epoch_train_loss=0.0007353708258486971
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0007353708258486971
996, epoch_train_loss=0.0007353708258486971
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.0007353708258486971
997, epoch_train_loss=0.0007353708258486971
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.0007353708258486971
998, epoch_train_loss=0.0007353708258486971
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.0007353708258486971
999, epoch_train_loss=0.0007353708258486971
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1000, epoch_train_loss=0.0007353708258486971
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1001, epoch_train_loss=0.0007353708258486971
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1002, epoch_train_loss=0.0007353708258486971
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1003, epoch_train_loss=0.0007353708258486971
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1004, epoch_train_loss=0.0007353708258486971
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1005, epoch_train_loss=0.0007353708258486971
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1006, epoch_train_loss=0.0007353708258486971
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1007, epoch_train_loss=0.0007353708258486971
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1008, epoch_train_loss=0.0007353708258486971
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1009, epoch_train_loss=0.0007353708258486971
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1010, epoch_train_loss=0.0007353708258486971
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1011, epoch_train_loss=0.0007353708258486971
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1012, epoch_train_loss=0.0007353708258486971
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1013, epoch_train_loss=0.0007353708258486971
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1014, epoch_train_loss=0.0007353708258486971
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1015, epoch_train_loss=0.0007353708258486971
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1016, epoch_train_loss=0.0007353708258486971
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1017, epoch_train_loss=0.0007353708258486971
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1018, epoch_train_loss=0.0007353708258486971
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1019, epoch_train_loss=0.0007353708258486971
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1020, epoch_train_loss=0.0007353708258486971
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1021, epoch_train_loss=0.0007353708258486971
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1022, epoch_train_loss=0.0007353708258486971
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1023, epoch_train_loss=0.0007353708258486971
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1024, epoch_train_loss=0.0007353708258486971
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1025, epoch_train_loss=0.0007353708258486971
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1026, epoch_train_loss=0.0007353708258486971
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1027, epoch_train_loss=0.0007353708258486971
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1028, epoch_train_loss=0.0007353708258486971
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1029, epoch_train_loss=0.0007353708258486971
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1030, epoch_train_loss=0.0007353708258486971
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1031, epoch_train_loss=0.0007353708258486971
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1032, epoch_train_loss=0.0007353708258486971
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1033, epoch_train_loss=0.0007353708258486971
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1034, epoch_train_loss=0.0007353708258486971
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1035, epoch_train_loss=0.0007353708258486971
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1036, epoch_train_loss=0.0007353708258486971
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1037, epoch_train_loss=0.0007353708258486971
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1038, epoch_train_loss=0.0007353708258486971
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1039, epoch_train_loss=0.0007353708258486971
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1040, epoch_train_loss=0.0007353708258486971
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1041, epoch_train_loss=0.0007353708258486971
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1042, epoch_train_loss=0.0007353708258486971
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1043, epoch_train_loss=0.0007353708258486971
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1044, epoch_train_loss=0.0007353708258486971
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1045, epoch_train_loss=0.0007353708258486971
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1046, epoch_train_loss=0.0007353708258486971
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1047, epoch_train_loss=0.0007353708258486971
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1048, epoch_train_loss=0.0007353708258486971
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1049, epoch_train_loss=0.0007353708258486971
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1050, epoch_train_loss=0.0007353708258486971
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1051, epoch_train_loss=0.0007353708258486971
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1052, epoch_train_loss=0.0007353708258486971
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1053, epoch_train_loss=0.0007353708258486971
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1054, epoch_train_loss=0.0007353708258486971
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1055, epoch_train_loss=0.0007353708258486971
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1056, epoch_train_loss=0.0007353708258486971
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1057, epoch_train_loss=0.0007353708258486971
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1058, epoch_train_loss=0.0007353708258486971
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1059, epoch_train_loss=0.0007353708258486971
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1060, epoch_train_loss=0.0007353708258486971
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1061, epoch_train_loss=0.0007353708258486971
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1062, epoch_train_loss=0.0007353708258486971
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1063, epoch_train_loss=0.0007353708258486971
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1064, epoch_train_loss=0.0007353708258486971
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1065, epoch_train_loss=0.0007353708258486971
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1066, epoch_train_loss=0.0007353708258486971
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1067, epoch_train_loss=0.0007353708258486971
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1068, epoch_train_loss=0.0007353708258486971
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1069, epoch_train_loss=0.0007353708258486971
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1070, epoch_train_loss=0.0007353708258486971
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1071, epoch_train_loss=0.0007353708258486971
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1072, epoch_train_loss=0.0007353708258486971
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1073, epoch_train_loss=0.0007353708258486971
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1074, epoch_train_loss=0.0007353708258486971
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1075, epoch_train_loss=0.0007353708258486971
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1076, epoch_train_loss=0.0007353708258486971
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1077, epoch_train_loss=0.0007353708258486971
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1078, epoch_train_loss=0.0007353708258486971
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1079, epoch_train_loss=0.0007353708258486971
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1080, epoch_train_loss=0.0007353708258486971
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1081, epoch_train_loss=0.0007353708258486971
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1082, epoch_train_loss=0.0007353708258486971
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1083, epoch_train_loss=0.0007353708258486971
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1084, epoch_train_loss=0.0007353708258486971
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1085, epoch_train_loss=0.0007353708258486971
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1086, epoch_train_loss=0.0007353708258486971
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1087, epoch_train_loss=0.0007353708258486971
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1088, epoch_train_loss=0.0007353708258486971
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1089, epoch_train_loss=0.0007353708258486971
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1090, epoch_train_loss=0.0007353708258486971
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1091, epoch_train_loss=0.0007353708258486971
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1092, epoch_train_loss=0.0007353708258486971
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1093, epoch_train_loss=0.0007353708258486971
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1094, epoch_train_loss=0.0007353708258486971
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1095, epoch_train_loss=0.0007353708258486971
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1096, epoch_train_loss=0.0007353708258486971
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1097, epoch_train_loss=0.0007353708258486971
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1098, epoch_train_loss=0.0007353708258486971
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1099, epoch_train_loss=0.0007353708258486971
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1100, epoch_train_loss=0.0007353708258486971
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1101, epoch_train_loss=0.0007353708258486971
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1102, epoch_train_loss=0.0007353708258486971
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1103, epoch_train_loss=0.0007353708258486971
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1104, epoch_train_loss=0.0007353708258486971
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1105, epoch_train_loss=0.0007353708258486971
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1106, epoch_train_loss=0.0007353708258486971
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1107, epoch_train_loss=0.0007353708258486971
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1108, epoch_train_loss=0.0007353708258486971
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1109, epoch_train_loss=0.0007353708258486971
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1110, epoch_train_loss=0.0007353708258486971
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1111, epoch_train_loss=0.0007353708258486971
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1112, epoch_train_loss=0.0007353708258486971
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1113, epoch_train_loss=0.0007353708258486971
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1114, epoch_train_loss=0.0007353708258486971
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1115, epoch_train_loss=0.0007353708258486971
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1116, epoch_train_loss=0.0007353708258486971
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1117, epoch_train_loss=0.0007353708258486971
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1118, epoch_train_loss=0.0007353708258486971
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1119, epoch_train_loss=0.0007353708258486971
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1120, epoch_train_loss=0.0007353708258486971
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1121, epoch_train_loss=0.0007353708258486971
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1122, epoch_train_loss=0.0007353708258486971
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1123, epoch_train_loss=0.0007353708258486971
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1124, epoch_train_loss=0.0007353708258486971
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1125, epoch_train_loss=0.0007353708258486971
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1126, epoch_train_loss=0.0007353708258486971
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1127, epoch_train_loss=0.0007353708258486971
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1128, epoch_train_loss=0.0007353708258486971
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1129, epoch_train_loss=0.0007353708258486971
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1130, epoch_train_loss=0.0007353708258486971
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1131, epoch_train_loss=0.0007353708258486971
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1132, epoch_train_loss=0.0007353708258486971
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1133, epoch_train_loss=0.0007353708258486971
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1134, epoch_train_loss=0.0007353708258486971
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1135, epoch_train_loss=0.0007353708258486971
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1136, epoch_train_loss=0.0007353708258486971
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1137, epoch_train_loss=0.0007353708258486971
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1138, epoch_train_loss=0.0007353708258486971
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1139, epoch_train_loss=0.0007353708258486971
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1140, epoch_train_loss=0.0007353708258486971
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1141, epoch_train_loss=0.0007353708258486971
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1142, epoch_train_loss=0.0007353708258486971
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1143, epoch_train_loss=0.0007353708258486971
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1144, epoch_train_loss=0.0007353708258486971
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1145, epoch_train_loss=0.0007353708258486971
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1146, epoch_train_loss=0.0007353708258486971
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1147, epoch_train_loss=0.0007353708258486971
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1148, epoch_train_loss=0.0007353708258486971
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1149, epoch_train_loss=0.0007353708258486971
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1150, epoch_train_loss=0.0007353708258486971
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1151, epoch_train_loss=0.0007353708258486971
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1152, epoch_train_loss=0.0007353708258486971
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1153, epoch_train_loss=0.0007353708258486971
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1154, epoch_train_loss=0.0007353708258486971
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1155, epoch_train_loss=0.0007353708258486971
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1156, epoch_train_loss=0.0007353708258486971
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1157, epoch_train_loss=0.0007353708258486971
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1158, epoch_train_loss=0.0007353708258486971
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1159, epoch_train_loss=0.0007353708258486971
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1160, epoch_train_loss=0.0007353708258486971
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1161, epoch_train_loss=0.0007353708258486971
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1162, epoch_train_loss=0.0007353708258486971
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1163, epoch_train_loss=0.0007353708258486971
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1164, epoch_train_loss=0.0007353708258486971
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1165, epoch_train_loss=0.0007353708258486971
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1166, epoch_train_loss=0.0007353708258486971
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1167, epoch_train_loss=0.0007353708258486971
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1168, epoch_train_loss=0.0007353708258486971
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1169, epoch_train_loss=0.0007353708258486971
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1170, epoch_train_loss=0.0007353708258486971
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1171, epoch_train_loss=0.0007353708258486971
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1172, epoch_train_loss=0.0007353708258486971
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1173, epoch_train_loss=0.0007353708258486971
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1174, epoch_train_loss=0.0007353708258486971
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1175, epoch_train_loss=0.0007353708258486971
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1176, epoch_train_loss=0.0007353708258486971
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1177, epoch_train_loss=0.0007353708258486971
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1178, epoch_train_loss=0.0007353708258486971
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1179, epoch_train_loss=0.0007353708258486971
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1180, epoch_train_loss=0.0007353708258486971
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1181, epoch_train_loss=0.0007353708258486971
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1182, epoch_train_loss=0.0007353708258486971
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1183, epoch_train_loss=0.0007353708258486971
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1184, epoch_train_loss=0.0007353708258486971
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1185, epoch_train_loss=0.0007353708258486971
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1186, epoch_train_loss=0.0007353708258486971
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1187, epoch_train_loss=0.0007353708258486971
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1188, epoch_train_loss=0.0007353708258486971
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1189, epoch_train_loss=0.0007353708258486971
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1190, epoch_train_loss=0.0007353708258486971
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1191, epoch_train_loss=0.0007353708258486971
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1192, epoch_train_loss=0.0007353708258486971
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1193, epoch_train_loss=0.0007353708258486971
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1194, epoch_train_loss=0.0007353708258486971
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1195, epoch_train_loss=0.0007353708258486971
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1196, epoch_train_loss=0.0007353708258486971
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1197, epoch_train_loss=0.0007353708258486971
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1198, epoch_train_loss=0.0007353708258486971
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1199, epoch_train_loss=0.0007353708258486971
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1200, epoch_train_loss=0.0007353708258486971
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1201, epoch_train_loss=0.0007353708258486971
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1202, epoch_train_loss=0.0007353708258486971
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1203, epoch_train_loss=0.0007353708258486971
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1204, epoch_train_loss=0.0007353708258486971
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1205, epoch_train_loss=0.0007353708258486971
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1206, epoch_train_loss=0.0007353708258486971
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1207, epoch_train_loss=0.0007353708258486971
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1208, epoch_train_loss=0.0007353708258486971
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1209, epoch_train_loss=0.0007353708258486971
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1210, epoch_train_loss=0.0007353708258486971
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1211, epoch_train_loss=0.0007353708258486971
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1212, epoch_train_loss=0.0007353708258486971
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1213, epoch_train_loss=0.0007353708258486971
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1214, epoch_train_loss=0.0007353708258486971
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1215, epoch_train_loss=0.0007353708258486971
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1216, epoch_train_loss=0.0007353708258486971
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1217, epoch_train_loss=0.0007353708258486971
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1218, epoch_train_loss=0.0007353708258486971
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1219, epoch_train_loss=0.0007353708258486971
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1220, epoch_train_loss=0.0007353708258486971
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1221, epoch_train_loss=0.0007353708258486971
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1222, epoch_train_loss=0.0007353708258486971
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1223, epoch_train_loss=0.0007353708258486971
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1224, epoch_train_loss=0.0007353708258486971
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1225, epoch_train_loss=0.0007353708258486971
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1226, epoch_train_loss=0.0007353708258486971
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1227, epoch_train_loss=0.0007353708258486971
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1228, epoch_train_loss=0.0007353708258486971
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1229, epoch_train_loss=0.0007353708258486971
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1230, epoch_train_loss=0.0007353708258486971
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1231, epoch_train_loss=0.0007353708258486971
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1232, epoch_train_loss=0.0007353708258486971
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1233, epoch_train_loss=0.0007353708258486971
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1234, epoch_train_loss=0.0007353708258486971
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1235, epoch_train_loss=0.0007353708258486971
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1236, epoch_train_loss=0.0007353708258486971
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1237, epoch_train_loss=0.0007353708258486971
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1238, epoch_train_loss=0.0007353708258486971
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1239, epoch_train_loss=0.0007353708258486971
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1240, epoch_train_loss=0.0007353708258486971
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1241, epoch_train_loss=0.0007353708258486971
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1242, epoch_train_loss=0.0007353708258486971
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1243, epoch_train_loss=0.0007353708258486971
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1244, epoch_train_loss=0.0007353708258486971
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1245, epoch_train_loss=0.0007353708258486971
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1246, epoch_train_loss=0.0007353708258486971
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1247, epoch_train_loss=0.0007353708258486971
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1248, epoch_train_loss=0.0007353708258486971
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1249, epoch_train_loss=0.0007353708258486971
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1250, epoch_train_loss=0.0007353708258486971
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1251, epoch_train_loss=0.0007353708258486971
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1252, epoch_train_loss=0.0007353708258486971
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1253, epoch_train_loss=0.0007353708258486971
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1254, epoch_train_loss=0.0007353708258486971
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1255, epoch_train_loss=0.0007353708258486971
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1256, epoch_train_loss=0.0007353708258486971
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1257, epoch_train_loss=0.0007353708258486971
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1258, epoch_train_loss=0.0007353708258486971
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1259, epoch_train_loss=0.0007353708258486971
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1260, epoch_train_loss=0.0007353708258486971
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1261, epoch_train_loss=0.0007353708258486971
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1262, epoch_train_loss=0.0007353708258486971
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1263, epoch_train_loss=0.0007353708258486971
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1264, epoch_train_loss=0.0007353708258486971
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1265, epoch_train_loss=0.0007353708258486971
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1266, epoch_train_loss=0.0007353708258486971
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1267, epoch_train_loss=0.0007353708258486971
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1268, epoch_train_loss=0.0007353708258486971
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1269, epoch_train_loss=0.0007353708258486971
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1270, epoch_train_loss=0.0007353708258486971
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1271, epoch_train_loss=0.0007353708258486971
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1272, epoch_train_loss=0.0007353708258486971
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1273, epoch_train_loss=0.0007353708258486971
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1274, epoch_train_loss=0.0007353708258486971
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1275, epoch_train_loss=0.0007353708258486971
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1276, epoch_train_loss=0.0007353708258486971
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1277, epoch_train_loss=0.0007353708258486971
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1278, epoch_train_loss=0.0007353708258486971
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1279, epoch_train_loss=0.0007353708258486971
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1280, epoch_train_loss=0.0007353708258486971
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1281, epoch_train_loss=0.0007353708258486971
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1282, epoch_train_loss=0.0007353708258486971
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1283, epoch_train_loss=0.0007353708258486971
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1284, epoch_train_loss=0.0007353708258486971
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1285, epoch_train_loss=0.0007353708258486971
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1286, epoch_train_loss=0.0007353708258486971
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1287, epoch_train_loss=0.0007353708258486971
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1288, epoch_train_loss=0.0007353708258486971
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1289, epoch_train_loss=0.0007353708258486971
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1290, epoch_train_loss=0.0007353708258486971
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1291, epoch_train_loss=0.0007353708258486971
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1292, epoch_train_loss=0.0007353708258486971
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1293, epoch_train_loss=0.0007353708258486971
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1294, epoch_train_loss=0.0007353708258486971
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1295, epoch_train_loss=0.0007353708258486971
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1296, epoch_train_loss=0.0007353708258486971
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1297, epoch_train_loss=0.0007353708258486971
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1298, epoch_train_loss=0.0007353708258486971
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1299, epoch_train_loss=0.0007353708258486971
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1300, epoch_train_loss=0.0007353708258486971
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1301, epoch_train_loss=0.0007353708258486971
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1302, epoch_train_loss=0.0007353708258486971
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1303, epoch_train_loss=0.0007353708258486971
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1304, epoch_train_loss=0.0007353708258486971
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1305, epoch_train_loss=0.0007353708258486971
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1306, epoch_train_loss=0.0007353708258486971
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1307, epoch_train_loss=0.0007353708258486971
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1308, epoch_train_loss=0.0007353708258486971
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1309, epoch_train_loss=0.0007353708258486971
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1310, epoch_train_loss=0.0007353708258486971
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1311, epoch_train_loss=0.0007353708258486971
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1312, epoch_train_loss=0.0007353708258486971
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1313, epoch_train_loss=0.0007353708258486971
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1314, epoch_train_loss=0.0007353708258486971
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1315, epoch_train_loss=0.0007353708258486971
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1316, epoch_train_loss=0.0007353708258486971
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1317, epoch_train_loss=0.0007353708258486971
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1318, epoch_train_loss=0.0007353708258486971
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1319, epoch_train_loss=0.0007353708258486971
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1320, epoch_train_loss=0.0007353708258486971
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1321, epoch_train_loss=0.0007353708258486971
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1322, epoch_train_loss=0.0007353708258486971
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1323, epoch_train_loss=0.0007353708258486971
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1324, epoch_train_loss=0.0007353708258486971
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1325, epoch_train_loss=0.0007353708258486971
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1326, epoch_train_loss=0.0007353708258486971
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1327, epoch_train_loss=0.0007353708258486971
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1328, epoch_train_loss=0.0007353708258486971
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1329, epoch_train_loss=0.0007353708258486971
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1330, epoch_train_loss=0.0007353708258486971
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1331, epoch_train_loss=0.0007353708258486971
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1332, epoch_train_loss=0.0007353708258486971
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1333, epoch_train_loss=0.0007353708258486971
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1334, epoch_train_loss=0.0007353708258486971
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1335, epoch_train_loss=0.0007353708258486971
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1336, epoch_train_loss=0.0007353708258486971
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1337, epoch_train_loss=0.0007353708258486971
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1338, epoch_train_loss=0.0007353708258486971
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1339, epoch_train_loss=0.0007353708258486971
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1340, epoch_train_loss=0.0007353708258486971
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1341, epoch_train_loss=0.0007353708258486971
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1342, epoch_train_loss=0.0007353708258486971
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1343, epoch_train_loss=0.0007353708258486971
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1344, epoch_train_loss=0.0007353708258486971
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1345, epoch_train_loss=0.0007353708258486971
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1346, epoch_train_loss=0.0007353708258486971
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1347, epoch_train_loss=0.0007353708258486971
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1348, epoch_train_loss=0.0007353708258486971
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1349, epoch_train_loss=0.0007353708258486971
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1350, epoch_train_loss=0.0007353708258486971
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1351, epoch_train_loss=0.0007353708258486971
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1352, epoch_train_loss=0.0007353708258486971
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1353, epoch_train_loss=0.0007353708258486971
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1354, epoch_train_loss=0.0007353708258486971
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1355, epoch_train_loss=0.0007353708258486971
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1356, epoch_train_loss=0.0007353708258486971
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1357, epoch_train_loss=0.0007353708258486971
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1358, epoch_train_loss=0.0007353708258486971
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1359, epoch_train_loss=0.0007353708258486971
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1360, epoch_train_loss=0.0007353708258486971
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1361, epoch_train_loss=0.0007353708258486971
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1362, epoch_train_loss=0.0007353708258486971
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1363, epoch_train_loss=0.0007353708258486971
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1364, epoch_train_loss=0.0007353708258486971
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1365, epoch_train_loss=0.0007353708258486971
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1366, epoch_train_loss=0.0007353708258486971
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1367, epoch_train_loss=0.0007353708258486971
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1368, epoch_train_loss=0.0007353708258486971
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1369, epoch_train_loss=0.0007353708258486971
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1370, epoch_train_loss=0.0007353708258486971
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1371, epoch_train_loss=0.0007353708258486971
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1372, epoch_train_loss=0.0007353708258486971
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1373, epoch_train_loss=0.0007353708258486971
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1374, epoch_train_loss=0.0007353708258486971
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1375, epoch_train_loss=0.0007353708258486971
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1376, epoch_train_loss=0.0007353708258486971
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1377, epoch_train_loss=0.0007353708258486971
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1378, epoch_train_loss=0.0007353708258486971
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1379, epoch_train_loss=0.0007353708258486971
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1380, epoch_train_loss=0.0007353708258486971
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1381, epoch_train_loss=0.0007353708258486971
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1382, epoch_train_loss=0.0007353708258486971
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1383, epoch_train_loss=0.0007353708258486971
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1384, epoch_train_loss=0.0007353708258486971
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1385, epoch_train_loss=0.0007353708258486971
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1386, epoch_train_loss=0.0007353708258486971
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1387, epoch_train_loss=0.0007353708258486971
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1388, epoch_train_loss=0.0007353708258486971
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1389, epoch_train_loss=0.0007353708258486971
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1390, epoch_train_loss=0.0007353708258486971
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1391, epoch_train_loss=0.0007353708258486971
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1392, epoch_train_loss=0.0007353708258486971
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1393, epoch_train_loss=0.0007353708258486971
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1394, epoch_train_loss=0.0007353708258486971
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1395, epoch_train_loss=0.0007353708258486971
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1396, epoch_train_loss=0.0007353708258486971
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1397, epoch_train_loss=0.0007353708258486971
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1398, epoch_train_loss=0.0007353708258486971
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1399, epoch_train_loss=0.0007353708258486971
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1400, epoch_train_loss=0.0007353708258486971
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1401, epoch_train_loss=0.0007353708258486971
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1402, epoch_train_loss=0.0007353708258486971
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1403, epoch_train_loss=0.0007353708258486971
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1404, epoch_train_loss=0.0007353708258486971
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1405, epoch_train_loss=0.0007353708258486971
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1406, epoch_train_loss=0.0007353708258486971
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1407, epoch_train_loss=0.0007353708258486971
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1408, epoch_train_loss=0.0007353708258486971
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1409, epoch_train_loss=0.0007353708258486971
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1410, epoch_train_loss=0.0007353708258486971
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1411, epoch_train_loss=0.0007353708258486971
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1412, epoch_train_loss=0.0007353708258486971
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1413, epoch_train_loss=0.0007353708258486971
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1414, epoch_train_loss=0.0007353708258486971
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1415, epoch_train_loss=0.0007353708258486971
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1416, epoch_train_loss=0.0007353708258486971
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1417, epoch_train_loss=0.0007353708258486971
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1418, epoch_train_loss=0.0007353708258486971
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1419, epoch_train_loss=0.0007353708258486971
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1420, epoch_train_loss=0.0007353708258486971
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1421, epoch_train_loss=0.0007353708258486971
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1422, epoch_train_loss=0.0007353708258486971
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1423, epoch_train_loss=0.0007353708258486971
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1424, epoch_train_loss=0.0007353708258486971
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1425, epoch_train_loss=0.0007353708258486971
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1426, epoch_train_loss=0.0007353708258486971
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1427, epoch_train_loss=0.0007353708258486971
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1428, epoch_train_loss=0.0007353708258486971
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1429, epoch_train_loss=0.0007353708258486971
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1430, epoch_train_loss=0.0007353708258486971
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1431, epoch_train_loss=0.0007353708258486971
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1432, epoch_train_loss=0.0007353708258486971
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1433, epoch_train_loss=0.0007353708258486971
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1434, epoch_train_loss=0.0007353708258486971
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1435, epoch_train_loss=0.0007353708258486971
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1436, epoch_train_loss=0.0007353708258486971
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1437, epoch_train_loss=0.0007353708258486971
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1438, epoch_train_loss=0.0007353708258486971
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1439, epoch_train_loss=0.0007353708258486971
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1440, epoch_train_loss=0.0007353708258486971
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1441, epoch_train_loss=0.0007353708258486971
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1442, epoch_train_loss=0.0007353708258486971
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1443, epoch_train_loss=0.0007353708258486971
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1444, epoch_train_loss=0.0007353708258486971
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1445, epoch_train_loss=0.0007353708258486971
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1446, epoch_train_loss=0.0007353708258486971
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1447, epoch_train_loss=0.0007353708258486971
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1448, epoch_train_loss=0.0007353708258486971
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1449, epoch_train_loss=0.0007353708258486971
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1450, epoch_train_loss=0.0007353708258486971
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1451, epoch_train_loss=0.0007353708258486971
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1452, epoch_train_loss=0.0007353708258486971
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1453, epoch_train_loss=0.0007353708258486971
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1454, epoch_train_loss=0.0007353708258486971
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1455, epoch_train_loss=0.0007353708258486971
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1456, epoch_train_loss=0.0007353708258486971
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1457, epoch_train_loss=0.0007353708258486971
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1458, epoch_train_loss=0.0007353708258486971
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1459, epoch_train_loss=0.0007353708258486971
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1460, epoch_train_loss=0.0007353708258486971
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1461, epoch_train_loss=0.0007353708258486971
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1462, epoch_train_loss=0.0007353708258486971
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1463, epoch_train_loss=0.0007353708258486971
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1464, epoch_train_loss=0.0007353708258486971
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1465, epoch_train_loss=0.0007353708258486971
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1466, epoch_train_loss=0.0007353708258486971
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1467, epoch_train_loss=0.0007353708258486971
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1468, epoch_train_loss=0.0007353708258486971
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1469, epoch_train_loss=0.0007353708258486971
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1470, epoch_train_loss=0.0007353708258486971
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1471, epoch_train_loss=0.0007353708258486971
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1472, epoch_train_loss=0.0007353708258486971
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1473, epoch_train_loss=0.0007353708258486971
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1474, epoch_train_loss=0.0007353708258486971
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1475, epoch_train_loss=0.0007353708258486971
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1476, epoch_train_loss=0.0007353708258486971
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1477, epoch_train_loss=0.0007353708258486971
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1478, epoch_train_loss=0.0007353708258486971
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1479, epoch_train_loss=0.0007353708258486971
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1480, epoch_train_loss=0.0007353708258486971
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1481, epoch_train_loss=0.0007353708258486971
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1482, epoch_train_loss=0.0007353708258486971
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1483, epoch_train_loss=0.0007353708258486971
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1484, epoch_train_loss=0.0007353708258486971
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1485, epoch_train_loss=0.0007353708258486971
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1486, epoch_train_loss=0.0007353708258486971
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1487, epoch_train_loss=0.0007353708258486971
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1488, epoch_train_loss=0.0007353708258486971
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1489, epoch_train_loss=0.0007353708258486971
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1490, epoch_train_loss=0.0007353708258486971
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1491, epoch_train_loss=0.0007353708258486971
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1492, epoch_train_loss=0.0007353708258486971
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1493, epoch_train_loss=0.0007353708258486971
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1494, epoch_train_loss=0.0007353708258486971
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1495, epoch_train_loss=0.0007353708258486971
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1496, epoch_train_loss=0.0007353708258486971
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1497, epoch_train_loss=0.0007353708258486971
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1498, epoch_train_loss=0.0007353708258486971
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1499, epoch_train_loss=0.0007353708258486971
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1500, epoch_train_loss=0.0007353708258486971
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1501, epoch_train_loss=0.0007353708258486971
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1502, epoch_train_loss=0.0007353708258486971
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1503, epoch_train_loss=0.0007353708258486971
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1504, epoch_train_loss=0.0007353708258486971
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1505, epoch_train_loss=0.0007353708258486971
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1506, epoch_train_loss=0.0007353708258486971
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1507, epoch_train_loss=0.0007353708258486971
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1508, epoch_train_loss=0.0007353708258486971
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1509, epoch_train_loss=0.0007353708258486971
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1510, epoch_train_loss=0.0007353708258486971
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1511, epoch_train_loss=0.0007353708258486971
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1512, epoch_train_loss=0.0007353708258486971
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1513, epoch_train_loss=0.0007353708258486971
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1514, epoch_train_loss=0.0007353708258486971
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1515, epoch_train_loss=0.0007353708258486971
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1516, epoch_train_loss=0.0007353708258486971
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1517, epoch_train_loss=0.0007353708258486971
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1518, epoch_train_loss=0.0007353708258486971
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1519, epoch_train_loss=0.0007353708258486971
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1520, epoch_train_loss=0.0007353708258486971
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1521, epoch_train_loss=0.0007353708258486971
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1522, epoch_train_loss=0.0007353708258486971
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1523, epoch_train_loss=0.0007353708258486971
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1524, epoch_train_loss=0.0007353708258486971
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1525, epoch_train_loss=0.0007353708258486971
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1526, epoch_train_loss=0.0007353708258486971
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1527, epoch_train_loss=0.0007353708258486971
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1528, epoch_train_loss=0.0007353708258486971
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1529, epoch_train_loss=0.0007353708258486971
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1530, epoch_train_loss=0.0007353708258486971
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1531, epoch_train_loss=0.0007353708258486971
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1532, epoch_train_loss=0.0007353708258486971
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1533, epoch_train_loss=0.0007353708258486971
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1534, epoch_train_loss=0.0007353708258486971
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1535, epoch_train_loss=0.0007353708258486971
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1536, epoch_train_loss=0.0007353708258486971
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1537, epoch_train_loss=0.0007353708258486971
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1538, epoch_train_loss=0.0007353708258486971
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1539, epoch_train_loss=0.0007353708258486971
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1540, epoch_train_loss=0.0007353708258486971
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1541, epoch_train_loss=0.0007353708258486971
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1542, epoch_train_loss=0.0007353708258486971
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1543, epoch_train_loss=0.0007353708258486971
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1544, epoch_train_loss=0.0007353708258486971
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1545, epoch_train_loss=0.0007353708258486971
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1546, epoch_train_loss=0.0007353708258486971
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1547, epoch_train_loss=0.0007353708258486971
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1548, epoch_train_loss=0.0007353708258486971
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1549, epoch_train_loss=0.0007353708258486971
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1550, epoch_train_loss=0.0007353708258486971
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1551, epoch_train_loss=0.0007353708258486971
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1552, epoch_train_loss=0.0007353708258486971
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1553, epoch_train_loss=0.0007353708258486971
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1554, epoch_train_loss=0.0007353708258486971
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1555, epoch_train_loss=0.0007353708258486971
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1556, epoch_train_loss=0.0007353708258486971
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1557, epoch_train_loss=0.0007353708258486971
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1558, epoch_train_loss=0.0007353708258486971
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1559, epoch_train_loss=0.0007353708258486971
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1560, epoch_train_loss=0.0007353708258486971
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1561, epoch_train_loss=0.0007353708258486971
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1562, epoch_train_loss=0.0007353708258486971
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1563, epoch_train_loss=0.0007353708258486971
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1564, epoch_train_loss=0.0007353708258486971
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1565, epoch_train_loss=0.0007353708258486971
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1566, epoch_train_loss=0.0007353708258486971
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1567, epoch_train_loss=0.0007353708258486971
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1568, epoch_train_loss=0.0007353708258486971
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1569, epoch_train_loss=0.0007353708258486971
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1570, epoch_train_loss=0.0007353708258486971
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1571, epoch_train_loss=0.0007353708258486971
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1572, epoch_train_loss=0.0007353708258486971
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1573, epoch_train_loss=0.0007353708258486971
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1574, epoch_train_loss=0.0007353708258486971
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1575, epoch_train_loss=0.0007353708258486971
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1576, epoch_train_loss=0.0007353708258486971
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1577, epoch_train_loss=0.0007353708258486971
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1578, epoch_train_loss=0.0007353708258486971
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1579, epoch_train_loss=0.0007353708258486971
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1580, epoch_train_loss=0.0007353708258486971
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1581, epoch_train_loss=0.0007353708258486971
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1582, epoch_train_loss=0.0007353708258486971
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1583, epoch_train_loss=0.0007353708258486971
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1584, epoch_train_loss=0.0007353708258486971
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1585, epoch_train_loss=0.0007353708258486971
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1586, epoch_train_loss=0.0007353708258486971
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1587, epoch_train_loss=0.0007353708258486971
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1588, epoch_train_loss=0.0007353708258486971
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1589, epoch_train_loss=0.0007353708258486971
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1590, epoch_train_loss=0.0007353708258486971
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1591, epoch_train_loss=0.0007353708258486971
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1592, epoch_train_loss=0.0007353708258486971
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1593, epoch_train_loss=0.0007353708258486971
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1594, epoch_train_loss=0.0007353708258486971
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1595, epoch_train_loss=0.0007353708258486971
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1596, epoch_train_loss=0.0007353708258486971
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1597, epoch_train_loss=0.0007353708258486971
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1598, epoch_train_loss=0.0007353708258486971
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1599, epoch_train_loss=0.0007353708258486971
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1600, epoch_train_loss=0.0007353708258486971
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1601, epoch_train_loss=0.0007353708258486971
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1602, epoch_train_loss=0.0007353708258486971
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1603, epoch_train_loss=0.0007353708258486971
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1604, epoch_train_loss=0.0007353708258486971
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1605, epoch_train_loss=0.0007353708258486971
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1606, epoch_train_loss=0.0007353708258486971
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1607, epoch_train_loss=0.0007353708258486971
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1608, epoch_train_loss=0.0007353708258486971
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1609, epoch_train_loss=0.0007353708258486971
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1610, epoch_train_loss=0.0007353708258486971
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1611, epoch_train_loss=0.0007353708258486971
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1612, epoch_train_loss=0.0007353708258486971
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1613, epoch_train_loss=0.0007353708258486971
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1614, epoch_train_loss=0.0007353708258486971
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1615, epoch_train_loss=0.0007353708258486971
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1616, epoch_train_loss=0.0007353708258486971
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1617, epoch_train_loss=0.0007353708258486971
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1618, epoch_train_loss=0.0007353708258486971
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1619, epoch_train_loss=0.0007353708258486971
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1620, epoch_train_loss=0.0007353708258486971
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1621, epoch_train_loss=0.0007353708258486971
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1622, epoch_train_loss=0.0007353708258486971
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1623, epoch_train_loss=0.0007353708258486971
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1624, epoch_train_loss=0.0007353708258486971
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1625, epoch_train_loss=0.0007353708258486971
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1626, epoch_train_loss=0.0007353708258486971
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1627, epoch_train_loss=0.0007353708258486971
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1628, epoch_train_loss=0.0007353708258486971
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1629, epoch_train_loss=0.0007353708258486971
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1630, epoch_train_loss=0.0007353708258486971
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1631, epoch_train_loss=0.0007353708258486971
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1632, epoch_train_loss=0.0007353708258486971
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1633, epoch_train_loss=0.0007353708258486971
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1634, epoch_train_loss=0.0007353708258486971
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1635, epoch_train_loss=0.0007353708258486971
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1636, epoch_train_loss=0.0007353708258486971
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1637, epoch_train_loss=0.0007353708258486971
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1638, epoch_train_loss=0.0007353708258486971
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1639, epoch_train_loss=0.0007353708258486971
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1640, epoch_train_loss=0.0007353708258486971
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1641, epoch_train_loss=0.0007353708258486971
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1642, epoch_train_loss=0.0007353708258486971
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1643, epoch_train_loss=0.0007353708258486971
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1644, epoch_train_loss=0.0007353708258486971
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1645, epoch_train_loss=0.0007353708258486971
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1646, epoch_train_loss=0.0007353708258486971
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1647, epoch_train_loss=0.0007353708258486971
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1648, epoch_train_loss=0.0007353708258486971
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1649, epoch_train_loss=0.0007353708258486971
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1650, epoch_train_loss=0.0007353708258486971
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1651, epoch_train_loss=0.0007353708258486971
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1652, epoch_train_loss=0.0007353708258486971
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1653, epoch_train_loss=0.0007353708258486971
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1654, epoch_train_loss=0.0007353708258486971
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1655, epoch_train_loss=0.0007353708258486971
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1656, epoch_train_loss=0.0007353708258486971
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1657, epoch_train_loss=0.0007353708258486971
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1658, epoch_train_loss=0.0007353708258486971
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1659, epoch_train_loss=0.0007353708258486971
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1660, epoch_train_loss=0.0007353708258486971
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1661, epoch_train_loss=0.0007353708258486971
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1662, epoch_train_loss=0.0007353708258486971
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1663, epoch_train_loss=0.0007353708258486971
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1664, epoch_train_loss=0.0007353708258486971
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1665, epoch_train_loss=0.0007353708258486971
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1666, epoch_train_loss=0.0007353708258486971
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1667, epoch_train_loss=0.0007353708258486971
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1668, epoch_train_loss=0.0007353708258486971
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1669, epoch_train_loss=0.0007353708258486971
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1670, epoch_train_loss=0.0007353708258486971
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1671, epoch_train_loss=0.0007353708258486971
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1672, epoch_train_loss=0.0007353708258486971
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1673, epoch_train_loss=0.0007353708258486971
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1674, epoch_train_loss=0.0007353708258486971
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1675, epoch_train_loss=0.0007353708258486971
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1676, epoch_train_loss=0.0007353708258486971
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1677, epoch_train_loss=0.0007353708258486971
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1678, epoch_train_loss=0.0007353708258486971
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1679, epoch_train_loss=0.0007353708258486971
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1680, epoch_train_loss=0.0007353708258486971
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1681, epoch_train_loss=0.0007353708258486971
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1682, epoch_train_loss=0.0007353708258486971
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1683, epoch_train_loss=0.0007353708258486971
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1684, epoch_train_loss=0.0007353708258486971
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1685, epoch_train_loss=0.0007353708258486971
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1686, epoch_train_loss=0.0007353708258486971
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1687, epoch_train_loss=0.0007353708258486971
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1688, epoch_train_loss=0.0007353708258486971
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1689, epoch_train_loss=0.0007353708258486971
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1690, epoch_train_loss=0.0007353708258486971
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1691, epoch_train_loss=0.0007353708258486971
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1692, epoch_train_loss=0.0007353708258486971
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1693, epoch_train_loss=0.0007353708258486971
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1694, epoch_train_loss=0.0007353708258486971
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1695, epoch_train_loss=0.0007353708258486971
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1696, epoch_train_loss=0.0007353708258486971
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1697, epoch_train_loss=0.0007353708258486971
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1698, epoch_train_loss=0.0007353708258486971
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1699, epoch_train_loss=0.0007353708258486971
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1700, epoch_train_loss=0.0007353708258486971
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1701, epoch_train_loss=0.0007353708258486971
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1702, epoch_train_loss=0.0007353708258486971
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1703, epoch_train_loss=0.0007353708258486971
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1704, epoch_train_loss=0.0007353708258486971
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1705, epoch_train_loss=0.0007353708258486971
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1706, epoch_train_loss=0.0007353708258486971
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1707, epoch_train_loss=0.0007353708258486971
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1708, epoch_train_loss=0.0007353708258486971
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1709, epoch_train_loss=0.0007353708258486971
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1710, epoch_train_loss=0.0007353708258486971
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1711, epoch_train_loss=0.0007353708258486971
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1712, epoch_train_loss=0.0007353708258486971
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1713, epoch_train_loss=0.0007353708258486971
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1714, epoch_train_loss=0.0007353708258486971
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1715, epoch_train_loss=0.0007353708258486971
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1716, epoch_train_loss=0.0007353708258486971
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1717, epoch_train_loss=0.0007353708258486971
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1718, epoch_train_loss=0.0007353708258486971
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1719, epoch_train_loss=0.0007353708258486971
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1720, epoch_train_loss=0.0007353708258486971
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1721, epoch_train_loss=0.0007353708258486971
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1722, epoch_train_loss=0.0007353708258486971
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1723, epoch_train_loss=0.0007353708258486971
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1724, epoch_train_loss=0.0007353708258486971
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1725, epoch_train_loss=0.0007353708258486971
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1726, epoch_train_loss=0.0007353708258486971
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1727, epoch_train_loss=0.0007353708258486971
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1728, epoch_train_loss=0.0007353708258486971
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1729, epoch_train_loss=0.0007353708258486971
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1730, epoch_train_loss=0.0007353708258486971
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1731, epoch_train_loss=0.0007353708258486971
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1732, epoch_train_loss=0.0007353708258486971
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1733, epoch_train_loss=0.0007353708258486971
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1734, epoch_train_loss=0.0007353708258486971
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1735, epoch_train_loss=0.0007353708258486971
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1736, epoch_train_loss=0.0007353708258486971
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1737, epoch_train_loss=0.0007353708258486971
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1738, epoch_train_loss=0.0007353708258486971
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1739, epoch_train_loss=0.0007353708258486971
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1740, epoch_train_loss=0.0007353708258486971
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1741, epoch_train_loss=0.0007353708258486971
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1742, epoch_train_loss=0.0007353708258486971
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1743, epoch_train_loss=0.0007353708258486971
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1744, epoch_train_loss=0.0007353708258486971
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1745, epoch_train_loss=0.0007353708258486971
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1746, epoch_train_loss=0.0007353708258486971
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1747, epoch_train_loss=0.0007353708258486971
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1748, epoch_train_loss=0.0007353708258486971
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1749, epoch_train_loss=0.0007353708258486971
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1750, epoch_train_loss=0.0007353708258486971
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1751, epoch_train_loss=0.0007353708258486971
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1752, epoch_train_loss=0.0007353708258486971
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1753, epoch_train_loss=0.0007353708258486971
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1754, epoch_train_loss=0.0007353708258486971
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1755, epoch_train_loss=0.0007353708258486971
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1756, epoch_train_loss=0.0007353708258486971
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1757, epoch_train_loss=0.0007353708258486971
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1758, epoch_train_loss=0.0007353708258486971
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1759, epoch_train_loss=0.0007353708258486971
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1760, epoch_train_loss=0.0007353708258486971
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1761, epoch_train_loss=0.0007353708258486971
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1762, epoch_train_loss=0.0007353708258486971
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1763, epoch_train_loss=0.0007353708258486971
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1764, epoch_train_loss=0.0007353708258486971
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1765, epoch_train_loss=0.0007353708258486971
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1766, epoch_train_loss=0.0007353708258486971
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1767, epoch_train_loss=0.0007353708258486971
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1768, epoch_train_loss=0.0007353708258486971
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1769, epoch_train_loss=0.0007353708258486971
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1770, epoch_train_loss=0.0007353708258486971
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1771, epoch_train_loss=0.0007353708258486971
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1772, epoch_train_loss=0.0007353708258486971
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1773, epoch_train_loss=0.0007353708258486971
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1774, epoch_train_loss=0.0007353708258486971
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1775, epoch_train_loss=0.0007353708258486971
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1776, epoch_train_loss=0.0007353708258486971
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1777, epoch_train_loss=0.0007353708258486971
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1778, epoch_train_loss=0.0007353708258486971
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1779, epoch_train_loss=0.0007353708258486971
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1780, epoch_train_loss=0.0007353708258486971
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1781, epoch_train_loss=0.0007353708258486971
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1782, epoch_train_loss=0.0007353708258486971
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1783, epoch_train_loss=0.0007353708258486971
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1784, epoch_train_loss=0.0007353708258486971
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1785, epoch_train_loss=0.0007353708258486971
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1786, epoch_train_loss=0.0007353708258486971
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1787, epoch_train_loss=0.0007353708258486971
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1788, epoch_train_loss=0.0007353708258486971
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1789, epoch_train_loss=0.0007353708258486971
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1790, epoch_train_loss=0.0007353708258486971
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1791, epoch_train_loss=0.0007353708258486971
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1792, epoch_train_loss=0.0007353708258486971
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1793, epoch_train_loss=0.0007353708258486971
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1794, epoch_train_loss=0.0007353708258486971
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1795, epoch_train_loss=0.0007353708258486971
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1796, epoch_train_loss=0.0007353708258486971
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1797, epoch_train_loss=0.0007353708258486971
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1798, epoch_train_loss=0.0007353708258486971
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1799, epoch_train_loss=0.0007353708258486971
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1800, epoch_train_loss=0.0007353708258486971
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1801, epoch_train_loss=0.0007353708258486971
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1802, epoch_train_loss=0.0007353708258486971
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1803, epoch_train_loss=0.0007353708258486971
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1804, epoch_train_loss=0.0007353708258486971
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1805, epoch_train_loss=0.0007353708258486971
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1806, epoch_train_loss=0.0007353708258486971
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1807, epoch_train_loss=0.0007353708258486971
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1808, epoch_train_loss=0.0007353708258486971
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1809, epoch_train_loss=0.0007353708258486971
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1810, epoch_train_loss=0.0007353708258486971
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1811, epoch_train_loss=0.0007353708258486971
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1812, epoch_train_loss=0.0007353708258486971
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1813, epoch_train_loss=0.0007353708258486971
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1814, epoch_train_loss=0.0007353708258486971
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1815, epoch_train_loss=0.0007353708258486971
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1816, epoch_train_loss=0.0007353708258486971
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1817, epoch_train_loss=0.0007353708258486971
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1818, epoch_train_loss=0.0007353708258486971
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1819, epoch_train_loss=0.0007353708258486971
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1820, epoch_train_loss=0.0007353708258486971
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1821, epoch_train_loss=0.0007353708258486971
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1822, epoch_train_loss=0.0007353708258486971
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1823, epoch_train_loss=0.0007353708258486971
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1824, epoch_train_loss=0.0007353708258486971
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1825, epoch_train_loss=0.0007353708258486971
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1826, epoch_train_loss=0.0007353708258486971
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1827, epoch_train_loss=0.0007353708258486971
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1828, epoch_train_loss=0.0007353708258486971
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1829, epoch_train_loss=0.0007353708258486971
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1830, epoch_train_loss=0.0007353708258486971
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1831, epoch_train_loss=0.0007353708258486971
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1832, epoch_train_loss=0.0007353708258486971
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1833, epoch_train_loss=0.0007353708258486971
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1834, epoch_train_loss=0.0007353708258486971
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1835, epoch_train_loss=0.0007353708258486971
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1836, epoch_train_loss=0.0007353708258486971
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1837, epoch_train_loss=0.0007353708258486971
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1838, epoch_train_loss=0.0007353708258486971
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1839, epoch_train_loss=0.0007353708258486971
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1840, epoch_train_loss=0.0007353708258486971
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1841, epoch_train_loss=0.0007353708258486971
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1842, epoch_train_loss=0.0007353708258486971
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1843, epoch_train_loss=0.0007353708258486971
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1844, epoch_train_loss=0.0007353708258486971
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1845, epoch_train_loss=0.0007353708258486971
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1846, epoch_train_loss=0.0007353708258486971
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1847, epoch_train_loss=0.0007353708258486971
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1848, epoch_train_loss=0.0007353708258486971
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1849, epoch_train_loss=0.0007353708258486971
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1850, epoch_train_loss=0.0007353708258486971
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1851, epoch_train_loss=0.0007353708258486971
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1852, epoch_train_loss=0.0007353708258486971
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1853, epoch_train_loss=0.0007353708258486971
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1854, epoch_train_loss=0.0007353708258486971
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1855, epoch_train_loss=0.0007353708258486971
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1856, epoch_train_loss=0.0007353708258486971
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1857, epoch_train_loss=0.0007353708258486971
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1858, epoch_train_loss=0.0007353708258486971
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1859, epoch_train_loss=0.0007353708258486971
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1860, epoch_train_loss=0.0007353708258486971
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1861, epoch_train_loss=0.0007353708258486971
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1862, epoch_train_loss=0.0007353708258486971
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1863, epoch_train_loss=0.0007353708258486971
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1864, epoch_train_loss=0.0007353708258486971
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1865, epoch_train_loss=0.0007353708258486971
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1866, epoch_train_loss=0.0007353708258486971
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1867, epoch_train_loss=0.0007353708258486971
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1868, epoch_train_loss=0.0007353708258486971
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1869, epoch_train_loss=0.0007353708258486971
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1870, epoch_train_loss=0.0007353708258486971
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1871, epoch_train_loss=0.0007353708258486971
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1872, epoch_train_loss=0.0007353708258486971
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1873, epoch_train_loss=0.0007353708258486971
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1874, epoch_train_loss=0.0007353708258486971
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1875, epoch_train_loss=0.0007353708258486971
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1876, epoch_train_loss=0.0007353708258486971
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1877, epoch_train_loss=0.0007353708258486971
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1878, epoch_train_loss=0.0007353708258486971
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1879, epoch_train_loss=0.0007353708258486971
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1880, epoch_train_loss=0.0007353708258486971
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1881, epoch_train_loss=0.0007353708258486971
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1882, epoch_train_loss=0.0007353708258486971
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1883, epoch_train_loss=0.0007353708258486971
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1884, epoch_train_loss=0.0007353708258486971
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1885, epoch_train_loss=0.0007353708258486971
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1886, epoch_train_loss=0.0007353708258486971
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1887, epoch_train_loss=0.0007353708258486971
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1888, epoch_train_loss=0.0007353708258486971
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1889, epoch_train_loss=0.0007353708258486971
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1890, epoch_train_loss=0.0007353708258486971
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1891, epoch_train_loss=0.0007353708258486971
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1892, epoch_train_loss=0.0007353708258486971
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1893, epoch_train_loss=0.0007353708258486971
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1894, epoch_train_loss=0.0007353708258486971
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1895, epoch_train_loss=0.0007353708258486971
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1896, epoch_train_loss=0.0007353708258486971
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1897, epoch_train_loss=0.0007353708258486971
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1898, epoch_train_loss=0.0007353708258486971
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1899, epoch_train_loss=0.0007353708258486971
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1900, epoch_train_loss=0.0007353708258486971
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1901, epoch_train_loss=0.0007353708258486971
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1902, epoch_train_loss=0.0007353708258486971
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1903, epoch_train_loss=0.0007353708258486971
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1904, epoch_train_loss=0.0007353708258486971
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1905, epoch_train_loss=0.0007353708258486971
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1906, epoch_train_loss=0.0007353708258486971
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1907, epoch_train_loss=0.0007353708258486971
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1908, epoch_train_loss=0.0007353708258486971
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1909, epoch_train_loss=0.0007353708258486971
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1910, epoch_train_loss=0.0007353708258486971
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1911, epoch_train_loss=0.0007353708258486971
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1912, epoch_train_loss=0.0007353708258486971
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1913, epoch_train_loss=0.0007353708258486971
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1914, epoch_train_loss=0.0007353708258486971
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1915, epoch_train_loss=0.0007353708258486971
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1916, epoch_train_loss=0.0007353708258486971
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1917, epoch_train_loss=0.0007353708258486971
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1918, epoch_train_loss=0.0007353708258486971
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1919, epoch_train_loss=0.0007353708258486971
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1920, epoch_train_loss=0.0007353708258486971
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1921, epoch_train_loss=0.0007353708258486971
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1922, epoch_train_loss=0.0007353708258486971
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1923, epoch_train_loss=0.0007353708258486971
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1924, epoch_train_loss=0.0007353708258486971
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1925, epoch_train_loss=0.0007353708258486971
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1926, epoch_train_loss=0.0007353708258486971
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1927, epoch_train_loss=0.0007353708258486971
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1928, epoch_train_loss=0.0007353708258486971
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1929, epoch_train_loss=0.0007353708258486971
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1930, epoch_train_loss=0.0007353708258486971
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1931, epoch_train_loss=0.0007353708258486971
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1932, epoch_train_loss=0.0007353708258486971
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1933, epoch_train_loss=0.0007353708258486971
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1934, epoch_train_loss=0.0007353708258486971
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1935, epoch_train_loss=0.0007353708258486971
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1936, epoch_train_loss=0.0007353708258486971
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1937, epoch_train_loss=0.0007353708258486971
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1938, epoch_train_loss=0.0007353708258486971
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1939, epoch_train_loss=0.0007353708258486971
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1940, epoch_train_loss=0.0007353708258486971
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1941, epoch_train_loss=0.0007353708258486971
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1942, epoch_train_loss=0.0007353708258486971
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1943, epoch_train_loss=0.0007353708258486971
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1944, epoch_train_loss=0.0007353708258486971
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1945, epoch_train_loss=0.0007353708258486971
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1946, epoch_train_loss=0.0007353708258486971
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1947, epoch_train_loss=0.0007353708258486971
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1948, epoch_train_loss=0.0007353708258486971
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1949, epoch_train_loss=0.0007353708258486971
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1950, epoch_train_loss=0.0007353708258486971
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1951, epoch_train_loss=0.0007353708258486971
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1952, epoch_train_loss=0.0007353708258486971
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1953, epoch_train_loss=0.0007353708258486971
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1954, epoch_train_loss=0.0007353708258486971
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1955, epoch_train_loss=0.0007353708258486971
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1956, epoch_train_loss=0.0007353708258486971
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1957, epoch_train_loss=0.0007353708258486971
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1958, epoch_train_loss=0.0007353708258486971
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1959, epoch_train_loss=0.0007353708258486971
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1960, epoch_train_loss=0.0007353708258486971
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1961, epoch_train_loss=0.0007353708258486971
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1962, epoch_train_loss=0.0007353708258486971
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1963, epoch_train_loss=0.0007353708258486971
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1964, epoch_train_loss=0.0007353708258486971
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1965, epoch_train_loss=0.0007353708258486971
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1966, epoch_train_loss=0.0007353708258486971
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1967, epoch_train_loss=0.0007353708258486971
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1968, epoch_train_loss=0.0007353708258486971
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1969, epoch_train_loss=0.0007353708258486971
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1970, epoch_train_loss=0.0007353708258486971
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1971, epoch_train_loss=0.0007353708258486971
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1972, epoch_train_loss=0.0007353708258486971
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1973, epoch_train_loss=0.0007353708258486971
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1974, epoch_train_loss=0.0007353708258486971
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1975, epoch_train_loss=0.0007353708258486971
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1976, epoch_train_loss=0.0007353708258486971
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1977, epoch_train_loss=0.0007353708258486971
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1978, epoch_train_loss=0.0007353708258486971
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1979, epoch_train_loss=0.0007353708258486971
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1980, epoch_train_loss=0.0007353708258486971
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1981, epoch_train_loss=0.0007353708258486971
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1982, epoch_train_loss=0.0007353708258486971
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1983, epoch_train_loss=0.0007353708258486971
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1984, epoch_train_loss=0.0007353708258486971
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1985, epoch_train_loss=0.0007353708258486971
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1986, epoch_train_loss=0.0007353708258486971
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1987, epoch_train_loss=0.0007353708258486971
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1988, epoch_train_loss=0.0007353708258486971
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1989, epoch_train_loss=0.0007353708258486971
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1990, epoch_train_loss=0.0007353708258486971
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1991, epoch_train_loss=0.0007353708258486971
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1992, epoch_train_loss=0.0007353708258486971
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1993, epoch_train_loss=0.0007353708258486971
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1994, epoch_train_loss=0.0007353708258486971
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1995, epoch_train_loss=0.0007353708258486971
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1996, epoch_train_loss=0.0007353708258486971
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1997, epoch_train_loss=0.0007353708258486971
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1998, epoch_train_loss=0.0007353708258486971
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 0.0007353708258486971
1999, epoch_train_loss=0.0007353708258486971
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2000, epoch_train_loss=0.0007353708258486971
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2001, epoch_train_loss=0.0007353708258486971
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2002, epoch_train_loss=0.0007353708258486971
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2003, epoch_train_loss=0.0007353708258486971
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2004, epoch_train_loss=0.0007353708258486971
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2005, epoch_train_loss=0.0007353708258486971
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2006, epoch_train_loss=0.0007353708258486971
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2007, epoch_train_loss=0.0007353708258486971
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2008, epoch_train_loss=0.0007353708258486971
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2009, epoch_train_loss=0.0007353708258486971
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2010, epoch_train_loss=0.0007353708258486971
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2011, epoch_train_loss=0.0007353708258486971
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2012, epoch_train_loss=0.0007353708258486971
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2013, epoch_train_loss=0.0007353708258486971
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2014, epoch_train_loss=0.0007353708258486971
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2015, epoch_train_loss=0.0007353708258486971
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2016, epoch_train_loss=0.0007353708258486971
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2017, epoch_train_loss=0.0007353708258486971
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2018, epoch_train_loss=0.0007353708258486971
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2019, epoch_train_loss=0.0007353708258486971
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2020, epoch_train_loss=0.0007353708258486971
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2021, epoch_train_loss=0.0007353708258486971
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2022, epoch_train_loss=0.0007353708258486971
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2023, epoch_train_loss=0.0007353708258486971
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2024, epoch_train_loss=0.0007353708258486971
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2025, epoch_train_loss=0.0007353708258486971
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2026, epoch_train_loss=0.0007353708258486971
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2027, epoch_train_loss=0.0007353708258486971
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2028, epoch_train_loss=0.0007353708258486971
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2029, epoch_train_loss=0.0007353708258486971
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2030, epoch_train_loss=0.0007353708258486971
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2031, epoch_train_loss=0.0007353708258486971
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2032, epoch_train_loss=0.0007353708258486971
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2033, epoch_train_loss=0.0007353708258486971
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2034, epoch_train_loss=0.0007353708258486971
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2035, epoch_train_loss=0.0007353708258486971
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2036, epoch_train_loss=0.0007353708258486971
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2037, epoch_train_loss=0.0007353708258486971
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2038, epoch_train_loss=0.0007353708258486971
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2039, epoch_train_loss=0.0007353708258486971
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2040, epoch_train_loss=0.0007353708258486971
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2041, epoch_train_loss=0.0007353708258486971
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2042, epoch_train_loss=0.0007353708258486971
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2043, epoch_train_loss=0.0007353708258486971
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2044, epoch_train_loss=0.0007353708258486971
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2045, epoch_train_loss=0.0007353708258486971
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2046, epoch_train_loss=0.0007353708258486971
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2047, epoch_train_loss=0.0007353708258486971
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2048, epoch_train_loss=0.0007353708258486971
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2049, epoch_train_loss=0.0007353708258486971
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2050, epoch_train_loss=0.0007353708258486971
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2051, epoch_train_loss=0.0007353708258486971
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2052, epoch_train_loss=0.0007353708258486971
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2053, epoch_train_loss=0.0007353708258486971
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2054, epoch_train_loss=0.0007353708258486971
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2055, epoch_train_loss=0.0007353708258486971
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2056, epoch_train_loss=0.0007353708258486971
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2057, epoch_train_loss=0.0007353708258486971
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2058, epoch_train_loss=0.0007353708258486971
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2059, epoch_train_loss=0.0007353708258486971
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2060, epoch_train_loss=0.0007353708258486971
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2061, epoch_train_loss=0.0007353708258486971
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2062, epoch_train_loss=0.0007353708258486971
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2063, epoch_train_loss=0.0007353708258486971
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2064, epoch_train_loss=0.0007353708258486971
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2065, epoch_train_loss=0.0007353708258486971
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2066, epoch_train_loss=0.0007353708258486971
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2067, epoch_train_loss=0.0007353708258486971
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2068, epoch_train_loss=0.0007353708258486971
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2069, epoch_train_loss=0.0007353708258486971
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2070, epoch_train_loss=0.0007353708258486971
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2071, epoch_train_loss=0.0007353708258486971
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2072, epoch_train_loss=0.0007353708258486971
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2073, epoch_train_loss=0.0007353708258486971
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2074, epoch_train_loss=0.0007353708258486971
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2075, epoch_train_loss=0.0007353708258486971
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2076, epoch_train_loss=0.0007353708258486971
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2077, epoch_train_loss=0.0007353708258486971
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2078, epoch_train_loss=0.0007353708258486971
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2079, epoch_train_loss=0.0007353708258486971
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2080, epoch_train_loss=0.0007353708258486971
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2081, epoch_train_loss=0.0007353708258486971
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2082, epoch_train_loss=0.0007353708258486971
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2083, epoch_train_loss=0.0007353708258486971
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2084, epoch_train_loss=0.0007353708258486971
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2085, epoch_train_loss=0.0007353708258486971
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2086, epoch_train_loss=0.0007353708258486971
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2087, epoch_train_loss=0.0007353708258486971
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2088, epoch_train_loss=0.0007353708258486971
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2089, epoch_train_loss=0.0007353708258486971
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2090, epoch_train_loss=0.0007353708258486971
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2091, epoch_train_loss=0.0007353708258486971
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2092, epoch_train_loss=0.0007353708258486971
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2093, epoch_train_loss=0.0007353708258486971
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2094, epoch_train_loss=0.0007353708258486971
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2095, epoch_train_loss=0.0007353708258486971
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2096, epoch_train_loss=0.0007353708258486971
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2097, epoch_train_loss=0.0007353708258486971
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2098, epoch_train_loss=0.0007353708258486971
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2099, epoch_train_loss=0.0007353708258486971
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2100, epoch_train_loss=0.0007353708258486971
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2101, epoch_train_loss=0.0007353708258486971
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2102, epoch_train_loss=0.0007353708258486971
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2103, epoch_train_loss=0.0007353708258486971
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2104, epoch_train_loss=0.0007353708258486971
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2105, epoch_train_loss=0.0007353708258486971
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2106, epoch_train_loss=0.0007353708258486971
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2107, epoch_train_loss=0.0007353708258486971
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2108, epoch_train_loss=0.0007353708258486971
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2109, epoch_train_loss=0.0007353708258486971
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2110, epoch_train_loss=0.0007353708258486971
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2111, epoch_train_loss=0.0007353708258486971
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2112, epoch_train_loss=0.0007353708258486971
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2113, epoch_train_loss=0.0007353708258486971
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2114, epoch_train_loss=0.0007353708258486971
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2115, epoch_train_loss=0.0007353708258486971
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2116, epoch_train_loss=0.0007353708258486971
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2117, epoch_train_loss=0.0007353708258486971
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2118, epoch_train_loss=0.0007353708258486971
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2119, epoch_train_loss=0.0007353708258486971
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2120, epoch_train_loss=0.0007353708258486971
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2121, epoch_train_loss=0.0007353708258486971
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2122, epoch_train_loss=0.0007353708258486971
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2123, epoch_train_loss=0.0007353708258486971
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2124, epoch_train_loss=0.0007353708258486971
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2125, epoch_train_loss=0.0007353708258486971
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2126, epoch_train_loss=0.0007353708258486971
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2127, epoch_train_loss=0.0007353708258486971
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2128, epoch_train_loss=0.0007353708258486971
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2129, epoch_train_loss=0.0007353708258486971
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2130, epoch_train_loss=0.0007353708258486971
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2131, epoch_train_loss=0.0007353708258486971
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2132, epoch_train_loss=0.0007353708258486971
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2133, epoch_train_loss=0.0007353708258486971
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2134, epoch_train_loss=0.0007353708258486971
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2135, epoch_train_loss=0.0007353708258486971
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2136, epoch_train_loss=0.0007353708258486971
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2137, epoch_train_loss=0.0007353708258486971
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2138, epoch_train_loss=0.0007353708258486971
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2139, epoch_train_loss=0.0007353708258486971
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2140, epoch_train_loss=0.0007353708258486971
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2141, epoch_train_loss=0.0007353708258486971
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2142, epoch_train_loss=0.0007353708258486971
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2143, epoch_train_loss=0.0007353708258486971
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2144, epoch_train_loss=0.0007353708258486971
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2145, epoch_train_loss=0.0007353708258486971
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2146, epoch_train_loss=0.0007353708258486971
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2147, epoch_train_loss=0.0007353708258486971
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2148, epoch_train_loss=0.0007353708258486971
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2149, epoch_train_loss=0.0007353708258486971
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2150, epoch_train_loss=0.0007353708258486971
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2151, epoch_train_loss=0.0007353708258486971
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2152, epoch_train_loss=0.0007353708258486971
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2153, epoch_train_loss=0.0007353708258486971
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2154, epoch_train_loss=0.0007353708258486971
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2155, epoch_train_loss=0.0007353708258486971
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2156, epoch_train_loss=0.0007353708258486971
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2157, epoch_train_loss=0.0007353708258486971
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2158, epoch_train_loss=0.0007353708258486971
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2159, epoch_train_loss=0.0007353708258486971
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2160, epoch_train_loss=0.0007353708258486971
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2161, epoch_train_loss=0.0007353708258486971
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2162, epoch_train_loss=0.0007353708258486971
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2163, epoch_train_loss=0.0007353708258486971
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2164, epoch_train_loss=0.0007353708258486971
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2165, epoch_train_loss=0.0007353708258486971
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2166, epoch_train_loss=0.0007353708258486971
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2167, epoch_train_loss=0.0007353708258486971
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2168, epoch_train_loss=0.0007353708258486971
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2169, epoch_train_loss=0.0007353708258486971
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2170, epoch_train_loss=0.0007353708258486971
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2171, epoch_train_loss=0.0007353708258486971
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2172, epoch_train_loss=0.0007353708258486971
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2173, epoch_train_loss=0.0007353708258486971
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2174, epoch_train_loss=0.0007353708258486971
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2175, epoch_train_loss=0.0007353708258486971
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2176, epoch_train_loss=0.0007353708258486971
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2177, epoch_train_loss=0.0007353708258486971
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2178, epoch_train_loss=0.0007353708258486971
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2179, epoch_train_loss=0.0007353708258486971
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2180, epoch_train_loss=0.0007353708258486971
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2181, epoch_train_loss=0.0007353708258486971
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2182, epoch_train_loss=0.0007353708258486971
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2183, epoch_train_loss=0.0007353708258486971
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2184, epoch_train_loss=0.0007353708258486971
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2185, epoch_train_loss=0.0007353708258486971
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2186, epoch_train_loss=0.0007353708258486971
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2187, epoch_train_loss=0.0007353708258486971
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2188, epoch_train_loss=0.0007353708258486971
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2189, epoch_train_loss=0.0007353708258486971
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2190, epoch_train_loss=0.0007353708258486971
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2191, epoch_train_loss=0.0007353708258486971
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2192, epoch_train_loss=0.0007353708258486971
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2193, epoch_train_loss=0.0007353708258486971
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2194, epoch_train_loss=0.0007353708258486971
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2195, epoch_train_loss=0.0007353708258486971
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2196, epoch_train_loss=0.0007353708258486971
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2197, epoch_train_loss=0.0007353708258486971
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2198, epoch_train_loss=0.0007353708258486971
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2199, epoch_train_loss=0.0007353708258486971
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2200, epoch_train_loss=0.0007353708258486971
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2201, epoch_train_loss=0.0007353708258486971
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2202, epoch_train_loss=0.0007353708258486971
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2203, epoch_train_loss=0.0007353708258486971
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2204, epoch_train_loss=0.0007353708258486971
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2205, epoch_train_loss=0.0007353708258486971
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2206, epoch_train_loss=0.0007353708258486971
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2207, epoch_train_loss=0.0007353708258486971
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2208, epoch_train_loss=0.0007353708258486971
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2209, epoch_train_loss=0.0007353708258486971
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2210, epoch_train_loss=0.0007353708258486971
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2211, epoch_train_loss=0.0007353708258486971
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2212, epoch_train_loss=0.0007353708258486971
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2213, epoch_train_loss=0.0007353708258486971
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2214, epoch_train_loss=0.0007353708258486971
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2215, epoch_train_loss=0.0007353708258486971
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2216, epoch_train_loss=0.0007353708258486971
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2217, epoch_train_loss=0.0007353708258486971
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2218, epoch_train_loss=0.0007353708258486971
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2219, epoch_train_loss=0.0007353708258486971
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2220, epoch_train_loss=0.0007353708258486971
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2221, epoch_train_loss=0.0007353708258486971
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2222, epoch_train_loss=0.0007353708258486971
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2223, epoch_train_loss=0.0007353708258486971
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2224, epoch_train_loss=0.0007353708258486971
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2225, epoch_train_loss=0.0007353708258486971
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2226, epoch_train_loss=0.0007353708258486971
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2227, epoch_train_loss=0.0007353708258486971
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2228, epoch_train_loss=0.0007353708258486971
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2229, epoch_train_loss=0.0007353708258486971
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2230, epoch_train_loss=0.0007353708258486971
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2231, epoch_train_loss=0.0007353708258486971
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2232, epoch_train_loss=0.0007353708258486971
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2233, epoch_train_loss=0.0007353708258486971
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2234, epoch_train_loss=0.0007353708258486971
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2235, epoch_train_loss=0.0007353708258486971
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2236, epoch_train_loss=0.0007353708258486971
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2237, epoch_train_loss=0.0007353708258486971
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2238, epoch_train_loss=0.0007353708258486971
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2239, epoch_train_loss=0.0007353708258486971
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2240, epoch_train_loss=0.0007353708258486971
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2241, epoch_train_loss=0.0007353708258486971
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2242, epoch_train_loss=0.0007353708258486971
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2243, epoch_train_loss=0.0007353708258486971
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2244, epoch_train_loss=0.0007353708258486971
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2245, epoch_train_loss=0.0007353708258486971
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2246, epoch_train_loss=0.0007353708258486971
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2247, epoch_train_loss=0.0007353708258486971
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2248, epoch_train_loss=0.0007353708258486971
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2249, epoch_train_loss=0.0007353708258486971
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2250, epoch_train_loss=0.0007353708258486971
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2251, epoch_train_loss=0.0007353708258486971
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2252, epoch_train_loss=0.0007353708258486971
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2253, epoch_train_loss=0.0007353708258486971
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2254, epoch_train_loss=0.0007353708258486971
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2255, epoch_train_loss=0.0007353708258486971
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2256, epoch_train_loss=0.0007353708258486971
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2257, epoch_train_loss=0.0007353708258486971
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2258, epoch_train_loss=0.0007353708258486971
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2259, epoch_train_loss=0.0007353708258486971
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2260, epoch_train_loss=0.0007353708258486971
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2261, epoch_train_loss=0.0007353708258486971
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2262, epoch_train_loss=0.0007353708258486971
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2263, epoch_train_loss=0.0007353708258486971
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2264, epoch_train_loss=0.0007353708258486971
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2265, epoch_train_loss=0.0007353708258486971
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2266, epoch_train_loss=0.0007353708258486971
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2267, epoch_train_loss=0.0007353708258486971
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2268, epoch_train_loss=0.0007353708258486971
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2269, epoch_train_loss=0.0007353708258486971
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2270, epoch_train_loss=0.0007353708258486971
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2271, epoch_train_loss=0.0007353708258486971
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2272, epoch_train_loss=0.0007353708258486971
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2273, epoch_train_loss=0.0007353708258486971
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2274, epoch_train_loss=0.0007353708258486971
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2275, epoch_train_loss=0.0007353708258486971
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2276, epoch_train_loss=0.0007353708258486971
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2277, epoch_train_loss=0.0007353708258486971
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2278, epoch_train_loss=0.0007353708258486971
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2279, epoch_train_loss=0.0007353708258486971
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2280, epoch_train_loss=0.0007353708258486971
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2281, epoch_train_loss=0.0007353708258486971
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2282, epoch_train_loss=0.0007353708258486971
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2283, epoch_train_loss=0.0007353708258486971
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2284, epoch_train_loss=0.0007353708258486971
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2285, epoch_train_loss=0.0007353708258486971
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2286, epoch_train_loss=0.0007353708258486971
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2287, epoch_train_loss=0.0007353708258486971
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2288, epoch_train_loss=0.0007353708258486971
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2289, epoch_train_loss=0.0007353708258486971
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2290, epoch_train_loss=0.0007353708258486971
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2291, epoch_train_loss=0.0007353708258486971
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2292, epoch_train_loss=0.0007353708258486971
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2293, epoch_train_loss=0.0007353708258486971
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2294, epoch_train_loss=0.0007353708258486971
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2295, epoch_train_loss=0.0007353708258486971
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2296, epoch_train_loss=0.0007353708258486971
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2297, epoch_train_loss=0.0007353708258486971
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2298, epoch_train_loss=0.0007353708258486971
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2299, epoch_train_loss=0.0007353708258486971
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2300, epoch_train_loss=0.0007353708258486971
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2301, epoch_train_loss=0.0007353708258486971
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2302, epoch_train_loss=0.0007353708258486971
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2303, epoch_train_loss=0.0007353708258486971
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2304, epoch_train_loss=0.0007353708258486971
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2305, epoch_train_loss=0.0007353708258486971
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2306, epoch_train_loss=0.0007353708258486971
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2307, epoch_train_loss=0.0007353708258486971
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2308, epoch_train_loss=0.0007353708258486971
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2309, epoch_train_loss=0.0007353708258486971
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2310, epoch_train_loss=0.0007353708258486971
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2311, epoch_train_loss=0.0007353708258486971
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2312, epoch_train_loss=0.0007353708258486971
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2313, epoch_train_loss=0.0007353708258486971
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2314, epoch_train_loss=0.0007353708258486971
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2315, epoch_train_loss=0.0007353708258486971
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2316, epoch_train_loss=0.0007353708258486971
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2317, epoch_train_loss=0.0007353708258486971
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2318, epoch_train_loss=0.0007353708258486971
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2319, epoch_train_loss=0.0007353708258486971
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2320, epoch_train_loss=0.0007353708258486971
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2321, epoch_train_loss=0.0007353708258486971
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2322, epoch_train_loss=0.0007353708258486971
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2323, epoch_train_loss=0.0007353708258486971
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2324, epoch_train_loss=0.0007353708258486971
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2325, epoch_train_loss=0.0007353708258486971
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2326, epoch_train_loss=0.0007353708258486971
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2327, epoch_train_loss=0.0007353708258486971
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2328, epoch_train_loss=0.0007353708258486971
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2329, epoch_train_loss=0.0007353708258486971
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2330, epoch_train_loss=0.0007353708258486971
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2331, epoch_train_loss=0.0007353708258486971
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2332, epoch_train_loss=0.0007353708258486971
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2333, epoch_train_loss=0.0007353708258486971
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2334, epoch_train_loss=0.0007353708258486971
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2335, epoch_train_loss=0.0007353708258486971
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2336, epoch_train_loss=0.0007353708258486971
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2337, epoch_train_loss=0.0007353708258486971
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2338, epoch_train_loss=0.0007353708258486971
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2339, epoch_train_loss=0.0007353708258486971
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2340, epoch_train_loss=0.0007353708258486971
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2341, epoch_train_loss=0.0007353708258486971
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2342, epoch_train_loss=0.0007353708258486971
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2343, epoch_train_loss=0.0007353708258486971
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2344, epoch_train_loss=0.0007353708258486971
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2345, epoch_train_loss=0.0007353708258486971
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2346, epoch_train_loss=0.0007353708258486971
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2347, epoch_train_loss=0.0007353708258486971
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2348, epoch_train_loss=0.0007353708258486971
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2349, epoch_train_loss=0.0007353708258486971
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2350, epoch_train_loss=0.0007353708258486971
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2351, epoch_train_loss=0.0007353708258486971
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2352, epoch_train_loss=0.0007353708258486971
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2353, epoch_train_loss=0.0007353708258486971
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2354, epoch_train_loss=0.0007353708258486971
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2355, epoch_train_loss=0.0007353708258486971
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2356, epoch_train_loss=0.0007353708258486971
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2357, epoch_train_loss=0.0007353708258486971
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2358, epoch_train_loss=0.0007353708258486971
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2359, epoch_train_loss=0.0007353708258486971
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2360, epoch_train_loss=0.0007353708258486971
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2361, epoch_train_loss=0.0007353708258486971
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2362, epoch_train_loss=0.0007353708258486971
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2363, epoch_train_loss=0.0007353708258486971
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2364, epoch_train_loss=0.0007353708258486971
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2365, epoch_train_loss=0.0007353708258486971
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2366, epoch_train_loss=0.0007353708258486971
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2367, epoch_train_loss=0.0007353708258486971
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2368, epoch_train_loss=0.0007353708258486971
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2369, epoch_train_loss=0.0007353708258486971
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2370, epoch_train_loss=0.0007353708258486971
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2371, epoch_train_loss=0.0007353708258486971
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2372, epoch_train_loss=0.0007353708258486971
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2373, epoch_train_loss=0.0007353708258486971
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2374, epoch_train_loss=0.0007353708258486971
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2375, epoch_train_loss=0.0007353708258486971
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2376, epoch_train_loss=0.0007353708258486971
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2377, epoch_train_loss=0.0007353708258486971
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2378, epoch_train_loss=0.0007353708258486971
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2379, epoch_train_loss=0.0007353708258486971
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2380, epoch_train_loss=0.0007353708258486971
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2381, epoch_train_loss=0.0007353708258486971
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2382, epoch_train_loss=0.0007353708258486971
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2383, epoch_train_loss=0.0007353708258486971
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2384, epoch_train_loss=0.0007353708258486971
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2385, epoch_train_loss=0.0007353708258486971
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2386, epoch_train_loss=0.0007353708258486971
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2387, epoch_train_loss=0.0007353708258486971
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2388, epoch_train_loss=0.0007353708258486971
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2389, epoch_train_loss=0.0007353708258486971
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2390, epoch_train_loss=0.0007353708258486971
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2391, epoch_train_loss=0.0007353708258486971
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2392, epoch_train_loss=0.0007353708258486971
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2393, epoch_train_loss=0.0007353708258486971
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2394, epoch_train_loss=0.0007353708258486971
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2395, epoch_train_loss=0.0007353708258486971
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2396, epoch_train_loss=0.0007353708258486971
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2397, epoch_train_loss=0.0007353708258486971
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2398, epoch_train_loss=0.0007353708258486971
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2399, epoch_train_loss=0.0007353708258486971
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2400, epoch_train_loss=0.0007353708258486971
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2401, epoch_train_loss=0.0007353708258486971
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2402, epoch_train_loss=0.0007353708258486971
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2403, epoch_train_loss=0.0007353708258486971
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2404, epoch_train_loss=0.0007353708258486971
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2405, epoch_train_loss=0.0007353708258486971
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2406, epoch_train_loss=0.0007353708258486971
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2407, epoch_train_loss=0.0007353708258486971
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2408, epoch_train_loss=0.0007353708258486971
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2409, epoch_train_loss=0.0007353708258486971
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2410, epoch_train_loss=0.0007353708258486971
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2411, epoch_train_loss=0.0007353708258486971
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2412, epoch_train_loss=0.0007353708258486971
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2413, epoch_train_loss=0.0007353708258486971
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2414, epoch_train_loss=0.0007353708258486971
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2415, epoch_train_loss=0.0007353708258486971
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2416, epoch_train_loss=0.0007353708258486971
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2417, epoch_train_loss=0.0007353708258486971
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2418, epoch_train_loss=0.0007353708258486971
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2419, epoch_train_loss=0.0007353708258486971
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2420, epoch_train_loss=0.0007353708258486971
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2421, epoch_train_loss=0.0007353708258486971
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2422, epoch_train_loss=0.0007353708258486971
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2423, epoch_train_loss=0.0007353708258486971
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2424, epoch_train_loss=0.0007353708258486971
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2425, epoch_train_loss=0.0007353708258486971
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2426, epoch_train_loss=0.0007353708258486971
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2427, epoch_train_loss=0.0007353708258486971
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2428, epoch_train_loss=0.0007353708258486971
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2429, epoch_train_loss=0.0007353708258486971
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2430, epoch_train_loss=0.0007353708258486971
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2431, epoch_train_loss=0.0007353708258486971
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2432, epoch_train_loss=0.0007353708258486971
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2433, epoch_train_loss=0.0007353708258486971
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2434, epoch_train_loss=0.0007353708258486971
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2435, epoch_train_loss=0.0007353708258486971
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2436, epoch_train_loss=0.0007353708258486971
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2437, epoch_train_loss=0.0007353708258486971
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2438, epoch_train_loss=0.0007353708258486971
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2439, epoch_train_loss=0.0007353708258486971
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2440, epoch_train_loss=0.0007353708258486971
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2441, epoch_train_loss=0.0007353708258486971
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2442, epoch_train_loss=0.0007353708258486971
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2443, epoch_train_loss=0.0007353708258486971
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2444, epoch_train_loss=0.0007353708258486971
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2445, epoch_train_loss=0.0007353708258486971
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2446, epoch_train_loss=0.0007353708258486971
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2447, epoch_train_loss=0.0007353708258486971
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2448, epoch_train_loss=0.0007353708258486971
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2449, epoch_train_loss=0.0007353708258486971
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2450, epoch_train_loss=0.0007353708258486971
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2451, epoch_train_loss=0.0007353708258486971
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2452, epoch_train_loss=0.0007353708258486971
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2453, epoch_train_loss=0.0007353708258486971
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2454, epoch_train_loss=0.0007353708258486971
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2455, epoch_train_loss=0.0007353708258486971
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2456, epoch_train_loss=0.0007353708258486971
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2457, epoch_train_loss=0.0007353708258486971
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2458, epoch_train_loss=0.0007353708258486971
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2459, epoch_train_loss=0.0007353708258486971
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2460, epoch_train_loss=0.0007353708258486971
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2461, epoch_train_loss=0.0007353708258486971
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2462, epoch_train_loss=0.0007353708258486971
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2463, epoch_train_loss=0.0007353708258486971
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2464, epoch_train_loss=0.0007353708258486971
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2465, epoch_train_loss=0.0007353708258486971
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2466, epoch_train_loss=0.0007353708258486971
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2467, epoch_train_loss=0.0007353708258486971
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2468, epoch_train_loss=0.0007353708258486971
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2469, epoch_train_loss=0.0007353708258486971
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2470, epoch_train_loss=0.0007353708258486971
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2471, epoch_train_loss=0.0007353708258486971
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2472, epoch_train_loss=0.0007353708258486971
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2473, epoch_train_loss=0.0007353708258486971
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2474, epoch_train_loss=0.0007353708258486971
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2475, epoch_train_loss=0.0007353708258486971
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2476, epoch_train_loss=0.0007353708258486971
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2477, epoch_train_loss=0.0007353708258486971
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2478, epoch_train_loss=0.0007353708258486971
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2479, epoch_train_loss=0.0007353708258486971
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2480, epoch_train_loss=0.0007353708258486971
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2481, epoch_train_loss=0.0007353708258486971
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2482, epoch_train_loss=0.0007353708258486971
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2483, epoch_train_loss=0.0007353708258486971
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2484, epoch_train_loss=0.0007353708258486971
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2485, epoch_train_loss=0.0007353708258486971
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2486, epoch_train_loss=0.0007353708258486971
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2487, epoch_train_loss=0.0007353708258486971
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2488, epoch_train_loss=0.0007353708258486971
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2489, epoch_train_loss=0.0007353708258486971
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2490, epoch_train_loss=0.0007353708258486971
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2491, epoch_train_loss=0.0007353708258486971
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2492, epoch_train_loss=0.0007353708258486971
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2493, epoch_train_loss=0.0007353708258486971
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2494, epoch_train_loss=0.0007353708258486971
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2495, epoch_train_loss=0.0007353708258486971
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2496, epoch_train_loss=0.0007353708258486971
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2497, epoch_train_loss=0.0007353708258486971
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2498, epoch_train_loss=0.0007353708258486971
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0007353708258486971
2499, epoch_train_loss=0.0007353708258486971
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb043e770> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb043e770> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeb043e770> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb043e140> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb043e2c0> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb043c1c0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb043e920> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb043d000> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0417f70> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0414e80> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0417490> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0415030> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb04159c0> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb0417df0> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0416470> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0414d60> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb04162c0> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb04175e0> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0417160> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0416140> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0414fa0> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0417e80> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb04169e0> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb0414430> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb027bac0> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeb027bf40> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb027a080> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb043e140> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb043e140> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051022 -0.00019156 -0.00051334 ... -0.02830887 -0.02830887
 -0.02830887] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046674  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb043e2c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb043e2c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-3.60081838e-04 -1.08775305e-04 -1.31917160e-05 ... -2.74817476e-02
 -2.74817476e-02 -2.74817476e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 4)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb043c1c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb043c1c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.92637321e-09 -1.31700807e-07 -9.61527370e-06 ... -7.42461648e-16
 -7.42461648e-16 -7.42461648e-16] = ,SCAN
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 4)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627841  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb043e920> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb043e920> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.31884219e-04 -2.81911891e-04 -2.81911891e-04 ... -1.27154711e-05
 -2.64861768e-02 -2.64861768e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 4)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033779898359  <S^2> = 2.002745  2S+1 = 3.0018295
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb043d000> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb043d000> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.45434152e-04 -2.65382434e-05 -1.39509791e-06 ... -2.76158567e-02
 -2.76158567e-02 -2.76158567e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 4)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577122011  <S^2> = 0.7516194  2S+1 = 2.0016187
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0417f70> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0417f70> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.47274792e-04 -2.58665272e-04 -8.59189419e-05 ... -2.84484395e-02
 -2.84484395e-02 -2.84484395e-02] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 4)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560982665  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0414e80> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0414e80> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.29181569e-03 -1.41393861e-03 -7.13182950e-04 ... -2.75245563e-05
 -2.94334504e-04 -2.55435775e-05] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 4)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786807958  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0417490> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0417490> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003666  -0.00017897 -0.00022555 ... -0.02838402 -0.02838402
 -0.02838402] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 3.5527137e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0415030> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0415030> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00043469 -0.00024024 -0.00035532 ... -0.00047537 -0.03728133
 -0.03728133] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 4)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.337792446513  <S^2> = 4.0073012e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb04159c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb04159c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-9.02468888e-05 -7.92694658e-06 -9.80568469e-06 ... -4.33714150e-02
 -4.33714150e-02 -4.33714150e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 4)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322844  <S^2> = 1.9539925e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0417df0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0417df0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.48187338e-05 -6.19475249e-05 -2.61742784e-04 ... -8.70042314e-07
 -2.73391097e-02 -2.73391097e-02] = ,SCAN
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 4)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888961  <S^2> = 5.0093263e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0416470> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0416470> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051559 -0.00027432 -0.00088583 ... -0.00027432 -0.04174728
 -0.04174728] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 4)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.2434498e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0414d60> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0414d60> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.53951178e-05 -5.93507199e-06 -3.10072916e-04 ... -5.94325581e-02
 -5.94325581e-02 -5.94325581e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 4)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894376045  <S^2> = 1.0018598  2S+1 = 2.2377308
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb04162c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb04162c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.51795935e-04 -2.87556219e-05 -1.57709105e-06 ... -4.22396682e-02
 -4.22396682e-02 -4.22396682e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 4)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346372  <S^2> = 1.7763568e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb04175e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb04175e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.72190712e-05 -2.72190712e-05 -2.84904833e-04 ... -1.08108260e-05
 -1.03072478e-05 -1.03072478e-05] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 4)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5902839e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0417160> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0417160> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00015688 -0.00024669 -0.00068269 ... -0.03791166 -0.03791166
 -0.03791166] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 4)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374077  <S^2> = 6.5725203e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0416140> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0416140> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.28500681e-05 -5.65091132e-06 -7.37932132e-06 ... -4.76689214e-02
 -4.76689214e-02 -4.76689214e-02] = ,SCAN
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 4)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.8159701e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0414fa0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0414fa0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003863  -0.00040095 -0.00040095 ... -0.0213199  -0.0213199
 -0.0213199 ] = ,SCAN
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 4)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5871748e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0417e80> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0417e80> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00088473 -0.00088473 -0.00116894 ... -0.00088473 -0.00088473
 -0.00116894] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 4)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.31335e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb04169e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb04169e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.91408540e-05 -1.46971271e-04 -1.08734417e-03 ... -2.81566369e-02
 -2.81566369e-02 -2.81566369e-02] = ,SCAN
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 4)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5380587e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0414430> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0414430> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.39373335e-04 -1.31641332e-04 -1.15950750e-05 ... -7.32416564e-02
 -7.32416564e-02 -7.32416564e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 4)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336161696  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb027bac0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb027bac0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.84682577e-05 -7.80524929e-05 -7.80560356e-05 ... -2.92531377e-02
 -2.92531377e-02 -2.92531377e-02] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 4)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864076  <S^2> = 3.1885605e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb027bf40> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb027bf40> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.56165538e-04 -7.34744214e-05 -5.30574304e-06 ... -7.93995702e-06
 -7.93995702e-06 -7.93995702e-06] = ,SCAN
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 4)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.1994854e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb027a080> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb027a080> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.28290753e-04 -1.41305449e-05 -6.13700492e-05 ... -2.47993463e-02
 -2.47993463e-02 -2.47993463e-02] = ,SCAN
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 4)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3161028e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.45512011e-04 -7.12775692e-05 -5.48666345e-06 ... -6.02613084e-06
 -6.02613084e-06 -6.02613084e-06] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 4)
PRE NAN FILT: tFxc.shape=(224145,), tdrho.shape=(224145, 4)
nan_filt_rho.shape=(224145,)
nan_filt_fxc.shape=(224145,)
tFxc.shape=(224145,), tdrho.shape=(224145, 4)
inp[0].shape = (224145, 2)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 0.36252103218837123
0, epoch_train_loss=0.36252103218837123
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 0.26503026873593327
1, epoch_train_loss=0.26503026873593327
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 0.19470141885544082
2, epoch_train_loss=0.19470141885544082
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 0.15814357425328662
3, epoch_train_loss=0.15814357425328662
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 0.11445443993267768
4, epoch_train_loss=0.11445443993267768
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 0.06774591019675286
5, epoch_train_loss=0.06774591019675286
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 0.03334267402746674
6, epoch_train_loss=0.03334267402746674
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.0133508108922338
7, epoch_train_loss=0.0133508108922338
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.004738559270935319
8, epoch_train_loss=0.004738559270935319
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.0019494517599508625
9, epoch_train_loss=0.0019494517599508625
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.001131958461782555
10, epoch_train_loss=0.001131958461782555
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.0008783692557455196
11, epoch_train_loss=0.0008783692557455196
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.0007923837345550672
12, epoch_train_loss=0.0007923837345550672
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.0007607156471241263
13, epoch_train_loss=0.0007607156471241263
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.0007480447450478648
14, epoch_train_loss=0.0007480447450478648
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.0007425261807320419
15, epoch_train_loss=0.0007425261807320419
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.0007399200155062931
16, epoch_train_loss=0.0007399200155062931
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.0007386016510189471
17, epoch_train_loss=0.0007386016510189471
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.0007379026511191614
18, epoch_train_loss=0.0007379026511191614
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.0007375276536093019
19, epoch_train_loss=0.0007375276536093019
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.0007373367046958972
20, epoch_train_loss=0.0007373367046958972
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.0007372585650961933
21, epoch_train_loss=0.0007372585650961933
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.0007372536953328784
22, epoch_train_loss=0.0007372536953328784
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.0007372971832826311
23, epoch_train_loss=0.0007372971832826311
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.0007373702113024106
24, epoch_train_loss=0.0007373702113024106
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.0007374556491913938
25, epoch_train_loss=0.0007374556491913938
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.0007375362295327777
26, epoch_train_loss=0.0007375362295327777
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0007375948780213071
27, epoch_train_loss=0.0007375948780213071
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.0007376168454991873
28, epoch_train_loss=0.0007376168454991873
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.0007375926914524152
29, epoch_train_loss=0.0007375926914524152
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0007375205517398669
30, epoch_train_loss=0.0007375205517398669
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.0007374062973975016
31, epoch_train_loss=0.0007374062973975016
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.000737261350487641
32, epoch_train_loss=0.000737261350487641
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.0007370992459347346
33, epoch_train_loss=0.0007370992459347346
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.0007369324855900705
34, epoch_train_loss=0.0007369324855900705
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.0007367706697739932
35, epoch_train_loss=0.0007367706697739932
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.0007366200024103534
36, epoch_train_loss=0.0007366200024103534
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.0007364837108489189
37, epoch_train_loss=0.0007364837108489189
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.0007363628365623555
38, epoch_train_loss=0.0007363628365623555
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.0007362570255443825
39, epoch_train_loss=0.0007362570255443825
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.000736165152185233
40, epoch_train_loss=0.000736165152185233
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.0007360857466910324
41, epoch_train_loss=0.0007360857466910324
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.0007360172580839319
42, epoch_train_loss=0.0007360172580839319
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.0007359582000962675
43, epoch_train_loss=0.0007359582000962675
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.0007359072217236696
44, epoch_train_loss=0.0007359072217236696
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.0007358631329576774
45, epoch_train_loss=0.0007358631329576774
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.0007358249057958626
46, epoch_train_loss=0.0007358249057958626
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.0007357916628728047
47, epoch_train_loss=0.0007357916628728047
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.0007357626608813582
48, epoch_train_loss=0.0007357626608813582
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.0007357372727235761
49, epoch_train_loss=0.0007357372727235761
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.0007357149704067644
50, epoch_train_loss=0.0007357149704067644
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.0007356953095986992
51, epoch_train_loss=0.0007356953095986992
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.000735677916874196
52, epoch_train_loss=0.000735677916874196
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.0007356624765486508
53, epoch_train_loss=0.0007356624765486508
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.0007356487219490262
54, epoch_train_loss=0.0007356487219490262
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.0007356364272857552
55, epoch_train_loss=0.0007356364272857552
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.0007356254008892985
56, epoch_train_loss=0.0007356254008892985
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.0007356154796062635
57, epoch_train_loss=0.0007356154796062635
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0007356065241588576
58, epoch_train_loss=0.0007356065241588576
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.0007355984152970222
59, epoch_train_loss=0.0007355984152970222
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.0007355910506175949
60, epoch_train_loss=0.0007355910506175949
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.0007355843419224677
61, epoch_train_loss=0.0007355843419224677
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.0007355782130268891
62, epoch_train_loss=0.0007355782130268891
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.0007355725979304112
63, epoch_train_loss=0.0007355725979304112
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.0007355674392954389
64, epoch_train_loss=0.0007355674392954389
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0007355626871722287
65, epoch_train_loss=0.0007355626871722287
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.0007355582979315918
66, epoch_train_loss=0.0007355582979315918
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0007355542333655147
67, epoch_train_loss=0.0007355542333655147
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.0007355504599302448
68, epoch_train_loss=0.0007355504599302448
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0007355469481060314
69, epoch_train_loss=0.0007355469481060314
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0007355436718540513
70, epoch_train_loss=0.0007355436718540513
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0007355406081556226
71, epoch_train_loss=0.0007355406081556226
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0007355377366179217
72, epoch_train_loss=0.0007355377366179217
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0007355350391375925
73, epoch_train_loss=0.0007355350391375925
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0007355324996128893
74, epoch_train_loss=0.0007355324996128893
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0007355301036950463
75, epoch_train_loss=0.0007355301036950463
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0007355278385745483
76, epoch_train_loss=0.0007355278385745483
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0007355256927967244
77, epoch_train_loss=0.0007355256927967244
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.0007355236561016138
78, epoch_train_loss=0.0007355236561016138
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0007355217192845833
79, epoch_train_loss=0.0007355217192845833
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0007355198740752717
80, epoch_train_loss=0.0007355198740752717
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.0007355181130323194
81, epoch_train_loss=0.0007355181130323194
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0007355164294503616
82, epoch_train_loss=0.0007355164294503616
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.0007355148172795023
83, epoch_train_loss=0.0007355148172795023
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0007355132710535972
84, epoch_train_loss=0.0007355132710535972
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0007355117858279363
85, epoch_train_loss=0.0007355117858279363
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.00073551035712382
86, epoch_train_loss=0.00073551035712382
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.0007355089808797952
87, epoch_train_loss=0.0007355089808797952
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0007355076534080845
88, epoch_train_loss=0.0007355076534080845
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0007355063713565411
89, epoch_train_loss=0.0007355063713565411
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0007355051316745584
90, epoch_train_loss=0.0007355051316745584
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0007355039315824802
91, epoch_train_loss=0.0007355039315824802
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0007355027685448811
92, epoch_train_loss=0.0007355027685448811
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0007355016402463809
93, epoch_train_loss=0.0007355016402463809
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.000735500544570206
94, epoch_train_loss=0.000735500544570206
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0007354994795786971
95, epoch_train_loss=0.0007354994795786971
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0007354984434963262
96, epoch_train_loss=0.0007354984434963262
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.0007354974346941639
97, epoch_train_loss=0.0007354974346941639
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.000735496451676016
98, epoch_train_loss=0.000735496451676016
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0007354954930659722
99, epoch_train_loss=0.0007354954930659722
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0007354945575972111
100, epoch_train_loss=0.0007354945575972111
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.0007354936441019247
101, epoch_train_loss=0.0007354936441019247
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0007354927515022458
102, epoch_train_loss=0.0007354927515022458
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.0007354918788020693
103, epoch_train_loss=0.0007354918788020693
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0007354910250796762
104, epoch_train_loss=0.0007354910250796762
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0007354901894810105
105, epoch_train_loss=0.0007354901894810105
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0007354893712138546
106, epoch_train_loss=0.0007354893712138546
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0007354885695422001
107, epoch_train_loss=0.0007354885695422001
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0007354877837813954
108, epoch_train_loss=0.0007354877837813954
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0007354870132936376
109, epoch_train_loss=0.0007354870132936376
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0007354862574841154
110, epoch_train_loss=0.0007354862574841154
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0007354855157971836
111, epoch_train_loss=0.0007354855157971836
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.000735484787713056
112, epoch_train_loss=0.000735484787713056
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0007354840727449674
113, epoch_train_loss=0.0007354840727449674
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0007354833704362827
114, epoch_train_loss=0.0007354833704362827
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0007354826803580782
115, epoch_train_loss=0.0007354826803580782
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0007354820021068927
116, epoch_train_loss=0.0007354820021068927
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007354813353026351
117, epoch_train_loss=0.0007354813353026351
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0007354806795868261
118, epoch_train_loss=0.0007354806795868261
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007354800346209035
119, epoch_train_loss=0.0007354800346209035
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.000735479400084537
120, epoch_train_loss=0.000735479400084537
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007354787756744178
121, epoch_train_loss=0.0007354787756744178
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007354781611027902
122, epoch_train_loss=0.0007354781611027902
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0007354775560964724
123, epoch_train_loss=0.0007354775560964724
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0007354769603956076
124, epoch_train_loss=0.0007354769603956076
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0007354763737528745
125, epoch_train_loss=0.0007354763737528745
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0007354757959324197
126, epoch_train_loss=0.0007354757959324197
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0007354752267091796
127, epoch_train_loss=0.0007354752267091796
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0007354746658680938
128, epoch_train_loss=0.0007354746658680938
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0007354741132034648
129, epoch_train_loss=0.0007354741132034648
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0007354735685182116
130, epoch_train_loss=0.0007354735685182116
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0007354730316234235
131, epoch_train_loss=0.0007354730316234235
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007354725023377949
132, epoch_train_loss=0.0007354725023377949
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007354719804871425
133, epoch_train_loss=0.0007354719804871425
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007354714659040029
134, epoch_train_loss=0.0007354714659040029
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0007354709584271094
135, epoch_train_loss=0.0007354709584271094
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007354704579011345
136, epoch_train_loss=0.0007354704579011345
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007354699641763054
137, epoch_train_loss=0.0007354699641763054
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0007354694771080869
138, epoch_train_loss=0.0007354694771080869
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007354689965568858
139, epoch_train_loss=0.0007354689965568858
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007354685223877821
140, epoch_train_loss=0.0007354685223877821
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007354680544702759
141, epoch_train_loss=0.0007354680544702759
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0007354675926780561
142, epoch_train_loss=0.0007354675926780561
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.000735467136888785
143, epoch_train_loss=0.000735467136888785
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0007354666869838982
144, epoch_train_loss=0.0007354666869838982
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.000735466242848386
145, epoch_train_loss=0.000735466242848386
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0007354658043707535
146, epoch_train_loss=0.0007354658043707535
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0007354653714426289
147, epoch_train_loss=0.0007354653714426289
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0007354649439588431
148, epoch_train_loss=0.0007354649439588431
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0007354645218171598
149, epoch_train_loss=0.0007354645218171598
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0007354641049181772
150, epoch_train_loss=0.0007354641049181772
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.0007354636931651755
151, epoch_train_loss=0.0007354636931651755
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0007354632864640954
152, epoch_train_loss=0.0007354632864640954
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0007354628847233371
153, epoch_train_loss=0.0007354628847233371
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0007354624878536624
154, epoch_train_loss=0.0007354624878536624
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.0007354620957681885
155, epoch_train_loss=0.0007354620957681885
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.00073546170838221
156, epoch_train_loss=0.00073546170838221
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.000735461325613116
157, epoch_train_loss=0.000735461325613116
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0007354609473803978
158, epoch_train_loss=0.0007354609473803978
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0007354605736054875
159, epoch_train_loss=0.0007354605736054875
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.0007354602042116889
160, epoch_train_loss=0.0007354602042116889
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0007354598391241938
161, epoch_train_loss=0.0007354598391241938
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.0007354594782699089
162, epoch_train_loss=0.0007354594782699089
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0007354591215774771
163, epoch_train_loss=0.0007354591215774771
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.0007354587689772209
164, epoch_train_loss=0.0007354587689772209
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0007354584204010071
165, epoch_train_loss=0.0007354584204010071
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0007354580757823028
166, epoch_train_loss=0.0007354580757823028
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0007354577350560199
167, epoch_train_loss=0.0007354577350560199
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0007354573981585478
168, epoch_train_loss=0.0007354573981585478
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0007354570650276824
169, epoch_train_loss=0.0007354570650276824
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0007354567356025828
170, epoch_train_loss=0.0007354567356025828
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0007354564098237556
171, epoch_train_loss=0.0007354564098237556
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.000735456087632942
172, epoch_train_loss=0.000735456087632942
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0007354557689731782
173, epoch_train_loss=0.0007354557689731782
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.0007354554537886397
174, epoch_train_loss=0.0007354554537886397
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0007354551420247729
175, epoch_train_loss=0.0007354551420247729
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0007354548336280968
176, epoch_train_loss=0.0007354548336280968
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.0007354545285462654
177, epoch_train_loss=0.0007354545285462654
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0007354542267280142
178, epoch_train_loss=0.0007354542267280142
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.00073545392812313
179, epoch_train_loss=0.00073545392812313
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0007354536326824234
180, epoch_train_loss=0.0007354536326824234
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0007354533403577013
181, epoch_train_loss=0.0007354533403577013
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.0007354530511017406
182, epoch_train_loss=0.0007354530511017406
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0007354527648682633
183, epoch_train_loss=0.0007354527648682633
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0007354524816119111
184, epoch_train_loss=0.0007354524816119111
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0007354522012882235
185, epoch_train_loss=0.0007354522012882235
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0007354519238535928
186, epoch_train_loss=0.0007354519238535928
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0007354516492653258
187, epoch_train_loss=0.0007354516492653258
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0007354513774814771
188, epoch_train_loss=0.0007354513774814771
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.000735451108460974
189, epoch_train_loss=0.000735451108460974
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0007354508421634931
190, epoch_train_loss=0.0007354508421634931
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0007354505785495222
191, epoch_train_loss=0.0007354505785495222
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.0007354503175802815
192, epoch_train_loss=0.0007354503175802815
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0007354500592177251
193, epoch_train_loss=0.0007354500592177251
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.0007354498034245242
194, epoch_train_loss=0.0007354498034245242
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0007354495501640305
195, epoch_train_loss=0.0007354495501640305
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.0007354492994003171
196, epoch_train_loss=0.0007354492994003171
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.000735449051098087
197, epoch_train_loss=0.000735449051098087
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.0007354488052227316
198, epoch_train_loss=0.0007354488052227316
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.0007354485617402606
199, epoch_train_loss=0.0007354485617402606
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0007354483206172874
200, epoch_train_loss=0.0007354483206172874
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.0007354480818210695
201, epoch_train_loss=0.0007354480818210695
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0007354478453194224
202, epoch_train_loss=0.0007354478453194224
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0007354476110807604
203, epoch_train_loss=0.0007354476110807604
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.0007354473790740821
204, epoch_train_loss=0.0007354473790740821
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0007354471492689063
205, epoch_train_loss=0.0007354471492689063
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0007354469216353116
206, epoch_train_loss=0.0007354469216353116
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0007354466961439244
207, epoch_train_loss=0.0007354466961439244
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.0007354464727658548
208, epoch_train_loss=0.0007354464727658548
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0007354462514727382
209, epoch_train_loss=0.0007354462514727382
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0007354460322367226
210, epoch_train_loss=0.0007354460322367226
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.0007354458150304082
211, epoch_train_loss=0.0007354458150304082
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.000735445599826887
212, epoch_train_loss=0.000735445599826887
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.000735445386599732
213, epoch_train_loss=0.000735445386599732
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0007354451753229387
214, epoch_train_loss=0.0007354451753229387
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0007354449659709484
215, epoch_train_loss=0.0007354449659709484
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.0007354447585186851
216, epoch_train_loss=0.0007354447585186851
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.0007354445529414524
217, epoch_train_loss=0.0007354445529414524
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0007354443492149871
218, epoch_train_loss=0.0007354443492149871
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0007354441473154356
219, epoch_train_loss=0.0007354441473154356
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.0007354439472193433
220, epoch_train_loss=0.0007354439472193433
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0007354437489036489
221, epoch_train_loss=0.0007354437489036489
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.0007354435523456744
222, epoch_train_loss=0.0007354435523456744
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.0007354433575231182
223, epoch_train_loss=0.0007354433575231182
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0007354431644140471
224, epoch_train_loss=0.0007354431644140471
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0007354429729968882
225, epoch_train_loss=0.0007354429729968882
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.0007354427832504232
226, epoch_train_loss=0.0007354427832504232
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.000735442595153765
227, epoch_train_loss=0.000735442595153765
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.000735442408686395
228, epoch_train_loss=0.000735442408686395
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0007354422238281129
229, epoch_train_loss=0.0007354422238281129
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.0007354420405590442
230, epoch_train_loss=0.0007354420405590442
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.0007354418588596336
231, epoch_train_loss=0.0007354418588596336
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.000735441678710626
232, epoch_train_loss=0.000735441678710626
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0007354415000931003
233, epoch_train_loss=0.0007354415000931003
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0007354413229884224
234, epoch_train_loss=0.0007354413229884224
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0007354411473782536
235, epoch_train_loss=0.0007354411473782536
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.0007354409732445442
236, epoch_train_loss=0.0007354409732445442
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0007354408005695156
237, epoch_train_loss=0.0007354408005695156
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.0007354406293356801
238, epoch_train_loss=0.0007354406293356801
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.000735440459525836
239, epoch_train_loss=0.000735440459525836
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.0007354402911230233
240, epoch_train_loss=0.0007354402911230233
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.0007354401241105698
241, epoch_train_loss=0.0007354401241105698
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0007354399584720482
242, epoch_train_loss=0.0007354399584720482
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.0007354397941912713
243, epoch_train_loss=0.0007354397941912713
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0007354396312523241
244, epoch_train_loss=0.0007354396312523241
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.0007354394696395111
245, epoch_train_loss=0.0007354394696395111
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.0007354393093373865
246, epoch_train_loss=0.0007354393093373865
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0007354391503307395
247, epoch_train_loss=0.0007354391503307395
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.0007354389926045999
248, epoch_train_loss=0.0007354389926045999
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.0007354388361442003
249, epoch_train_loss=0.0007354388361442003
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0007354386809350055
250, epoch_train_loss=0.0007354386809350055
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0007354385269627094
251, epoch_train_loss=0.0007354385269627094
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0007354383742131957
252, epoch_train_loss=0.0007354383742131957
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.0007354382226725696
253, epoch_train_loss=0.0007354382226725696
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.000735438072327152
254, epoch_train_loss=0.000735438072327152
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0007354379231634436
255, epoch_train_loss=0.0007354379231634436
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.0007354377751681543
256, epoch_train_loss=0.0007354377751681543
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0007354376283281888
257, epoch_train_loss=0.0007354376283281888
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.000735437482630642
258, epoch_train_loss=0.000735437482630642
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0007354373380627966
259, epoch_train_loss=0.0007354373380627966
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.0007354371946121205
260, epoch_train_loss=0.0007354371946121205
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.0007354370522662608
261, epoch_train_loss=0.0007354370522662608
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.0007354369110130434
262, epoch_train_loss=0.0007354369110130434
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.0007354367708404687
263, epoch_train_loss=0.0007354367708404687
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.000735436631736708
264, epoch_train_loss=0.000735436631736708
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.0007354364936901016
265, epoch_train_loss=0.0007354364936901016
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0007354363566891547
266, epoch_train_loss=0.0007354363566891547
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.0007354362207225356
267, epoch_train_loss=0.0007354362207225356
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0007354360857790723
268, epoch_train_loss=0.0007354360857790723
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.0007354359518477395
269, epoch_train_loss=0.0007354359518477395
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.0007354358189176865
270, epoch_train_loss=0.0007354358189176865
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.000735435686978204
271, epoch_train_loss=0.000735435686978204
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0007354355560187321
272, epoch_train_loss=0.0007354355560187321
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.0007354354260288472
273, epoch_train_loss=0.0007354354260288472
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0007354352969982892
274, epoch_train_loss=0.0007354352969982892
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0007354351689169204
275, epoch_train_loss=0.0007354351689169204
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.0007354350417747612
276, epoch_train_loss=0.0007354350417747612
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.0007354349155619591
277, epoch_train_loss=0.0007354349155619591
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0007354347902687966
278, epoch_train_loss=0.0007354347902687966
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.0007354346658856781
279, epoch_train_loss=0.0007354346658856781
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.0007354345424031576
280, epoch_train_loss=0.0007354345424031576
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.0007354344198118979
281, epoch_train_loss=0.0007354344198118979
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.000735434298102706
282, epoch_train_loss=0.000735434298102706
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.000735434177266494
283, epoch_train_loss=0.000735434177266494
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0007354340572943052
284, epoch_train_loss=0.0007354340572943052
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0007354339381773113
285, epoch_train_loss=0.0007354339381773113
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.0007354338199067921
286, epoch_train_loss=0.0007354338199067921
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.0007354337024741344
287, epoch_train_loss=0.0007354337024741344
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.0007354335858708479
288, epoch_train_loss=0.0007354335858708479
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0007354334700885546
289, epoch_train_loss=0.0007354334700885546
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.0007354333551189944
290, epoch_train_loss=0.0007354333551189944
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.0007354332409539988
291, epoch_train_loss=0.0007354332409539988
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.0007354331275855228
292, epoch_train_loss=0.0007354331275855228
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.0007354330150056092
293, epoch_train_loss=0.0007354330150056092
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.000735432903206413
294, epoch_train_loss=0.000735432903206413
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.0007354327921801902
295, epoch_train_loss=0.0007354327921801902
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.0007354326819192967
296, epoch_train_loss=0.0007354326819192967
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.0007354325724161956
297, epoch_train_loss=0.0007354325724161956
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.0007354324636634296
298, epoch_train_loss=0.0007354324636634296
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.0007354323556536371
299, epoch_train_loss=0.0007354323556536371
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.0007354322483795666
300, epoch_train_loss=0.0007354322483795666
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0007354321418340586
301, epoch_train_loss=0.0007354321418340586
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.0007354320360100283
302, epoch_train_loss=0.0007354320360100283
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.000735431930900481
303, epoch_train_loss=0.000735431930900481
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.000735431826498525
304, epoch_train_loss=0.000735431826498525
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.000735431722797356
305, epoch_train_loss=0.000735431722797356
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.0007354316197902306
306, epoch_train_loss=0.0007354316197902306
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.0007354315174705139
307, epoch_train_loss=0.0007354315174705139
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.0007354314158316454
308, epoch_train_loss=0.0007354314158316454
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.0007354313148671461
309, epoch_train_loss=0.0007354313148671461
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0007354312145706172
310, epoch_train_loss=0.0007354312145706172
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0007354311149357312
311, epoch_train_loss=0.0007354311149357312
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.0007354310159562611
312, epoch_train_loss=0.0007354310159562611
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.0007354309176260268
313, epoch_train_loss=0.0007354309176260268
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.0007354308199389384
314, epoch_train_loss=0.0007354308199389384
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.0007354307228889948
315, epoch_train_loss=0.0007354307228889948
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0007354306264702389
316, epoch_train_loss=0.0007354306264702389
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.0007354305306768006
317, epoch_train_loss=0.0007354305306768006
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.0007354304355028947
318, epoch_train_loss=0.0007354304355028947
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.000735430340942778
319, epoch_train_loss=0.000735430340942778
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.0007354302469907899
320, epoch_train_loss=0.0007354302469907899
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.0007354301536413449
321, epoch_train_loss=0.0007354301536413449
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.0007354300608889172
322, epoch_train_loss=0.0007354300608889172
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0007354299687280406
323, epoch_train_loss=0.0007354299687280406
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.0007354298771533271
324, epoch_train_loss=0.0007354298771533271
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.000735429786159439
325, epoch_train_loss=0.000735429786159439
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.0007354296957411158
326, epoch_train_loss=0.0007354296957411158
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.0007354296058931449
327, epoch_train_loss=0.0007354296058931449
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.0007354295166103824
328, epoch_train_loss=0.0007354295166103824
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.0007354294278877507
329, epoch_train_loss=0.0007354294278877507
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.000735429339720219
330, epoch_train_loss=0.000735429339720219
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0007354292521028218
331, epoch_train_loss=0.0007354292521028218
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0007354291650306507
332, epoch_train_loss=0.0007354291650306507
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0007354290784988615
333, epoch_train_loss=0.0007354290784988615
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.0007354289925026528
334, epoch_train_loss=0.0007354289925026528
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.0007354289070372848
335, epoch_train_loss=0.0007354289070372848
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.000735428822098073
336, epoch_train_loss=0.000735428822098073
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0007354287376803862
337, epoch_train_loss=0.0007354287376803862
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.0007354286537796525
338, epoch_train_loss=0.0007354286537796525
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0007354285703913333
339, epoch_train_loss=0.0007354285703913333
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.0007354284875109669
340, epoch_train_loss=0.0007354284875109669
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0007354284051341238
341, epoch_train_loss=0.0007354284051341238
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.0007354283232564306
342, epoch_train_loss=0.0007354283232564306
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.0007354282418735631
343, epoch_train_loss=0.0007354282418735631
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.0007354281609812462
344, epoch_train_loss=0.0007354281609812462
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.0007354280805752469
345, epoch_train_loss=0.0007354280805752469
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.0007354280006513973
346, epoch_train_loss=0.0007354280006513973
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0007354279212055524
347, epoch_train_loss=0.0007354279212055524
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0007354278422336373
348, epoch_train_loss=0.0007354278422336373
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.0007354277637315981
349, epoch_train_loss=0.0007354277637315981
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.000735427685695445
350, epoch_train_loss=0.000735427685695445
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0007354276081212249
351, epoch_train_loss=0.0007354276081212249
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.000735427531005029
352, epoch_train_loss=0.000735427531005029
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.0007354274543429918
353, epoch_train_loss=0.0007354274543429918
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.0007354273781312839
354, epoch_train_loss=0.0007354273781312839
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.0007354273023661298
355, epoch_train_loss=0.0007354273023661298
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.0007354272270437835
356, epoch_train_loss=0.0007354272270437835
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0007354271521605515
357, epoch_train_loss=0.0007354271521605515
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.0007354270777127745
358, epoch_train_loss=0.0007354270777127745
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.0007354270036968272
359, epoch_train_loss=0.0007354270036968272
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.0007354269301091351
360, epoch_train_loss=0.0007354269301091351
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.0007354268569461504
361, epoch_train_loss=0.0007354268569461504
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.0007354267842043757
362, epoch_train_loss=0.0007354267842043757
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0007354267118803443
363, epoch_train_loss=0.0007354267118803443
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.000735426639970622
364, epoch_train_loss=0.000735426639970622
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.0007354265684718219
365, epoch_train_loss=0.0007354265684718219
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007354264973805822
366, epoch_train_loss=0.0007354264973805822
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0007354264266935827
367, epoch_train_loss=0.0007354264266935827
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0007354263564075432
368, epoch_train_loss=0.0007354263564075432
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0007354262865192076
369, epoch_train_loss=0.0007354262865192076
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.0007354262170253652
370, epoch_train_loss=0.0007354262170253652
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.0007354261479228279
371, epoch_train_loss=0.0007354261479228279
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.000735426079208447
372, epoch_train_loss=0.000735426079208447
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.0007354260108791058
373, epoch_train_loss=0.0007354260108791058
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0007354259429317265
374, epoch_train_loss=0.0007354259429317265
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0007354258753632523
375, epoch_train_loss=0.0007354258753632523
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.0007354258081706631
376, epoch_train_loss=0.0007354258081706631
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.0007354257413509758
377, epoch_train_loss=0.0007354257413509758
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0007354256749012278
378, epoch_train_loss=0.0007354256749012278
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0007354256088184873
379, epoch_train_loss=0.0007354256088184873
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.000735425543099867
380, epoch_train_loss=0.000735425543099867
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.000735425477742495
381, epoch_train_loss=0.000735425477742495
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0007354254127435336
382, epoch_train_loss=0.0007354254127435336
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0007354253481001736
383, epoch_train_loss=0.0007354253481001736
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0007354252838096355
384, epoch_train_loss=0.0007354252838096355
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0007354252198691669
385, epoch_train_loss=0.0007354252198691669
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.000735425156276044
386, epoch_train_loss=0.000735425156276044
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0007354250930275658
387, epoch_train_loss=0.0007354250930275658
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.0007354250301210727
388, epoch_train_loss=0.0007354250301210727
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0007354249675539174
389, epoch_train_loss=0.0007354249675539174
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0007354249053234845
390, epoch_train_loss=0.0007354249053234845
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0007354248434271798
391, epoch_train_loss=0.0007354248434271798
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.0007354247818624442
392, epoch_train_loss=0.0007354247818624442
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.0007354247206267399
393, epoch_train_loss=0.0007354247206267399
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007354246597175541
394, epoch_train_loss=0.0007354246597175541
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0007354245991323992
395, epoch_train_loss=0.0007354245991323992
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.0007354245388688074
396, epoch_train_loss=0.0007354245388688074
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.0007354244789243401
397, epoch_train_loss=0.0007354244789243401
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.000735424419296587
398, epoch_train_loss=0.000735424419296587
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0007354243599831574
399, epoch_train_loss=0.0007354243599831574
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0007354243009816836
400, epoch_train_loss=0.0007354243009816836
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0007354242422898174
401, epoch_train_loss=0.0007354242422898174
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0007354241839052412
402, epoch_train_loss=0.0007354241839052412
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.0007354241258256527
403, epoch_train_loss=0.0007354241258256527
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.0007354240680487751
404, epoch_train_loss=0.0007354240680487751
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.0007354240105723588
405, epoch_train_loss=0.0007354240105723588
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0007354239533941713
406, epoch_train_loss=0.0007354239533941713
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.0007354238965119974
407, epoch_train_loss=0.0007354238965119974
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0007354238399236522
408, epoch_train_loss=0.0007354238399236522
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0007354237836269627
409, epoch_train_loss=0.0007354237836269627
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0007354237276197858
410, epoch_train_loss=0.0007354237276197858
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.0007354236718999902
411, epoch_train_loss=0.0007354236718999902
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.0007354236164654691
412, epoch_train_loss=0.0007354236164654691
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0007354235613141361
413, epoch_train_loss=0.0007354235613141361
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0007354235064439245
414, epoch_train_loss=0.0007354235064439245
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0007354234518527867
415, epoch_train_loss=0.0007354234518527867
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0007354233975386996
416, epoch_train_loss=0.0007354233975386996
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.0007354233434996504
417, epoch_train_loss=0.0007354233434996504
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.0007354232897336494
418, epoch_train_loss=0.0007354232897336494
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.0007354232362387259
419, epoch_train_loss=0.0007354232362387259
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.0007354231830129312
420, epoch_train_loss=0.0007354231830129312
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.0007354231300543275
421, epoch_train_loss=0.0007354231300543275
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.0007354230773609984
422, epoch_train_loss=0.0007354230773609984
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0007354230249310461
423, epoch_train_loss=0.0007354230249310461
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.0007354229727625899
424, epoch_train_loss=0.0007354229727625899
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.0007354229208537668
425, epoch_train_loss=0.0007354229208537668
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0007354228692027313
426, epoch_train_loss=0.0007354228692027313
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.0007354228178076545
427, epoch_train_loss=0.0007354228178076545
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.0007354227666667245
428, epoch_train_loss=0.0007354227666667245
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.0007354227157781425
429, epoch_train_loss=0.0007354227157781425
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.0007354226651401337
430, epoch_train_loss=0.0007354226651401337
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.0007354226147509358
431, epoch_train_loss=0.0007354226147509358
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.0007354225646088025
432, epoch_train_loss=0.0007354225646088025
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.0007354225147120035
433, epoch_train_loss=0.0007354225147120035
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0007354224650588208
434, epoch_train_loss=0.0007354224650588208
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.0007354224156475588
435, epoch_train_loss=0.0007354224156475588
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.0007354223664765343
436, epoch_train_loss=0.0007354223664765343
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.0007354223175440791
437, epoch_train_loss=0.0007354223175440791
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0007354222688485401
438, epoch_train_loss=0.0007354222688485401
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0007354222203882784
439, epoch_train_loss=0.0007354222203882784
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0007354221721616673
440, epoch_train_loss=0.0007354221721616673
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.0007354221241671013
441, epoch_train_loss=0.0007354221241671013
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0007354220764029824
442, epoch_train_loss=0.0007354220764029824
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0007354220288677298
443, epoch_train_loss=0.0007354220288677298
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.0007354219815597816
444, epoch_train_loss=0.0007354219815597816
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.0007354219344775815
445, epoch_train_loss=0.0007354219344775815
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0007354218876195944
446, epoch_train_loss=0.0007354218876195944
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.000735421840984296
447, epoch_train_loss=0.000735421840984296
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.0007354217945701708
448, epoch_train_loss=0.0007354217945701708
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.0007354217483757249
449, epoch_train_loss=0.0007354217483757249
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.0007354217023994695
450, epoch_train_loss=0.0007354217023994695
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0007354216566399328
451, epoch_train_loss=0.0007354216566399328
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.0007354216110956566
452, epoch_train_loss=0.0007354216110956566
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0007354215657651977
453, epoch_train_loss=0.0007354215657651977
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0007354215206471192
454, epoch_train_loss=0.0007354215206471192
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0007354214757400006
455, epoch_train_loss=0.0007354214757400006
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.0007354214310424362
456, epoch_train_loss=0.0007354214310424362
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0007354213865530266
457, epoch_train_loss=0.0007354213865530266
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.0007354213422703876
458, epoch_train_loss=0.0007354213422703876
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.00073542129819315
459, epoch_train_loss=0.00073542129819315
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.000735421254319947
460, epoch_train_loss=0.000735421254319947
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.000735421210649433
461, epoch_train_loss=0.000735421210649433
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0007354211671802711
462, epoch_train_loss=0.0007354211671802711
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0007354211239111389
463, epoch_train_loss=0.0007354211239111389
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.0007354210808407188
464, epoch_train_loss=0.0007354210808407188
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0007354210379677077
465, epoch_train_loss=0.0007354210379677077
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0007354209952908107
466, epoch_train_loss=0.0007354209952908107
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.0007354209528087528
467, epoch_train_loss=0.0007354209528087528
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.0007354209105202614
468, epoch_train_loss=0.0007354209105202614
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0007354208684240734
469, epoch_train_loss=0.0007354208684240734
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.0007354208265189439
470, epoch_train_loss=0.0007354208265189439
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.0007354207848036375
471, epoch_train_loss=0.0007354207848036375
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.0007354207432769207
472, epoch_train_loss=0.0007354207432769207
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.0007354207019375788
473, epoch_train_loss=0.0007354207019375788
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0007354206607844054
474, epoch_train_loss=0.0007354206607844054
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.0007354206198162028
475, epoch_train_loss=0.0007354206198162028
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.0007354205790317814
476, epoch_train_loss=0.0007354205790317814
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.0007354205384299668
477, epoch_train_loss=0.0007354205384299668
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.0007354204980095924
478, epoch_train_loss=0.0007354204980095924
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.000735420457769497
479, epoch_train_loss=0.000735420457769497
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.0007354204177085358
480, epoch_train_loss=0.0007354204177085358
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.0007354203778255707
481, epoch_train_loss=0.0007354203778255707
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.0007354203381194694
482, epoch_train_loss=0.0007354203381194694
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.0007354202985891151
483, epoch_train_loss=0.0007354202985891151
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.0007354202592333973
484, epoch_train_loss=0.0007354202592333973
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.000735420220051212
485, epoch_train_loss=0.000735420220051212
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.0007354201810414696
486, epoch_train_loss=0.0007354201810414696
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0007354201422030835
487, epoch_train_loss=0.0007354201422030835
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0007354201035349796
488, epoch_train_loss=0.0007354201035349796
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.0007354200650360949
489, epoch_train_loss=0.0007354200650360949
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0007354200267053692
490, epoch_train_loss=0.0007354200267053692
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0007354199885417573
491, epoch_train_loss=0.0007354199885417573
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.0007354199505442158
492, epoch_train_loss=0.0007354199505442158
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0007354199127117136
493, epoch_train_loss=0.0007354199127117136
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0007354198750432299
494, epoch_train_loss=0.0007354198750432299
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.0007354198375377471
495, epoch_train_loss=0.0007354198375377471
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0007354198001942614
496, epoch_train_loss=0.0007354198001942614
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0007354197630117679
497, epoch_train_loss=0.0007354197630117679
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.0007354197259892819
498, epoch_train_loss=0.0007354197259892819
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.0007354196891258176
499, epoch_train_loss=0.0007354196891258176
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.0007354196524203998
500, epoch_train_loss=0.0007354196524203998
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.0007354196158720621
501, epoch_train_loss=0.0007354196158720621
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.0007354195794798443
502, epoch_train_loss=0.0007354195794798443
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.0007354195432427977
503, epoch_train_loss=0.0007354195432427977
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0007354195071599724
504, epoch_train_loss=0.0007354195071599724
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.0007354194712304368
505, epoch_train_loss=0.0007354194712304368
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.0007354194354532562
506, epoch_train_loss=0.0007354194354532562
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.0007354193998275143
507, epoch_train_loss=0.0007354193998275143
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.0007354193643522902
508, epoch_train_loss=0.0007354193643522902
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.000735419329026682
509, epoch_train_loss=0.000735419329026682
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.0007354192938497838
510, epoch_train_loss=0.0007354192938497838
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.0007354192588207046
511, epoch_train_loss=0.0007354192588207046
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.0007354192239385581
512, epoch_train_loss=0.0007354192239385581
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.0007354191892024645
513, epoch_train_loss=0.0007354191892024645
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0007354191546115514
514, epoch_train_loss=0.0007354191546115514
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.0007354191201649524
515, epoch_train_loss=0.0007354191201649524
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.0007354190858618087
516, epoch_train_loss=0.0007354190858618087
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0007354190517012648
517, epoch_train_loss=0.0007354190517012648
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.0007354190176824774
518, epoch_train_loss=0.0007354190176824774
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.0007354189838046045
519, epoch_train_loss=0.0007354189838046045
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.0007354189500668156
520, epoch_train_loss=0.0007354189500668156
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.000735418916468284
521, epoch_train_loss=0.000735418916468284
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.0007354188830081897
522, epoch_train_loss=0.0007354188830081897
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0007354188496857186
523, epoch_train_loss=0.0007354188496857186
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.000735418816500058
524, epoch_train_loss=0.000735418816500058
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0007354187834504112
525, epoch_train_loss=0.0007354187834504112
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.0007354187505359826
526, epoch_train_loss=0.0007354187505359826
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.0007354187177559806
527, epoch_train_loss=0.0007354187177559806
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.0007354186851096241
528, epoch_train_loss=0.0007354186851096241
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0007354186525961332
529, epoch_train_loss=0.0007354186525961332
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.0007354186202147388
530, epoch_train_loss=0.0007354186202147388
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.0007354185879646749
531, epoch_train_loss=0.0007354185879646749
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.0007354185558451769
532, epoch_train_loss=0.0007354185558451769
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.0007354185238554953
533, epoch_train_loss=0.0007354185238554953
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.0007354184919948813
534, epoch_train_loss=0.0007354184919948813
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.0007354184602625871
535, epoch_train_loss=0.0007354184602625871
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0007354184286578803
536, epoch_train_loss=0.0007354184286578803
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.0007354183971800266
537, epoch_train_loss=0.0007354183971800266
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.000735418365828299
538, epoch_train_loss=0.000735418365828299
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.0007354183346019794
539, epoch_train_loss=0.0007354183346019794
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.0007354183035003497
540, epoch_train_loss=0.0007354183035003497
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.000735418272522699
541, epoch_train_loss=0.000735418272522699
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.0007354182416683229
542, epoch_train_loss=0.0007354182416683229
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0007354182109365209
543, epoch_train_loss=0.0007354182109365209
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.0007354181803266009
544, epoch_train_loss=0.0007354181803266009
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.0007354181498378685
545, epoch_train_loss=0.0007354181498378685
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.0007354181194696417
546, epoch_train_loss=0.0007354181194696417
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.0007354180892212432
547, epoch_train_loss=0.0007354180892212432
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.000735418059091996
548, epoch_train_loss=0.000735418059091996
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.0007354180290812283
549, epoch_train_loss=0.0007354180290812283
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.0007354179991882777
550, epoch_train_loss=0.0007354179991882777
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0007354179694124845
551, epoch_train_loss=0.0007354179694124845
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.0007354179397531957
552, epoch_train_loss=0.0007354179397531957
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0007354179102097567
553, epoch_train_loss=0.0007354179102097567
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.0007354178807815241
554, epoch_train_loss=0.0007354178807815241
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.000735417851467857
555, epoch_train_loss=0.000735417851467857
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0007354178222681192
556, epoch_train_loss=0.0007354178222681192
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.000735417793181679
557, epoch_train_loss=0.000735417793181679
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.0007354177642079073
558, epoch_train_loss=0.0007354177642079073
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.0007354177353461834
559, epoch_train_loss=0.0007354177353461834
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.0007354177065958894
560, epoch_train_loss=0.0007354177065958894
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.0007354176779564094
561, epoch_train_loss=0.0007354176779564094
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.0007354176494271363
562, epoch_train_loss=0.0007354176494271363
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.0007354176210074651
563, epoch_train_loss=0.0007354176210074651
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.0007354175926967934
564, epoch_train_loss=0.0007354175926967934
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.0007354175644945268
565, epoch_train_loss=0.0007354175644945268
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.0007354175364000708
566, epoch_train_loss=0.0007354175364000708
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0007354175084128399
567, epoch_train_loss=0.0007354175084128399
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0007354174805322505
568, epoch_train_loss=0.0007354174805322505
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.000735417452757721
569, epoch_train_loss=0.000735417452757721
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0007354174250886777
570, epoch_train_loss=0.0007354174250886777
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.0007354173975245473
571, epoch_train_loss=0.0007354173975245473
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.0007354173700647622
572, epoch_train_loss=0.0007354173700647622
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.0007354173427087594
573, epoch_train_loss=0.0007354173427087594
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.0007354173154559811
574, epoch_train_loss=0.0007354173154559811
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.00073541728830587
575, epoch_train_loss=0.00073541728830587
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.0007354172612578765
576, epoch_train_loss=0.0007354172612578765
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.0007354172343114505
577, epoch_train_loss=0.0007354172343114505
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.0007354172074660484
578, epoch_train_loss=0.0007354172074660484
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.000735417180721132
579, epoch_train_loss=0.000735417180721132
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0007354171540761628
580, epoch_train_loss=0.0007354171540761628
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.000735417127530608
581, epoch_train_loss=0.000735417127530608
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.0007354171010839387
582, epoch_train_loss=0.0007354171010839387
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.0007354170747356317
583, epoch_train_loss=0.0007354170747356317
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.000735417048485163
584, epoch_train_loss=0.000735417048485163
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.0007354170223320146
585, epoch_train_loss=0.0007354170223320146
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.0007354169962756721
586, epoch_train_loss=0.0007354169962756721
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.0007354169703156246
587, epoch_train_loss=0.0007354169703156246
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.0007354169444513643
588, epoch_train_loss=0.0007354169444513643
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.0007354169186823872
589, epoch_train_loss=0.0007354169186823872
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.0007354168930081929
590, epoch_train_loss=0.0007354168930081929
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0007354168674282843
591, epoch_train_loss=0.0007354168674282843
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.0007354168419421675
592, epoch_train_loss=0.0007354168419421675
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.000735416816549352
593, epoch_train_loss=0.000735416816549352
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.0007354167912493511
594, epoch_train_loss=0.0007354167912493511
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.0007354167660416788
595, epoch_train_loss=0.0007354167660416788
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.0007354167409258568
596, epoch_train_loss=0.0007354167409258568
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0007354167159014075
597, epoch_train_loss=0.0007354167159014075
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.0007354166909678573
598, epoch_train_loss=0.0007354166909678573
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.0007354166661247333
599, epoch_train_loss=0.0007354166661247333
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.0007354166413715699
600, epoch_train_loss=0.0007354166413715699
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.0007354166167079023
601, epoch_train_loss=0.0007354166167079023
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0007354165921332678
602, epoch_train_loss=0.0007354165921332678
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.0007354165676472095
603, epoch_train_loss=0.0007354165676472095
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.0007354165432492725
604, epoch_train_loss=0.0007354165432492725
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.0007354165189390026
605, epoch_train_loss=0.0007354165189390026
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.0007354164947159525
606, epoch_train_loss=0.0007354164947159525
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.0007354164705796762
607, epoch_train_loss=0.0007354164705796762
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.0007354164465297286
608, epoch_train_loss=0.0007354164465297286
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.0007354164225656712
609, epoch_train_loss=0.0007354164225656712
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.0007354163986870649
610, epoch_train_loss=0.0007354163986870649
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0007354163748934773
611, epoch_train_loss=0.0007354163748934773
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.0007354163511844746
612, epoch_train_loss=0.0007354163511844746
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.0007354163275596285
613, epoch_train_loss=0.0007354163275596285
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.0007354163040185147
614, epoch_train_loss=0.0007354163040185147
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.0007354162805607102
615, epoch_train_loss=0.0007354162805607102
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.0007354162571857929
616, epoch_train_loss=0.0007354162571857929
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.0007354162338933454
617, epoch_train_loss=0.0007354162338933454
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.0007354162106829524
618, epoch_train_loss=0.0007354162106829524
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.0007354161875542023
619, epoch_train_loss=0.0007354161875542023
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.0007354161645066875
620, epoch_train_loss=0.0007354161645066875
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.0007354161415399991
621, epoch_train_loss=0.0007354161415399991
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.0007354161186537336
622, epoch_train_loss=0.0007354161186537336
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.0007354160958474887
623, epoch_train_loss=0.0007354160958474887
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.0007354160731208664
624, epoch_train_loss=0.0007354160731208664
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.0007354160504734716
625, epoch_train_loss=0.0007354160504734716
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.0007354160279049092
626, epoch_train_loss=0.0007354160279049092
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.0007354160054147878
627, epoch_train_loss=0.0007354160054147878
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0007354159830027189
628, epoch_train_loss=0.0007354159830027189
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0007354159606683165
629, epoch_train_loss=0.0007354159606683165
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.0007354159384111965
630, epoch_train_loss=0.0007354159384111965
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.0007354159162309782
631, epoch_train_loss=0.0007354159162309782
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.0007354158941272827
632, epoch_train_loss=0.0007354158941272827
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.0007354158720997336
633, epoch_train_loss=0.0007354158720997336
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.0007354158501479574
634, epoch_train_loss=0.0007354158501479574
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.0007354158282715818
635, epoch_train_loss=0.0007354158282715818
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.0007354158064702363
636, epoch_train_loss=0.0007354158064702363
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.0007354157847435579
637, epoch_train_loss=0.0007354157847435579
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.0007354157630911785
638, epoch_train_loss=0.0007354157630911785
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.0007354157415127374
639, epoch_train_loss=0.0007354157415127374
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.0007354157200078749
640, epoch_train_loss=0.0007354157200078749
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.0007354156985762335
641, epoch_train_loss=0.0007354156985762335
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.0007354156772174562
642, epoch_train_loss=0.0007354156772174562
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.0007354156559311915
643, epoch_train_loss=0.0007354156559311915
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.0007354156347170885
644, epoch_train_loss=0.0007354156347170885
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0007354156135747969
645, epoch_train_loss=0.0007354156135747969
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0007354155925039721
646, epoch_train_loss=0.0007354155925039721
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.0007354155715042696
647, epoch_train_loss=0.0007354155715042696
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0007354155505753457
648, epoch_train_loss=0.0007354155505753457
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.0007354155297168621
649, epoch_train_loss=0.0007354155297168621
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.0007354155089284793
650, epoch_train_loss=0.0007354155089284793
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.0007354154882098615
651, epoch_train_loss=0.0007354154882098615
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.0007354154675606767
652, epoch_train_loss=0.0007354154675606767
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.0007354154469805917
653, epoch_train_loss=0.0007354154469805917
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.0007354154264692784
654, epoch_train_loss=0.0007354154264692784
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0007354154060264094
655, epoch_train_loss=0.0007354154060264094
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.000735415385651658
656, epoch_train_loss=0.000735415385651658
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.0007354153653447001
657, epoch_train_loss=0.0007354153653447001
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.0007354153451052148
658, epoch_train_loss=0.0007354153451052148
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.0007354153249328841
659, epoch_train_loss=0.0007354153249328841
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.0007354153048273885
660, epoch_train_loss=0.0007354153048273885
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.000735415284788413
661, epoch_train_loss=0.000735415284788413
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.0007354152648156454
662, epoch_train_loss=0.0007354152648156454
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0007354152449087706
663, epoch_train_loss=0.0007354152449087706
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0007354152250674823
664, epoch_train_loss=0.0007354152250674823
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.0007354152052914709
665, epoch_train_loss=0.0007354152052914709
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.000735415185580432
666, epoch_train_loss=0.000735415185580432
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0007354151659340581
667, epoch_train_loss=0.0007354151659340581
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.0007354151463520503
668, epoch_train_loss=0.0007354151463520503
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.0007354151268341051
669, epoch_train_loss=0.0007354151268341051
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.0007354151073799266
670, epoch_train_loss=0.0007354151073799266
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.0007354150879892167
671, epoch_train_loss=0.0007354150879892167
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.0007354150686616806
672, epoch_train_loss=0.0007354150686616806
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.000735415049397023
673, epoch_train_loss=0.000735415049397023
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.0007354150301949558
674, epoch_train_loss=0.0007354150301949558
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.0007354150110551862
675, epoch_train_loss=0.0007354150110551862
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0007354149919774291
676, epoch_train_loss=0.0007354149919774291
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.0007354149729613957
677, epoch_train_loss=0.0007354149729613957
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.0007354149540068024
678, epoch_train_loss=0.0007354149540068024
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.0007354149351133667
679, epoch_train_loss=0.0007354149351133667
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0007354149162808073
680, epoch_train_loss=0.0007354149162808073
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0007354148975088436
681, epoch_train_loss=0.0007354148975088436
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0007354148787971991
682, epoch_train_loss=0.0007354148787971991
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.0007354148601455974
683, epoch_train_loss=0.0007354148601455974
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0007354148415537646
684, epoch_train_loss=0.0007354148415537646
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.0007354148230214273
685, epoch_train_loss=0.0007354148230214273
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.0007354148045483132
686, epoch_train_loss=0.0007354148045483132
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0007354147861341539
687, epoch_train_loss=0.0007354147861341539
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.0007354147677786799
688, epoch_train_loss=0.0007354147677786799
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.0007354147494816265
689, epoch_train_loss=0.0007354147494816265
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0007354147312427286
690, epoch_train_loss=0.0007354147312427286
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0007354147130617215
691, epoch_train_loss=0.0007354147130617215
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.0007354146949383448
692, epoch_train_loss=0.0007354146949383448
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.0007354146768723371
693, epoch_train_loss=0.0007354146768723371
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.0007354146588634395
694, epoch_train_loss=0.0007354146588634395
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0007354146409113963
695, epoch_train_loss=0.0007354146409113963
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0007354146230159506
696, epoch_train_loss=0.0007354146230159506
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.000735414605176849
697, epoch_train_loss=0.000735414605176849
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.0007354145873938382
698, epoch_train_loss=0.0007354145873938382
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0007354145696666667
699, epoch_train_loss=0.0007354145696666667
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0007354145519950859
700, epoch_train_loss=0.0007354145519950859
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.0007354145343788464
701, epoch_train_loss=0.0007354145343788464
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.0007354145168177013
702, epoch_train_loss=0.0007354145168177013
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0007354144993114049
703, epoch_train_loss=0.0007354144993114049
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.0007354144818597151
704, epoch_train_loss=0.0007354144818597151
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.0007354144644623875
705, epoch_train_loss=0.0007354144644623875
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0007354144471191811
706, epoch_train_loss=0.0007354144471191811
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0007354144298298558
707, epoch_train_loss=0.0007354144298298558
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0007354144125941749
708, epoch_train_loss=0.0007354144125941749
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0007354143954118986
709, epoch_train_loss=0.0007354143954118986
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.0007354143782827923
710, epoch_train_loss=0.0007354143782827923
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.0007354143612066235
711, epoch_train_loss=0.0007354143612066235
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0007354143441831573
712, epoch_train_loss=0.0007354143441831573
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.0007354143272121612
713, epoch_train_loss=0.0007354143272121612
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.0007354143102934072
714, epoch_train_loss=0.0007354143102934072
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.000735414293426665
715, epoch_train_loss=0.000735414293426665
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.0007354142766117069
716, epoch_train_loss=0.0007354142766117069
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0007354142598483053
717, epoch_train_loss=0.0007354142598483053
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.0007354142431362362
718, epoch_train_loss=0.0007354142431362362
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0007354142264752759
719, epoch_train_loss=0.0007354142264752759
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.0007354142098652017
720, epoch_train_loss=0.0007354142098652017
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0007354141933057924
721, epoch_train_loss=0.0007354141933057924
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.0007354141767968266
722, epoch_train_loss=0.0007354141767968266
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.0007354141603380867
723, epoch_train_loss=0.0007354141603380867
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.0007354141439293552
724, epoch_train_loss=0.0007354141439293552
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.0007354141275704154
725, epoch_train_loss=0.0007354141275704154
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0007354141112610527
726, epoch_train_loss=0.0007354141112610527
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.0007354140950010512
727, epoch_train_loss=0.0007354140950010512
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0007354140787902002
728, epoch_train_loss=0.0007354140787902002
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0007354140626282863
729, epoch_train_loss=0.0007354140626282863
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.0007354140465151007
730, epoch_train_loss=0.0007354140465151007
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.000735414030450434
731, epoch_train_loss=0.000735414030450434
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.0007354140144340784
732, epoch_train_loss=0.0007354140144340784
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.0007354139984658256
733, epoch_train_loss=0.0007354139984658256
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.00073541398254547
734, epoch_train_loss=0.00073541398254547
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.0007354139666728069
735, epoch_train_loss=0.0007354139666728069
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.0007354139508476342
736, epoch_train_loss=0.0007354139508476342
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0007354139350697485
737, epoch_train_loss=0.0007354139350697485
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.0007354139193389496
738, epoch_train_loss=0.0007354139193389496
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.0007354139036550361
739, epoch_train_loss=0.0007354139036550361
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.0007354138880178107
740, epoch_train_loss=0.0007354138880178107
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.000735413872427074
741, epoch_train_loss=0.000735413872427074
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.0007354138568826305
742, epoch_train_loss=0.0007354138568826305
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.0007354138413842832
743, epoch_train_loss=0.0007354138413842832
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.0007354138259318377
744, epoch_train_loss=0.0007354138259318377
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.0007354138105251
745, epoch_train_loss=0.0007354138105251
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.0007354137951638783
746, epoch_train_loss=0.0007354137951638783
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.0007354137798479807
747, epoch_train_loss=0.0007354137798479807
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.0007354137645772168
748, epoch_train_loss=0.0007354137645772168
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0007354137493513975
749, epoch_train_loss=0.0007354137493513975
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0007354137341703355
750, epoch_train_loss=0.0007354137341703355
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0007354137190338423
751, epoch_train_loss=0.0007354137190338423
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.0007354137039417316
752, epoch_train_loss=0.0007354137039417316
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.0007354136888938182
753, epoch_train_loss=0.0007354136888938182
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.0007354136738899178
754, epoch_train_loss=0.0007354136738899178
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.0007354136589298472
755, epoch_train_loss=0.0007354136589298472
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.0007354136440134244
756, epoch_train_loss=0.0007354136440134244
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.0007354136291404677
757, epoch_train_loss=0.0007354136291404677
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.0007354136143107968
758, epoch_train_loss=0.0007354136143107968
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.0007354135995242325
759, epoch_train_loss=0.0007354135995242325
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.0007354135847805957
760, epoch_train_loss=0.0007354135847805957
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.0007354135700797093
761, epoch_train_loss=0.0007354135700797093
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.0007354135554213974
762, epoch_train_loss=0.0007354135554213974
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 0.0007354135408054845
763, epoch_train_loss=0.0007354135408054845
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 0.000735413526231796
764, epoch_train_loss=0.000735413526231796
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.0007354135117001579
765, epoch_train_loss=0.0007354135117001579
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 0.000735413497210398
766, epoch_train_loss=0.000735413497210398
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 0.0007354134827623431
767, epoch_train_loss=0.0007354134827623431
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 0.0007354134683558236
768, epoch_train_loss=0.0007354134683558236
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 0.0007354134539906695
769, epoch_train_loss=0.0007354134539906695
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 0.0007354134396667106
770, epoch_train_loss=0.0007354134396667106
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 0.0007354134253837799
771, epoch_train_loss=0.0007354134253837799
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 0.0007354134111417091
772, epoch_train_loss=0.0007354134111417091
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 0.0007354133969403327
773, epoch_train_loss=0.0007354133969403327
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 0.0007354133827794842
774, epoch_train_loss=0.0007354133827794842
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 0.0007354133686590003
775, epoch_train_loss=0.0007354133686590003
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 0.0007354133545787171
776, epoch_train_loss=0.0007354133545787171
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 0.0007354133405384707
777, epoch_train_loss=0.0007354133405384707
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 0.0007354133265380988
778, epoch_train_loss=0.0007354133265380988
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 0.0007354133125774416
779, epoch_train_loss=0.0007354133125774416
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 0.0007354132986563375
780, epoch_train_loss=0.0007354132986563375
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 0.0007354132847746272
781, epoch_train_loss=0.0007354132847746272
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 0.0007354132709321531
782, epoch_train_loss=0.0007354132709321531
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 0.0007354132571287561
783, epoch_train_loss=0.0007354132571287561
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 0.0007354132433642804
784, epoch_train_loss=0.0007354132433642804
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 0.0007354132296385689
785, epoch_train_loss=0.0007354132296385689
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 0.0007354132159514661
786, epoch_train_loss=0.0007354132159514661
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 0.0007354132023028174
787, epoch_train_loss=0.0007354132023028174
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 0.0007354131886924703
788, epoch_train_loss=0.0007354131886924703
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 0.0007354131751202706
789, epoch_train_loss=0.0007354131751202706
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 0.0007354131615860663
790, epoch_train_loss=0.0007354131615860663
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 0.0007354131480897058
791, epoch_train_loss=0.0007354131480897058
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 0.0007354131346310388
792, epoch_train_loss=0.0007354131346310388
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 0.0007354131212099155
793, epoch_train_loss=0.0007354131212099155
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 0.0007354131078261864
794, epoch_train_loss=0.0007354131078261864
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 0.0007354130944797039
795, epoch_train_loss=0.0007354130944797039
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 0.0007354130811703201
796, epoch_train_loss=0.0007354130811703201
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 0.0007354130678978883
797, epoch_train_loss=0.0007354130678978883
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 0.0007354130546622628
798, epoch_train_loss=0.0007354130546622628
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 0.0007354130414632978
799, epoch_train_loss=0.0007354130414632978
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 0.0007354130283008495
800, epoch_train_loss=0.0007354130283008495
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 0.0007354130151747737
801, epoch_train_loss=0.0007354130151747737
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 0.0007354130020849275
802, epoch_train_loss=0.0007354130020849275
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 0.0007354129890311676
803, epoch_train_loss=0.0007354129890311676
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 0.0007354129760133546
804, epoch_train_loss=0.0007354129760133546
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 0.0007354129630313455
805, epoch_train_loss=0.0007354129630313455
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 0.000735412950085001
806, epoch_train_loss=0.000735412950085001
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 0.0007354129371741822
807, epoch_train_loss=0.0007354129371741822
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 0.0007354129242987492
808, epoch_train_loss=0.0007354129242987492
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 0.0007354129114585646
809, epoch_train_loss=0.0007354129114585646
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 0.0007354128986534917
810, epoch_train_loss=0.0007354128986534917
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 0.0007354128858833926
811, epoch_train_loss=0.0007354128858833926
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 0.0007354128731481326
812, epoch_train_loss=0.0007354128731481326
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 0.0007354128604475762
813, epoch_train_loss=0.0007354128604475762
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 0.0007354128477815882
814, epoch_train_loss=0.0007354128477815882
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 0.0007354128351500343
815, epoch_train_loss=0.0007354128351500343
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 0.0007354128225527837
816, epoch_train_loss=0.0007354128225527837
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 0.0007354128099897017
817, epoch_train_loss=0.0007354128099897017
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 0.0007354127974606565
818, epoch_train_loss=0.0007354127974606565
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 0.0007354127849655179
819, epoch_train_loss=0.0007354127849655179
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 0.0007354127725041545
820, epoch_train_loss=0.0007354127725041545
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 0.0007354127600764372
821, epoch_train_loss=0.0007354127600764372
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 0.0007354127476822362
822, epoch_train_loss=0.0007354127476822362
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 0.0007354127353214222
823, epoch_train_loss=0.0007354127353214222
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 0.0007354127229938689
824, epoch_train_loss=0.0007354127229938689
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 0.0007354127106994478
825, epoch_train_loss=0.0007354127106994478
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 0.000735412698438032
826, epoch_train_loss=0.000735412698438032
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 0.0007354126862094957
827, epoch_train_loss=0.0007354126862094957
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 0.0007354126740137146
828, epoch_train_loss=0.0007354126740137146
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 0.0007354126618505625
829, epoch_train_loss=0.0007354126618505625
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 0.0007354126497199156
830, epoch_train_loss=0.0007354126497199156
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 0.0007354126376216503
831, epoch_train_loss=0.0007354126376216503
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 0.0007354126255556435
832, epoch_train_loss=0.0007354126255556435
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 0.0007354126135217739
833, epoch_train_loss=0.0007354126135217739
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 0.0007354126015199179
834, epoch_train_loss=0.0007354126015199179
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 0.0007354125895499561
835, epoch_train_loss=0.0007354125895499561
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 0.0007354125776117662
836, epoch_train_loss=0.0007354125776117662
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 0.0007354125657052301
837, epoch_train_loss=0.0007354125657052301
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 0.0007354125538302265
838, epoch_train_loss=0.0007354125538302265
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 0.0007354125419866387
839, epoch_train_loss=0.0007354125419866387
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 0.0007354125301743463
840, epoch_train_loss=0.0007354125301743463
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 0.0007354125183932338
841, epoch_train_loss=0.0007354125183932338
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 0.0007354125066431821
842, epoch_train_loss=0.0007354125066431821
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 0.000735412494924076
843, epoch_train_loss=0.000735412494924076
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 0.0007354124832357992
844, epoch_train_loss=0.0007354124832357992
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 0.0007354124715782367
845, epoch_train_loss=0.0007354124715782367
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 0.0007354124599512733
846, epoch_train_loss=0.0007354124599512733
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.0007354124483547951
847, epoch_train_loss=0.0007354124483547951
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.0007354124367886883
848, epoch_train_loss=0.0007354124367886883
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0007354124252528391
849, epoch_train_loss=0.0007354124252528391
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.0007354124137471355
850, epoch_train_loss=0.0007354124137471355
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0007354124022714646
851, epoch_train_loss=0.0007354124022714646
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.000735412390825716
852, epoch_train_loss=0.000735412390825716
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.0007354123794097789
853, epoch_train_loss=0.0007354123794097789
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.0007354123680235417
854, epoch_train_loss=0.0007354123680235417
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.0007354123566668955
855, epoch_train_loss=0.0007354123566668955
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.00073541234533973
856, epoch_train_loss=0.00073541234533973
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.0007354123340419373
857, epoch_train_loss=0.0007354123340419373
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.0007354123227734092
858, epoch_train_loss=0.0007354123227734092
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.0007354123115340369
859, epoch_train_loss=0.0007354123115340369
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.000735412300323714
860, epoch_train_loss=0.000735412300323714
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.000735412289142333
861, epoch_train_loss=0.000735412289142333
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.0007354122779897874
862, epoch_train_loss=0.0007354122779897874
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.0007354122668659725
863, epoch_train_loss=0.0007354122668659725
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.0007354122557707825
864, epoch_train_loss=0.0007354122557707825
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.0007354122447041128
865, epoch_train_loss=0.0007354122447041128
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.000735412233665859
866, epoch_train_loss=0.000735412233665859
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.000735412222655917
867, epoch_train_loss=0.000735412222655917
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.0007354122116741838
868, epoch_train_loss=0.0007354122116741838
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.000735412200720557
869, epoch_train_loss=0.000735412200720557
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0007354121897949339
870, epoch_train_loss=0.0007354121897949339
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.0007354121788972128
871, epoch_train_loss=0.0007354121788972128
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.0007354121680272919
872, epoch_train_loss=0.0007354121680272919
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0007354121571850718
873, epoch_train_loss=0.0007354121571850718
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.00073541214637045
874, epoch_train_loss=0.00073541214637045
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.0007354121355833285
875, epoch_train_loss=0.0007354121355833285
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.0007354121248236069
876, epoch_train_loss=0.0007354121248236069
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.0007354121140911864
877, epoch_train_loss=0.0007354121140911864
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.0007354121033859686
878, epoch_train_loss=0.0007354121033859686
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.0007354120927078555
879, epoch_train_loss=0.0007354120927078555
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.000735412082056749
880, epoch_train_loss=0.000735412082056749
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.0007354120714325526
881, epoch_train_loss=0.0007354120714325526
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.0007354120608351695
882, epoch_train_loss=0.0007354120608351695
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0007354120502645036
883, epoch_train_loss=0.0007354120502645036
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0007354120397204587
884, epoch_train_loss=0.0007354120397204587
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0007354120292029398
885, epoch_train_loss=0.0007354120292029398
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.0007354120187118515
886, epoch_train_loss=0.0007354120187118515
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0007354120082470996
887, epoch_train_loss=0.0007354120082470996
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0007354119978085905
888, epoch_train_loss=0.0007354119978085905
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0007354119873962307
889, epoch_train_loss=0.0007354119873962307
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.0007354119770099268
890, epoch_train_loss=0.0007354119770099268
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0007354119666495855
891, epoch_train_loss=0.0007354119666495855
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0007354119563151153
892, epoch_train_loss=0.0007354119563151153
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.0007354119460064245
893, epoch_train_loss=0.0007354119460064245
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.0007354119357234207
894, epoch_train_loss=0.0007354119357234207
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0007354119254660137
895, epoch_train_loss=0.0007354119254660137
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.000735411915234113
896, epoch_train_loss=0.000735411915234113
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.000735411905027628
897, epoch_train_loss=0.000735411905027628
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0007354118948464687
898, epoch_train_loss=0.0007354118948464687
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0007354118846905463
899, epoch_train_loss=0.0007354118846905463
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0007354118745597722
900, epoch_train_loss=0.0007354118745597722
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.000735411864454057
901, epoch_train_loss=0.000735411864454057
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0007354118543733134
902, epoch_train_loss=0.0007354118543733134
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.0007354118443174531
903, epoch_train_loss=0.0007354118443174531
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0007354118342863892
904, epoch_train_loss=0.0007354118342863892
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007354118242800343
905, epoch_train_loss=0.0007354118242800343
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.0007354118142983019
906, epoch_train_loss=0.0007354118142983019
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.0007354118043411056
907, epoch_train_loss=0.0007354118043411056
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.000735411794408361
908, epoch_train_loss=0.000735411794408361
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.0007354117844999815
909, epoch_train_loss=0.0007354117844999815
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.0007354117746158822
910, epoch_train_loss=0.0007354117746158822
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0007354117647559797
911, epoch_train_loss=0.0007354117647559797
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.0007354117549201888
912, epoch_train_loss=0.0007354117549201888
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.0007354117451084256
913, epoch_train_loss=0.0007354117451084256
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.0007354117353206074
914, epoch_train_loss=0.0007354117353206074
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0007354117255566508
915, epoch_train_loss=0.0007354117255566508
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.0007354117158164729
916, epoch_train_loss=0.0007354117158164729
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.0007354117060999911
917, epoch_train_loss=0.0007354117060999911
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.0007354116964071241
918, epoch_train_loss=0.0007354116964071241
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0007354116867377897
919, epoch_train_loss=0.0007354116867377897
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.0007354116770919072
920, epoch_train_loss=0.0007354116770919072
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.0007354116674693958
921, epoch_train_loss=0.0007354116674693958
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.0007354116578701745
922, epoch_train_loss=0.0007354116578701745
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.0007354116482941638
923, epoch_train_loss=0.0007354116482941638
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.0007354116387412835
924, epoch_train_loss=0.0007354116387412835
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.0007354116292114546
925, epoch_train_loss=0.0007354116292114546
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0007354116197045977
926, epoch_train_loss=0.0007354116197045977
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.0007354116102206343
927, epoch_train_loss=0.0007354116102206343
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.000735411600759486
928, epoch_train_loss=0.000735411600759486
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0007354115913210743
929, epoch_train_loss=0.0007354115913210743
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.000735411581905322
930, epoch_train_loss=0.000735411581905322
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.0007354115725121521
931, epoch_train_loss=0.0007354115725121521
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.0007354115631414865
932, epoch_train_loss=0.0007354115631414865
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.0007354115537932498
933, epoch_train_loss=0.0007354115537932498
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.0007354115444673654
934, epoch_train_loss=0.0007354115444673654
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.0007354115351637569
935, epoch_train_loss=0.0007354115351637569
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.0007354115258823492
936, epoch_train_loss=0.0007354115258823492
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.0007354115166230671
937, epoch_train_loss=0.0007354115166230671
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.0007354115073858355
938, epoch_train_loss=0.0007354115073858355
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.0007354114981705795
939, epoch_train_loss=0.0007354114981705795
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.0007354114889772252
940, epoch_train_loss=0.0007354114889772252
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.000735411479805698
941, epoch_train_loss=0.000735411479805698
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.000735411470655925
942, epoch_train_loss=0.000735411470655925
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.0007354114615278323
943, epoch_train_loss=0.0007354114615278323
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.0007354114524213467
944, epoch_train_loss=0.0007354114524213467
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.0007354114433363965
945, epoch_train_loss=0.0007354114433363965
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.0007354114342729094
946, epoch_train_loss=0.0007354114342729094
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.000735411425230812
947, epoch_train_loss=0.000735411425230812
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.0007354114162100334
948, epoch_train_loss=0.0007354114162100334
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.0007354114072105026
949, epoch_train_loss=0.0007354114072105026
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.0007354113982321476
950, epoch_train_loss=0.0007354113982321476
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0007354113892748982
951, epoch_train_loss=0.0007354113892748982
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.0007354113803386839
952, epoch_train_loss=0.0007354113803386839
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.000735411371423434
953, epoch_train_loss=0.000735411371423434
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.0007354113625290791
954, epoch_train_loss=0.0007354113625290791
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.0007354113536555492
955, epoch_train_loss=0.0007354113536555492
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.0007354113448027754
956, epoch_train_loss=0.0007354113448027754
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.000735411335970689
957, epoch_train_loss=0.000735411335970689
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.0007354113271592209
958, epoch_train_loss=0.0007354113271592209
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.0007354113183683027
959, epoch_train_loss=0.0007354113183683027
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0007354113095978658
960, epoch_train_loss=0.0007354113095978658
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0007354113008478434
961, epoch_train_loss=0.0007354113008478434
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.0007354112921181676
962, epoch_train_loss=0.0007354112921181676
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0007354112834087712
963, epoch_train_loss=0.0007354112834087712
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.0007354112747195872
964, epoch_train_loss=0.0007354112747195872
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.000735411266050549
965, epoch_train_loss=0.000735411266050549
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.0007354112574015902
966, epoch_train_loss=0.0007354112574015902
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.0007354112487726449
967, epoch_train_loss=0.0007354112487726449
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.0007354112401636467
968, epoch_train_loss=0.0007354112401636467
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0007354112315745312
969, epoch_train_loss=0.0007354112315745312
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.0007354112230052321
970, epoch_train_loss=0.0007354112230052321
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.0007354112144556848
971, epoch_train_loss=0.0007354112144556848
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.000735411205925825
972, epoch_train_loss=0.000735411205925825
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.0007354111974155884
973, epoch_train_loss=0.0007354111974155884
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.0007354111889249096
974, epoch_train_loss=0.0007354111889249096
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.0007354111804537262
975, epoch_train_loss=0.0007354111804537262
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.000735411172001974
976, epoch_train_loss=0.000735411172001974
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0007354111635695896
977, epoch_train_loss=0.0007354111635695896
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.0007354111551565101
978, epoch_train_loss=0.0007354111551565101
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.000735411146762673
979, epoch_train_loss=0.000735411146762673
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.0007354111383880152
980, epoch_train_loss=0.0007354111383880152
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0007354111300324751
981, epoch_train_loss=0.0007354111300324751
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.0007354111216959906
982, epoch_train_loss=0.0007354111216959906
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.0007354111133784995
983, epoch_train_loss=0.0007354111133784995
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0007354111050799408
984, epoch_train_loss=0.0007354111050799408
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.000735411096800253
985, epoch_train_loss=0.000735411096800253
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.0007354110885393748
986, epoch_train_loss=0.0007354110885393748
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.0007354110802972462
987, epoch_train_loss=0.0007354110802972462
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.0007354110720738065
988, epoch_train_loss=0.0007354110720738065
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.0007354110638689959
989, epoch_train_loss=0.0007354110638689959
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.0007354110556827538
990, epoch_train_loss=0.0007354110556827538
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0007354110475150206
991, epoch_train_loss=0.0007354110475150206
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0007354110393657375
992, epoch_train_loss=0.0007354110393657375
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0007354110312348448
993, epoch_train_loss=0.0007354110312348448
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.0007354110231222839
994, epoch_train_loss=0.0007354110231222839
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0007354110150279954
995, epoch_train_loss=0.0007354110150279954
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0007354110069519214
996, epoch_train_loss=0.0007354110069519214
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.0007354109988940037
997, epoch_train_loss=0.0007354109988940037
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.0007354109908541841
998, epoch_train_loss=0.0007354109908541841
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.000735410982832405
999, epoch_train_loss=0.000735410982832405
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.0007354109748286088
1000, epoch_train_loss=0.0007354109748286088
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.0007354109668427389
1001, epoch_train_loss=0.0007354109668427389
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.0007354109588747371
1002, epoch_train_loss=0.0007354109588747371
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0007354109509245479
1003, epoch_train_loss=0.0007354109509245479
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0007354109429921136
1004, epoch_train_loss=0.0007354109429921136
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.000735410935077379
1005, epoch_train_loss=0.000735410935077379
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.0007354109271802868
1006, epoch_train_loss=0.0007354109271802868
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0007354109193007825
1007, epoch_train_loss=0.0007354109193007825
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.0007354109114388091
1008, epoch_train_loss=0.0007354109114388091
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.0007354109035943119
1009, epoch_train_loss=0.0007354109035943119
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.000735410895767236
1010, epoch_train_loss=0.000735410895767236
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.0007354108879575263
1011, epoch_train_loss=0.0007354108879575263
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.0007354108801651282
1012, epoch_train_loss=0.0007354108801651282
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.000735410872389987
1013, epoch_train_loss=0.000735410872389987
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.0007354108646320486
1014, epoch_train_loss=0.0007354108646320486
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0007354108568912584
1015, epoch_train_loss=0.0007354108568912584
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.0007354108491675631
1016, epoch_train_loss=0.0007354108491675631
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.0007354108414609086
1017, epoch_train_loss=0.0007354108414609086
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0007354108337712428
1018, epoch_train_loss=0.0007354108337712428
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.0007354108260985111
1019, epoch_train_loss=0.0007354108260985111
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0007354108184426613
1020, epoch_train_loss=0.0007354108184426613
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0007354108108036407
1021, epoch_train_loss=0.0007354108108036407
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0007354108031813961
1022, epoch_train_loss=0.0007354108031813961
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.000735410795575876
1023, epoch_train_loss=0.000735410795575876
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.0007354107879870277
1024, epoch_train_loss=0.0007354107879870277
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.0007354107804147998
1025, epoch_train_loss=0.0007354107804147998
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.00073541077285914
1026, epoch_train_loss=0.00073541077285914
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0007354107653199969
1027, epoch_train_loss=0.0007354107653199969
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.0007354107577973199
1028, epoch_train_loss=0.0007354107577973199
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.000735410750291058
1029, epoch_train_loss=0.000735410750291058
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.0007354107428011597
1030, epoch_train_loss=0.0007354107428011597
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.0007354107353275744
1031, epoch_train_loss=0.0007354107353275744
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.0007354107278702522
1032, epoch_train_loss=0.0007354107278702522
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.0007354107204291424
1033, epoch_train_loss=0.0007354107204291424
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0007354107130041949
1034, epoch_train_loss=0.0007354107130041949
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.0007354107055953604
1035, epoch_train_loss=0.0007354107055953604
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.0007354106982025889
1036, epoch_train_loss=0.0007354106982025889
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.0007354106908258308
1037, epoch_train_loss=0.0007354106908258308
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.0007354106834650375
1038, epoch_train_loss=0.0007354106834650375
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.0007354106761201589
1039, epoch_train_loss=0.0007354106761201589
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.0007354106687911473
1040, epoch_train_loss=0.0007354106687911473
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 0.0007354106614779533
1041, epoch_train_loss=0.0007354106614779533
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.0007354106541805286
1042, epoch_train_loss=0.0007354106541805286
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.0007354106468988251
1043, epoch_train_loss=0.0007354106468988251
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.0007354106396327945
1044, epoch_train_loss=0.0007354106396327945
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 0.0007354106323823897
1045, epoch_train_loss=0.0007354106323823897
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 0.0007354106251475617
1046, epoch_train_loss=0.0007354106251475617
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 0.0007354106179282636
1047, epoch_train_loss=0.0007354106179282636
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 0.0007354106107244482
1048, epoch_train_loss=0.0007354106107244482
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 0.0007354106035360687
1049, epoch_train_loss=0.0007354106035360687
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 0.0007354105963630777
1050, epoch_train_loss=0.0007354105963630777
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 0.0007354105892054282
1051, epoch_train_loss=0.0007354105892054282
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 0.0007354105820630741
1052, epoch_train_loss=0.0007354105820630741
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 0.0007354105749359691
1053, epoch_train_loss=0.0007354105749359691
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 0.0007354105678240667
1054, epoch_train_loss=0.0007354105678240667
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 0.0007354105607273204
1055, epoch_train_loss=0.0007354105607273204
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 0.0007354105536456853
1056, epoch_train_loss=0.0007354105536456853
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 0.0007354105465791152
1057, epoch_train_loss=0.0007354105465791152
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 0.0007354105395275649
1058, epoch_train_loss=0.0007354105395275649
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 0.0007354105324909893
1059, epoch_train_loss=0.0007354105324909893
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 0.0007354105254693424
1060, epoch_train_loss=0.0007354105254693424
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 0.00073541051846258
1061, epoch_train_loss=0.00073541051846258
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 0.0007354105114706566
1062, epoch_train_loss=0.0007354105114706566
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 0.0007354105044935286
1063, epoch_train_loss=0.0007354105044935286
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 0.000735410497531151
1064, epoch_train_loss=0.000735410497531151
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 0.0007354104905834799
1065, epoch_train_loss=0.0007354104905834799
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 0.0007354104836504707
1066, epoch_train_loss=0.0007354104836504707
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 0.0007354104767320795
1067, epoch_train_loss=0.0007354104767320795
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 0.000735410469828263
1068, epoch_train_loss=0.000735410469828263
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 0.0007354104629389772
1069, epoch_train_loss=0.0007354104629389772
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 0.0007354104560641793
1070, epoch_train_loss=0.0007354104560641793
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 0.0007354104492038252
1071, epoch_train_loss=0.0007354104492038252
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 0.0007354104423578729
1072, epoch_train_loss=0.0007354104423578729
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 0.0007354104355262787
1073, epoch_train_loss=0.0007354104355262787
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 0.0007354104287090004
1074, epoch_train_loss=0.0007354104287090004
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 0.000735410421905995
1075, epoch_train_loss=0.000735410421905995
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 0.00073541041511722
1076, epoch_train_loss=0.00073541041511722
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 0.0007354104083426336
1077, epoch_train_loss=0.0007354104083426336
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 0.000735410401582193
1078, epoch_train_loss=0.000735410401582193
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 0.0007354103948358575
1079, epoch_train_loss=0.0007354103948358575
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 0.0007354103881035844
1080, epoch_train_loss=0.0007354103881035844
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 0.0007354103813853323
1081, epoch_train_loss=0.0007354103813853323
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 0.0007354103746810599
1082, epoch_train_loss=0.0007354103746810599
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 0.0007354103679907263
1083, epoch_train_loss=0.0007354103679907263
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 0.0007354103613142897
1084, epoch_train_loss=0.0007354103613142897
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 0.0007354103546517096
1085, epoch_train_loss=0.0007354103546517096
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 0.000735410348002945
1086, epoch_train_loss=0.000735410348002945
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 0.0007354103413679552
1087, epoch_train_loss=0.0007354103413679552
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 0.0007354103347466997
1088, epoch_train_loss=0.0007354103347466997
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 0.0007354103281391383
1089, epoch_train_loss=0.0007354103281391383
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 0.0007354103215452309
1090, epoch_train_loss=0.0007354103215452309
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 0.0007354103149649372
1091, epoch_train_loss=0.0007354103149649372
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 0.0007354103083982177
1092, epoch_train_loss=0.0007354103083982177
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 0.0007354103018450323
1093, epoch_train_loss=0.0007354103018450323
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 0.0007354102953053418
1094, epoch_train_loss=0.0007354102953053418
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 0.0007354102887791067
1095, epoch_train_loss=0.0007354102887791067
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 0.0007354102822662871
1096, epoch_train_loss=0.0007354102822662871
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 0.0007354102757668446
1097, epoch_train_loss=0.0007354102757668446
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 0.0007354102692807399
1098, epoch_train_loss=0.0007354102692807399
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 0.0007354102628079346
1099, epoch_train_loss=0.0007354102628079346
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 0.0007354102563483892
1100, epoch_train_loss=0.0007354102563483892
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 0.0007354102499020658
1101, epoch_train_loss=0.0007354102499020658
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 0.0007354102434689262
1102, epoch_train_loss=0.0007354102434689262
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 0.0007354102370489317
1103, epoch_train_loss=0.0007354102370489317
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 0.0007354102306420447
1104, epoch_train_loss=0.0007354102306420447
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 0.0007354102242482266
1105, epoch_train_loss=0.0007354102242482266
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 0.00073541021786744
1106, epoch_train_loss=0.00073541021786744
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 0.0007354102114996468
1107, epoch_train_loss=0.0007354102114996468
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 0.0007354102051448101
1108, epoch_train_loss=0.0007354102051448101
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 0.0007354101988028918
1109, epoch_train_loss=0.0007354101988028918
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 0.000735410192473855
1110, epoch_train_loss=0.000735410192473855
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 0.0007354101861576626
1111, epoch_train_loss=0.0007354101861576626
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 0.0007354101798542781
1112, epoch_train_loss=0.0007354101798542781
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 0.000735410173563664
1113, epoch_train_loss=0.000735410173563664
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 0.000735410167285784
1114, epoch_train_loss=0.000735410167285784
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 0.0007354101610206012
1115, epoch_train_loss=0.0007354101610206012
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 0.0007354101547680794
1116, epoch_train_loss=0.0007354101547680794
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 0.0007354101485281818
1117, epoch_train_loss=0.0007354101485281818
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 0.000735410142300873
1118, epoch_train_loss=0.000735410142300873
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 0.0007354101360861175
1119, epoch_train_loss=0.0007354101360861175
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 0.0007354101298838782
1120, epoch_train_loss=0.0007354101298838782
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 0.0007354101236941195
1121, epoch_train_loss=0.0007354101236941195
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 0.0007354101175168062
1122, epoch_train_loss=0.0007354101175168062
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 0.0007354101113519026
1123, epoch_train_loss=0.0007354101113519026
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 0.0007354101051993736
1124, epoch_train_loss=0.0007354101051993736
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 0.0007354100990591839
1125, epoch_train_loss=0.0007354100990591839
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 0.0007354100929312981
1126, epoch_train_loss=0.0007354100929312981
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 0.0007354100868156809
1127, epoch_train_loss=0.0007354100868156809
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 0.0007354100807122985
1128, epoch_train_loss=0.0007354100807122985
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 0.0007354100746211159
1129, epoch_train_loss=0.0007354100746211159
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 0.0007354100685420979
1130, epoch_train_loss=0.0007354100685420979
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 0.0007354100624752106
1131, epoch_train_loss=0.0007354100624752106
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 0.0007354100564204197
1132, epoch_train_loss=0.0007354100564204197
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 0.0007354100503776908
1133, epoch_train_loss=0.0007354100503776908
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 0.0007354100443469899
1134, epoch_train_loss=0.0007354100443469899
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 0.0007354100383282824
1135, epoch_train_loss=0.0007354100383282824
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 0.0007354100323215359
1136, epoch_train_loss=0.0007354100323215359
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 0.000735410026326716
1137, epoch_train_loss=0.000735410026326716
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 0.0007354100203437885
1138, epoch_train_loss=0.0007354100203437885
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 0.0007354100143727206
1139, epoch_train_loss=0.0007354100143727206
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 0.000735410008413479
1140, epoch_train_loss=0.000735410008413479
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 0.0007354100024660305
1141, epoch_train_loss=0.0007354100024660305
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 0.0007354099965303416
1142, epoch_train_loss=0.0007354099965303416
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 0.0007354099906063798
1143, epoch_train_loss=0.0007354099906063798
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 0.0007354099846941121
1144, epoch_train_loss=0.0007354099846941121
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 0.0007354099787935052
1145, epoch_train_loss=0.0007354099787935052
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 0.0007354099729045278
1146, epoch_train_loss=0.0007354099729045278
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 0.0007354099670271461
1147, epoch_train_loss=0.0007354099670271461
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 0.0007354099611613283
1148, epoch_train_loss=0.0007354099611613283
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 0.0007354099553070419
1149, epoch_train_loss=0.0007354099553070419
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 0.0007354099494642556
1150, epoch_train_loss=0.0007354099494642556
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 0.0007354099436329362
1151, epoch_train_loss=0.0007354099436329362
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 0.0007354099378130527
1152, epoch_train_loss=0.0007354099378130527
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 0.0007354099320045726
1153, epoch_train_loss=0.0007354099320045726
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 0.0007354099262074649
1154, epoch_train_loss=0.0007354099262074649
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 0.0007354099204216975
1155, epoch_train_loss=0.0007354099204216975
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 0.000735409914647239
1156, epoch_train_loss=0.000735409914647239
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 0.0007354099088840584
1157, epoch_train_loss=0.0007354099088840584
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 0.0007354099031321242
1158, epoch_train_loss=0.0007354099031321242
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 0.0007354098973914058
1159, epoch_train_loss=0.0007354098973914058
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 0.0007354098916618714
1160, epoch_train_loss=0.0007354098916618714
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 0.0007354098859434907
1161, epoch_train_loss=0.0007354098859434907
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 0.0007354098802362329
1162, epoch_train_loss=0.0007354098802362329
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 0.0007354098745400666
1163, epoch_train_loss=0.0007354098745400666
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 0.0007354098688549622
1164, epoch_train_loss=0.0007354098688549622
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 0.0007354098631808885
1165, epoch_train_loss=0.0007354098631808885
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 0.0007354098575178163
1166, epoch_train_loss=0.0007354098575178163
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 0.0007354098518657138
1167, epoch_train_loss=0.0007354098518657138
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 0.0007354098462245524
1168, epoch_train_loss=0.0007354098462245524
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 0.0007354098405943011
1169, epoch_train_loss=0.0007354098405943011
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 0.0007354098349749301
1170, epoch_train_loss=0.0007354098349749301
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 0.0007354098293664099
1171, epoch_train_loss=0.0007354098293664099
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 0.0007354098237687106
1172, epoch_train_loss=0.0007354098237687106
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 0.0007354098181818027
1173, epoch_train_loss=0.0007354098181818027
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 0.0007354098126056568
1174, epoch_train_loss=0.0007354098126056568
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 0.0007354098070402432
1175, epoch_train_loss=0.0007354098070402432
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 0.0007354098014855331
1176, epoch_train_loss=0.0007354098014855331
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 0.0007354097959414971
1177, epoch_train_loss=0.0007354097959414971
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 0.0007354097904081058
1178, epoch_train_loss=0.0007354097904081058
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 0.000735409784885331
1179, epoch_train_loss=0.000735409784885331
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 0.0007354097793731434
1180, epoch_train_loss=0.0007354097793731434
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 0.0007354097738715137
1181, epoch_train_loss=0.0007354097738715137
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 0.0007354097683804139
1182, epoch_train_loss=0.0007354097683804139
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 0.0007354097628998154
1183, epoch_train_loss=0.0007354097628998154
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 0.0007354097574296896
1184, epoch_train_loss=0.0007354097574296896
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 0.0007354097519700081
1185, epoch_train_loss=0.0007354097519700081
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 0.0007354097465207426
1186, epoch_train_loss=0.0007354097465207426
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 0.0007354097410818655
1187, epoch_train_loss=0.0007354097410818655
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 0.0007354097356533477
1188, epoch_train_loss=0.0007354097356533477
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 0.0007354097302351622
1189, epoch_train_loss=0.0007354097302351622
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 0.0007354097248272805
1190, epoch_train_loss=0.0007354097248272805
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 0.0007354097194296751
1191, epoch_train_loss=0.0007354097194296751
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 0.0007354097140423188
1192, epoch_train_loss=0.0007354097140423188
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 0.0007354097086651832
1193, epoch_train_loss=0.0007354097086651832
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 0.0007354097032982414
1194, epoch_train_loss=0.0007354097032982414
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 0.0007354096979414656
1195, epoch_train_loss=0.0007354096979414656
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 0.0007354096925948291
1196, epoch_train_loss=0.0007354096925948291
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 0.0007354096872583044
1197, epoch_train_loss=0.0007354096872583044
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 0.000735409681931864
1198, epoch_train_loss=0.000735409681931864
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 0.0007354096766154812
1199, epoch_train_loss=0.0007354096766154812
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 0.0007354096713091295
1200, epoch_train_loss=0.0007354096713091295
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 0.0007354096660127816
1201, epoch_train_loss=0.0007354096660127816
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 0.0007354096607264109
1202, epoch_train_loss=0.0007354096607264109
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 0.0007354096554499907
1203, epoch_train_loss=0.0007354096554499907
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 0.0007354096501834948
1204, epoch_train_loss=0.0007354096501834948
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 0.0007354096449268964
1205, epoch_train_loss=0.0007354096449268964
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 0.0007354096396801692
1206, epoch_train_loss=0.0007354096396801692
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 0.0007354096344432868
1207, epoch_train_loss=0.0007354096344432868
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 0.0007354096292162234
1208, epoch_train_loss=0.0007354096292162234
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 0.0007354096239989529
1209, epoch_train_loss=0.0007354096239989529
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 0.000735409618791449
1210, epoch_train_loss=0.000735409618791449
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 0.0007354096135936858
1211, epoch_train_loss=0.0007354096135936858
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 0.0007354096084056377
1212, epoch_train_loss=0.0007354096084056377
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.0007354096032272792
1213, epoch_train_loss=0.0007354096032272792
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.0007354095980585842
1214, epoch_train_loss=0.0007354095980585842
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.000735409592899527
1215, epoch_train_loss=0.000735409592899527
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.0007354095877500831
1216, epoch_train_loss=0.0007354095877500831
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.0007354095826102266
1217, epoch_train_loss=0.0007354095826102266
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.0007354095774799316
1218, epoch_train_loss=0.0007354095774799316
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0007354095723591735
1219, epoch_train_loss=0.0007354095723591735
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.0007354095672479271
1220, epoch_train_loss=0.0007354095672479271
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.0007354095621461675
1221, epoch_train_loss=0.0007354095621461675
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.0007354095570538698
1222, epoch_train_loss=0.0007354095570538698
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.0007354095519710085
1223, epoch_train_loss=0.0007354095519710085
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.0007354095468975596
1224, epoch_train_loss=0.0007354095468975596
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.0007354095418334981
1225, epoch_train_loss=0.0007354095418334981
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.0007354095367787995
1226, epoch_train_loss=0.0007354095367787995
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.0007354095317334395
1227, epoch_train_loss=0.0007354095317334395
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.0007354095266973931
1228, epoch_train_loss=0.0007354095266973931
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.0007354095216706363
1229, epoch_train_loss=0.0007354095216706363
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.000735409516653145
1230, epoch_train_loss=0.000735409516653145
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0007354095116448948
1231, epoch_train_loss=0.0007354095116448948
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0007354095066458617
1232, epoch_train_loss=0.0007354095066458617
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0007354095016560214
1233, epoch_train_loss=0.0007354095016560214
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007354094966753501
1234, epoch_train_loss=0.0007354094966753501
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.0007354094917038239
1235, epoch_train_loss=0.0007354094917038239
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.000735409486741419
1236, epoch_train_loss=0.000735409486741419
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.0007354094817881119
1237, epoch_train_loss=0.0007354094817881119
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0007354094768438793
1238, epoch_train_loss=0.0007354094768438793
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0007354094719086967
1239, epoch_train_loss=0.0007354094719086967
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.0007354094669825416
1240, epoch_train_loss=0.0007354094669825416
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.00073540946206539
1241, epoch_train_loss=0.00073540946206539
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.0007354094571572186
1242, epoch_train_loss=0.0007354094571572186
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.0007354094522580043
1243, epoch_train_loss=0.0007354094522580043
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.0007354094473677242
1244, epoch_train_loss=0.0007354094473677242
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0007354094424863551
1245, epoch_train_loss=0.0007354094424863551
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0007354094376138737
1246, epoch_train_loss=0.0007354094376138737
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0007354094327502575
1247, epoch_train_loss=0.0007354094327502575
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0007354094278954836
1248, epoch_train_loss=0.0007354094278954836
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.000735409423049529
1249, epoch_train_loss=0.000735409423049529
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.000735409418212371
1250, epoch_train_loss=0.000735409418212371
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0007354094133839877
1251, epoch_train_loss=0.0007354094133839877
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.0007354094085643557
1252, epoch_train_loss=0.0007354094085643557
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.000735409403753453
1253, epoch_train_loss=0.000735409403753453
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0007354093989512568
1254, epoch_train_loss=0.0007354093989512568
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0007354093941577452
1255, epoch_train_loss=0.0007354093941577452
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.0007354093893728959
1256, epoch_train_loss=0.0007354093893728959
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0007354093845966864
1257, epoch_train_loss=0.0007354093845966864
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0007354093798290951
1258, epoch_train_loss=0.0007354093798290951
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.0007354093750700999
1259, epoch_train_loss=0.0007354093750700999
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007354093703196783
1260, epoch_train_loss=0.0007354093703196783
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0007354093655778091
1261, epoch_train_loss=0.0007354093655778091
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0007354093608444703
1262, epoch_train_loss=0.0007354093608444703
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0007354093561196402
1263, epoch_train_loss=0.0007354093561196402
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0007354093514032972
1264, epoch_train_loss=0.0007354093514032972
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0007354093466954195
1265, epoch_train_loss=0.0007354093466954195
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0007354093419959856
1266, epoch_train_loss=0.0007354093419959856
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0007354093373049739
1267, epoch_train_loss=0.0007354093373049739
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0007354093326223636
1268, epoch_train_loss=0.0007354093326223636
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0007354093279481332
1269, epoch_train_loss=0.0007354093279481332
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0007354093232822611
1270, epoch_train_loss=0.0007354093232822611
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0007354093186247264
1271, epoch_train_loss=0.0007354093186247264
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.0007354093139755078
1272, epoch_train_loss=0.0007354093139755078
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.0007354093093345847
1273, epoch_train_loss=0.0007354093093345847
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.000735409304701936
1274, epoch_train_loss=0.000735409304701936
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.000735409300077541
1275, epoch_train_loss=0.000735409300077541
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0007354092954613787
1276, epoch_train_loss=0.0007354092954613787
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007354092908534282
1277, epoch_train_loss=0.0007354092908534282
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0007354092862536691
1278, epoch_train_loss=0.0007354092862536691
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0007354092816620804
1279, epoch_train_loss=0.0007354092816620804
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.0007354092770786414
1280, epoch_train_loss=0.0007354092770786414
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.0007354092725033324
1281, epoch_train_loss=0.0007354092725033324
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.0007354092679361325
1282, epoch_train_loss=0.0007354092679361325
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0007354092633770216
1283, epoch_train_loss=0.0007354092633770216
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.0007354092588259793
1284, epoch_train_loss=0.0007354092588259793
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0007354092542829854
1285, epoch_train_loss=0.0007354092542829854
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.0007354092497480197
1286, epoch_train_loss=0.0007354092497480197
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.000735409245221062
1287, epoch_train_loss=0.000735409245221062
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0007354092407020923
1288, epoch_train_loss=0.0007354092407020923
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0007354092361910911
1289, epoch_train_loss=0.0007354092361910911
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0007354092316880382
1290, epoch_train_loss=0.0007354092316880382
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0007354092271929136
1291, epoch_train_loss=0.0007354092271929136
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.0007354092227056978
1292, epoch_train_loss=0.0007354092227056978
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.0007354092182263706
1293, epoch_train_loss=0.0007354092182263706
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.0007354092137549135
1294, epoch_train_loss=0.0007354092137549135
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.0007354092092913062
1295, epoch_train_loss=0.0007354092092913062
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.000735409204835529
1296, epoch_train_loss=0.000735409204835529
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.0007354092003875629
1297, epoch_train_loss=0.0007354092003875629
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.0007354091959473881
1298, epoch_train_loss=0.0007354091959473881
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.000735409191514986
1299, epoch_train_loss=0.000735409191514986
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.0007354091870903365
1300, epoch_train_loss=0.0007354091870903365
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.0007354091826734209
1301, epoch_train_loss=0.0007354091826734209
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.0007354091782642197
1302, epoch_train_loss=0.0007354091782642197
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.0007354091738627148
1303, epoch_train_loss=0.0007354091738627148
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0007354091694688861
1304, epoch_train_loss=0.0007354091694688861
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.0007354091650827149
1305, epoch_train_loss=0.0007354091650827149
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0007354091607041827
1306, epoch_train_loss=0.0007354091607041827
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.0007354091563332705
1307, epoch_train_loss=0.0007354091563332705
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.0007354091519699594
1308, epoch_train_loss=0.0007354091519699594
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.0007354091476142305
1309, epoch_train_loss=0.0007354091476142305
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.000735409143266066
1310, epoch_train_loss=0.000735409143266066
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 0.0007354091389254465
1311, epoch_train_loss=0.0007354091389254465
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.0007354091345923533
1312, epoch_train_loss=0.0007354091345923533
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.0007354091302667691
1313, epoch_train_loss=0.0007354091302667691
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.0007354091259486744
1314, epoch_train_loss=0.0007354091259486744
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 0.0007354091216380508
1315, epoch_train_loss=0.0007354091216380508
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.0007354091173348811
1316, epoch_train_loss=0.0007354091173348811
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.0007354091130391463
1317, epoch_train_loss=0.0007354091130391463
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 0.000735409108750828
1318, epoch_train_loss=0.000735409108750828
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 0.0007354091044699088
1319, epoch_train_loss=0.0007354091044699088
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 0.0007354091001963702
1320, epoch_train_loss=0.0007354091001963702
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 0.0007354090959301939
1321, epoch_train_loss=0.0007354090959301939
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 0.0007354090916713628
1322, epoch_train_loss=0.0007354090916713628
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 0.000735409087419858
1323, epoch_train_loss=0.000735409087419858
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 0.0007354090831756627
1324, epoch_train_loss=0.0007354090831756627
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 0.0007354090789387582
1325, epoch_train_loss=0.0007354090789387582
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 0.0007354090747091271
1326, epoch_train_loss=0.0007354090747091271
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 0.0007354090704867523
1327, epoch_train_loss=0.0007354090704867523
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 0.0007354090662716154
1328, epoch_train_loss=0.0007354090662716154
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 0.0007354090620636996
1329, epoch_train_loss=0.0007354090620636996
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 0.0007354090578629868
1330, epoch_train_loss=0.0007354090578629868
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 0.0007354090536694596
1331, epoch_train_loss=0.0007354090536694596
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 0.000735409049483101
1332, epoch_train_loss=0.000735409049483101
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 0.000735409045303893
1333, epoch_train_loss=0.000735409045303893
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 0.0007354090411318191
1334, epoch_train_loss=0.0007354090411318191
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 0.0007354090369668618
1335, epoch_train_loss=0.0007354090369668618
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 0.0007354090328090038
1336, epoch_train_loss=0.0007354090328090038
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 0.0007354090286582279
1337, epoch_train_loss=0.0007354090286582279
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 0.0007354090245145175
1338, epoch_train_loss=0.0007354090245145175
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 0.0007354090203778552
1339, epoch_train_loss=0.0007354090203778552
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 0.0007354090162482241
1340, epoch_train_loss=0.0007354090162482241
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 0.0007354090121256074
1341, epoch_train_loss=0.0007354090121256074
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 0.0007354090080099882
1342, epoch_train_loss=0.0007354090080099882
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 0.0007354090039013494
1343, epoch_train_loss=0.0007354090039013494
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 0.0007354089997996748
1344, epoch_train_loss=0.0007354089997996748
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 0.0007354089957049475
1345, epoch_train_loss=0.0007354089957049475
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 0.0007354089916171506
1346, epoch_train_loss=0.0007354089916171506
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 0.0007354089875362678
1347, epoch_train_loss=0.0007354089875362678
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 0.0007354089834622829
1348, epoch_train_loss=0.0007354089834622829
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 0.0007354089793951782
1349, epoch_train_loss=0.0007354089793951782
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 0.0007354089753349387
1350, epoch_train_loss=0.0007354089753349387
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 0.0007354089712815471
1351, epoch_train_loss=0.0007354089712815471
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 0.0007354089672349874
1352, epoch_train_loss=0.0007354089672349874
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 0.0007354089631952431
1353, epoch_train_loss=0.0007354089631952431
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 0.0007354089591622984
1354, epoch_train_loss=0.0007354089591622984
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 0.0007354089551361369
1355, epoch_train_loss=0.0007354089551361369
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 0.0007354089511167422
1356, epoch_train_loss=0.0007354089511167422
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 0.0007354089471040988
1357, epoch_train_loss=0.0007354089471040988
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 0.0007354089430981899
1358, epoch_train_loss=0.0007354089430981899
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 0.0007354089390990001
1359, epoch_train_loss=0.0007354089390990001
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 0.0007354089351065132
1360, epoch_train_loss=0.0007354089351065132
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 0.0007354089311207134
1361, epoch_train_loss=0.0007354089311207134
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 0.0007354089271415852
1362, epoch_train_loss=0.0007354089271415852
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 0.0007354089231691122
1363, epoch_train_loss=0.0007354089231691122
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 0.0007354089192032791
1364, epoch_train_loss=0.0007354089192032791
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 0.0007354089152440699
1365, epoch_train_loss=0.0007354089152440699
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 0.0007354089112914696
1366, epoch_train_loss=0.0007354089112914696
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 0.0007354089073454617
1367, epoch_train_loss=0.0007354089073454617
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 0.0007354089034060309
1368, epoch_train_loss=0.0007354089034060309
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 0.0007354088994731622
1369, epoch_train_loss=0.0007354088994731622
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 0.0007354088955468399
1370, epoch_train_loss=0.0007354088955468399
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 0.0007354088916270482
1371, epoch_train_loss=0.0007354088916270482
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 0.0007354088877137725
1372, epoch_train_loss=0.0007354088877137725
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 0.0007354088838069971
1373, epoch_train_loss=0.0007354088838069971
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 0.0007354088799067063
1374, epoch_train_loss=0.0007354088799067063
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 0.0007354088760128857
1375, epoch_train_loss=0.0007354088760128857
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 0.0007354088721255194
1376, epoch_train_loss=0.0007354088721255194
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 0.0007354088682445928
1377, epoch_train_loss=0.0007354088682445928
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 0.0007354088643700903
1378, epoch_train_loss=0.0007354088643700903
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 0.0007354088605019974
1379, epoch_train_loss=0.0007354088605019974
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 0.0007354088566402991
1380, epoch_train_loss=0.0007354088566402991
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 0.0007354088527849799
1381, epoch_train_loss=0.0007354088527849799
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 0.0007354088489360255
1382, epoch_train_loss=0.0007354088489360255
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 0.0007354088450934207
1383, epoch_train_loss=0.0007354088450934207
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 0.000735408841257151
1384, epoch_train_loss=0.000735408841257151
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 0.0007354088374272012
1385, epoch_train_loss=0.0007354088374272012
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 0.000735408833603557
1386, epoch_train_loss=0.000735408833603557
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 0.0007354088297862036
1387, epoch_train_loss=0.0007354088297862036
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 0.0007354088259751263
1388, epoch_train_loss=0.0007354088259751263
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 0.0007354088221703104
1389, epoch_train_loss=0.0007354088221703104
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 0.0007354088183717417
1390, epoch_train_loss=0.0007354088183717417
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 0.0007354088145794056
1391, epoch_train_loss=0.0007354088145794056
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 0.0007354088107932874
1392, epoch_train_loss=0.0007354088107932874
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 0.0007354088070133728
1393, epoch_train_loss=0.0007354088070133728
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 0.0007354088032396474
1394, epoch_train_loss=0.0007354088032396474
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 0.000735408799472097
1395, epoch_train_loss=0.000735408799472097
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 0.0007354087957107076
1396, epoch_train_loss=0.0007354087957107076
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 0.0007354087919554645
1397, epoch_train_loss=0.0007354087919554645
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 0.0007354087882063535
1398, epoch_train_loss=0.0007354087882063535
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 0.0007354087844633608
1399, epoch_train_loss=0.0007354087844633608
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 0.0007354087807264722
1400, epoch_train_loss=0.0007354087807264722
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 0.0007354087769956733
1401, epoch_train_loss=0.0007354087769956733
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 0.0007354087732709503
1402, epoch_train_loss=0.0007354087732709503
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 0.0007354087695522896
1403, epoch_train_loss=0.0007354087695522896
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 0.0007354087658396765
1404, epoch_train_loss=0.0007354087658396765
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 0.0007354087621330978
1405, epoch_train_loss=0.0007354087621330978
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 0.0007354087584325391
1406, epoch_train_loss=0.0007354087584325391
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 0.0007354087547379871
1407, epoch_train_loss=0.0007354087547379871
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 0.0007354087510494275
1408, epoch_train_loss=0.0007354087510494275
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 0.0007354087473668469
1409, epoch_train_loss=0.0007354087473668469
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 0.0007354087436902319
1410, epoch_train_loss=0.0007354087436902319
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 0.0007354087400195682
1411, epoch_train_loss=0.0007354087400195682
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 0.0007354087363548422
1412, epoch_train_loss=0.0007354087363548422
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 0.0007354087326960408
1413, epoch_train_loss=0.0007354087326960408
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 0.0007354087290431501
1414, epoch_train_loss=0.0007354087290431501
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 0.0007354087253961568
1415, epoch_train_loss=0.0007354087253961568
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 0.0007354087217550474
1416, epoch_train_loss=0.0007354087217550474
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 0.0007354087181198087
1417, epoch_train_loss=0.0007354087181198087
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 0.0007354087144904271
1418, epoch_train_loss=0.0007354087144904271
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 0.0007354087108668893
1419, epoch_train_loss=0.0007354087108668893
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 0.0007354087072491819
1420, epoch_train_loss=0.0007354087072491819
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 0.0007354087036372919
1421, epoch_train_loss=0.0007354087036372919
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 0.000735408700031206
1422, epoch_train_loss=0.000735408700031206
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 0.000735408696430911
1423, epoch_train_loss=0.000735408696430911
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 0.0007354086928363937
1424, epoch_train_loss=0.0007354086928363937
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 0.000735408689247641
1425, epoch_train_loss=0.000735408689247641
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 0.0007354086856646399
1426, epoch_train_loss=0.0007354086856646399
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 0.0007354086820873771
1427, epoch_train_loss=0.0007354086820873771
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 0.0007354086785158401
1428, epoch_train_loss=0.0007354086785158401
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 0.0007354086749500156
1429, epoch_train_loss=0.0007354086749500156
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 0.0007354086713898911
1430, epoch_train_loss=0.0007354086713898911
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 0.0007354086678354533
1431, epoch_train_loss=0.0007354086678354533
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 0.0007354086642866896
1432, epoch_train_loss=0.0007354086642866896
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 0.000735408660743587
1433, epoch_train_loss=0.000735408660743587
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 0.0007354086572061329
1434, epoch_train_loss=0.0007354086572061329
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 0.0007354086536743149
1435, epoch_train_loss=0.0007354086536743149
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 0.0007354086501481199
1436, epoch_train_loss=0.0007354086501481199
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 0.000735408646627535
1437, epoch_train_loss=0.000735408646627535
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 0.0007354086431125482
1438, epoch_train_loss=0.0007354086431125482
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 0.0007354086396031466
1439, epoch_train_loss=0.0007354086396031466
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 0.0007354086360993175
1440, epoch_train_loss=0.0007354086360993175
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 0.0007354086326010488
1441, epoch_train_loss=0.0007354086326010488
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 0.000735408629108328
1442, epoch_train_loss=0.000735408629108328
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 0.0007354086256211422
1443, epoch_train_loss=0.0007354086256211422
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 0.0007354086221394796
1444, epoch_train_loss=0.0007354086221394796
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 0.0007354086186633277
1445, epoch_train_loss=0.0007354086186633277
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 0.0007354086151926741
1446, epoch_train_loss=0.0007354086151926741
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 0.0007354086117275065
1447, epoch_train_loss=0.0007354086117275065
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 0.0007354086082678129
1448, epoch_train_loss=0.0007354086082678129
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0007354086048135804
1449, epoch_train_loss=0.0007354086048135804
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.0007354086013647976
1450, epoch_train_loss=0.0007354086013647976
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.0007354085979214519
1451, epoch_train_loss=0.0007354085979214519
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0007354085944835312
1452, epoch_train_loss=0.0007354085944835312
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0007354085910510237
1453, epoch_train_loss=0.0007354085910510237
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.0007354085876239173
1454, epoch_train_loss=0.0007354085876239173
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.0007354085842021999
1455, epoch_train_loss=0.0007354085842021999
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.0007354085807858596
1456, epoch_train_loss=0.0007354085807858596
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.0007354085773748842
1457, epoch_train_loss=0.0007354085773748842
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.0007354085739692621
1458, epoch_train_loss=0.0007354085739692621
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.0007354085705689815
1459, epoch_train_loss=0.0007354085705689815
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.0007354085671740307
1460, epoch_train_loss=0.0007354085671740307
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.0007354085637843975
1461, epoch_train_loss=0.0007354085637843975
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.0007354085604000702
1462, epoch_train_loss=0.0007354085604000702
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.0007354085570210373
1463, epoch_train_loss=0.0007354085570210373
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.000735408553647287
1464, epoch_train_loss=0.000735408553647287
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0007354085502788077
1465, epoch_train_loss=0.0007354085502788077
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.0007354085469155876
1466, epoch_train_loss=0.0007354085469155876
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.0007354085435576153
1467, epoch_train_loss=0.0007354085435576153
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.0007354085402048789
1468, epoch_train_loss=0.0007354085402048789
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0007354085368573673
1469, epoch_train_loss=0.0007354085368573673
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.0007354085335150687
1470, epoch_train_loss=0.0007354085335150687
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0007354085301779721
1471, epoch_train_loss=0.0007354085301779721
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.0007354085268460653
1472, epoch_train_loss=0.0007354085268460653
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.0007354085235193375
1473, epoch_train_loss=0.0007354085235193375
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0007354085201977773
1474, epoch_train_loss=0.0007354085201977773
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007354085168813735
1475, epoch_train_loss=0.0007354085168813735
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.0007354085135701141
1476, epoch_train_loss=0.0007354085135701141
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.0007354085102639885
1477, epoch_train_loss=0.0007354085102639885
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.0007354085069629853
1478, epoch_train_loss=0.0007354085069629853
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.0007354085036670932
1479, epoch_train_loss=0.0007354085036670932
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0007354085003763009
1480, epoch_train_loss=0.0007354085003763009
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.000735408497090598
1481, epoch_train_loss=0.000735408497090598
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.0007354084938099724
1482, epoch_train_loss=0.0007354084938099724
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0007354084905344133
1483, epoch_train_loss=0.0007354084905344133
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0007354084872639103
1484, epoch_train_loss=0.0007354084872639103
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0007354084839984515
1485, epoch_train_loss=0.0007354084839984515
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0007354084807380265
1486, epoch_train_loss=0.0007354084807380265
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.0007354084774826241
1487, epoch_train_loss=0.0007354084774826241
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.0007354084742322338
1488, epoch_train_loss=0.0007354084742322338
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.000735408470986844
1489, epoch_train_loss=0.000735408470986844
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.0007354084677464444
1490, epoch_train_loss=0.0007354084677464444
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.0007354084645110238
1491, epoch_train_loss=0.0007354084645110238
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.000735408461280572
1492, epoch_train_loss=0.000735408461280572
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0007354084580550776
1493, epoch_train_loss=0.0007354084580550776
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0007354084548345299
1494, epoch_train_loss=0.0007354084548345299
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0007354084516189185
1495, epoch_train_loss=0.0007354084516189185
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.0007354084484082326
1496, epoch_train_loss=0.0007354084484082326
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0007354084452024617
1497, epoch_train_loss=0.0007354084452024617
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0007354084420015949
1498, epoch_train_loss=0.0007354084420015949
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0007354084388056216
1499, epoch_train_loss=0.0007354084388056216
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.0007354084356145319
1500, epoch_train_loss=0.0007354084356145319
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.0007354084324283142
1501, epoch_train_loss=0.0007354084324283142
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.0007354084292469592
1502, epoch_train_loss=0.0007354084292469592
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.0007354084260704555
1503, epoch_train_loss=0.0007354084260704555
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.000735408422898793
1504, epoch_train_loss=0.000735408422898793
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0007354084197319611
1505, epoch_train_loss=0.0007354084197319611
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0007354084165699498
1506, epoch_train_loss=0.0007354084165699498
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.0007354084134127485
1507, epoch_train_loss=0.0007354084134127485
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.0007354084102603469
1508, epoch_train_loss=0.0007354084102603469
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.0007354084071127347
1509, epoch_train_loss=0.0007354084071127347
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.0007354084039699016
1510, epoch_train_loss=0.0007354084039699016
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.0007354084008318376
1511, epoch_train_loss=0.0007354084008318376
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.000735408397698532
1512, epoch_train_loss=0.000735408397698532
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.0007354083945699752
1513, epoch_train_loss=0.0007354083945699752
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.0007354083914461566
1514, epoch_train_loss=0.0007354083914461566
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0007354083883270666
1515, epoch_train_loss=0.0007354083883270666
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.0007354083852126944
1516, epoch_train_loss=0.0007354083852126944
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.0007354083821030305
1517, epoch_train_loss=0.0007354083821030305
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 0.0007354083789980644
1518, epoch_train_loss=0.0007354083789980644
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 0.0007354083758977865
1519, epoch_train_loss=0.0007354083758977865
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0007354083728021866
1520, epoch_train_loss=0.0007354083728021866
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.0007354083697112549
1521, epoch_train_loss=0.0007354083697112549
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.000735408366624981
1522, epoch_train_loss=0.000735408366624981
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 0.0007354083635433557
1523, epoch_train_loss=0.0007354083635433557
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 0.0007354083604663686
1524, epoch_train_loss=0.0007354083604663686
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.0007354083573940102
1525, epoch_train_loss=0.0007354083573940102
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.0007354083543262706
1526, epoch_train_loss=0.0007354083543262706
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.0007354083512631398
1527, epoch_train_loss=0.0007354083512631398
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 0.0007354083482046081
1528, epoch_train_loss=0.0007354083482046081
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 0.0007354083451506656
1529, epoch_train_loss=0.0007354083451506656
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 0.0007354083421013031
1530, epoch_train_loss=0.0007354083421013031
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 0.0007354083390565106
1531, epoch_train_loss=0.0007354083390565106
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 0.0007354083360162784
1532, epoch_train_loss=0.0007354083360162784
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 0.000735408332980597
1533, epoch_train_loss=0.000735408332980597
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 0.0007354083299494565
1534, epoch_train_loss=0.0007354083299494565
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 0.0007354083269228478
1535, epoch_train_loss=0.0007354083269228478
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 0.0007354083239007613
1536, epoch_train_loss=0.0007354083239007613
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.000735408320883187
1537, epoch_train_loss=0.000735408320883187
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.0007354083178701159
1538, epoch_train_loss=0.0007354083178701159
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0007354083148615379
1539, epoch_train_loss=0.0007354083148615379
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.0007354083118574442
1540, epoch_train_loss=0.0007354083118574442
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.000735408308857825
1541, epoch_train_loss=0.000735408308857825
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.000735408305862671
1542, epoch_train_loss=0.000735408305862671
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.0007354083028719728
1543, epoch_train_loss=0.0007354083028719728
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0007354082998857213
1544, epoch_train_loss=0.0007354082998857213
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.0007354082969039068
1545, epoch_train_loss=0.0007354082969039068
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.0007354082939265203
1546, epoch_train_loss=0.0007354082939265203
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.0007354082909535525
1547, epoch_train_loss=0.0007354082909535525
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.0007354082879849939
1548, epoch_train_loss=0.0007354082879849939
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.0007354082850208355
1549, epoch_train_loss=0.0007354082850208355
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.0007354082820610681
1550, epoch_train_loss=0.0007354082820610681
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.0007354082791056825
1551, epoch_train_loss=0.0007354082791056825
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.0007354082761546693
1552, epoch_train_loss=0.0007354082761546693
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.0007354082732080196
1553, epoch_train_loss=0.0007354082732080196
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0007354082702657246
1554, epoch_train_loss=0.0007354082702657246
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.0007354082673277749
1555, epoch_train_loss=0.0007354082673277749
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.0007354082643941612
1556, epoch_train_loss=0.0007354082643941612
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0007354082614648751
1557, epoch_train_loss=0.0007354082614648751
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.0007354082585399073
1558, epoch_train_loss=0.0007354082585399073
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.0007354082556192486
1559, epoch_train_loss=0.0007354082556192486
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.0007354082527028902
1560, epoch_train_loss=0.0007354082527028902
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0007354082497908232
1561, epoch_train_loss=0.0007354082497908232
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.0007354082468830388
1562, epoch_train_loss=0.0007354082468830388
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.0007354082439795282
1563, epoch_train_loss=0.0007354082439795282
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.0007354082410802824
1564, epoch_train_loss=0.0007354082410802824
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.0007354082381852923
1565, epoch_train_loss=0.0007354082381852923
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0007354082352945497
1566, epoch_train_loss=0.0007354082352945497
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.0007354082324080452
1567, epoch_train_loss=0.0007354082324080452
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0007354082295257707
1568, epoch_train_loss=0.0007354082295257707
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.0007354082266477169
1569, epoch_train_loss=0.0007354082266477169
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0007354082237738748
1570, epoch_train_loss=0.0007354082237738748
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.0007354082209042364
1571, epoch_train_loss=0.0007354082209042364
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.0007354082180387931
1572, epoch_train_loss=0.0007354082180387931
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.0007354082151775358
1573, epoch_train_loss=0.0007354082151775358
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.0007354082123204561
1574, epoch_train_loss=0.0007354082123204561
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0007354082094675453
1575, epoch_train_loss=0.0007354082094675453
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0007354082066187949
1576, epoch_train_loss=0.0007354082066187949
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0007354082037741962
1577, epoch_train_loss=0.0007354082037741962
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.0007354082009337409
1578, epoch_train_loss=0.0007354082009337409
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.0007354081980974205
1579, epoch_train_loss=0.0007354081980974205
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.0007354081952652263
1580, epoch_train_loss=0.0007354081952652263
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.00073540819243715
1581, epoch_train_loss=0.00073540819243715
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.0007354081896131832
1582, epoch_train_loss=0.0007354081896131832
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0007354081867933175
1583, epoch_train_loss=0.0007354081867933175
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.0007354081839775441
1584, epoch_train_loss=0.0007354081839775441
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.000735408181165855
1585, epoch_train_loss=0.000735408181165855
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.000735408178358242
1586, epoch_train_loss=0.000735408178358242
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.0007354081755546963
1587, epoch_train_loss=0.0007354081755546963
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.00073540817275521
1588, epoch_train_loss=0.00073540817275521
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0007354081699597748
1589, epoch_train_loss=0.0007354081699597748
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.0007354081671683823
1590, epoch_train_loss=0.0007354081671683823
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.0007354081643810242
1591, epoch_train_loss=0.0007354081643810242
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.0007354081615976922
1592, epoch_train_loss=0.0007354081615976922
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.0007354081588183785
1593, epoch_train_loss=0.0007354081588183785
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.0007354081560430748
1594, epoch_train_loss=0.0007354081560430748
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.0007354081532717729
1595, epoch_train_loss=0.0007354081532717729
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.0007354081505044645
1596, epoch_train_loss=0.0007354081505044645
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.0007354081477411414
1597, epoch_train_loss=0.0007354081477411414
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.0007354081449817961
1598, epoch_train_loss=0.0007354081449817961
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.0007354081422264199
1599, epoch_train_loss=0.0007354081422264199
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.000735408139475005
1600, epoch_train_loss=0.000735408139475005
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.0007354081367275436
1601, epoch_train_loss=0.0007354081367275436
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.0007354081339840272
1602, epoch_train_loss=0.0007354081339840272
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.0007354081312444484
1603, epoch_train_loss=0.0007354081312444484
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.0007354081285087989
1604, epoch_train_loss=0.0007354081285087989
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 0.0007354081257770708
1605, epoch_train_loss=0.0007354081257770708
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.0007354081230492562
1606, epoch_train_loss=0.0007354081230492562
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.0007354081203253473
1607, epoch_train_loss=0.0007354081203253473
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.0007354081176053361
1608, epoch_train_loss=0.0007354081176053361
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 0.0007354081148892145
1609, epoch_train_loss=0.0007354081148892145
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.0007354081121769752
1610, epoch_train_loss=0.0007354081121769752
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.0007354081094686101
1611, epoch_train_loss=0.0007354081094686101
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.0007354081067641112
1612, epoch_train_loss=0.0007354081067641112
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0007354081040634712
1613, epoch_train_loss=0.0007354081040634712
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 0.0007354081013666817
1614, epoch_train_loss=0.0007354081013666817
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 0.0007354080986737356
1615, epoch_train_loss=0.0007354080986737356
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.000735408095984625
1616, epoch_train_loss=0.000735408095984625
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.0007354080932993422
1617, epoch_train_loss=0.0007354080932993422
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 0.0007354080906178795
1618, epoch_train_loss=0.0007354080906178795
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 0.0007354080879402293
1619, epoch_train_loss=0.0007354080879402293
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 0.0007354080852663837
1620, epoch_train_loss=0.0007354080852663837
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 0.0007354080825963355
1621, epoch_train_loss=0.0007354080825963355
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 0.0007354080799300764
1622, epoch_train_loss=0.0007354080799300764
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 0.0007354080772675999
1623, epoch_train_loss=0.0007354080772675999
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 0.0007354080746088974
1624, epoch_train_loss=0.0007354080746088974
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 0.0007354080719539621
1625, epoch_train_loss=0.0007354080719539621
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 0.0007354080693027861
1626, epoch_train_loss=0.0007354080693027861
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 0.0007354080666553621
1627, epoch_train_loss=0.0007354080666553621
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 0.0007354080640116826
1628, epoch_train_loss=0.0007354080640116826
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 0.0007354080613717398
1629, epoch_train_loss=0.0007354080613717398
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 0.0007354080587355264
1630, epoch_train_loss=0.0007354080587355264
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 0.0007354080561030356
1631, epoch_train_loss=0.0007354080561030356
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 0.0007354080534742594
1632, epoch_train_loss=0.0007354080534742594
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 0.0007354080508491903
1633, epoch_train_loss=0.0007354080508491903
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 0.0007354080482278214
1634, epoch_train_loss=0.0007354080482278214
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 0.000735408045610145
1635, epoch_train_loss=0.000735408045610145
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 0.000735408042996154
1636, epoch_train_loss=0.000735408042996154
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 0.0007354080403858408
1637, epoch_train_loss=0.0007354080403858408
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 0.0007354080377791987
1638, epoch_train_loss=0.0007354080377791987
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 0.0007354080351762197
1639, epoch_train_loss=0.0007354080351762197
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 0.000735408032576897
1640, epoch_train_loss=0.000735408032576897
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 0.0007354080299812235
1641, epoch_train_loss=0.0007354080299812235
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 0.0007354080273891917
1642, epoch_train_loss=0.0007354080273891917
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 0.0007354080248007943
1643, epoch_train_loss=0.0007354080248007943
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 0.0007354080222160242
1644, epoch_train_loss=0.0007354080222160242
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 0.0007354080196348747
1645, epoch_train_loss=0.0007354080196348747
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 0.0007354080170573383
1646, epoch_train_loss=0.0007354080170573383
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 0.0007354080144834076
1647, epoch_train_loss=0.0007354080144834076
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 0.0007354080119130757
1648, epoch_train_loss=0.0007354080119130757
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 0.0007354080093463359
1649, epoch_train_loss=0.0007354080093463359
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 0.0007354080067831807
1650, epoch_train_loss=0.0007354080067831807
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 0.000735408004223603
1651, epoch_train_loss=0.000735408004223603
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 0.0007354080016675963
1652, epoch_train_loss=0.0007354080016675963
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 0.0007354079991151531
1653, epoch_train_loss=0.0007354079991151531
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 0.0007354079965662665
1654, epoch_train_loss=0.0007354079965662665
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 0.0007354079940209297
1655, epoch_train_loss=0.0007354079940209297
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 0.0007354079914791355
1656, epoch_train_loss=0.0007354079914791355
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 0.0007354079889408772
1657, epoch_train_loss=0.0007354079889408772
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 0.0007354079864061478
1658, epoch_train_loss=0.0007354079864061478
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 0.0007354079838749403
1659, epoch_train_loss=0.0007354079838749403
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 0.0007354079813472476
1660, epoch_train_loss=0.0007354079813472476
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 0.0007354079788230635
1661, epoch_train_loss=0.0007354079788230635
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 0.0007354079763023804
1662, epoch_train_loss=0.0007354079763023804
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 0.0007354079737851922
1663, epoch_train_loss=0.0007354079737851922
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 0.0007354079712714915
1664, epoch_train_loss=0.0007354079712714915
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 0.0007354079687612714
1665, epoch_train_loss=0.0007354079687612714
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 0.0007354079662545257
1666, epoch_train_loss=0.0007354079662545257
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 0.0007354079637512473
1667, epoch_train_loss=0.0007354079637512473
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 0.0007354079612514295
1668, epoch_train_loss=0.0007354079612514295
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 0.0007354079587550656
1669, epoch_train_loss=0.0007354079587550656
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 0.0007354079562621487
1670, epoch_train_loss=0.0007354079562621487
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 0.0007354079537726724
1671, epoch_train_loss=0.0007354079537726724
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 0.0007354079512866296
1672, epoch_train_loss=0.0007354079512866296
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 0.0007354079488040143
1673, epoch_train_loss=0.0007354079488040143
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 0.0007354079463248193
1674, epoch_train_loss=0.0007354079463248193
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 0.0007354079438490381
1675, epoch_train_loss=0.0007354079438490381
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.0007354079413766641
1676, epoch_train_loss=0.0007354079413766641
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.0007354079389076906
1677, epoch_train_loss=0.0007354079389076906
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.0007354079364421112
1678, epoch_train_loss=0.0007354079364421112
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.0007354079339799194
1679, epoch_train_loss=0.0007354079339799194
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0007354079315211084
1680, epoch_train_loss=0.0007354079315211084
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.0007354079290656718
1681, epoch_train_loss=0.0007354079290656718
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.0007354079266136032
1682, epoch_train_loss=0.0007354079266136032
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.000735407924164896
1683, epoch_train_loss=0.000735407924164896
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.0007354079217195432
1684, epoch_train_loss=0.0007354079217195432
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.0007354079192775393
1685, epoch_train_loss=0.0007354079192775393
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0007354079168388772
1686, epoch_train_loss=0.0007354079168388772
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.0007354079144035508
1687, epoch_train_loss=0.0007354079144035508
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.0007354079119715534
1688, epoch_train_loss=0.0007354079119715534
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.0007354079095428787
1689, epoch_train_loss=0.0007354079095428787
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.0007354079071175204
1690, epoch_train_loss=0.0007354079071175204
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.000735407904695472
1691, epoch_train_loss=0.000735407904695472
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.0007354079022767272
1692, epoch_train_loss=0.0007354079022767272
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0007354078998612799
1693, epoch_train_loss=0.0007354078998612799
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.0007354078974491234
1694, epoch_train_loss=0.0007354078974491234
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.0007354078950402514
1695, epoch_train_loss=0.0007354078950402514
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.0007354078926346578
1696, epoch_train_loss=0.0007354078926346578
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.0007354078902323365
1697, epoch_train_loss=0.0007354078902323365
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0007354078878332811
1698, epoch_train_loss=0.0007354078878332811
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.0007354078854374849
1699, epoch_train_loss=0.0007354078854374849
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.0007354078830449424
1700, epoch_train_loss=0.0007354078830449424
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.0007354078806556467
1701, epoch_train_loss=0.0007354078806556467
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.000735407878269592
1702, epoch_train_loss=0.000735407878269592
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.0007354078758867724
1703, epoch_train_loss=0.0007354078758867724
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.000735407873507181
1704, epoch_train_loss=0.000735407873507181
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0007354078711308121
1705, epoch_train_loss=0.0007354078711308121
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.0007354078687576595
1706, epoch_train_loss=0.0007354078687576595
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.0007354078663877172
1707, epoch_train_loss=0.0007354078663877172
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.000735407864020979
1708, epoch_train_loss=0.000735407864020979
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.0007354078616574387
1709, epoch_train_loss=0.0007354078616574387
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.0007354078592970904
1710, epoch_train_loss=0.0007354078592970904
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.0007354078569399279
1711, epoch_train_loss=0.0007354078569399279
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.000735407854585945
1712, epoch_train_loss=0.000735407854585945
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0007354078522351361
1713, epoch_train_loss=0.0007354078522351361
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.0007354078498874949
1714, epoch_train_loss=0.0007354078498874949
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.0007354078475430154
1715, epoch_train_loss=0.0007354078475430154
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.0007354078452016916
1716, epoch_train_loss=0.0007354078452016916
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.0007354078428635176
1717, epoch_train_loss=0.0007354078428635176
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.0007354078405284875
1718, epoch_train_loss=0.0007354078405284875
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.0007354078381965955
1719, epoch_train_loss=0.0007354078381965955
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.0007354078358678351
1720, epoch_train_loss=0.0007354078358678351
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.000735407833542201
1721, epoch_train_loss=0.000735407833542201
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0007354078312196868
1722, epoch_train_loss=0.0007354078312196868
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.0007354078289002872
1723, epoch_train_loss=0.0007354078289002872
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.0007354078265839956
1724, epoch_train_loss=0.0007354078265839956
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.0007354078242708068
1725, epoch_train_loss=0.0007354078242708068
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0007354078219607146
1726, epoch_train_loss=0.0007354078219607146
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.0007354078196537133
1727, epoch_train_loss=0.0007354078196537133
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.0007354078173497971
1728, epoch_train_loss=0.0007354078173497971
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0007354078150489602
1729, epoch_train_loss=0.0007354078150489602
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0007354078127511965
1730, epoch_train_loss=0.0007354078127511965
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.0007354078104565008
1731, epoch_train_loss=0.0007354078104565008
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.0007354078081648668
1732, epoch_train_loss=0.0007354078081648668
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.0007354078058762892
1733, epoch_train_loss=0.0007354078058762892
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.000735407803590762
1734, epoch_train_loss=0.000735407803590762
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.0007354078013082796
1735, epoch_train_loss=0.0007354078013082796
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.000735407799028836
1736, epoch_train_loss=0.000735407799028836
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.0007354077967524259
1737, epoch_train_loss=0.0007354077967524259
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.0007354077944790435
1738, epoch_train_loss=0.0007354077944790435
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.0007354077922086833
1739, epoch_train_loss=0.0007354077922086833
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.0007354077899413393
1740, epoch_train_loss=0.0007354077899413393
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 0.000735407787677006
1741, epoch_train_loss=0.000735407787677006
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.000735407785415678
1742, epoch_train_loss=0.000735407785415678
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.0007354077831573495
1743, epoch_train_loss=0.0007354077831573495
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.0007354077809020149
1744, epoch_train_loss=0.0007354077809020149
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0007354077786496686
1745, epoch_train_loss=0.0007354077786496686
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 0.0007354077764003053
1746, epoch_train_loss=0.0007354077764003053
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 0.0007354077741539188
1747, epoch_train_loss=0.0007354077741539188
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0007354077719105046
1748, epoch_train_loss=0.0007354077719105046
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.0007354077696700561
1749, epoch_train_loss=0.0007354077696700561
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.0007354077674325684
1750, epoch_train_loss=0.0007354077674325684
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 0.000735407765198036
1751, epoch_train_loss=0.000735407765198036
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 0.0007354077629664534
1752, epoch_train_loss=0.0007354077629664534
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.0007354077607378147
1753, epoch_train_loss=0.0007354077607378147
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.0007354077585121151
1754, epoch_train_loss=0.0007354077585121151
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 0.0007354077562893486
1755, epoch_train_loss=0.0007354077562893486
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 0.0007354077540695097
1756, epoch_train_loss=0.0007354077540695097
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 0.0007354077518525938
1757, epoch_train_loss=0.0007354077518525938
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 0.0007354077496385946
1758, epoch_train_loss=0.0007354077496385946
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 0.0007354077474275071
1759, epoch_train_loss=0.0007354077474275071
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 0.000735407745219326
1760, epoch_train_loss=0.000735407745219326
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 0.0007354077430140461
1761, epoch_train_loss=0.0007354077430140461
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 0.0007354077408116616
1762, epoch_train_loss=0.0007354077408116616
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 0.0007354077386121672
1763, epoch_train_loss=0.0007354077386121672
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 0.0007354077364155578
1764, epoch_train_loss=0.0007354077364155578
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 0.000735407734221828
1765, epoch_train_loss=0.000735407734221828
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 0.0007354077320309725
1766, epoch_train_loss=0.0007354077320309725
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 0.0007354077298429858
1767, epoch_train_loss=0.0007354077298429858
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 0.0007354077276578631
1768, epoch_train_loss=0.0007354077276578631
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 0.0007354077254755986
1769, epoch_train_loss=0.0007354077254755986
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 0.0007354077232961875
1770, epoch_train_loss=0.0007354077232961875
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 0.0007354077211196243
1771, epoch_train_loss=0.0007354077211196243
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 0.0007354077189459037
1772, epoch_train_loss=0.0007354077189459037
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 0.0007354077167750206
1773, epoch_train_loss=0.0007354077167750206
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 0.0007354077146069698
1774, epoch_train_loss=0.0007354077146069698
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 0.0007354077124417463
1775, epoch_train_loss=0.0007354077124417463
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 0.0007354077102793448
1776, epoch_train_loss=0.0007354077102793448
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 0.0007354077081197599
1777, epoch_train_loss=0.0007354077081197599
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 0.0007354077059629867
1778, epoch_train_loss=0.0007354077059629867
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 0.0007354077038090201
1779, epoch_train_loss=0.0007354077038090201
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 0.0007354077016578546
1780, epoch_train_loss=0.0007354077016578546
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 0.0007354076995094857
1781, epoch_train_loss=0.0007354076995094857
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 0.0007354076973639077
1782, epoch_train_loss=0.0007354076973639077
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 0.0007354076952211157
1783, epoch_train_loss=0.0007354076952211157
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 0.0007354076930811049
1784, epoch_train_loss=0.0007354076930811049
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 0.0007354076909438696
1785, epoch_train_loss=0.0007354076909438696
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 0.0007354076888094053
1786, epoch_train_loss=0.0007354076888094053
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 0.000735407686677707
1787, epoch_train_loss=0.000735407686677707
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.0007354076845487692
1788, epoch_train_loss=0.0007354076845487692
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.0007354076824225874
1789, epoch_train_loss=0.0007354076824225874
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0007354076802991559
1790, epoch_train_loss=0.0007354076802991559
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0007354076781784705
1791, epoch_train_loss=0.0007354076781784705
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0007354076760605257
1792, epoch_train_loss=0.0007354076760605257
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.0007354076739453169
1793, epoch_train_loss=0.0007354076739453169
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.0007354076718328388
1794, epoch_train_loss=0.0007354076718328388
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.0007354076697230864
1795, epoch_train_loss=0.0007354076697230864
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.0007354076676160551
1796, epoch_train_loss=0.0007354076676160551
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.0007354076655117399
1797, epoch_train_loss=0.0007354076655117399
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.0007354076634101353
1798, epoch_train_loss=0.0007354076634101353
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.0007354076613112373
1799, epoch_train_loss=0.0007354076613112373
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.0007354076592150406
1800, epoch_train_loss=0.0007354076592150406
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.0007354076571215402
1801, epoch_train_loss=0.0007354076571215402
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.0007354076550307314
1802, epoch_train_loss=0.0007354076550307314
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.0007354076529426091
1803, epoch_train_loss=0.0007354076529426091
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.0007354076508571687
1804, epoch_train_loss=0.0007354076508571687
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.0007354076487744055
1805, epoch_train_loss=0.0007354076487744055
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.0007354076466943144
1806, epoch_train_loss=0.0007354076466943144
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.0007354076446168908
1807, epoch_train_loss=0.0007354076446168908
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0007354076425421297
1808, epoch_train_loss=0.0007354076425421297
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.0007354076404700263
1809, epoch_train_loss=0.0007354076404700263
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.000735407638400576
1810, epoch_train_loss=0.000735407638400576
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.0007354076363337736
1811, epoch_train_loss=0.0007354076363337736
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.0007354076342696149
1812, epoch_train_loss=0.0007354076342696149
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.0007354076322080949
1813, epoch_train_loss=0.0007354076322080949
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.000735407630149209
1814, epoch_train_loss=0.000735407630149209
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.0007354076280929522
1815, epoch_train_loss=0.0007354076280929522
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.0007354076260393203
1816, epoch_train_loss=0.0007354076260393203
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.0007354076239883077
1817, epoch_train_loss=0.0007354076239883077
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0007354076219399105
1818, epoch_train_loss=0.0007354076219399105
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0007354076198941241
1819, epoch_train_loss=0.0007354076198941241
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0007354076178509432
1820, epoch_train_loss=0.0007354076178509432
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0007354076158103635
1821, epoch_train_loss=0.0007354076158103635
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0007354076137723805
1822, epoch_train_loss=0.0007354076137723805
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.0007354076117369892
1823, epoch_train_loss=0.0007354076117369892
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.0007354076097041851
1824, epoch_train_loss=0.0007354076097041851
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0007354076076739638
1825, epoch_train_loss=0.0007354076076739638
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.0007354076056463205
1826, epoch_train_loss=0.0007354076056463205
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.0007354076036212506
1827, epoch_train_loss=0.0007354076036212506
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.0007354076015987495
1828, epoch_train_loss=0.0007354076015987495
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007354075995788129
1829, epoch_train_loss=0.0007354075995788129
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.0007354075975614358
1830, epoch_train_loss=0.0007354075975614358
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0007354075955466141
1831, epoch_train_loss=0.0007354075955466141
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.0007354075935343428
1832, epoch_train_loss=0.0007354075935343428
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.0007354075915246177
1833, epoch_train_loss=0.0007354075915246177
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0007354075895174342
1834, epoch_train_loss=0.0007354075895174342
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.0007354075875127878
1835, epoch_train_loss=0.0007354075875127878
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.000735407585510674
1836, epoch_train_loss=0.000735407585510674
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.0007354075835110881
1837, epoch_train_loss=0.0007354075835110881
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.0007354075815140259
1838, epoch_train_loss=0.0007354075815140259
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0007354075795194826
1839, epoch_train_loss=0.0007354075795194826
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.0007354075775274543
1840, epoch_train_loss=0.0007354075775274543
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0007354075755379365
1841, epoch_train_loss=0.0007354075755379365
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.0007354075735509241
1842, epoch_train_loss=0.0007354075735509241
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.0007354075715664131
1843, epoch_train_loss=0.0007354075715664131
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.0007354075695843994
1844, epoch_train_loss=0.0007354075695843994
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.0007354075676048778
1845, epoch_train_loss=0.0007354075676048778
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.0007354075656278446
1846, epoch_train_loss=0.0007354075656278446
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 0.0007354075636532948
1847, epoch_train_loss=0.0007354075636532948
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.0007354075616812247
1848, epoch_train_loss=0.0007354075616812247
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.0007354075597116296
1849, epoch_train_loss=0.0007354075597116296
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.0007354075577445052
1850, epoch_train_loss=0.0007354075577445052
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.0007354075557798472
1851, epoch_train_loss=0.0007354075557798472
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 0.0007354075538176509
1852, epoch_train_loss=0.0007354075538176509
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.0007354075518579123
1853, epoch_train_loss=0.0007354075518579123
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.0007354075499006274
1854, epoch_train_loss=0.0007354075499006274
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.0007354075479457913
1855, epoch_train_loss=0.0007354075479457913
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.0007354075459933997
1856, epoch_train_loss=0.0007354075459933997
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 0.0007354075440434486
1857, epoch_train_loss=0.0007354075440434486
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 0.0007354075420959339
1858, epoch_train_loss=0.0007354075420959339
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.000735407540150851
1859, epoch_train_loss=0.000735407540150851
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.0007354075382081957
1860, epoch_train_loss=0.0007354075382081957
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.0007354075362679639
1861, epoch_train_loss=0.0007354075362679639
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 0.0007354075343301513
1862, epoch_train_loss=0.0007354075343301513
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 0.0007354075323947533
1863, epoch_train_loss=0.0007354075323947533
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 0.0007354075304617662
1864, epoch_train_loss=0.0007354075304617662
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 0.0007354075285311856
1865, epoch_train_loss=0.0007354075285311856
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 0.0007354075266030074
1866, epoch_train_loss=0.0007354075266030074
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 0.0007354075246772271
1867, epoch_train_loss=0.0007354075246772271
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 0.000735407522753841
1868, epoch_train_loss=0.000735407522753841
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 0.0007354075208328444
1869, epoch_train_loss=0.0007354075208328444
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 0.0007354075189142336
1870, epoch_train_loss=0.0007354075189142336
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 0.0007354075169980042
1871, epoch_train_loss=0.0007354075169980042
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 0.000735407515084152
1872, epoch_train_loss=0.000735407515084152
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 0.000735407513172673
1873, epoch_train_loss=0.000735407513172673
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 0.0007354075112635627
1874, epoch_train_loss=0.0007354075112635627
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 0.0007354075093568177
1875, epoch_train_loss=0.0007354075093568177
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 0.0007354075074524334
1876, epoch_train_loss=0.0007354075074524334
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 0.0007354075055504058
1877, epoch_train_loss=0.0007354075055504058
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 0.0007354075036507307
1878, epoch_train_loss=0.0007354075036507307
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 0.0007354075017534043
1879, epoch_train_loss=0.0007354075017534043
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 0.0007354074998584224
1880, epoch_train_loss=0.0007354074998584224
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 0.0007354074979657808
1881, epoch_train_loss=0.0007354074979657808
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 0.0007354074960754757
1882, epoch_train_loss=0.0007354074960754757
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 0.0007354074941875029
1883, epoch_train_loss=0.0007354074941875029
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 0.0007354074923018582
1884, epoch_train_loss=0.0007354074923018582
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 0.000735407490418538
1885, epoch_train_loss=0.000735407490418538
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 0.0007354074885375379
1886, epoch_train_loss=0.0007354074885375379
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 0.000735407486658854
1887, epoch_train_loss=0.000735407486658854
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 0.0007354074847824826
1888, epoch_train_loss=0.0007354074847824826
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 0.0007354074829084192
1889, epoch_train_loss=0.0007354074829084192
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 0.0007354074810366601
1890, epoch_train_loss=0.0007354074810366601
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 0.0007354074791672016
1891, epoch_train_loss=0.0007354074791672016
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 0.000735407477300039
1892, epoch_train_loss=0.000735407477300039
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 0.0007354074754351691
1893, epoch_train_loss=0.0007354074754351691
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 0.0007354074735725876
1894, epoch_train_loss=0.0007354074735725876
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 0.0007354074717122905
1895, epoch_train_loss=0.0007354074717122905
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 0.0007354074698542741
1896, epoch_train_loss=0.0007354074698542741
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 0.0007354074679985343
1897, epoch_train_loss=0.0007354074679985343
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 0.0007354074661450673
1898, epoch_train_loss=0.0007354074661450673
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 0.0007354074642938691
1899, epoch_train_loss=0.0007354074642938691
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 0.0007354074624449358
1900, epoch_train_loss=0.0007354074624449358
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 0.0007354074605982638
1901, epoch_train_loss=0.0007354074605982638
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 0.0007354074587538488
1902, epoch_train_loss=0.0007354074587538488
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 0.0007354074569116873
1903, epoch_train_loss=0.0007354074569116873
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 0.0007354074550717753
1904, epoch_train_loss=0.0007354074550717753
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 0.0007354074532341089
1905, epoch_train_loss=0.0007354074532341089
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 0.0007354074513986842
1906, epoch_train_loss=0.0007354074513986842
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 0.0007354074495654976
1907, epoch_train_loss=0.0007354074495654976
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 0.0007354074477345452
1908, epoch_train_loss=0.0007354074477345452
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 0.0007354074459058229
1909, epoch_train_loss=0.0007354074459058229
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.0007354074440793274
1910, epoch_train_loss=0.0007354074440793274
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.0007354074422550544
1911, epoch_train_loss=0.0007354074422550544
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.0007354074404330003
1912, epoch_train_loss=0.0007354074404330003
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.0007354074386131616
1913, epoch_train_loss=0.0007354074386131616
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0007354074367955342
1914, epoch_train_loss=0.0007354074367955342
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0007354074349801144
1915, epoch_train_loss=0.0007354074349801144
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.0007354074331668985
1916, epoch_train_loss=0.0007354074331668985
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.0007354074313558826
1917, epoch_train_loss=0.0007354074313558826
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.0007354074295470631
1918, epoch_train_loss=0.0007354074295470631
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.0007354074277404363
1919, epoch_train_loss=0.0007354074277404363
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.0007354074259359985
1920, epoch_train_loss=0.0007354074259359985
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.000735407424133746
1921, epoch_train_loss=0.000735407424133746
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.0007354074223336747
1922, epoch_train_loss=0.0007354074223336747
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.0007354074205357813
1923, epoch_train_loss=0.0007354074205357813
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.000735407418740062
1924, epoch_train_loss=0.000735407418740062
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.0007354074169465132
1925, epoch_train_loss=0.0007354074169465132
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.0007354074151551311
1926, epoch_train_loss=0.0007354074151551311
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.0007354074133659122
1927, epoch_train_loss=0.0007354074133659122
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.0007354074115788527
1928, epoch_train_loss=0.0007354074115788527
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.0007354074097939493
1929, epoch_train_loss=0.0007354074097939493
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.0007354074080111977
1930, epoch_train_loss=0.0007354074080111977
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.0007354074062305946
1931, epoch_train_loss=0.0007354074062305946
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.0007354074044521364
1932, epoch_train_loss=0.0007354074044521364
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.0007354074026758195
1933, epoch_train_loss=0.0007354074026758195
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.0007354074009016402
1934, epoch_train_loss=0.0007354074009016402
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.000735407399129595
1935, epoch_train_loss=0.000735407399129595
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0007354073973596804
1936, epoch_train_loss=0.0007354073973596804
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0007354073955918927
1937, epoch_train_loss=0.0007354073955918927
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0007354073938262282
1938, epoch_train_loss=0.0007354073938262282
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.0007354073920626833
1939, epoch_train_loss=0.0007354073920626833
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.0007354073903012548
1940, epoch_train_loss=0.0007354073903012548
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0007354073885419388
1941, epoch_train_loss=0.0007354073885419388
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.000735407386784732
1942, epoch_train_loss=0.000735407386784732
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0007354073850296306
1943, epoch_train_loss=0.0007354073850296306
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.0007354073832766312
1944, epoch_train_loss=0.0007354073832766312
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.0007354073815257303
1945, epoch_train_loss=0.0007354073815257303
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.0007354073797769243
1946, epoch_train_loss=0.0007354073797769243
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0007354073780302098
1947, epoch_train_loss=0.0007354073780302098
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0007354073762855833
1948, epoch_train_loss=0.0007354073762855833
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0007354073745430411
1949, epoch_train_loss=0.0007354073745430411
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.0007354073728025801
1950, epoch_train_loss=0.0007354073728025801
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007354073710641963
1951, epoch_train_loss=0.0007354073710641963
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.0007354073693278867
1952, epoch_train_loss=0.0007354073693278867
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0007354073675936477
1953, epoch_train_loss=0.0007354073675936477
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0007354073658614758
1954, epoch_train_loss=0.0007354073658614758
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.0007354073641313673
1955, epoch_train_loss=0.0007354073641313673
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007354073624033193
1956, epoch_train_loss=0.0007354073624033193
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007354073606773279
1957, epoch_train_loss=0.0007354073606773279
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.0007354073589533899
1958, epoch_train_loss=0.0007354073589533899
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.0007354073572315017
1959, epoch_train_loss=0.0007354073572315017
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.0007354073555116601
1960, epoch_train_loss=0.0007354073555116601
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0007354073537938619
1961, epoch_train_loss=0.0007354073537938619
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0007354073520781031
1962, epoch_train_loss=0.0007354073520781031
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.0007354073503643806
1963, epoch_train_loss=0.0007354073503643806
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.0007354073486526912
1964, epoch_train_loss=0.0007354073486526912
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.0007354073469430315
1965, epoch_train_loss=0.0007354073469430315
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.0007354073452353979
1966, epoch_train_loss=0.0007354073452353979
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0007354073435297872
1967, epoch_train_loss=0.0007354073435297872
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.0007354073418261958
1968, epoch_train_loss=0.0007354073418261958
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 0.0007354073401246206
1969, epoch_train_loss=0.0007354073401246206
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.0007354073384250581
1970, epoch_train_loss=0.0007354073384250581
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0007354073367275055
1971, epoch_train_loss=0.0007354073367275055
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.0007354073350319587
1972, epoch_train_loss=0.0007354073350319587
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.0007354073333384149
1973, epoch_train_loss=0.0007354073333384149
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 0.0007354073316468707
1974, epoch_train_loss=0.0007354073316468707
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.0007354073299573225
1975, epoch_train_loss=0.0007354073299573225
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.0007354073282697672
1976, epoch_train_loss=0.0007354073282697672
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0007354073265842016
1977, epoch_train_loss=0.0007354073265842016
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.0007354073249006225
1978, epoch_train_loss=0.0007354073249006225
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 0.0007354073232190264
1979, epoch_train_loss=0.0007354073232190264
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 0.0007354073215394103
1980, epoch_train_loss=0.0007354073215394103
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.0007354073198617706
1981, epoch_train_loss=0.0007354073198617706
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.0007354073181861043
1982, epoch_train_loss=0.0007354073181861043
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.0007354073165124077
1983, epoch_train_loss=0.0007354073165124077
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 0.0007354073148406785
1984, epoch_train_loss=0.0007354073148406785
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 0.0007354073131709126
1985, epoch_train_loss=0.0007354073131709126
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 0.0007354073115031072
1986, epoch_train_loss=0.0007354073115031072
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.0007354073098372586
1987, epoch_train_loss=0.0007354073098372586
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 0.0007354073081733642
1988, epoch_train_loss=0.0007354073081733642
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 0.0007354073065114206
1989, epoch_train_loss=0.0007354073065114206
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 0.0007354073048514244
1990, epoch_train_loss=0.0007354073048514244
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 0.0007354073031933725
1991, epoch_train_loss=0.0007354073031933725
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 0.0007354073015372617
1992, epoch_train_loss=0.0007354073015372617
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 0.0007354072998830889
1993, epoch_train_loss=0.0007354072998830889
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 0.0007354072982308509
1994, epoch_train_loss=0.0007354072982308509
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 0.0007354072965805445
1995, epoch_train_loss=0.0007354072965805445
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 0.0007354072949321668
1996, epoch_train_loss=0.0007354072949321668
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 0.0007354072932857143
1997, epoch_train_loss=0.0007354072932857143
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 0.0007354072916411838
1998, epoch_train_loss=0.0007354072916411838
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 0.0007354072899985727
1999, epoch_train_loss=0.0007354072899985727
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 0.0007354072883578773
2000, epoch_train_loss=0.0007354072883578773
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 0.0007354072867190947
2001, epoch_train_loss=0.0007354072867190947
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 0.0007354072850822216
2002, epoch_train_loss=0.0007354072850822216
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 0.0007354072834472555
2003, epoch_train_loss=0.0007354072834472555
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 0.0007354072818141925
2004, epoch_train_loss=0.0007354072818141925
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.00073540728018303
2005, epoch_train_loss=0.00073540728018303
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.0007354072785537647
2006, epoch_train_loss=0.0007354072785537647
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.0007354072769263937
2007, epoch_train_loss=0.0007354072769263937
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.0007354072753009137
2008, epoch_train_loss=0.0007354072753009137
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0007354072736773216
2009, epoch_train_loss=0.0007354072736773216
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007354072720556148
2010, epoch_train_loss=0.0007354072720556148
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0007354072704357896
2011, epoch_train_loss=0.0007354072704357896
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0007354072688178434
2012, epoch_train_loss=0.0007354072688178434
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.000735407267201773
2013, epoch_train_loss=0.000735407267201773
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.0007354072655875752
2014, epoch_train_loss=0.0007354072655875752
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.0007354072639752475
2015, epoch_train_loss=0.0007354072639752475
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.0007354072623647862
2016, epoch_train_loss=0.0007354072623647862
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.0007354072607561888
2017, epoch_train_loss=0.0007354072607561888
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.0007354072591494518
2018, epoch_train_loss=0.0007354072591494518
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.0007354072575445726
2019, epoch_train_loss=0.0007354072575445726
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.0007354072559415481
2020, epoch_train_loss=0.0007354072559415481
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.0007354072543403752
2021, epoch_train_loss=0.0007354072543403752
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0007354072527410512
2022, epoch_train_loss=0.0007354072527410512
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.0007354072511435725
2023, epoch_train_loss=0.0007354072511435725
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.0007354072495479369
2024, epoch_train_loss=0.0007354072495479369
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.0007354072479541408
2025, epoch_train_loss=0.0007354072479541408
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.0007354072463621815
2026, epoch_train_loss=0.0007354072463621815
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.0007354072447720562
2027, epoch_train_loss=0.0007354072447720562
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.0007354072431837617
2028, epoch_train_loss=0.0007354072431837617
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.0007354072415972951
2029, epoch_train_loss=0.0007354072415972951
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.0007354072400126535
2030, epoch_train_loss=0.0007354072400126535
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.0007354072384298339
2031, epoch_train_loss=0.0007354072384298339
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0007354072368488335
2032, epoch_train_loss=0.0007354072368488335
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0007354072352696493
2033, epoch_train_loss=0.0007354072352696493
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0007354072336922784
2034, epoch_train_loss=0.0007354072336922784
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.0007354072321167179
2035, epoch_train_loss=0.0007354072321167179
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0007354072305429648
2036, epoch_train_loss=0.0007354072305429648
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0007354072289710164
2037, epoch_train_loss=0.0007354072289710164
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.0007354072274008696
2038, epoch_train_loss=0.0007354072274008696
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.0007354072258325216
2039, epoch_train_loss=0.0007354072258325216
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0007354072242659695
2040, epoch_train_loss=0.0007354072242659695
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.0007354072227012104
2041, epoch_train_loss=0.0007354072227012104
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.0007354072211382418
2042, epoch_train_loss=0.0007354072211382418
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.0007354072195770603
2043, epoch_train_loss=0.0007354072195770603
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.0007354072180176634
2044, epoch_train_loss=0.0007354072180176634
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.000735407216460048
2045, epoch_train_loss=0.000735407216460048
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007354072149042114
2046, epoch_train_loss=0.0007354072149042114
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.0007354072133501507
2047, epoch_train_loss=0.0007354072133501507
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.0007354072117978633
2048, epoch_train_loss=0.0007354072117978633
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.000735407210247346
2049, epoch_train_loss=0.000735407210247346
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.0007354072086985963
2050, epoch_train_loss=0.0007354072086985963
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.0007354072071516113
2051, epoch_train_loss=0.0007354072071516113
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0007354072056063878
2052, epoch_train_loss=0.0007354072056063878
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0007354072040629238
2053, epoch_train_loss=0.0007354072040629238
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.0007354072025212157
2054, epoch_train_loss=0.0007354072025212157
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.0007354072009812612
2055, epoch_train_loss=0.0007354072009812612
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0007354071994430575
2056, epoch_train_loss=0.0007354071994430575
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.0007354071979066016
2057, epoch_train_loss=0.0007354071979066016
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.0007354071963718906
2058, epoch_train_loss=0.0007354071963718906
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.0007354071948389222
2059, epoch_train_loss=0.0007354071948389222
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.0007354071933076934
2060, epoch_train_loss=0.0007354071933076934
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 0.0007354071917782013
2061, epoch_train_loss=0.0007354071917782013
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.0007354071902504432
2062, epoch_train_loss=0.0007354071902504432
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0007354071887244166
2063, epoch_train_loss=0.0007354071887244166
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.0007354071872001185
2064, epoch_train_loss=0.0007354071872001185
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.0007354071856775465
2065, epoch_train_loss=0.0007354071856775465
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 0.0007354071841566974
2066, epoch_train_loss=0.0007354071841566974
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 0.0007354071826375688
2067, epoch_train_loss=0.0007354071826375688
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.0007354071811201579
2068, epoch_train_loss=0.0007354071811201579
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0007354071796044619
2069, epoch_train_loss=0.0007354071796044619
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0007354071780904782
2070, epoch_train_loss=0.0007354071780904782
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.0007354071765782041
2071, epoch_train_loss=0.0007354071765782041
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 0.0007354071750676369
2072, epoch_train_loss=0.0007354071750676369
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 0.000735407173558774
2073, epoch_train_loss=0.000735407173558774
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 0.0007354071720516124
2074, epoch_train_loss=0.0007354071720516124
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.0007354071705461498
2075, epoch_train_loss=0.0007354071705461498
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.0007354071690423832
2076, epoch_train_loss=0.0007354071690423832
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 0.0007354071675403102
2077, epoch_train_loss=0.0007354071675403102
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 0.000735407166039928
2078, epoch_train_loss=0.000735407166039928
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 0.0007354071645412339
2079, epoch_train_loss=0.0007354071645412339
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 0.0007354071630442254
2080, epoch_train_loss=0.0007354071630442254
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 0.0007354071615488998
2081, epoch_train_loss=0.0007354071615488998
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 0.0007354071600552543
2082, epoch_train_loss=0.0007354071600552543
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 0.0007354071585632866
2083, epoch_train_loss=0.0007354071585632866
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 0.0007354071570729938
2084, epoch_train_loss=0.0007354071570729938
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 0.0007354071555843732
2085, epoch_train_loss=0.0007354071555843732
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 0.0007354071540974225
2086, epoch_train_loss=0.0007354071540974225
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 0.0007354071526121392
2087, epoch_train_loss=0.0007354071526121392
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 0.00073540715112852
2088, epoch_train_loss=0.00073540715112852
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 0.0007354071496465626
2089, epoch_train_loss=0.0007354071496465626
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 0.0007354071481662647
2090, epoch_train_loss=0.0007354071481662647
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 0.0007354071466876234
2091, epoch_train_loss=0.0007354071466876234
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 0.0007354071452106364
2092, epoch_train_loss=0.0007354071452106364
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 0.0007354071437353009
2093, epoch_train_loss=0.0007354071437353009
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 0.0007354071422616144
2094, epoch_train_loss=0.0007354071422616144
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 0.0007354071407895742
2095, epoch_train_loss=0.0007354071407895742
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 0.0007354071393191779
2096, epoch_train_loss=0.0007354071393191779
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 0.0007354071378504228
2097, epoch_train_loss=0.0007354071378504228
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 0.0007354071363833064
2098, epoch_train_loss=0.0007354071363833064
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 0.0007354071349178262
2099, epoch_train_loss=0.0007354071349178262
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 0.0007354071334539798
2100, epoch_train_loss=0.0007354071334539798
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 0.0007354071319917642
2101, epoch_train_loss=0.0007354071319917642
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 0.0007354071305311772
2102, epoch_train_loss=0.0007354071305311772
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 0.0007354071290722162
2103, epoch_train_loss=0.0007354071290722162
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 0.0007354071276148789
2104, epoch_train_loss=0.0007354071276148789
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 0.0007354071261591624
2105, epoch_train_loss=0.0007354071261591624
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 0.0007354071247050644
2106, epoch_train_loss=0.0007354071247050644
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 0.0007354071232525823
2107, epoch_train_loss=0.0007354071232525823
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 0.0007354071218017138
2108, epoch_train_loss=0.0007354071218017138
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 0.000735407120352456
2109, epoch_train_loss=0.000735407120352456
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 0.0007354071189048067
2110, epoch_train_loss=0.0007354071189048067
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 0.0007354071174587634
2111, epoch_train_loss=0.0007354071174587634
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 0.0007354071160143235
2112, epoch_train_loss=0.0007354071160143235
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 0.0007354071145714844
2113, epoch_train_loss=0.0007354071145714844
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 0.0007354071131302441
2114, epoch_train_loss=0.0007354071131302441
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 0.0007354071116905998
2115, epoch_train_loss=0.0007354071116905998
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 0.0007354071102525492
2116, epoch_train_loss=0.0007354071102525492
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 0.0007354071088160895
2117, epoch_train_loss=0.0007354071088160895
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 0.0007354071073812184
2118, epoch_train_loss=0.0007354071073812184
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 0.0007354071059479337
2119, epoch_train_loss=0.0007354071059479337
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 0.0007354071045162327
2120, epoch_train_loss=0.0007354071045162327
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 0.0007354071030861129
2121, epoch_train_loss=0.0007354071030861129
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 0.0007354071016575722
2122, epoch_train_loss=0.0007354071016575722
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 0.0007354071002306078
2123, epoch_train_loss=0.0007354071002306078
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 0.0007354070988052176
2124, epoch_train_loss=0.0007354070988052176
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 0.0007354070973813988
2125, epoch_train_loss=0.0007354070973813988
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 0.0007354070959591494
2126, epoch_train_loss=0.0007354070959591494
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 0.0007354070945384667
2127, epoch_train_loss=0.0007354070945384667
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 0.0007354070931193483
2128, epoch_train_loss=0.0007354070931193483
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 0.0007354070917017921
2129, epoch_train_loss=0.0007354070917017921
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 0.0007354070902857953
2130, epoch_train_loss=0.0007354070902857953
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 0.0007354070888713559
2131, epoch_train_loss=0.0007354070888713559
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 0.0007354070874584711
2132, epoch_train_loss=0.0007354070874584711
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 0.0007354070860471389
2133, epoch_train_loss=0.0007354070860471389
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 0.0007354070846373564
2134, epoch_train_loss=0.0007354070846373564
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 0.0007354070832291219
2135, epoch_train_loss=0.0007354070832291219
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 0.0007354070818224327
2136, epoch_train_loss=0.0007354070818224327
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.0007354070804172865
2137, epoch_train_loss=0.0007354070804172865
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.0007354070790136807
2138, epoch_train_loss=0.0007354070790136807
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0007354070776116133
2139, epoch_train_loss=0.0007354070776116133
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0007354070762110817
2140, epoch_train_loss=0.0007354070762110817
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0007354070748120836
2141, epoch_train_loss=0.0007354070748120836
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0007354070734146168
2142, epoch_train_loss=0.0007354070734146168
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.0007354070720186786
2143, epoch_train_loss=0.0007354070720186786
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0007354070706242671
2144, epoch_train_loss=0.0007354070706242671
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0007354070692313797
2145, epoch_train_loss=0.0007354070692313797
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.0007354070678400144
2146, epoch_train_loss=0.0007354070678400144
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.0007354070664501686
2147, epoch_train_loss=0.0007354070664501686
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.00073540706506184
2148, epoch_train_loss=0.00073540706506184
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.0007354070636750262
2149, epoch_train_loss=0.0007354070636750262
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.000735407062289725
2150, epoch_train_loss=0.000735407062289725
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.0007354070609059343
2151, epoch_train_loss=0.0007354070609059343
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.0007354070595236517
2152, epoch_train_loss=0.0007354070595236517
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.0007354070581428748
2153, epoch_train_loss=0.0007354070581428748
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0007354070567636014
2154, epoch_train_loss=0.0007354070567636014
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.0007354070553858289
2155, epoch_train_loss=0.0007354070553858289
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.0007354070540095555
2156, epoch_train_loss=0.0007354070540095555
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.0007354070526347788
2157, epoch_train_loss=0.0007354070526347788
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0007354070512614966
2158, epoch_train_loss=0.0007354070512614966
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0007354070498897065
2159, epoch_train_loss=0.0007354070498897065
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.0007354070485194059
2160, epoch_train_loss=0.0007354070485194059
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.0007354070471505932
2161, epoch_train_loss=0.0007354070471505932
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0007354070457832657
2162, epoch_train_loss=0.0007354070457832657
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.0007354070444174212
2163, epoch_train_loss=0.0007354070444174212
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.0007354070430530579
2164, epoch_train_loss=0.0007354070430530579
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.0007354070416901731
2165, epoch_train_loss=0.0007354070416901731
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.0007354070403287646
2166, epoch_train_loss=0.0007354070403287646
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.0007354070389688302
2167, epoch_train_loss=0.0007354070389688302
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0007354070376103678
2168, epoch_train_loss=0.0007354070376103678
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0007354070362533752
2169, epoch_train_loss=0.0007354070362533752
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.0007354070348978501
2170, epoch_train_loss=0.0007354070348978501
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.0007354070335437905
2171, epoch_train_loss=0.0007354070335437905
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.0007354070321911937
2172, epoch_train_loss=0.0007354070321911937
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.0007354070308400578
2173, epoch_train_loss=0.0007354070308400578
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0007354070294903808
2174, epoch_train_loss=0.0007354070294903808
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.00073540702814216
2175, epoch_train_loss=0.00073540702814216
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0007354070267953936
2176, epoch_train_loss=0.0007354070267953936
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.0007354070254500794
2177, epoch_train_loss=0.0007354070254500794
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.0007354070241062153
2178, epoch_train_loss=0.0007354070241062153
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.0007354070227637988
2179, epoch_train_loss=0.0007354070227637988
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.0007354070214228278
2180, epoch_train_loss=0.0007354070214228278
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.0007354070200833005
2181, epoch_train_loss=0.0007354070200833005
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.0007354070187452141
2182, epoch_train_loss=0.0007354070187452141
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007354070174085671
2183, epoch_train_loss=0.0007354070174085671
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007354070160733569
2184, epoch_train_loss=0.0007354070160733569
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.0007354070147395816
2185, epoch_train_loss=0.0007354070147395816
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.000735407013407239
2186, epoch_train_loss=0.000735407013407239
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0007354070120763266
2187, epoch_train_loss=0.0007354070120763266
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0007354070107468429
2188, epoch_train_loss=0.0007354070107468429
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0007354070094187854
2189, epoch_train_loss=0.0007354070094187854
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0007354070080921522
2190, epoch_train_loss=0.0007354070080921522
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0007354070067669405
2191, epoch_train_loss=0.0007354070067669405
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.000735407005443149
2192, epoch_train_loss=0.000735407005443149
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.0007354070041207751
2193, epoch_train_loss=0.0007354070041207751
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.000735407002799817
2194, epoch_train_loss=0.000735407002799817
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.0007354070014802723
2195, epoch_train_loss=0.0007354070014802723
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.000735407000162139
2196, epoch_train_loss=0.000735407000162139
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0007354069988454152
2197, epoch_train_loss=0.0007354069988454152
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.0007354069975300983
2198, epoch_train_loss=0.0007354069975300983
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.0007354069962161868
2199, epoch_train_loss=0.0007354069962161868
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.0007354069949036782
2200, epoch_train_loss=0.0007354069949036782
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.0007354069935925706
2201, epoch_train_loss=0.0007354069935925706
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.0007354069922828619
2202, epoch_train_loss=0.0007354069922828619
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.00073540699097455
2203, epoch_train_loss=0.00073540699097455
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0007354069896676326
2204, epoch_train_loss=0.0007354069896676326
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.0007354069883621082
2205, epoch_train_loss=0.0007354069883621082
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.0007354069870579742
2206, epoch_train_loss=0.0007354069870579742
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.0007354069857552287
2207, epoch_train_loss=0.0007354069857552287
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0007354069844538697
2208, epoch_train_loss=0.0007354069844538697
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.0007354069831538952
2209, epoch_train_loss=0.0007354069831538952
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.0007354069818553029
2210, epoch_train_loss=0.0007354069818553029
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0007354069805580911
2211, epoch_train_loss=0.0007354069805580911
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.0007354069792622574
2212, epoch_train_loss=0.0007354069792622574
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.0007354069779678
2213, epoch_train_loss=0.0007354069779678
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0007354069766747169
2214, epoch_train_loss=0.0007354069766747169
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.0007354069753830059
2215, epoch_train_loss=0.0007354069753830059
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.000735406974092665
2216, epoch_train_loss=0.000735406974092665
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0007354069728036924
2217, epoch_train_loss=0.0007354069728036924
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0007354069715160858
2218, epoch_train_loss=0.0007354069715160858
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0007354069702298435
2219, epoch_train_loss=0.0007354069702298435
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007354069689449631
2220, epoch_train_loss=0.0007354069689449631
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.0007354069676614427
2221, epoch_train_loss=0.0007354069676614427
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.0007354069663792805
2222, epoch_train_loss=0.0007354069663792805
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.0007354069650984744
2223, epoch_train_loss=0.0007354069650984744
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.0007354069638190223
2224, epoch_train_loss=0.0007354069638190223
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.0007354069625409223
2225, epoch_train_loss=0.0007354069625409223
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.0007354069612641725
2226, epoch_train_loss=0.0007354069612641725
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0007354069599887708
2227, epoch_train_loss=0.0007354069599887708
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.0007354069587147154
2228, epoch_train_loss=0.0007354069587147154
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.0007354069574420041
2229, epoch_train_loss=0.0007354069574420041
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0007354069561706348
2230, epoch_train_loss=0.0007354069561706348
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0007354069549006058
2231, epoch_train_loss=0.0007354069549006058
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.000735406953631915
2232, epoch_train_loss=0.000735406953631915
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.0007354069523645609
2233, epoch_train_loss=0.0007354069523645609
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.0007354069510985406
2234, epoch_train_loss=0.0007354069510985406
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.0007354069498338531
2235, epoch_train_loss=0.0007354069498338531
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.0007354069485704959
2236, epoch_train_loss=0.0007354069485704959
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0007354069473084672
2237, epoch_train_loss=0.0007354069473084672
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.000735406946047765
2238, epoch_train_loss=0.000735406946047765
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.0007354069447883875
2239, epoch_train_loss=0.0007354069447883875
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 0.0007354069435303327
2240, epoch_train_loss=0.0007354069435303327
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.0007354069422735985
2241, epoch_train_loss=0.0007354069422735985
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.0007354069410181833
2242, epoch_train_loss=0.0007354069410181833
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.000735406939764085
2243, epoch_train_loss=0.000735406939764085
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0007354069385113014
2244, epoch_train_loss=0.0007354069385113014
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.0007354069372598312
2245, epoch_train_loss=0.0007354069372598312
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 0.0007354069360096721
2246, epoch_train_loss=0.0007354069360096721
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 0.0007354069347608221
2247, epoch_train_loss=0.0007354069347608221
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 0.0007354069335132795
2248, epoch_train_loss=0.0007354069335132795
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.0007354069322670423
2249, epoch_train_loss=0.0007354069322670423
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.0007354069310221087
2250, epoch_train_loss=0.0007354069310221087
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.0007354069297784766
2251, epoch_train_loss=0.0007354069297784766
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 0.0007354069285361443
2252, epoch_train_loss=0.0007354069285361443
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 0.0007354069272951099
2253, epoch_train_loss=0.0007354069272951099
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 0.0007354069260553715
2254, epoch_train_loss=0.0007354069260553715
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 0.0007354069248169272
2255, epoch_train_loss=0.0007354069248169272
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 0.000735406923579775
2256, epoch_train_loss=0.000735406923579775
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 0.0007354069223439132
2257, epoch_train_loss=0.0007354069223439132
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 0.0007354069211093398
2258, epoch_train_loss=0.0007354069211093398
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 0.000735406919876053
2259, epoch_train_loss=0.000735406919876053
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 0.0007354069186440512
2260, epoch_train_loss=0.0007354069186440512
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 0.0007354069174133321
2261, epoch_train_loss=0.0007354069174133321
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 0.000735406916183894
2262, epoch_train_loss=0.000735406916183894
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 0.0007354069149557351
2263, epoch_train_loss=0.0007354069149557351
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 0.0007354069137288535
2264, epoch_train_loss=0.0007354069137288535
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 0.0007354069125032476
2265, epoch_train_loss=0.0007354069125032476
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 0.0007354069112789149
2266, epoch_train_loss=0.0007354069112789149
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 0.0007354069100558544
2267, epoch_train_loss=0.0007354069100558544
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 0.0007354069088340636
2268, epoch_train_loss=0.0007354069088340636
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 0.0007354069076135412
2269, epoch_train_loss=0.0007354069076135412
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 0.0007354069063942849
2270, epoch_train_loss=0.0007354069063942849
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 0.000735406905176293
2271, epoch_train_loss=0.000735406905176293
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 0.000735406903959564
2272, epoch_train_loss=0.000735406903959564
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 0.0007354069027440957
2273, epoch_train_loss=0.0007354069027440957
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 0.0007354069015298863
2274, epoch_train_loss=0.0007354069015298863
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 0.0007354069003169343
2275, epoch_train_loss=0.0007354069003169343
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 0.0007354068991052376
2276, epoch_train_loss=0.0007354068991052376
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 0.0007354068978947944
2277, epoch_train_loss=0.0007354068978947944
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 0.0007354068966856031
2278, epoch_train_loss=0.0007354068966856031
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 0.0007354068954776618
2279, epoch_train_loss=0.0007354068954776618
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 0.0007354068942709687
2280, epoch_train_loss=0.0007354068942709687
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 0.000735406893065522
2281, epoch_train_loss=0.000735406893065522
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 0.00073540689186132
2282, epoch_train_loss=0.00073540689186132
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 0.0007354068906583606
2283, epoch_train_loss=0.0007354068906583606
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 0.0007354068894566425
2284, epoch_train_loss=0.0007354068894566425
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 0.0007354068882561637
2285, epoch_train_loss=0.0007354068882561637
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 0.0007354068870569222
2286, epoch_train_loss=0.0007354068870569222
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 0.0007354068858589166
2287, epoch_train_loss=0.0007354068858589166
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 0.0007354068846621449
2288, epoch_train_loss=0.0007354068846621449
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 0.0007354068834666053
2289, epoch_train_loss=0.0007354068834666053
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 0.0007354068822722964
2290, epoch_train_loss=0.0007354068822722964
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 0.0007354068810792159
2291, epoch_train_loss=0.0007354068810792159
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 0.0007354068798873624
2292, epoch_train_loss=0.0007354068798873624
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 0.0007354068786967342
2293, epoch_train_loss=0.0007354068786967342
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 0.0007354068775073293
2294, epoch_train_loss=0.0007354068775073293
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 0.000735406876319146
2295, epoch_train_loss=0.000735406876319146
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 0.0007354068751321826
2296, epoch_train_loss=0.0007354068751321826
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 0.0007354068739464377
2297, epoch_train_loss=0.0007354068739464377
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 0.0007354068727619089
2298, epoch_train_loss=0.0007354068727619089
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 0.000735406871578595
2299, epoch_train_loss=0.000735406871578595
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 0.000735406870396494
2300, epoch_train_loss=0.000735406870396494
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 0.0007354068692156044
2301, epoch_train_loss=0.0007354068692156044
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 0.0007354068680359244
2302, epoch_train_loss=0.0007354068680359244
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 0.000735406866857452
2303, epoch_train_loss=0.000735406866857452
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 0.0007354068656801859
2304, epoch_train_loss=0.0007354068656801859
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 0.0007354068645041242
2305, epoch_train_loss=0.0007354068645041242
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 0.000735406863329265
2306, epoch_train_loss=0.000735406863329265
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 0.0007354068621556071
2307, epoch_train_loss=0.0007354068621556071
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 0.0007354068609831482
2308, epoch_train_loss=0.0007354068609831482
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 0.0007354068598118871
2309, epoch_train_loss=0.0007354068598118871
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 0.0007354068586418219
2310, epoch_train_loss=0.0007354068586418219
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 0.0007354068574729508
2311, epoch_train_loss=0.0007354068574729508
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 0.0007354068563052723
2312, epoch_train_loss=0.0007354068563052723
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 0.0007354068551387845
2313, epoch_train_loss=0.0007354068551387845
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 0.0007354068539734858
2314, epoch_train_loss=0.0007354068539734858
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 0.0007354068528093745
2315, epoch_train_loss=0.0007354068528093745
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 0.0007354068516464491
2316, epoch_train_loss=0.0007354068516464491
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 0.0007354068504847077
2317, epoch_train_loss=0.0007354068504847077
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 0.0007354068493241486
2318, epoch_train_loss=0.0007354068493241486
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 0.0007354068481647703
2319, epoch_train_loss=0.0007354068481647703
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 0.0007354068470065712
2320, epoch_train_loss=0.0007354068470065712
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 0.0007354068458495496
2321, epoch_train_loss=0.0007354068458495496
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 0.0007354068446937036
2322, epoch_train_loss=0.0007354068446937036
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 0.0007354068435390317
2323, epoch_train_loss=0.0007354068435390317
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 0.0007354068423855322
2324, epoch_train_loss=0.0007354068423855322
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 0.0007354068412332035
2325, epoch_train_loss=0.0007354068412332035
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 0.0007354068400820439
2326, epoch_train_loss=0.0007354068400820439
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 0.0007354068389320518
2327, epoch_train_loss=0.0007354068389320518
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 0.0007354068377832256
2328, epoch_train_loss=0.0007354068377832256
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 0.0007354068366355638
2329, epoch_train_loss=0.0007354068366355638
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 0.0007354068354890643
2330, epoch_train_loss=0.0007354068354890643
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 0.0007354068343437259
2331, epoch_train_loss=0.0007354068343437259
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 0.0007354068331995468
2332, epoch_train_loss=0.0007354068331995468
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 0.0007354068320565252
2333, epoch_train_loss=0.0007354068320565252
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 0.0007354068309146597
2334, epoch_train_loss=0.0007354068309146597
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 0.0007354068297739487
2335, epoch_train_loss=0.0007354068297739487
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 0.0007354068286343907
2336, epoch_train_loss=0.0007354068286343907
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 0.0007354068274959837
2337, epoch_train_loss=0.0007354068274959837
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 0.0007354068263587264
2338, epoch_train_loss=0.0007354068263587264
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 0.0007354068252226169
2339, epoch_train_loss=0.0007354068252226169
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.000735406824087654
2340, epoch_train_loss=0.000735406824087654
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.0007354068229538358
2341, epoch_train_loss=0.0007354068229538358
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.0007354068218211607
2342, epoch_train_loss=0.0007354068218211607
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.0007354068206896273
2343, epoch_train_loss=0.0007354068206896273
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.0007354068195592338
2344, epoch_train_loss=0.0007354068195592338
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0007354068184299786
2345, epoch_train_loss=0.0007354068184299786
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0007354068173018603
2346, epoch_train_loss=0.0007354068173018603
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.0007354068161748772
2347, epoch_train_loss=0.0007354068161748772
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0007354068150490277
2348, epoch_train_loss=0.0007354068150490277
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.0007354068139243103
2349, epoch_train_loss=0.0007354068139243103
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0007354068128007232
2350, epoch_train_loss=0.0007354068128007232
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.0007354068116782653
2351, epoch_train_loss=0.0007354068116782653
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.0007354068105569345
2352, epoch_train_loss=0.0007354068105569345
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.0007354068094367294
2353, epoch_train_loss=0.0007354068094367294
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.0007354068083176486
2354, epoch_train_loss=0.0007354068083176486
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.0007354068071996903
2355, epoch_train_loss=0.0007354068071996903
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.0007354068060828531
2356, epoch_train_loss=0.0007354068060828531
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.0007354068049671355
2357, epoch_train_loss=0.0007354068049671355
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.0007354068038525358
2358, epoch_train_loss=0.0007354068038525358
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007354068027390524
2359, epoch_train_loss=0.0007354068027390524
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.0007354068016266838
2360, epoch_train_loss=0.0007354068016266838
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.0007354068005154287
2361, epoch_train_loss=0.0007354068005154287
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.0007354067994052853
2362, epoch_train_loss=0.0007354067994052853
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0007354067982962521
2363, epoch_train_loss=0.0007354067982962521
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.0007354067971883275
2364, epoch_train_loss=0.0007354067971883275
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0007354067960815099
2365, epoch_train_loss=0.0007354067960815099
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0007354067949757982
2366, epoch_train_loss=0.0007354067949757982
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.0007354067938711904
2367, epoch_train_loss=0.0007354067938711904
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.0007354067927676853
2368, epoch_train_loss=0.0007354067927676853
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.000735406791665281
2369, epoch_train_loss=0.000735406791665281
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0007354067905639765
2370, epoch_train_loss=0.0007354067905639765
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0007354067894637696
2371, epoch_train_loss=0.0007354067894637696
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0007354067883646594
2372, epoch_train_loss=0.0007354067883646594
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.000735406787266644
2373, epoch_train_loss=0.000735406787266644
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0007354067861697223
2374, epoch_train_loss=0.0007354067861697223
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0007354067850738923
2375, epoch_train_loss=0.0007354067850738923
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0007354067839791528
2376, epoch_train_loss=0.0007354067839791528
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0007354067828855022
2377, epoch_train_loss=0.0007354067828855022
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.0007354067817929388
2378, epoch_train_loss=0.0007354067817929388
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.0007354067807014616
2379, epoch_train_loss=0.0007354067807014616
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0007354067796110689
2380, epoch_train_loss=0.0007354067796110689
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.0007354067785217589
2381, epoch_train_loss=0.0007354067785217589
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0007354067774335304
2382, epoch_train_loss=0.0007354067774335304
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.000735406776346382
2383, epoch_train_loss=0.000735406776346382
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.000735406775260312
2384, epoch_train_loss=0.000735406775260312
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.000735406774175319
2385, epoch_train_loss=0.000735406774175319
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.0007354067730914013
2386, epoch_train_loss=0.0007354067730914013
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.0007354067720085577
2387, epoch_train_loss=0.0007354067720085577
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.0007354067709267869
2388, epoch_train_loss=0.0007354067709267869
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0007354067698460869
2389, epoch_train_loss=0.0007354067698460869
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0007354067687664567
2390, epoch_train_loss=0.0007354067687664567
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0007354067676878947
2391, epoch_train_loss=0.0007354067676878947
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.0007354067666103994
2392, epoch_train_loss=0.0007354067666103994
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.0007354067655339692
2393, epoch_train_loss=0.0007354067655339692
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.0007354067644586026
2394, epoch_train_loss=0.0007354067644586026
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0007354067633842987
2395, epoch_train_loss=0.0007354067633842987
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0007354067623110556
2396, epoch_train_loss=0.0007354067623110556
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.0007354067612388719
2397, epoch_train_loss=0.0007354067612388719
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0007354067601677459
2398, epoch_train_loss=0.0007354067601677459
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0007354067590976767
2399, epoch_train_loss=0.0007354067590976767
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.0007354067580286625
2400, epoch_train_loss=0.0007354067580286625
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.0007354067569607019
2401, epoch_train_loss=0.0007354067569607019
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0007354067558937935
2402, epoch_train_loss=0.0007354067558937935
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.000735406754827936
2403, epoch_train_loss=0.000735406754827936
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.0007354067537631276
2404, epoch_train_loss=0.0007354067537631276
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0007354067526993672
2405, epoch_train_loss=0.0007354067526993672
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0007354067516366532
2406, epoch_train_loss=0.0007354067516366532
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0007354067505749844
2407, epoch_train_loss=0.0007354067505749844
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.0007354067495143592
2408, epoch_train_loss=0.0007354067495143592
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.0007354067484547761
2409, epoch_train_loss=0.0007354067484547761
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.000735406747396234
2410, epoch_train_loss=0.000735406747396234
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.0007354067463387311
2411, epoch_train_loss=0.0007354067463387311
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.0007354067452822661
2412, epoch_train_loss=0.0007354067452822661
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.000735406744226838
2413, epoch_train_loss=0.000735406744226838
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.0007354067431724446
2414, epoch_train_loss=0.0007354067431724446
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 0.0007354067421190852
2415, epoch_train_loss=0.0007354067421190852
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0007354067410667582
2416, epoch_train_loss=0.0007354067410667582
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.000735406740015462
2417, epoch_train_loss=0.000735406740015462
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0007354067389651953
2418, epoch_train_loss=0.0007354067389651953
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.0007354067379159569
2419, epoch_train_loss=0.0007354067379159569
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 0.0007354067368677452
2420, epoch_train_loss=0.0007354067368677452
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0007354067358205588
2421, epoch_train_loss=0.0007354067358205588
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0007354067347743965
2422, epoch_train_loss=0.0007354067347743965
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.0007354067337292566
2423, epoch_train_loss=0.0007354067337292566
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.000735406732685138
2424, epoch_train_loss=0.000735406732685138
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.0007354067316420394
2425, epoch_train_loss=0.0007354067316420394
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 0.000735406730599959
2426, epoch_train_loss=0.000735406730599959
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.0007354067295588958
2427, epoch_train_loss=0.0007354067295588958
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.0007354067285188483
2428, epoch_train_loss=0.0007354067285188483
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.000735406727479815
2429, epoch_train_loss=0.000735406727479815
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.0007354067264417946
2430, epoch_train_loss=0.0007354067264417946
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 0.000735406725404786
2431, epoch_train_loss=0.000735406725404786
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 0.0007354067243687877
2432, epoch_train_loss=0.0007354067243687877
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.0007354067233337981
2433, epoch_train_loss=0.0007354067233337981
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0007354067222998161
2434, epoch_train_loss=0.0007354067222998161
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.0007354067212668402
2435, epoch_train_loss=0.0007354067212668402
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 0.0007354067202348691
2436, epoch_train_loss=0.0007354067202348691
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 0.0007354067192039015
2437, epoch_train_loss=0.0007354067192039015
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 0.0007354067181739359
2438, epoch_train_loss=0.0007354067181739359
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.0007354067171449712
2439, epoch_train_loss=0.0007354067171449712
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.0007354067161170057
2440, epoch_train_loss=0.0007354067161170057
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 0.0007354067150900385
2441, epoch_train_loss=0.0007354067150900385
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 0.0007354067140640679
2442, epoch_train_loss=0.0007354067140640679
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 0.0007354067130390928
2443, epoch_train_loss=0.0007354067130390928
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 0.0007354067120151117
2444, epoch_train_loss=0.0007354067120151117
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 0.0007354067109921233
2445, epoch_train_loss=0.0007354067109921233
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 0.0007354067099701262
2446, epoch_train_loss=0.0007354067099701262
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 0.0007354067089491195
2447, epoch_train_loss=0.0007354067089491195
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 0.0007354067079291012
2448, epoch_train_loss=0.0007354067079291012
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 0.0007354067069100703
2449, epoch_train_loss=0.0007354067069100703
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 0.0007354067058920255
2450, epoch_train_loss=0.0007354067058920255
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 0.0007354067048749656
2451, epoch_train_loss=0.0007354067048749656
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 0.0007354067038588891
2452, epoch_train_loss=0.0007354067038588891
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 0.0007354067028437949
2453, epoch_train_loss=0.0007354067028437949
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 0.0007354067018296813
2454, epoch_train_loss=0.0007354067018296813
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 0.0007354067008165473
2455, epoch_train_loss=0.0007354067008165473
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 0.0007354066998043916
2456, epoch_train_loss=0.0007354066998043916
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 0.0007354066987932127
2457, epoch_train_loss=0.0007354066987932127
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 0.0007354066977830094
2458, epoch_train_loss=0.0007354066977830094
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 0.0007354066967737805
2459, epoch_train_loss=0.0007354066967737805
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 0.0007354066957655244
2460, epoch_train_loss=0.0007354066957655244
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 0.0007354066947582402
2461, epoch_train_loss=0.0007354066947582402
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 0.0007354066937519264
2462, epoch_train_loss=0.0007354066937519264
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 0.0007354066927465816
2463, epoch_train_loss=0.0007354066927465816
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 0.0007354066917422046
2464, epoch_train_loss=0.0007354066917422046
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 0.0007354066907387944
2465, epoch_train_loss=0.0007354066907387944
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 0.0007354066897363494
2466, epoch_train_loss=0.0007354066897363494
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 0.0007354066887348682
2467, epoch_train_loss=0.0007354066887348682
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 0.0007354066877343496
2468, epoch_train_loss=0.0007354066877343496
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 0.0007354066867347926
2469, epoch_train_loss=0.0007354066867347926
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 0.0007354066857361958
2470, epoch_train_loss=0.0007354066857361958
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 0.0007354066847385578
2471, epoch_train_loss=0.0007354066847385578
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 0.0007354066837418773
2472, epoch_train_loss=0.0007354066837418773
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 0.0007354066827461532
2473, epoch_train_loss=0.0007354066827461532
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.0007354066817513842
2474, epoch_train_loss=0.0007354066817513842
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.000735406680757569
2475, epoch_train_loss=0.000735406680757569
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.0007354066797647063
2476, epoch_train_loss=0.0007354066797647063
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.0007354066787727948
2477, epoch_train_loss=0.0007354066787727948
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.0007354066777818335
2478, epoch_train_loss=0.0007354066777818335
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0007354066767918207
2479, epoch_train_loss=0.0007354066767918207
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0007354066758027556
2480, epoch_train_loss=0.0007354066758027556
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007354066748146368
2481, epoch_train_loss=0.0007354066748146368
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.0007354066738274628
2482, epoch_train_loss=0.0007354066738274628
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.0007354066728412324
2483, epoch_train_loss=0.0007354066728412324
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.0007354066718559447
2484, epoch_train_loss=0.0007354066718559447
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.000735406670871598
2485, epoch_train_loss=0.000735406670871598
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.0007354066698881918
2486, epoch_train_loss=0.0007354066698881918
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.000735406668905724
2487, epoch_train_loss=0.000735406668905724
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.0007354066679241939
2488, epoch_train_loss=0.0007354066679241939
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.0007354066669435999
2489, epoch_train_loss=0.0007354066669435999
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.0007354066659639413
2490, epoch_train_loss=0.0007354066659639413
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.0007354066649852163
2491, epoch_train_loss=0.0007354066649852163
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.0007354066640074241
2492, epoch_train_loss=0.0007354066640074241
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.000735406663030563
2493, epoch_train_loss=0.000735406663030563
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0007354066620546323
2494, epoch_train_loss=0.0007354066620546323
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0007354066610796305
2495, epoch_train_loss=0.0007354066610796305
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0007354066601055562
2496, epoch_train_loss=0.0007354066601055562
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.0007354066591324086
2497, epoch_train_loss=0.0007354066591324086
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.0007354066581601863
2498, epoch_train_loss=0.0007354066581601863
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0007354066571888878
2499, epoch_train_loss=0.0007354066571888878
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8108760> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8108760> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffec8108760> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec81084c0> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec810aaa0> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec81092a0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec8109090> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec81088b0> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec8109720> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec8109690> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec8109540> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec8109b10> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffec810a140> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffec8109bd0> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810a590> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810a5c0> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec8109fc0> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffec810a860> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810a770> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810a6e0> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810aa10> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810ac20> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffec810a9b0> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffec810aec0> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec810ab60> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffec810b010> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffec810b340> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffec81084c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec81084c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051022 -0.00019156 -0.00051334 ... -0.02830887 -0.02830887
 -0.02830887] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046674  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810aaa0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810aaa0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-3.60081838e-04 -1.08775305e-04 -1.31917160e-05 ... -2.74817476e-02
 -2.74817476e-02 -2.74817476e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 4)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffec81092a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec81092a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.92637305e-09 -1.31700807e-07 -9.61527370e-06 ... -7.35522754e-16
 -7.35522754e-16 -7.35522754e-16] = ,SCAN
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 4)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109090> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109090> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.31884219e-04 -2.81911891e-04 -2.81911891e-04 ... -1.27154711e-05
 -2.64861768e-02 -2.64861768e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 4)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033774438603  <S^2> = 2.0027452  2S+1 = 3.0018296
Warning: <pyscf.gto.mole.Mole object at 0x7ffec81088b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec81088b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.96731013e-04 -3.63515368e-05 -1.93077612e-06 ... -2.76158570e-02
 -2.76158570e-02 -2.76158570e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 4)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121193  <S^2> = 0.75161939  2S+1 = 2.0016187
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109720> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109720> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.42991538e-04 -2.60255071e-04 -8.61793995e-05 ... -2.84484396e-02
 -2.84484396e-02 -2.84484396e-02] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 4)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560989243  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109690> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109690> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.12369990e-03 -1.34687832e-03 -6.90063325e-04 ... -2.71546352e-05
 -1.90328177e-04 -1.52141565e-05] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 4)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786807174  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109540> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109540> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00038739 -0.00017489 -0.0002337  ... -0.02838402 -0.02838402
 -0.02838402] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 1.7763568e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109b10> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109b10> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00043469 -0.00024024 -0.00035532 ... -0.00047537 -0.03728133
 -0.03728133] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 4)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.337792446513  <S^2> = 4.0072834e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a140> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a140> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-9.02468888e-05 -7.92694658e-06 -9.80568469e-06 ... -4.33714150e-02
 -4.33714150e-02 -4.33714150e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 4)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322844  <S^2> = 1.7763568e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109bd0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109bd0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.48187338e-05 -6.19475249e-05 -2.61742784e-04 ... -8.70042314e-07
 -2.73391097e-02 -2.73391097e-02] = ,SCAN
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 4)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888959  <S^2> = 5.0448534e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a590> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a590> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051559 -0.00027432 -0.00088583 ... -0.00027432 -0.04174728
 -0.04174728] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 4)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.1368684e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a5c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a5c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.53951178e-05 -5.93507199e-06 -3.10072916e-04 ... -5.94325581e-02
 -5.94325581e-02 -5.94325581e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 4)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894499368  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffec8109fc0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec8109fc0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.59565049e-04 -2.99665525e-05 -1.62992734e-06 ... -4.22396737e-02
 -4.22396737e-02 -4.22396737e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 4)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346375  <S^2> = 7.1054274e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a860> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a860> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.72190712e-05 -2.72190712e-05 -2.84904833e-04 ... -1.08108260e-05
 -1.03072478e-05 -1.03072478e-05] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 4)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.6080474e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a770> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a770> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00015688 -0.00024669 -0.00068269 ... -0.03791166 -0.03791166
 -0.03791166] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 4)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374078  <S^2> = 7.1054274e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a6e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a6e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.28500681e-05 -5.65091132e-06 -7.37932132e-06 ... -4.76689214e-02
 -4.76689214e-02 -4.76689214e-02] = ,SCAN
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 4)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018921  <S^2> = 7.7937656e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810aa10> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810aa10> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003863  -0.00040095 -0.00040095 ... -0.0213199  -0.0213199
 -0.0213199 ] = ,SCAN
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 4)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5866419e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810ac20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810ac20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00088473 -0.00088473 -0.00116894 ... -0.00088473 -0.00088473
 -0.00116894] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 4)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.3844043e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810a9b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810a9b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.91408540e-05 -1.46971271e-04 -1.08734417e-03 ... -2.81566369e-02
 -2.81566369e-02 -2.81566369e-02] = ,SCAN
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 4)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5394797e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810aec0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810aec0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.39373335e-04 -1.31641332e-04 -1.15950750e-05 ... -7.32416564e-02
 -7.32416564e-02 -7.32416564e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 4)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336224065  <S^2> = 1.0034704  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810ab60> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810ab60> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.84689335e-05 -7.80566952e-05 -7.80532148e-05 ... -2.92531429e-02
 -2.92531429e-02 -2.92531429e-02] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 4)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864077  <S^2> = 3.170797e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810b010> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810b010> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.56165538e-04 -7.34744214e-05 -5.30574304e-06 ... -7.93995702e-06
 -7.93995702e-06 -7.93995702e-06] = ,SCAN
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 4)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.2017058e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffec810b340> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec810b340> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.28290753e-04 -1.41305449e-05 -6.13700492e-05 ... -2.47993463e-02
 -2.47993463e-02 -2.47993463e-02] = ,SCAN
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 4)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3153922e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.45512011e-04 -7.12775692e-05 -5.48666345e-06 ... -6.02613084e-06
 -6.02613084e-06 -6.02613084e-06] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 4)
PRE NAN FILT: tFxc.shape=(224163,), tdrho.shape=(224163, 4)
nan_filt_rho.shape=(224163,)
nan_filt_fxc.shape=(224163,)
tFxc.shape=(224163,), tdrho.shape=(224163, 4)
inp[0].shape = (224163, 4)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 0.5575331385264622
0, epoch_train_loss=0.5575331385264622
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 0.4319077597298362
1, epoch_train_loss=0.4319077597298362
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 0.31270296508235124
2, epoch_train_loss=0.31270296508235124
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 0.18133195754395354
3, epoch_train_loss=0.18133195754395354
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 0.0693789784810709
4, epoch_train_loss=0.0693789784810709
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 0.013953397212471878
5, epoch_train_loss=0.013953397212471878
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 0.0022827517601994416
6, epoch_train_loss=0.0022827517601994416
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.0009243687486323422
7, epoch_train_loss=0.0009243687486323422
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.0007586089064860026
8, epoch_train_loss=0.0007586089064860026
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.0007378162239392393
9, epoch_train_loss=0.0007378162239392393
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.0007355480617653163
10, epoch_train_loss=0.0007355480617653163
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.0007353359418479493
11, epoch_train_loss=0.0007353359418479493
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.0007353181630051405
12, epoch_train_loss=0.0007353181630051405
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.0007353167441436885
13, epoch_train_loss=0.0007353167441436885
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.0007353166294085306
14, epoch_train_loss=0.0007353166294085306
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.0007353166194707184
15, epoch_train_loss=0.0007353166194707184
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.0007353166185077571
16, epoch_train_loss=0.0007353166185077571
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.0007353166184004425
17, epoch_train_loss=0.0007353166184004425
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.0007353166183865392
18, epoch_train_loss=0.0007353166183865392
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.000735316618384451
19, epoch_train_loss=0.000735316618384451
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.000735316618384091
20, epoch_train_loss=0.000735316618384091
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.0007353166183840205
21, epoch_train_loss=0.0007353166183840205
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.0007353166183840052
22, epoch_train_loss=0.0007353166183840052
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.0007353166183840014
23, epoch_train_loss=0.0007353166183840014
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.0007353166183840004
24, epoch_train_loss=0.0007353166183840004
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.0007353166183840001
25, epoch_train_loss=0.0007353166183840001
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.0007353166183839999
26, epoch_train_loss=0.0007353166183839999
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0007353166183839999
27, epoch_train_loss=0.0007353166183839999
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.0007353166183839999
28, epoch_train_loss=0.0007353166183839999
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.0007353166183839999
29, epoch_train_loss=0.0007353166183839999
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0007353166183839999
30, epoch_train_loss=0.0007353166183839999
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.0007353166183839999
31, epoch_train_loss=0.0007353166183839999
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.0007353166183839999
32, epoch_train_loss=0.0007353166183839999
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.0007353166183839999
33, epoch_train_loss=0.0007353166183839999
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.0007353166183839999
34, epoch_train_loss=0.0007353166183839999
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.0007353166183839999
35, epoch_train_loss=0.0007353166183839999
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.0007353166183839999
36, epoch_train_loss=0.0007353166183839999
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.0007353166183839999
37, epoch_train_loss=0.0007353166183839999
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.0007353166183839999
38, epoch_train_loss=0.0007353166183839999
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.0007353166183839999
39, epoch_train_loss=0.0007353166183839999
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.0007353166183839999
40, epoch_train_loss=0.0007353166183839999
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.0007353166183839999
41, epoch_train_loss=0.0007353166183839999
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.0007353166183839999
42, epoch_train_loss=0.0007353166183839999
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.0007353166183839999
43, epoch_train_loss=0.0007353166183839999
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.0007353166183839999
44, epoch_train_loss=0.0007353166183839999
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.0007353166183839999
45, epoch_train_loss=0.0007353166183839999
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.0007353166183839999
46, epoch_train_loss=0.0007353166183839999
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.0007353166183839999
47, epoch_train_loss=0.0007353166183839999
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.0007353166183839999
48, epoch_train_loss=0.0007353166183839999
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.0007353166183839999
49, epoch_train_loss=0.0007353166183839999
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.0007353166183839999
50, epoch_train_loss=0.0007353166183839999
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.0007353166183839999
51, epoch_train_loss=0.0007353166183839999
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.0007353166183839999
52, epoch_train_loss=0.0007353166183839999
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.0007353166183839999
53, epoch_train_loss=0.0007353166183839999
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.0007353166183839999
54, epoch_train_loss=0.0007353166183839999
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.0007353166183839999
55, epoch_train_loss=0.0007353166183839999
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.0007353166183839999
56, epoch_train_loss=0.0007353166183839999
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.0007353166183839999
57, epoch_train_loss=0.0007353166183839999
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0007353166183839999
58, epoch_train_loss=0.0007353166183839999
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.0007353166183839999
59, epoch_train_loss=0.0007353166183839999
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.0007353166183839999
60, epoch_train_loss=0.0007353166183839999
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.0007353166183839999
61, epoch_train_loss=0.0007353166183839999
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.0007353166183839999
62, epoch_train_loss=0.0007353166183839999
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.0007353166183839999
63, epoch_train_loss=0.0007353166183839999
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.0007353166183839999
64, epoch_train_loss=0.0007353166183839999
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0007353166183839999
65, epoch_train_loss=0.0007353166183839999
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.0007353166183839999
66, epoch_train_loss=0.0007353166183839999
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0007353166183839999
67, epoch_train_loss=0.0007353166183839999
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.0007353166183839999
68, epoch_train_loss=0.0007353166183839999
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0007353166183839999
69, epoch_train_loss=0.0007353166183839999
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0007353166183839999
70, epoch_train_loss=0.0007353166183839999
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0007353166183839999
71, epoch_train_loss=0.0007353166183839999
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0007353166183839999
72, epoch_train_loss=0.0007353166183839999
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0007353166183839999
73, epoch_train_loss=0.0007353166183839999
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0007353166183839999
74, epoch_train_loss=0.0007353166183839999
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0007353166183839999
75, epoch_train_loss=0.0007353166183839999
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0007353166183839999
76, epoch_train_loss=0.0007353166183839999
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0007353166183839999
77, epoch_train_loss=0.0007353166183839999
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.0007353166183839999
78, epoch_train_loss=0.0007353166183839999
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0007353166183839999
79, epoch_train_loss=0.0007353166183839999
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0007353166183839999
80, epoch_train_loss=0.0007353166183839999
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.0007353166183839999
81, epoch_train_loss=0.0007353166183839999
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0007353166183839999
82, epoch_train_loss=0.0007353166183839999
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.0007353166183839999
83, epoch_train_loss=0.0007353166183839999
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0007353166183839999
84, epoch_train_loss=0.0007353166183839999
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0007353166183839999
85, epoch_train_loss=0.0007353166183839999
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.0007353166183839999
86, epoch_train_loss=0.0007353166183839999
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.0007353166183839999
87, epoch_train_loss=0.0007353166183839999
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0007353166183839999
88, epoch_train_loss=0.0007353166183839999
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0007353166183839999
89, epoch_train_loss=0.0007353166183839999
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0007353166183839999
90, epoch_train_loss=0.0007353166183839999
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0007353166183839999
91, epoch_train_loss=0.0007353166183839999
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0007353166183839999
92, epoch_train_loss=0.0007353166183839999
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0007353166183839999
93, epoch_train_loss=0.0007353166183839999
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.0007353166183839999
94, epoch_train_loss=0.0007353166183839999
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0007353166183839999
95, epoch_train_loss=0.0007353166183839999
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0007353166183839999
96, epoch_train_loss=0.0007353166183839999
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.0007353166183839999
97, epoch_train_loss=0.0007353166183839999
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0007353166183839999
98, epoch_train_loss=0.0007353166183839999
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0007353166183839999
99, epoch_train_loss=0.0007353166183839999
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0007353166183839999
100, epoch_train_loss=0.0007353166183839999
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.0007353166183839999
101, epoch_train_loss=0.0007353166183839999
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0007353166183839999
102, epoch_train_loss=0.0007353166183839999
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.0007353166183839999
103, epoch_train_loss=0.0007353166183839999
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0007353166183839999
104, epoch_train_loss=0.0007353166183839999
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0007353166183839999
105, epoch_train_loss=0.0007353166183839999
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0007353166183839999
106, epoch_train_loss=0.0007353166183839999
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0007353166183839999
107, epoch_train_loss=0.0007353166183839999
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0007353166183839999
108, epoch_train_loss=0.0007353166183839999
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0007353166183839999
109, epoch_train_loss=0.0007353166183839999
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0007353166183839999
110, epoch_train_loss=0.0007353166183839999
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0007353166183839999
111, epoch_train_loss=0.0007353166183839999
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0007353166183839999
112, epoch_train_loss=0.0007353166183839999
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0007353166183839999
113, epoch_train_loss=0.0007353166183839999
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0007353166183839999
114, epoch_train_loss=0.0007353166183839999
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0007353166183839999
115, epoch_train_loss=0.0007353166183839999
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0007353166183839999
116, epoch_train_loss=0.0007353166183839999
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007353166183839999
117, epoch_train_loss=0.0007353166183839999
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0007353166183839999
118, epoch_train_loss=0.0007353166183839999
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007353166183839999
119, epoch_train_loss=0.0007353166183839999
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.0007353166183839999
120, epoch_train_loss=0.0007353166183839999
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007353166183839999
121, epoch_train_loss=0.0007353166183839999
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007353166183839999
122, epoch_train_loss=0.0007353166183839999
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0007353166183839999
123, epoch_train_loss=0.0007353166183839999
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0007353166183839999
124, epoch_train_loss=0.0007353166183839999
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0007353166183839999
125, epoch_train_loss=0.0007353166183839999
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0007353166183839999
126, epoch_train_loss=0.0007353166183839999
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0007353166183839999
127, epoch_train_loss=0.0007353166183839999
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0007353166183839999
128, epoch_train_loss=0.0007353166183839999
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0007353166183839999
129, epoch_train_loss=0.0007353166183839999
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0007353166183839999
130, epoch_train_loss=0.0007353166183839999
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0007353166183839999
131, epoch_train_loss=0.0007353166183839999
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007353166183839999
132, epoch_train_loss=0.0007353166183839999
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007353166183839999
133, epoch_train_loss=0.0007353166183839999
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007353166183839999
134, epoch_train_loss=0.0007353166183839999
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0007353166183839999
135, epoch_train_loss=0.0007353166183839999
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007353166183839999
136, epoch_train_loss=0.0007353166183839999
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007353166183839999
137, epoch_train_loss=0.0007353166183839999
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0007353166183839999
138, epoch_train_loss=0.0007353166183839999
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007353166183839999
139, epoch_train_loss=0.0007353166183839999
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007353166183839999
140, epoch_train_loss=0.0007353166183839999
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007353166183839999
141, epoch_train_loss=0.0007353166183839999
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0007353166183839999
142, epoch_train_loss=0.0007353166183839999
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0007353166183839999
143, epoch_train_loss=0.0007353166183839999
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0007353166183839999
144, epoch_train_loss=0.0007353166183839999
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.0007353166183839999
145, epoch_train_loss=0.0007353166183839999
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0007353166183839999
146, epoch_train_loss=0.0007353166183839999
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0007353166183839999
147, epoch_train_loss=0.0007353166183839999
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0007353166183839999
148, epoch_train_loss=0.0007353166183839999
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0007353166183839999
149, epoch_train_loss=0.0007353166183839999
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0007353166183839999
150, epoch_train_loss=0.0007353166183839999
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.0007353166183839999
151, epoch_train_loss=0.0007353166183839999
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0007353166183839999
152, epoch_train_loss=0.0007353166183839999
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0007353166183839999
153, epoch_train_loss=0.0007353166183839999
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0007353166183839999
154, epoch_train_loss=0.0007353166183839999
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.0007353166183839999
155, epoch_train_loss=0.0007353166183839999
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0007353166183839999
156, epoch_train_loss=0.0007353166183839999
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.0007353166183839999
157, epoch_train_loss=0.0007353166183839999
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0007353166183839999
158, epoch_train_loss=0.0007353166183839999
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0007353166183839999
159, epoch_train_loss=0.0007353166183839999
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.0007353166183839999
160, epoch_train_loss=0.0007353166183839999
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0007353166183839999
161, epoch_train_loss=0.0007353166183839999
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.0007353166183839999
162, epoch_train_loss=0.0007353166183839999
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0007353166183839999
163, epoch_train_loss=0.0007353166183839999
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.0007353166183839999
164, epoch_train_loss=0.0007353166183839999
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0007353166183839999
165, epoch_train_loss=0.0007353166183839999
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0007353166183839999
166, epoch_train_loss=0.0007353166183839999
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0007353166183839999
167, epoch_train_loss=0.0007353166183839999
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0007353166183839999
168, epoch_train_loss=0.0007353166183839999
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0007353166183839999
169, epoch_train_loss=0.0007353166183839999
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0007353166183839999
170, epoch_train_loss=0.0007353166183839999
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0007353166183839999
171, epoch_train_loss=0.0007353166183839999
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.0007353166183839999
172, epoch_train_loss=0.0007353166183839999
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0007353166183839999
173, epoch_train_loss=0.0007353166183839999
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.0007353166183839999
174, epoch_train_loss=0.0007353166183839999
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0007353166183839999
175, epoch_train_loss=0.0007353166183839999
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0007353166183839999
176, epoch_train_loss=0.0007353166183839999
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.0007353166183839999
177, epoch_train_loss=0.0007353166183839999
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0007353166183839999
178, epoch_train_loss=0.0007353166183839999
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.0007353166183839999
179, epoch_train_loss=0.0007353166183839999
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0007353166183839999
180, epoch_train_loss=0.0007353166183839999
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0007353166183839999
181, epoch_train_loss=0.0007353166183839999
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.0007353166183839999
182, epoch_train_loss=0.0007353166183839999
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0007353166183839999
183, epoch_train_loss=0.0007353166183839999
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0007353166183839999
184, epoch_train_loss=0.0007353166183839999
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0007353166183839999
185, epoch_train_loss=0.0007353166183839999
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0007353166183839999
186, epoch_train_loss=0.0007353166183839999
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0007353166183839999
187, epoch_train_loss=0.0007353166183839999
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0007353166183839999
188, epoch_train_loss=0.0007353166183839999
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.0007353166183839999
189, epoch_train_loss=0.0007353166183839999
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0007353166183839999
190, epoch_train_loss=0.0007353166183839999
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0007353166183839999
191, epoch_train_loss=0.0007353166183839999
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.0007353166183839999
192, epoch_train_loss=0.0007353166183839999
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0007353166183839999
193, epoch_train_loss=0.0007353166183839999
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.0007353166183839999
194, epoch_train_loss=0.0007353166183839999
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0007353166183839999
195, epoch_train_loss=0.0007353166183839999
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.0007353166183839999
196, epoch_train_loss=0.0007353166183839999
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.0007353166183839999
197, epoch_train_loss=0.0007353166183839999
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.0007353166183839999
198, epoch_train_loss=0.0007353166183839999
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.0007353166183839999
199, epoch_train_loss=0.0007353166183839999
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0007353166183839999
200, epoch_train_loss=0.0007353166183839999
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.0007353166183839999
201, epoch_train_loss=0.0007353166183839999
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0007353166183839999
202, epoch_train_loss=0.0007353166183839999
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0007353166183839999
203, epoch_train_loss=0.0007353166183839999
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.0007353166183839999
204, epoch_train_loss=0.0007353166183839999
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0007353166183839999
205, epoch_train_loss=0.0007353166183839999
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0007353166183839999
206, epoch_train_loss=0.0007353166183839999
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0007353166183839999
207, epoch_train_loss=0.0007353166183839999
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.0007353166183839999
208, epoch_train_loss=0.0007353166183839999
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0007353166183839999
209, epoch_train_loss=0.0007353166183839999
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0007353166183839999
210, epoch_train_loss=0.0007353166183839999
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.0007353166183839999
211, epoch_train_loss=0.0007353166183839999
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.0007353166183839999
212, epoch_train_loss=0.0007353166183839999
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.0007353166183839999
213, epoch_train_loss=0.0007353166183839999
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0007353166183839999
214, epoch_train_loss=0.0007353166183839999
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0007353166183839999
215, epoch_train_loss=0.0007353166183839999
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.0007353166183839999
216, epoch_train_loss=0.0007353166183839999
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.0007353166183839999
217, epoch_train_loss=0.0007353166183839999
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0007353166183839999
218, epoch_train_loss=0.0007353166183839999
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0007353166183839999
219, epoch_train_loss=0.0007353166183839999
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.0007353166183839999
220, epoch_train_loss=0.0007353166183839999
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0007353166183839999
221, epoch_train_loss=0.0007353166183839999
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.0007353166183839999
222, epoch_train_loss=0.0007353166183839999
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.0007353166183839999
223, epoch_train_loss=0.0007353166183839999
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0007353166183839999
224, epoch_train_loss=0.0007353166183839999
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0007353166183839999
225, epoch_train_loss=0.0007353166183839999
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.0007353166183839999
226, epoch_train_loss=0.0007353166183839999
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.0007353166183839999
227, epoch_train_loss=0.0007353166183839999
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.0007353166183839999
228, epoch_train_loss=0.0007353166183839999
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0007353166183839999
229, epoch_train_loss=0.0007353166183839999
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.0007353166183839999
230, epoch_train_loss=0.0007353166183839999
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.0007353166183839999
231, epoch_train_loss=0.0007353166183839999
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.0007353166183839999
232, epoch_train_loss=0.0007353166183839999
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0007353166183839999
233, epoch_train_loss=0.0007353166183839999
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0007353166183839999
234, epoch_train_loss=0.0007353166183839999
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0007353166183839999
235, epoch_train_loss=0.0007353166183839999
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.0007353166183839999
236, epoch_train_loss=0.0007353166183839999
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0007353166183839999
237, epoch_train_loss=0.0007353166183839999
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.0007353166183839999
238, epoch_train_loss=0.0007353166183839999
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.0007353166183839999
239, epoch_train_loss=0.0007353166183839999
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.0007353166183839999
240, epoch_train_loss=0.0007353166183839999
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.0007353166183839999
241, epoch_train_loss=0.0007353166183839999
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0007353166183839999
242, epoch_train_loss=0.0007353166183839999
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.0007353166183839999
243, epoch_train_loss=0.0007353166183839999
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0007353166183839999
244, epoch_train_loss=0.0007353166183839999
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.0007353166183839999
245, epoch_train_loss=0.0007353166183839999
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.0007353166183839999
246, epoch_train_loss=0.0007353166183839999
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0007353166183839999
247, epoch_train_loss=0.0007353166183839999
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.0007353166183839999
248, epoch_train_loss=0.0007353166183839999
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.0007353166183839999
249, epoch_train_loss=0.0007353166183839999
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0007353166183839999
250, epoch_train_loss=0.0007353166183839999
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0007353166183839999
251, epoch_train_loss=0.0007353166183839999
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0007353166183839999
252, epoch_train_loss=0.0007353166183839999
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.0007353166183839999
253, epoch_train_loss=0.0007353166183839999
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.0007353166183839999
254, epoch_train_loss=0.0007353166183839999
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0007353166183839999
255, epoch_train_loss=0.0007353166183839999
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.0007353166183839999
256, epoch_train_loss=0.0007353166183839999
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0007353166183839999
257, epoch_train_loss=0.0007353166183839999
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.0007353166183839999
258, epoch_train_loss=0.0007353166183839999
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0007353166183839999
259, epoch_train_loss=0.0007353166183839999
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.0007353166183839999
260, epoch_train_loss=0.0007353166183839999
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.0007353166183839999
261, epoch_train_loss=0.0007353166183839999
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.0007353166183839999
262, epoch_train_loss=0.0007353166183839999
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.0007353166183839999
263, epoch_train_loss=0.0007353166183839999
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.0007353166183839999
264, epoch_train_loss=0.0007353166183839999
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.0007353166183839999
265, epoch_train_loss=0.0007353166183839999
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0007353166183839999
266, epoch_train_loss=0.0007353166183839999
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.0007353166183839999
267, epoch_train_loss=0.0007353166183839999
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0007353166183839999
268, epoch_train_loss=0.0007353166183839999
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.0007353166183839999
269, epoch_train_loss=0.0007353166183839999
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.0007353166183839999
270, epoch_train_loss=0.0007353166183839999
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.0007353166183839999
271, epoch_train_loss=0.0007353166183839999
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0007353166183839999
272, epoch_train_loss=0.0007353166183839999
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.0007353166183839999
273, epoch_train_loss=0.0007353166183839999
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0007353166183839999
274, epoch_train_loss=0.0007353166183839999
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0007353166183839999
275, epoch_train_loss=0.0007353166183839999
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.0007353166183839999
276, epoch_train_loss=0.0007353166183839999
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.0007353166183839999
277, epoch_train_loss=0.0007353166183839999
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0007353166183839999
278, epoch_train_loss=0.0007353166183839999
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.0007353166183839999
279, epoch_train_loss=0.0007353166183839999
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.0007353166183839999
280, epoch_train_loss=0.0007353166183839999
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.0007353166183839999
281, epoch_train_loss=0.0007353166183839999
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.0007353166183839999
282, epoch_train_loss=0.0007353166183839999
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.0007353166183839999
283, epoch_train_loss=0.0007353166183839999
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0007353166183839999
284, epoch_train_loss=0.0007353166183839999
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0007353166183839999
285, epoch_train_loss=0.0007353166183839999
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.0007353166183839999
286, epoch_train_loss=0.0007353166183839999
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.0007353166183839999
287, epoch_train_loss=0.0007353166183839999
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.0007353166183839999
288, epoch_train_loss=0.0007353166183839999
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0007353166183839999
289, epoch_train_loss=0.0007353166183839999
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.0007353166183839999
290, epoch_train_loss=0.0007353166183839999
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.0007353166183839999
291, epoch_train_loss=0.0007353166183839999
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.0007353166183839999
292, epoch_train_loss=0.0007353166183839999
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.0007353166183839999
293, epoch_train_loss=0.0007353166183839999
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.0007353166183839999
294, epoch_train_loss=0.0007353166183839999
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.0007353166183839999
295, epoch_train_loss=0.0007353166183839999
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.0007353166183839999
296, epoch_train_loss=0.0007353166183839999
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.0007353166183839999
297, epoch_train_loss=0.0007353166183839999
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.0007353166183839999
298, epoch_train_loss=0.0007353166183839999
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.0007353166183839999
299, epoch_train_loss=0.0007353166183839999
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.0007353166183839999
300, epoch_train_loss=0.0007353166183839999
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0007353166183839999
301, epoch_train_loss=0.0007353166183839999
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.0007353166183839999
302, epoch_train_loss=0.0007353166183839999
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.0007353166183839999
303, epoch_train_loss=0.0007353166183839999
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.0007353166183839999
304, epoch_train_loss=0.0007353166183839999
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.0007353166183839999
305, epoch_train_loss=0.0007353166183839999
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.0007353166183839999
306, epoch_train_loss=0.0007353166183839999
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.0007353166183839999
307, epoch_train_loss=0.0007353166183839999
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.0007353166183839999
308, epoch_train_loss=0.0007353166183839999
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.0007353166183839999
309, epoch_train_loss=0.0007353166183839999
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0007353166183839999
310, epoch_train_loss=0.0007353166183839999
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0007353166183839999
311, epoch_train_loss=0.0007353166183839999
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.0007353166183839999
312, epoch_train_loss=0.0007353166183839999
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.0007353166183839999
313, epoch_train_loss=0.0007353166183839999
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.0007353166183839999
314, epoch_train_loss=0.0007353166183839999
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.0007353166183839999
315, epoch_train_loss=0.0007353166183839999
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0007353166183839999
316, epoch_train_loss=0.0007353166183839999
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.0007353166183839999
317, epoch_train_loss=0.0007353166183839999
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.0007353166183839999
318, epoch_train_loss=0.0007353166183839999
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.0007353166183839999
319, epoch_train_loss=0.0007353166183839999
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.0007353166183839999
320, epoch_train_loss=0.0007353166183839999
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.0007353166183839999
321, epoch_train_loss=0.0007353166183839999
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.0007353166183839999
322, epoch_train_loss=0.0007353166183839999
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0007353166183839999
323, epoch_train_loss=0.0007353166183839999
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.0007353166183839999
324, epoch_train_loss=0.0007353166183839999
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.0007353166183839999
325, epoch_train_loss=0.0007353166183839999
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.0007353166183839999
326, epoch_train_loss=0.0007353166183839999
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.0007353166183839999
327, epoch_train_loss=0.0007353166183839999
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.0007353166183839999
328, epoch_train_loss=0.0007353166183839999
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.0007353166183839999
329, epoch_train_loss=0.0007353166183839999
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.0007353166183839999
330, epoch_train_loss=0.0007353166183839999
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0007353166183839999
331, epoch_train_loss=0.0007353166183839999
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0007353166183839999
332, epoch_train_loss=0.0007353166183839999
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0007353166183839999
333, epoch_train_loss=0.0007353166183839999
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.0007353166183839999
334, epoch_train_loss=0.0007353166183839999
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.0007353166183839999
335, epoch_train_loss=0.0007353166183839999
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.0007353166183839999
336, epoch_train_loss=0.0007353166183839999
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0007353166183839999
337, epoch_train_loss=0.0007353166183839999
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.0007353166183839999
338, epoch_train_loss=0.0007353166183839999
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0007353166183839999
339, epoch_train_loss=0.0007353166183839999
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.0007353166183839999
340, epoch_train_loss=0.0007353166183839999
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0007353166183839999
341, epoch_train_loss=0.0007353166183839999
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.0007353166183839999
342, epoch_train_loss=0.0007353166183839999
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.0007353166183839999
343, epoch_train_loss=0.0007353166183839999
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.0007353166183839999
344, epoch_train_loss=0.0007353166183839999
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.0007353166183839999
345, epoch_train_loss=0.0007353166183839999
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.0007353166183839999
346, epoch_train_loss=0.0007353166183839999
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0007353166183839999
347, epoch_train_loss=0.0007353166183839999
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0007353166183839999
348, epoch_train_loss=0.0007353166183839999
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.0007353166183839999
349, epoch_train_loss=0.0007353166183839999
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.0007353166183839999
350, epoch_train_loss=0.0007353166183839999
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0007353166183839999
351, epoch_train_loss=0.0007353166183839999
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.0007353166183839999
352, epoch_train_loss=0.0007353166183839999
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.0007353166183839999
353, epoch_train_loss=0.0007353166183839999
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.0007353166183839999
354, epoch_train_loss=0.0007353166183839999
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.0007353166183839999
355, epoch_train_loss=0.0007353166183839999
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.0007353166183839999
356, epoch_train_loss=0.0007353166183839999
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0007353166183839999
357, epoch_train_loss=0.0007353166183839999
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.0007353166183839999
358, epoch_train_loss=0.0007353166183839999
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.0007353166183839999
359, epoch_train_loss=0.0007353166183839999
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.0007353166183839999
360, epoch_train_loss=0.0007353166183839999
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.0007353166183839999
361, epoch_train_loss=0.0007353166183839999
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.0007353166183839999
362, epoch_train_loss=0.0007353166183839999
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0007353166183839999
363, epoch_train_loss=0.0007353166183839999
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.0007353166183839999
364, epoch_train_loss=0.0007353166183839999
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.0007353166183839999
365, epoch_train_loss=0.0007353166183839999
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007353166183839999
366, epoch_train_loss=0.0007353166183839999
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0007353166183839999
367, epoch_train_loss=0.0007353166183839999
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0007353166183839999
368, epoch_train_loss=0.0007353166183839999
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0007353166183839999
369, epoch_train_loss=0.0007353166183839999
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.0007353166183839999
370, epoch_train_loss=0.0007353166183839999
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.0007353166183839999
371, epoch_train_loss=0.0007353166183839999
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.0007353166183839999
372, epoch_train_loss=0.0007353166183839999
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.0007353166183839999
373, epoch_train_loss=0.0007353166183839999
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0007353166183839999
374, epoch_train_loss=0.0007353166183839999
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0007353166183839999
375, epoch_train_loss=0.0007353166183839999
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.0007353166183839999
376, epoch_train_loss=0.0007353166183839999
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.0007353166183839999
377, epoch_train_loss=0.0007353166183839999
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0007353166183839999
378, epoch_train_loss=0.0007353166183839999
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0007353166183839999
379, epoch_train_loss=0.0007353166183839999
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.0007353166183839999
380, epoch_train_loss=0.0007353166183839999
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.0007353166183839999
381, epoch_train_loss=0.0007353166183839999
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0007353166183839999
382, epoch_train_loss=0.0007353166183839999
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0007353166183839999
383, epoch_train_loss=0.0007353166183839999
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0007353166183839999
384, epoch_train_loss=0.0007353166183839999
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0007353166183839999
385, epoch_train_loss=0.0007353166183839999
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.0007353166183839999
386, epoch_train_loss=0.0007353166183839999
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0007353166183839999
387, epoch_train_loss=0.0007353166183839999
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.0007353166183839999
388, epoch_train_loss=0.0007353166183839999
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0007353166183839999
389, epoch_train_loss=0.0007353166183839999
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0007353166183839999
390, epoch_train_loss=0.0007353166183839999
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0007353166183839999
391, epoch_train_loss=0.0007353166183839999
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.0007353166183839999
392, epoch_train_loss=0.0007353166183839999
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.0007353166183839999
393, epoch_train_loss=0.0007353166183839999
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007353166183839999
394, epoch_train_loss=0.0007353166183839999
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0007353166183839999
395, epoch_train_loss=0.0007353166183839999
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.0007353166183839999
396, epoch_train_loss=0.0007353166183839999
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.0007353166183839999
397, epoch_train_loss=0.0007353166183839999
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.0007353166183839999
398, epoch_train_loss=0.0007353166183839999
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0007353166183839999
399, epoch_train_loss=0.0007353166183839999
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0007353166183839999
400, epoch_train_loss=0.0007353166183839999
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0007353166183839999
401, epoch_train_loss=0.0007353166183839999
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0007353166183839999
402, epoch_train_loss=0.0007353166183839999
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.0007353166183839999
403, epoch_train_loss=0.0007353166183839999
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.0007353166183839999
404, epoch_train_loss=0.0007353166183839999
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.0007353166183839999
405, epoch_train_loss=0.0007353166183839999
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0007353166183839999
406, epoch_train_loss=0.0007353166183839999
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.0007353166183839999
407, epoch_train_loss=0.0007353166183839999
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0007353166183839999
408, epoch_train_loss=0.0007353166183839999
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0007353166183839999
409, epoch_train_loss=0.0007353166183839999
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0007353166183839999
410, epoch_train_loss=0.0007353166183839999
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.0007353166183839999
411, epoch_train_loss=0.0007353166183839999
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.0007353166183839999
412, epoch_train_loss=0.0007353166183839999
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0007353166183839999
413, epoch_train_loss=0.0007353166183839999
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0007353166183839999
414, epoch_train_loss=0.0007353166183839999
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0007353166183839999
415, epoch_train_loss=0.0007353166183839999
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0007353166183839999
416, epoch_train_loss=0.0007353166183839999
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.0007353166183839999
417, epoch_train_loss=0.0007353166183839999
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.0007353166183839999
418, epoch_train_loss=0.0007353166183839999
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.0007353166183839999
419, epoch_train_loss=0.0007353166183839999
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.0007353166183839999
420, epoch_train_loss=0.0007353166183839999
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.0007353166183839999
421, epoch_train_loss=0.0007353166183839999
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.0007353166183839999
422, epoch_train_loss=0.0007353166183839999
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0007353166183839999
423, epoch_train_loss=0.0007353166183839999
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.0007353166183839999
424, epoch_train_loss=0.0007353166183839999
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.0007353166183839999
425, epoch_train_loss=0.0007353166183839999
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0007353166183839999
426, epoch_train_loss=0.0007353166183839999
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.0007353166183839999
427, epoch_train_loss=0.0007353166183839999
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.0007353166183839999
428, epoch_train_loss=0.0007353166183839999
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.0007353166183839999
429, epoch_train_loss=0.0007353166183839999
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.0007353166183839999
430, epoch_train_loss=0.0007353166183839999
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.0007353166183839999
431, epoch_train_loss=0.0007353166183839999
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.0007353166183839999
432, epoch_train_loss=0.0007353166183839999
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.0007353166183839999
433, epoch_train_loss=0.0007353166183839999
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0007353166183839999
434, epoch_train_loss=0.0007353166183839999
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.0007353166183839999
435, epoch_train_loss=0.0007353166183839999
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.0007353166183839999
436, epoch_train_loss=0.0007353166183839999
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.0007353166183839999
437, epoch_train_loss=0.0007353166183839999
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0007353166183839999
438, epoch_train_loss=0.0007353166183839999
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0007353166183839999
439, epoch_train_loss=0.0007353166183839999
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0007353166183839999
440, epoch_train_loss=0.0007353166183839999
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.0007353166183839999
441, epoch_train_loss=0.0007353166183839999
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0007353166183839999
442, epoch_train_loss=0.0007353166183839999
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0007353166183839999
443, epoch_train_loss=0.0007353166183839999
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.0007353166183839999
444, epoch_train_loss=0.0007353166183839999
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.0007353166183839999
445, epoch_train_loss=0.0007353166183839999
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0007353166183839999
446, epoch_train_loss=0.0007353166183839999
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.0007353166183839999
447, epoch_train_loss=0.0007353166183839999
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.0007353166183839999
448, epoch_train_loss=0.0007353166183839999
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.0007353166183839999
449, epoch_train_loss=0.0007353166183839999
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.0007353166183839999
450, epoch_train_loss=0.0007353166183839999
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0007353166183839999
451, epoch_train_loss=0.0007353166183839999
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.0007353166183839999
452, epoch_train_loss=0.0007353166183839999
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0007353166183839999
453, epoch_train_loss=0.0007353166183839999
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0007353166183839999
454, epoch_train_loss=0.0007353166183839999
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0007353166183839999
455, epoch_train_loss=0.0007353166183839999
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.0007353166183839999
456, epoch_train_loss=0.0007353166183839999
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0007353166183839999
457, epoch_train_loss=0.0007353166183839999
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.0007353166183839999
458, epoch_train_loss=0.0007353166183839999
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.0007353166183839999
459, epoch_train_loss=0.0007353166183839999
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.0007353166183839999
460, epoch_train_loss=0.0007353166183839999
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.0007353166183839999
461, epoch_train_loss=0.0007353166183839999
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0007353166183839999
462, epoch_train_loss=0.0007353166183839999
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0007353166183839999
463, epoch_train_loss=0.0007353166183839999
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.0007353166183839999
464, epoch_train_loss=0.0007353166183839999
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0007353166183839999
465, epoch_train_loss=0.0007353166183839999
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0007353166183839999
466, epoch_train_loss=0.0007353166183839999
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.0007353166183839999
467, epoch_train_loss=0.0007353166183839999
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.0007353166183839999
468, epoch_train_loss=0.0007353166183839999
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0007353166183839999
469, epoch_train_loss=0.0007353166183839999
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.0007353166183839999
470, epoch_train_loss=0.0007353166183839999
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.0007353166183839999
471, epoch_train_loss=0.0007353166183839999
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.0007353166183839999
472, epoch_train_loss=0.0007353166183839999
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.0007353166183839999
473, epoch_train_loss=0.0007353166183839999
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0007353166183839999
474, epoch_train_loss=0.0007353166183839999
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.0007353166183839999
475, epoch_train_loss=0.0007353166183839999
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.0007353166183839999
476, epoch_train_loss=0.0007353166183839999
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.0007353166183839999
477, epoch_train_loss=0.0007353166183839999
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.0007353166183839999
478, epoch_train_loss=0.0007353166183839999
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.0007353166183839999
479, epoch_train_loss=0.0007353166183839999
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.0007353166183839999
480, epoch_train_loss=0.0007353166183839999
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.0007353166183839999
481, epoch_train_loss=0.0007353166183839999
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.0007353166183839999
482, epoch_train_loss=0.0007353166183839999
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.0007353166183839999
483, epoch_train_loss=0.0007353166183839999
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.0007353166183839999
484, epoch_train_loss=0.0007353166183839999
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.0007353166183839999
485, epoch_train_loss=0.0007353166183839999
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.0007353166183839999
486, epoch_train_loss=0.0007353166183839999
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0007353166183839999
487, epoch_train_loss=0.0007353166183839999
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0007353166183839999
488, epoch_train_loss=0.0007353166183839999
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.0007353166183839999
489, epoch_train_loss=0.0007353166183839999
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0007353166183839999
490, epoch_train_loss=0.0007353166183839999
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0007353166183839999
491, epoch_train_loss=0.0007353166183839999
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.0007353166183839999
492, epoch_train_loss=0.0007353166183839999
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0007353166183839999
493, epoch_train_loss=0.0007353166183839999
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0007353166183839999
494, epoch_train_loss=0.0007353166183839999
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.0007353166183839999
495, epoch_train_loss=0.0007353166183839999
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0007353166183839999
496, epoch_train_loss=0.0007353166183839999
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0007353166183839999
497, epoch_train_loss=0.0007353166183839999
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.0007353166183839999
498, epoch_train_loss=0.0007353166183839999
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.0007353166183839999
499, epoch_train_loss=0.0007353166183839999
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.0007353166183839999
500, epoch_train_loss=0.0007353166183839999
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.0007353166183839999
501, epoch_train_loss=0.0007353166183839999
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.0007353166183839999
502, epoch_train_loss=0.0007353166183839999
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.0007353166183839999
503, epoch_train_loss=0.0007353166183839999
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0007353166183839999
504, epoch_train_loss=0.0007353166183839999
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.0007353166183839999
505, epoch_train_loss=0.0007353166183839999
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.0007353166183839999
506, epoch_train_loss=0.0007353166183839999
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.0007353166183839999
507, epoch_train_loss=0.0007353166183839999
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.0007353166183839999
508, epoch_train_loss=0.0007353166183839999
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.0007353166183839999
509, epoch_train_loss=0.0007353166183839999
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.0007353166183839999
510, epoch_train_loss=0.0007353166183839999
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.0007353166183839999
511, epoch_train_loss=0.0007353166183839999
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.0007353166183839999
512, epoch_train_loss=0.0007353166183839999
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.0007353166183839999
513, epoch_train_loss=0.0007353166183839999
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0007353166183839999
514, epoch_train_loss=0.0007353166183839999
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.0007353166183839999
515, epoch_train_loss=0.0007353166183839999
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.0007353166183839999
516, epoch_train_loss=0.0007353166183839999
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0007353166183839999
517, epoch_train_loss=0.0007353166183839999
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.0007353166183839999
518, epoch_train_loss=0.0007353166183839999
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.0007353166183839999
519, epoch_train_loss=0.0007353166183839999
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.0007353166183839999
520, epoch_train_loss=0.0007353166183839999
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.0007353166183839999
521, epoch_train_loss=0.0007353166183839999
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.0007353166183839999
522, epoch_train_loss=0.0007353166183839999
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0007353166183839999
523, epoch_train_loss=0.0007353166183839999
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.0007353166183839999
524, epoch_train_loss=0.0007353166183839999
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0007353166183839999
525, epoch_train_loss=0.0007353166183839999
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.0007353166183839999
526, epoch_train_loss=0.0007353166183839999
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.0007353166183839999
527, epoch_train_loss=0.0007353166183839999
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.0007353166183839999
528, epoch_train_loss=0.0007353166183839999
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0007353166183839999
529, epoch_train_loss=0.0007353166183839999
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.0007353166183839999
530, epoch_train_loss=0.0007353166183839999
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.0007353166183839999
531, epoch_train_loss=0.0007353166183839999
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.0007353166183839999
532, epoch_train_loss=0.0007353166183839999
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.0007353166183839999
533, epoch_train_loss=0.0007353166183839999
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.0007353166183839999
534, epoch_train_loss=0.0007353166183839999
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.0007353166183839999
535, epoch_train_loss=0.0007353166183839999
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0007353166183839999
536, epoch_train_loss=0.0007353166183839999
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.0007353166183839999
537, epoch_train_loss=0.0007353166183839999
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.0007353166183839999
538, epoch_train_loss=0.0007353166183839999
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.0007353166183839999
539, epoch_train_loss=0.0007353166183839999
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.0007353166183839999
540, epoch_train_loss=0.0007353166183839999
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.0007353166183839999
541, epoch_train_loss=0.0007353166183839999
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.0007353166183839999
542, epoch_train_loss=0.0007353166183839999
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0007353166183839999
543, epoch_train_loss=0.0007353166183839999
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.0007353166183839999
544, epoch_train_loss=0.0007353166183839999
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.0007353166183839999
545, epoch_train_loss=0.0007353166183839999
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.0007353166183839999
546, epoch_train_loss=0.0007353166183839999
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.0007353166183839999
547, epoch_train_loss=0.0007353166183839999
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.0007353166183839999
548, epoch_train_loss=0.0007353166183839999
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.0007353166183839999
549, epoch_train_loss=0.0007353166183839999
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.0007353166183839999
550, epoch_train_loss=0.0007353166183839999
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0007353166183839999
551, epoch_train_loss=0.0007353166183839999
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.0007353166183839999
552, epoch_train_loss=0.0007353166183839999
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0007353166183839999
553, epoch_train_loss=0.0007353166183839999
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.0007353166183839999
554, epoch_train_loss=0.0007353166183839999
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.0007353166183839999
555, epoch_train_loss=0.0007353166183839999
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0007353166183839999
556, epoch_train_loss=0.0007353166183839999
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.0007353166183839999
557, epoch_train_loss=0.0007353166183839999
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.0007353166183839999
558, epoch_train_loss=0.0007353166183839999
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.0007353166183839999
559, epoch_train_loss=0.0007353166183839999
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.0007353166183839999
560, epoch_train_loss=0.0007353166183839999
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.0007353166183839999
561, epoch_train_loss=0.0007353166183839999
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.0007353166183839999
562, epoch_train_loss=0.0007353166183839999
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.0007353166183839999
563, epoch_train_loss=0.0007353166183839999
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.0007353166183839999
564, epoch_train_loss=0.0007353166183839999
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.0007353166183839999
565, epoch_train_loss=0.0007353166183839999
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.0007353166183839999
566, epoch_train_loss=0.0007353166183839999
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0007353166183839999
567, epoch_train_loss=0.0007353166183839999
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0007353166183839999
568, epoch_train_loss=0.0007353166183839999
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.0007353166183839999
569, epoch_train_loss=0.0007353166183839999
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0007353166183839999
570, epoch_train_loss=0.0007353166183839999
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.0007353166183839999
571, epoch_train_loss=0.0007353166183839999
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.0007353166183839999
572, epoch_train_loss=0.0007353166183839999
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.0007353166183839999
573, epoch_train_loss=0.0007353166183839999
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.0007353166183839999
574, epoch_train_loss=0.0007353166183839999
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.0007353166183839999
575, epoch_train_loss=0.0007353166183839999
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.0007353166183839999
576, epoch_train_loss=0.0007353166183839999
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.0007353166183839999
577, epoch_train_loss=0.0007353166183839999
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.0007353166183839999
578, epoch_train_loss=0.0007353166183839999
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.0007353166183839999
579, epoch_train_loss=0.0007353166183839999
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0007353166183839999
580, epoch_train_loss=0.0007353166183839999
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.0007353166183839999
581, epoch_train_loss=0.0007353166183839999
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.0007353166183839999
582, epoch_train_loss=0.0007353166183839999
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.0007353166183839999
583, epoch_train_loss=0.0007353166183839999
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.0007353166183839999
584, epoch_train_loss=0.0007353166183839999
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.0007353166183839999
585, epoch_train_loss=0.0007353166183839999
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.0007353166183839999
586, epoch_train_loss=0.0007353166183839999
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.0007353166183839999
587, epoch_train_loss=0.0007353166183839999
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.0007353166183839999
588, epoch_train_loss=0.0007353166183839999
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.0007353166183839999
589, epoch_train_loss=0.0007353166183839999
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.0007353166183839999
590, epoch_train_loss=0.0007353166183839999
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0007353166183839999
591, epoch_train_loss=0.0007353166183839999
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.0007353166183839999
592, epoch_train_loss=0.0007353166183839999
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.0007353166183839999
593, epoch_train_loss=0.0007353166183839999
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.0007353166183839999
594, epoch_train_loss=0.0007353166183839999
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.0007353166183839999
595, epoch_train_loss=0.0007353166183839999
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.0007353166183839999
596, epoch_train_loss=0.0007353166183839999
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0007353166183839999
597, epoch_train_loss=0.0007353166183839999
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.0007353166183839999
598, epoch_train_loss=0.0007353166183839999
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.0007353166183839999
599, epoch_train_loss=0.0007353166183839999
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.0007353166183839999
600, epoch_train_loss=0.0007353166183839999
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.0007353166183839999
601, epoch_train_loss=0.0007353166183839999
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0007353166183839999
602, epoch_train_loss=0.0007353166183839999
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.0007353166183839999
603, epoch_train_loss=0.0007353166183839999
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.0007353166183839999
604, epoch_train_loss=0.0007353166183839999
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.0007353166183839999
605, epoch_train_loss=0.0007353166183839999
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.0007353166183839999
606, epoch_train_loss=0.0007353166183839999
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.0007353166183839999
607, epoch_train_loss=0.0007353166183839999
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.0007353166183839999
608, epoch_train_loss=0.0007353166183839999
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.0007353166183839999
609, epoch_train_loss=0.0007353166183839999
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.0007353166183839999
610, epoch_train_loss=0.0007353166183839999
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0007353166183839999
611, epoch_train_loss=0.0007353166183839999
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.0007353166183839999
612, epoch_train_loss=0.0007353166183839999
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.0007353166183839999
613, epoch_train_loss=0.0007353166183839999
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.0007353166183839999
614, epoch_train_loss=0.0007353166183839999
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.0007353166183839999
615, epoch_train_loss=0.0007353166183839999
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.0007353166183839999
616, epoch_train_loss=0.0007353166183839999
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.0007353166183839999
617, epoch_train_loss=0.0007353166183839999
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.0007353166183839999
618, epoch_train_loss=0.0007353166183839999
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.0007353166183839999
619, epoch_train_loss=0.0007353166183839999
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.0007353166183839999
620, epoch_train_loss=0.0007353166183839999
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.0007353166183839999
621, epoch_train_loss=0.0007353166183839999
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.0007353166183839999
622, epoch_train_loss=0.0007353166183839999
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.0007353166183839999
623, epoch_train_loss=0.0007353166183839999
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.0007353166183839999
624, epoch_train_loss=0.0007353166183839999
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.0007353166183839999
625, epoch_train_loss=0.0007353166183839999
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.0007353166183839999
626, epoch_train_loss=0.0007353166183839999
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.0007353166183839999
627, epoch_train_loss=0.0007353166183839999
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0007353166183839999
628, epoch_train_loss=0.0007353166183839999
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0007353166183839999
629, epoch_train_loss=0.0007353166183839999
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.0007353166183839999
630, epoch_train_loss=0.0007353166183839999
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.0007353166183839999
631, epoch_train_loss=0.0007353166183839999
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.0007353166183839999
632, epoch_train_loss=0.0007353166183839999
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.0007353166183839999
633, epoch_train_loss=0.0007353166183839999
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.0007353166183839999
634, epoch_train_loss=0.0007353166183839999
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.0007353166183839999
635, epoch_train_loss=0.0007353166183839999
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.0007353166183839999
636, epoch_train_loss=0.0007353166183839999
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.0007353166183839999
637, epoch_train_loss=0.0007353166183839999
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.0007353166183839999
638, epoch_train_loss=0.0007353166183839999
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.0007353166183839999
639, epoch_train_loss=0.0007353166183839999
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.0007353166183839999
640, epoch_train_loss=0.0007353166183839999
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.0007353166183839999
641, epoch_train_loss=0.0007353166183839999
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.0007353166183839999
642, epoch_train_loss=0.0007353166183839999
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.0007353166183839999
643, epoch_train_loss=0.0007353166183839999
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.0007353166183839999
644, epoch_train_loss=0.0007353166183839999
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0007353166183839999
645, epoch_train_loss=0.0007353166183839999
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0007353166183839999
646, epoch_train_loss=0.0007353166183839999
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.0007353166183839999
647, epoch_train_loss=0.0007353166183839999
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0007353166183839999
648, epoch_train_loss=0.0007353166183839999
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.0007353166183839999
649, epoch_train_loss=0.0007353166183839999
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.0007353166183839999
650, epoch_train_loss=0.0007353166183839999
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.0007353166183839999
651, epoch_train_loss=0.0007353166183839999
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.0007353166183839999
652, epoch_train_loss=0.0007353166183839999
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.0007353166183839999
653, epoch_train_loss=0.0007353166183839999
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.0007353166183839999
654, epoch_train_loss=0.0007353166183839999
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0007353166183839999
655, epoch_train_loss=0.0007353166183839999
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.0007353166183839999
656, epoch_train_loss=0.0007353166183839999
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.0007353166183839999
657, epoch_train_loss=0.0007353166183839999
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.0007353166183839999
658, epoch_train_loss=0.0007353166183839999
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.0007353166183839999
659, epoch_train_loss=0.0007353166183839999
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.0007353166183839999
660, epoch_train_loss=0.0007353166183839999
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0007353166183839999
661, epoch_train_loss=0.0007353166183839999
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.0007353166183839999
662, epoch_train_loss=0.0007353166183839999
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0007353166183839999
663, epoch_train_loss=0.0007353166183839999
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0007353166183839999
664, epoch_train_loss=0.0007353166183839999
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.0007353166183839999
665, epoch_train_loss=0.0007353166183839999
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.0007353166183839999
666, epoch_train_loss=0.0007353166183839999
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0007353166183839999
667, epoch_train_loss=0.0007353166183839999
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.0007353166183839999
668, epoch_train_loss=0.0007353166183839999
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.0007353166183839999
669, epoch_train_loss=0.0007353166183839999
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.0007353166183839999
670, epoch_train_loss=0.0007353166183839999
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.0007353166183839999
671, epoch_train_loss=0.0007353166183839999
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.0007353166183839999
672, epoch_train_loss=0.0007353166183839999
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.0007353166183839999
673, epoch_train_loss=0.0007353166183839999
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.0007353166183839999
674, epoch_train_loss=0.0007353166183839999
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.0007353166183839999
675, epoch_train_loss=0.0007353166183839999
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0007353166183839999
676, epoch_train_loss=0.0007353166183839999
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.0007353166183839999
677, epoch_train_loss=0.0007353166183839999
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.0007353166183839999
678, epoch_train_loss=0.0007353166183839999
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.0007353166183839999
679, epoch_train_loss=0.0007353166183839999
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0007353166183839999
680, epoch_train_loss=0.0007353166183839999
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0007353166183839999
681, epoch_train_loss=0.0007353166183839999
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0007353166183839999
682, epoch_train_loss=0.0007353166183839999
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.0007353166183839999
683, epoch_train_loss=0.0007353166183839999
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0007353166183839999
684, epoch_train_loss=0.0007353166183839999
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.0007353166183839999
685, epoch_train_loss=0.0007353166183839999
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.0007353166183839999
686, epoch_train_loss=0.0007353166183839999
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0007353166183839999
687, epoch_train_loss=0.0007353166183839999
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.0007353166183839999
688, epoch_train_loss=0.0007353166183839999
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.0007353166183839999
689, epoch_train_loss=0.0007353166183839999
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0007353166183839999
690, epoch_train_loss=0.0007353166183839999
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0007353166183839999
691, epoch_train_loss=0.0007353166183839999
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.0007353166183839999
692, epoch_train_loss=0.0007353166183839999
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.0007353166183839999
693, epoch_train_loss=0.0007353166183839999
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.0007353166183839999
694, epoch_train_loss=0.0007353166183839999
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0007353166183839999
695, epoch_train_loss=0.0007353166183839999
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0007353166183839999
696, epoch_train_loss=0.0007353166183839999
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.0007353166183839999
697, epoch_train_loss=0.0007353166183839999
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.0007353166183839999
698, epoch_train_loss=0.0007353166183839999
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0007353166183839999
699, epoch_train_loss=0.0007353166183839999
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0007353166183839999
700, epoch_train_loss=0.0007353166183839999
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.0007353166183839999
701, epoch_train_loss=0.0007353166183839999
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.0007353166183839999
702, epoch_train_loss=0.0007353166183839999
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0007353166183839999
703, epoch_train_loss=0.0007353166183839999
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.0007353166183839999
704, epoch_train_loss=0.0007353166183839999
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.0007353166183839999
705, epoch_train_loss=0.0007353166183839999
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0007353166183839999
706, epoch_train_loss=0.0007353166183839999
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0007353166183839999
707, epoch_train_loss=0.0007353166183839999
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0007353166183839999
708, epoch_train_loss=0.0007353166183839999
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0007353166183839999
709, epoch_train_loss=0.0007353166183839999
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.0007353166183839999
710, epoch_train_loss=0.0007353166183839999
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.0007353166183839999
711, epoch_train_loss=0.0007353166183839999
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0007353166183839999
712, epoch_train_loss=0.0007353166183839999
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.0007353166183839999
713, epoch_train_loss=0.0007353166183839999
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.0007353166183839999
714, epoch_train_loss=0.0007353166183839999
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.0007353166183839999
715, epoch_train_loss=0.0007353166183839999
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.0007353166183839999
716, epoch_train_loss=0.0007353166183839999
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0007353166183839999
717, epoch_train_loss=0.0007353166183839999
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.0007353166183839999
718, epoch_train_loss=0.0007353166183839999
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0007353166183839999
719, epoch_train_loss=0.0007353166183839999
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.0007353166183839999
720, epoch_train_loss=0.0007353166183839999
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0007353166183839999
721, epoch_train_loss=0.0007353166183839999
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.0007353166183839999
722, epoch_train_loss=0.0007353166183839999
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.0007353166183839999
723, epoch_train_loss=0.0007353166183839999
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.0007353166183839999
724, epoch_train_loss=0.0007353166183839999
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.0007353166183839999
725, epoch_train_loss=0.0007353166183839999
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0007353166183839999
726, epoch_train_loss=0.0007353166183839999
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.0007353166183839999
727, epoch_train_loss=0.0007353166183839999
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0007353166183839999
728, epoch_train_loss=0.0007353166183839999
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0007353166183839999
729, epoch_train_loss=0.0007353166183839999
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.0007353166183839999
730, epoch_train_loss=0.0007353166183839999
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.0007353166183839999
731, epoch_train_loss=0.0007353166183839999
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.0007353166183839999
732, epoch_train_loss=0.0007353166183839999
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.0007353166183839999
733, epoch_train_loss=0.0007353166183839999
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.0007353166183839999
734, epoch_train_loss=0.0007353166183839999
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.0007353166183839999
735, epoch_train_loss=0.0007353166183839999
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.0007353166183839999
736, epoch_train_loss=0.0007353166183839999
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0007353166183839999
737, epoch_train_loss=0.0007353166183839999
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.0007353166183839999
738, epoch_train_loss=0.0007353166183839999
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.0007353166183839999
739, epoch_train_loss=0.0007353166183839999
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.0007353166183839999
740, epoch_train_loss=0.0007353166183839999
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.0007353166183839999
741, epoch_train_loss=0.0007353166183839999
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.0007353166183839999
742, epoch_train_loss=0.0007353166183839999
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.0007353166183839999
743, epoch_train_loss=0.0007353166183839999
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.0007353166183839999
744, epoch_train_loss=0.0007353166183839999
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.0007353166183839999
745, epoch_train_loss=0.0007353166183839999
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.0007353166183839999
746, epoch_train_loss=0.0007353166183839999
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.0007353166183839999
747, epoch_train_loss=0.0007353166183839999
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.0007353166183839999
748, epoch_train_loss=0.0007353166183839999
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0007353166183839999
749, epoch_train_loss=0.0007353166183839999
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0007353166183839999
750, epoch_train_loss=0.0007353166183839999
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0007353166183839999
751, epoch_train_loss=0.0007353166183839999
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.0007353166183839999
752, epoch_train_loss=0.0007353166183839999
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.0007353166183839999
753, epoch_train_loss=0.0007353166183839999
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.0007353166183839999
754, epoch_train_loss=0.0007353166183839999
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.0007353166183839999
755, epoch_train_loss=0.0007353166183839999
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.0007353166183839999
756, epoch_train_loss=0.0007353166183839999
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.0007353166183839999
757, epoch_train_loss=0.0007353166183839999
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.0007353166183839999
758, epoch_train_loss=0.0007353166183839999
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.0007353166183839999
759, epoch_train_loss=0.0007353166183839999
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.0007353166183839999
760, epoch_train_loss=0.0007353166183839999
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.0007353166183839999
761, epoch_train_loss=0.0007353166183839999
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.0007353166183839999
762, epoch_train_loss=0.0007353166183839999
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 0.0007353166183839999
763, epoch_train_loss=0.0007353166183839999
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 0.0007353166183839999
764, epoch_train_loss=0.0007353166183839999
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.0007353166183839999
765, epoch_train_loss=0.0007353166183839999
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 0.0007353166183839999
766, epoch_train_loss=0.0007353166183839999
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 0.0007353166183839999
767, epoch_train_loss=0.0007353166183839999
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 0.0007353166183839999
768, epoch_train_loss=0.0007353166183839999
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 0.0007353166183839999
769, epoch_train_loss=0.0007353166183839999
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 0.0007353166183839999
770, epoch_train_loss=0.0007353166183839999
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 0.0007353166183839999
771, epoch_train_loss=0.0007353166183839999
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 0.0007353166183839999
772, epoch_train_loss=0.0007353166183839999
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 0.0007353166183839999
773, epoch_train_loss=0.0007353166183839999
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 0.0007353166183839999
774, epoch_train_loss=0.0007353166183839999
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 0.0007353166183839999
775, epoch_train_loss=0.0007353166183839999
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 0.0007353166183839999
776, epoch_train_loss=0.0007353166183839999
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 0.0007353166183839999
777, epoch_train_loss=0.0007353166183839999
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 0.0007353166183839999
778, epoch_train_loss=0.0007353166183839999
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 0.0007353166183839999
779, epoch_train_loss=0.0007353166183839999
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 0.0007353166183839999
780, epoch_train_loss=0.0007353166183839999
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 0.0007353166183839999
781, epoch_train_loss=0.0007353166183839999
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 0.0007353166183839999
782, epoch_train_loss=0.0007353166183839999
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 0.0007353166183839999
783, epoch_train_loss=0.0007353166183839999
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 0.0007353166183839999
784, epoch_train_loss=0.0007353166183839999
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 0.0007353166183839999
785, epoch_train_loss=0.0007353166183839999
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 0.0007353166183839999
786, epoch_train_loss=0.0007353166183839999
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 0.0007353166183839999
787, epoch_train_loss=0.0007353166183839999
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 0.0007353166183839999
788, epoch_train_loss=0.0007353166183839999
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 0.0007353166183839999
789, epoch_train_loss=0.0007353166183839999
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 0.0007353166183839999
790, epoch_train_loss=0.0007353166183839999
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 0.0007353166183839999
791, epoch_train_loss=0.0007353166183839999
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 0.0007353166183839999
792, epoch_train_loss=0.0007353166183839999
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 0.0007353166183839999
793, epoch_train_loss=0.0007353166183839999
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 0.0007353166183839999
794, epoch_train_loss=0.0007353166183839999
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 0.0007353166183839999
795, epoch_train_loss=0.0007353166183839999
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 0.0007353166183839999
796, epoch_train_loss=0.0007353166183839999
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 0.0007353166183839999
797, epoch_train_loss=0.0007353166183839999
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 0.0007353166183839999
798, epoch_train_loss=0.0007353166183839999
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 0.0007353166183839999
799, epoch_train_loss=0.0007353166183839999
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 0.0007353166183839999
800, epoch_train_loss=0.0007353166183839999
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 0.0007353166183839999
801, epoch_train_loss=0.0007353166183839999
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 0.0007353166183839999
802, epoch_train_loss=0.0007353166183839999
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 0.0007353166183839999
803, epoch_train_loss=0.0007353166183839999
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 0.0007353166183839999
804, epoch_train_loss=0.0007353166183839999
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 0.0007353166183839999
805, epoch_train_loss=0.0007353166183839999
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 0.0007353166183839999
806, epoch_train_loss=0.0007353166183839999
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 0.0007353166183839999
807, epoch_train_loss=0.0007353166183839999
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 0.0007353166183839999
808, epoch_train_loss=0.0007353166183839999
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 0.0007353166183839999
809, epoch_train_loss=0.0007353166183839999
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 0.0007353166183839999
810, epoch_train_loss=0.0007353166183839999
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 0.0007353166183839999
811, epoch_train_loss=0.0007353166183839999
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 0.0007353166183839999
812, epoch_train_loss=0.0007353166183839999
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 0.0007353166183839999
813, epoch_train_loss=0.0007353166183839999
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 0.0007353166183839999
814, epoch_train_loss=0.0007353166183839999
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 0.0007353166183839999
815, epoch_train_loss=0.0007353166183839999
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 0.0007353166183839999
816, epoch_train_loss=0.0007353166183839999
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 0.0007353166183839999
817, epoch_train_loss=0.0007353166183839999
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 0.0007353166183839999
818, epoch_train_loss=0.0007353166183839999
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 0.0007353166183839999
819, epoch_train_loss=0.0007353166183839999
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 0.0007353166183839999
820, epoch_train_loss=0.0007353166183839999
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 0.0007353166183839999
821, epoch_train_loss=0.0007353166183839999
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 0.0007353166183839999
822, epoch_train_loss=0.0007353166183839999
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 0.0007353166183839999
823, epoch_train_loss=0.0007353166183839999
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 0.0007353166183839999
824, epoch_train_loss=0.0007353166183839999
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 0.0007353166183839999
825, epoch_train_loss=0.0007353166183839999
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 0.0007353166183839999
826, epoch_train_loss=0.0007353166183839999
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 0.0007353166183839999
827, epoch_train_loss=0.0007353166183839999
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 0.0007353166183839999
828, epoch_train_loss=0.0007353166183839999
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 0.0007353166183839999
829, epoch_train_loss=0.0007353166183839999
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 0.0007353166183839999
830, epoch_train_loss=0.0007353166183839999
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 0.0007353166183839999
831, epoch_train_loss=0.0007353166183839999
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 0.0007353166183839999
832, epoch_train_loss=0.0007353166183839999
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 0.0007353166183839999
833, epoch_train_loss=0.0007353166183839999
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 0.0007353166183839999
834, epoch_train_loss=0.0007353166183839999
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 0.0007353166183839999
835, epoch_train_loss=0.0007353166183839999
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 0.0007353166183839999
836, epoch_train_loss=0.0007353166183839999
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 0.0007353166183839999
837, epoch_train_loss=0.0007353166183839999
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 0.0007353166183839999
838, epoch_train_loss=0.0007353166183839999
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 0.0007353166183839999
839, epoch_train_loss=0.0007353166183839999
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 0.0007353166183839999
840, epoch_train_loss=0.0007353166183839999
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 0.0007353166183839999
841, epoch_train_loss=0.0007353166183839999
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 0.0007353166183839999
842, epoch_train_loss=0.0007353166183839999
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 0.0007353166183839999
843, epoch_train_loss=0.0007353166183839999
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 0.0007353166183839999
844, epoch_train_loss=0.0007353166183839999
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 0.0007353166183839999
845, epoch_train_loss=0.0007353166183839999
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 0.0007353166183839999
846, epoch_train_loss=0.0007353166183839999
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.0007353166183839999
847, epoch_train_loss=0.0007353166183839999
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.0007353166183839999
848, epoch_train_loss=0.0007353166183839999
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0007353166183839999
849, epoch_train_loss=0.0007353166183839999
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.0007353166183839999
850, epoch_train_loss=0.0007353166183839999
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0007353166183839999
851, epoch_train_loss=0.0007353166183839999
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.0007353166183839999
852, epoch_train_loss=0.0007353166183839999
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.0007353166183839999
853, epoch_train_loss=0.0007353166183839999
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.0007353166183839999
854, epoch_train_loss=0.0007353166183839999
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.0007353166183839999
855, epoch_train_loss=0.0007353166183839999
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.0007353166183839999
856, epoch_train_loss=0.0007353166183839999
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.0007353166183839999
857, epoch_train_loss=0.0007353166183839999
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.0007353166183839999
858, epoch_train_loss=0.0007353166183839999
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.0007353166183839999
859, epoch_train_loss=0.0007353166183839999
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.0007353166183839999
860, epoch_train_loss=0.0007353166183839999
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.0007353166183839999
861, epoch_train_loss=0.0007353166183839999
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.0007353166183839999
862, epoch_train_loss=0.0007353166183839999
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.0007353166183839999
863, epoch_train_loss=0.0007353166183839999
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.0007353166183839999
864, epoch_train_loss=0.0007353166183839999
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.0007353166183839999
865, epoch_train_loss=0.0007353166183839999
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.0007353166183839999
866, epoch_train_loss=0.0007353166183839999
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.0007353166183839999
867, epoch_train_loss=0.0007353166183839999
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.0007353166183839999
868, epoch_train_loss=0.0007353166183839999
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.0007353166183839999
869, epoch_train_loss=0.0007353166183839999
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0007353166183839999
870, epoch_train_loss=0.0007353166183839999
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.0007353166183839999
871, epoch_train_loss=0.0007353166183839999
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.0007353166183839999
872, epoch_train_loss=0.0007353166183839999
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0007353166183839999
873, epoch_train_loss=0.0007353166183839999
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.0007353166183839999
874, epoch_train_loss=0.0007353166183839999
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.0007353166183839999
875, epoch_train_loss=0.0007353166183839999
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.0007353166183839999
876, epoch_train_loss=0.0007353166183839999
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.0007353166183839999
877, epoch_train_loss=0.0007353166183839999
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.0007353166183839999
878, epoch_train_loss=0.0007353166183839999
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.0007353166183839999
879, epoch_train_loss=0.0007353166183839999
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.0007353166183839999
880, epoch_train_loss=0.0007353166183839999
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.0007353166183839999
881, epoch_train_loss=0.0007353166183839999
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.0007353166183839999
882, epoch_train_loss=0.0007353166183839999
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0007353166183839999
883, epoch_train_loss=0.0007353166183839999
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0007353166183839999
884, epoch_train_loss=0.0007353166183839999
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0007353166183839999
885, epoch_train_loss=0.0007353166183839999
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.0007353166183839999
886, epoch_train_loss=0.0007353166183839999
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0007353166183839999
887, epoch_train_loss=0.0007353166183839999
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0007353166183839999
888, epoch_train_loss=0.0007353166183839999
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0007353166183839999
889, epoch_train_loss=0.0007353166183839999
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.0007353166183839999
890, epoch_train_loss=0.0007353166183839999
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0007353166183839999
891, epoch_train_loss=0.0007353166183839999
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0007353166183839999
892, epoch_train_loss=0.0007353166183839999
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.0007353166183839999
893, epoch_train_loss=0.0007353166183839999
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.0007353166183839999
894, epoch_train_loss=0.0007353166183839999
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0007353166183839999
895, epoch_train_loss=0.0007353166183839999
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.0007353166183839999
896, epoch_train_loss=0.0007353166183839999
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.0007353166183839999
897, epoch_train_loss=0.0007353166183839999
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0007353166183839999
898, epoch_train_loss=0.0007353166183839999
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0007353166183839999
899, epoch_train_loss=0.0007353166183839999
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0007353166183839999
900, epoch_train_loss=0.0007353166183839999
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.0007353166183839999
901, epoch_train_loss=0.0007353166183839999
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0007353166183839999
902, epoch_train_loss=0.0007353166183839999
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.0007353166183839999
903, epoch_train_loss=0.0007353166183839999
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0007353166183839999
904, epoch_train_loss=0.0007353166183839999
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007353166183839999
905, epoch_train_loss=0.0007353166183839999
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.0007353166183839999
906, epoch_train_loss=0.0007353166183839999
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.0007353166183839999
907, epoch_train_loss=0.0007353166183839999
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.0007353166183839999
908, epoch_train_loss=0.0007353166183839999
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.0007353166183839999
909, epoch_train_loss=0.0007353166183839999
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.0007353166183839999
910, epoch_train_loss=0.0007353166183839999
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0007353166183839999
911, epoch_train_loss=0.0007353166183839999
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.0007353166183839999
912, epoch_train_loss=0.0007353166183839999
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.0007353166183839999
913, epoch_train_loss=0.0007353166183839999
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.0007353166183839999
914, epoch_train_loss=0.0007353166183839999
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0007353166183839999
915, epoch_train_loss=0.0007353166183839999
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.0007353166183839999
916, epoch_train_loss=0.0007353166183839999
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.0007353166183839999
917, epoch_train_loss=0.0007353166183839999
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.0007353166183839999
918, epoch_train_loss=0.0007353166183839999
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0007353166183839999
919, epoch_train_loss=0.0007353166183839999
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.0007353166183839999
920, epoch_train_loss=0.0007353166183839999
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.0007353166183839999
921, epoch_train_loss=0.0007353166183839999
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.0007353166183839999
922, epoch_train_loss=0.0007353166183839999
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.0007353166183839999
923, epoch_train_loss=0.0007353166183839999
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.0007353166183839999
924, epoch_train_loss=0.0007353166183839999
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.0007353166183839999
925, epoch_train_loss=0.0007353166183839999
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0007353166183839999
926, epoch_train_loss=0.0007353166183839999
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.0007353166183839999
927, epoch_train_loss=0.0007353166183839999
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.0007353166183839999
928, epoch_train_loss=0.0007353166183839999
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0007353166183839999
929, epoch_train_loss=0.0007353166183839999
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.0007353166183839999
930, epoch_train_loss=0.0007353166183839999
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.0007353166183839999
931, epoch_train_loss=0.0007353166183839999
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.0007353166183839999
932, epoch_train_loss=0.0007353166183839999
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.0007353166183839999
933, epoch_train_loss=0.0007353166183839999
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.0007353166183839999
934, epoch_train_loss=0.0007353166183839999
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.0007353166183839999
935, epoch_train_loss=0.0007353166183839999
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.0007353166183839999
936, epoch_train_loss=0.0007353166183839999
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.0007353166183839999
937, epoch_train_loss=0.0007353166183839999
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.0007353166183839999
938, epoch_train_loss=0.0007353166183839999
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.0007353166183839999
939, epoch_train_loss=0.0007353166183839999
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.0007353166183839999
940, epoch_train_loss=0.0007353166183839999
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.0007353166183839999
941, epoch_train_loss=0.0007353166183839999
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.0007353166183839999
942, epoch_train_loss=0.0007353166183839999
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.0007353166183839999
943, epoch_train_loss=0.0007353166183839999
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.0007353166183839999
944, epoch_train_loss=0.0007353166183839999
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.0007353166183839999
945, epoch_train_loss=0.0007353166183839999
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.0007353166183839999
946, epoch_train_loss=0.0007353166183839999
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.0007353166183839999
947, epoch_train_loss=0.0007353166183839999
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.0007353166183839999
948, epoch_train_loss=0.0007353166183839999
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.0007353166183839999
949, epoch_train_loss=0.0007353166183839999
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.0007353166183839999
950, epoch_train_loss=0.0007353166183839999
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0007353166183839999
951, epoch_train_loss=0.0007353166183839999
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.0007353166183839999
952, epoch_train_loss=0.0007353166183839999
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.0007353166183839999
953, epoch_train_loss=0.0007353166183839999
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.0007353166183839999
954, epoch_train_loss=0.0007353166183839999
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.0007353166183839999
955, epoch_train_loss=0.0007353166183839999
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.0007353166183839999
956, epoch_train_loss=0.0007353166183839999
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.0007353166183839999
957, epoch_train_loss=0.0007353166183839999
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.0007353166183839999
958, epoch_train_loss=0.0007353166183839999
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.0007353166183839999
959, epoch_train_loss=0.0007353166183839999
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0007353166183839999
960, epoch_train_loss=0.0007353166183839999
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0007353166183839999
961, epoch_train_loss=0.0007353166183839999
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.0007353166183839999
962, epoch_train_loss=0.0007353166183839999
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0007353166183839999
963, epoch_train_loss=0.0007353166183839999
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.0007353166183839999
964, epoch_train_loss=0.0007353166183839999
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.0007353166183839999
965, epoch_train_loss=0.0007353166183839999
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.0007353166183839999
966, epoch_train_loss=0.0007353166183839999
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.0007353166183839999
967, epoch_train_loss=0.0007353166183839999
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.0007353166183839999
968, epoch_train_loss=0.0007353166183839999
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0007353166183839999
969, epoch_train_loss=0.0007353166183839999
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.0007353166183839999
970, epoch_train_loss=0.0007353166183839999
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.0007353166183839999
971, epoch_train_loss=0.0007353166183839999
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.0007353166183839999
972, epoch_train_loss=0.0007353166183839999
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.0007353166183839999
973, epoch_train_loss=0.0007353166183839999
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.0007353166183839999
974, epoch_train_loss=0.0007353166183839999
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.0007353166183839999
975, epoch_train_loss=0.0007353166183839999
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.0007353166183839999
976, epoch_train_loss=0.0007353166183839999
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0007353166183839999
977, epoch_train_loss=0.0007353166183839999
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.0007353166183839999
978, epoch_train_loss=0.0007353166183839999
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.0007353166183839999
979, epoch_train_loss=0.0007353166183839999
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.0007353166183839999
980, epoch_train_loss=0.0007353166183839999
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0007353166183839999
981, epoch_train_loss=0.0007353166183839999
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.0007353166183839999
982, epoch_train_loss=0.0007353166183839999
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.0007353166183839999
983, epoch_train_loss=0.0007353166183839999
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0007353166183839999
984, epoch_train_loss=0.0007353166183839999
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.0007353166183839999
985, epoch_train_loss=0.0007353166183839999
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.0007353166183839999
986, epoch_train_loss=0.0007353166183839999
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.0007353166183839999
987, epoch_train_loss=0.0007353166183839999
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.0007353166183839999
988, epoch_train_loss=0.0007353166183839999
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.0007353166183839999
989, epoch_train_loss=0.0007353166183839999
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.0007353166183839999
990, epoch_train_loss=0.0007353166183839999
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0007353166183839999
991, epoch_train_loss=0.0007353166183839999
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0007353166183839999
992, epoch_train_loss=0.0007353166183839999
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0007353166183839999
993, epoch_train_loss=0.0007353166183839999
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.0007353166183839999
994, epoch_train_loss=0.0007353166183839999
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0007353166183839999
995, epoch_train_loss=0.0007353166183839999
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0007353166183839999
996, epoch_train_loss=0.0007353166183839999
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.0007353166183839999
997, epoch_train_loss=0.0007353166183839999
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.0007353166183839999
998, epoch_train_loss=0.0007353166183839999
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.0007353166183839999
999, epoch_train_loss=0.0007353166183839999
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1000, epoch_train_loss=0.0007353166183839999
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1001, epoch_train_loss=0.0007353166183839999
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1002, epoch_train_loss=0.0007353166183839999
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1003, epoch_train_loss=0.0007353166183839999
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1004, epoch_train_loss=0.0007353166183839999
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1005, epoch_train_loss=0.0007353166183839999
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1006, epoch_train_loss=0.0007353166183839999
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1007, epoch_train_loss=0.0007353166183839999
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1008, epoch_train_loss=0.0007353166183839999
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1009, epoch_train_loss=0.0007353166183839999
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1010, epoch_train_loss=0.0007353166183839999
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1011, epoch_train_loss=0.0007353166183839999
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1012, epoch_train_loss=0.0007353166183839999
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1013, epoch_train_loss=0.0007353166183839999
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1014, epoch_train_loss=0.0007353166183839999
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1015, epoch_train_loss=0.0007353166183839999
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1016, epoch_train_loss=0.0007353166183839999
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1017, epoch_train_loss=0.0007353166183839999
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1018, epoch_train_loss=0.0007353166183839999
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1019, epoch_train_loss=0.0007353166183839999
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1020, epoch_train_loss=0.0007353166183839999
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1021, epoch_train_loss=0.0007353166183839999
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1022, epoch_train_loss=0.0007353166183839999
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1023, epoch_train_loss=0.0007353166183839999
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1024, epoch_train_loss=0.0007353166183839999
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1025, epoch_train_loss=0.0007353166183839999
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1026, epoch_train_loss=0.0007353166183839999
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1027, epoch_train_loss=0.0007353166183839999
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1028, epoch_train_loss=0.0007353166183839999
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1029, epoch_train_loss=0.0007353166183839999
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1030, epoch_train_loss=0.0007353166183839999
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1031, epoch_train_loss=0.0007353166183839999
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1032, epoch_train_loss=0.0007353166183839999
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1033, epoch_train_loss=0.0007353166183839999
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1034, epoch_train_loss=0.0007353166183839999
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1035, epoch_train_loss=0.0007353166183839999
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1036, epoch_train_loss=0.0007353166183839999
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1037, epoch_train_loss=0.0007353166183839999
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1038, epoch_train_loss=0.0007353166183839999
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1039, epoch_train_loss=0.0007353166183839999
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1040, epoch_train_loss=0.0007353166183839999
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1041, epoch_train_loss=0.0007353166183839999
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1042, epoch_train_loss=0.0007353166183839999
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1043, epoch_train_loss=0.0007353166183839999
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1044, epoch_train_loss=0.0007353166183839999
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1045, epoch_train_loss=0.0007353166183839999
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1046, epoch_train_loss=0.0007353166183839999
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1047, epoch_train_loss=0.0007353166183839999
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1048, epoch_train_loss=0.0007353166183839999
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1049, epoch_train_loss=0.0007353166183839999
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1050, epoch_train_loss=0.0007353166183839999
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1051, epoch_train_loss=0.0007353166183839999
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1052, epoch_train_loss=0.0007353166183839999
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1053, epoch_train_loss=0.0007353166183839999
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1054, epoch_train_loss=0.0007353166183839999
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1055, epoch_train_loss=0.0007353166183839999
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1056, epoch_train_loss=0.0007353166183839999
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1057, epoch_train_loss=0.0007353166183839999
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1058, epoch_train_loss=0.0007353166183839999
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1059, epoch_train_loss=0.0007353166183839999
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1060, epoch_train_loss=0.0007353166183839999
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1061, epoch_train_loss=0.0007353166183839999
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1062, epoch_train_loss=0.0007353166183839999
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1063, epoch_train_loss=0.0007353166183839999
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1064, epoch_train_loss=0.0007353166183839999
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1065, epoch_train_loss=0.0007353166183839999
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1066, epoch_train_loss=0.0007353166183839999
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1067, epoch_train_loss=0.0007353166183839999
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1068, epoch_train_loss=0.0007353166183839999
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1069, epoch_train_loss=0.0007353166183839999
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1070, epoch_train_loss=0.0007353166183839999
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1071, epoch_train_loss=0.0007353166183839999
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1072, epoch_train_loss=0.0007353166183839999
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1073, epoch_train_loss=0.0007353166183839999
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1074, epoch_train_loss=0.0007353166183839999
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1075, epoch_train_loss=0.0007353166183839999
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1076, epoch_train_loss=0.0007353166183839999
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1077, epoch_train_loss=0.0007353166183839999
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1078, epoch_train_loss=0.0007353166183839999
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1079, epoch_train_loss=0.0007353166183839999
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1080, epoch_train_loss=0.0007353166183839999
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1081, epoch_train_loss=0.0007353166183839999
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1082, epoch_train_loss=0.0007353166183839999
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1083, epoch_train_loss=0.0007353166183839999
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1084, epoch_train_loss=0.0007353166183839999
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1085, epoch_train_loss=0.0007353166183839999
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1086, epoch_train_loss=0.0007353166183839999
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1087, epoch_train_loss=0.0007353166183839999
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1088, epoch_train_loss=0.0007353166183839999
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1089, epoch_train_loss=0.0007353166183839999
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1090, epoch_train_loss=0.0007353166183839999
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1091, epoch_train_loss=0.0007353166183839999
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1092, epoch_train_loss=0.0007353166183839999
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1093, epoch_train_loss=0.0007353166183839999
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1094, epoch_train_loss=0.0007353166183839999
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1095, epoch_train_loss=0.0007353166183839999
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1096, epoch_train_loss=0.0007353166183839999
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1097, epoch_train_loss=0.0007353166183839999
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1098, epoch_train_loss=0.0007353166183839999
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1099, epoch_train_loss=0.0007353166183839999
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1100, epoch_train_loss=0.0007353166183839999
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1101, epoch_train_loss=0.0007353166183839999
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1102, epoch_train_loss=0.0007353166183839999
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1103, epoch_train_loss=0.0007353166183839999
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1104, epoch_train_loss=0.0007353166183839999
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1105, epoch_train_loss=0.0007353166183839999
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1106, epoch_train_loss=0.0007353166183839999
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1107, epoch_train_loss=0.0007353166183839999
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1108, epoch_train_loss=0.0007353166183839999
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1109, epoch_train_loss=0.0007353166183839999
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1110, epoch_train_loss=0.0007353166183839999
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1111, epoch_train_loss=0.0007353166183839999
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1112, epoch_train_loss=0.0007353166183839999
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1113, epoch_train_loss=0.0007353166183839999
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1114, epoch_train_loss=0.0007353166183839999
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1115, epoch_train_loss=0.0007353166183839999
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1116, epoch_train_loss=0.0007353166183839999
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1117, epoch_train_loss=0.0007353166183839999
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1118, epoch_train_loss=0.0007353166183839999
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1119, epoch_train_loss=0.0007353166183839999
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1120, epoch_train_loss=0.0007353166183839999
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1121, epoch_train_loss=0.0007353166183839999
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1122, epoch_train_loss=0.0007353166183839999
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1123, epoch_train_loss=0.0007353166183839999
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1124, epoch_train_loss=0.0007353166183839999
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1125, epoch_train_loss=0.0007353166183839999
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1126, epoch_train_loss=0.0007353166183839999
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1127, epoch_train_loss=0.0007353166183839999
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1128, epoch_train_loss=0.0007353166183839999
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1129, epoch_train_loss=0.0007353166183839999
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1130, epoch_train_loss=0.0007353166183839999
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1131, epoch_train_loss=0.0007353166183839999
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1132, epoch_train_loss=0.0007353166183839999
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1133, epoch_train_loss=0.0007353166183839999
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1134, epoch_train_loss=0.0007353166183839999
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1135, epoch_train_loss=0.0007353166183839999
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1136, epoch_train_loss=0.0007353166183839999
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1137, epoch_train_loss=0.0007353166183839999
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1138, epoch_train_loss=0.0007353166183839999
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1139, epoch_train_loss=0.0007353166183839999
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1140, epoch_train_loss=0.0007353166183839999
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1141, epoch_train_loss=0.0007353166183839999
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1142, epoch_train_loss=0.0007353166183839999
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1143, epoch_train_loss=0.0007353166183839999
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1144, epoch_train_loss=0.0007353166183839999
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1145, epoch_train_loss=0.0007353166183839999
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1146, epoch_train_loss=0.0007353166183839999
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1147, epoch_train_loss=0.0007353166183839999
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1148, epoch_train_loss=0.0007353166183839999
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1149, epoch_train_loss=0.0007353166183839999
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1150, epoch_train_loss=0.0007353166183839999
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1151, epoch_train_loss=0.0007353166183839999
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1152, epoch_train_loss=0.0007353166183839999
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1153, epoch_train_loss=0.0007353166183839999
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1154, epoch_train_loss=0.0007353166183839999
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1155, epoch_train_loss=0.0007353166183839999
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1156, epoch_train_loss=0.0007353166183839999
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1157, epoch_train_loss=0.0007353166183839999
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1158, epoch_train_loss=0.0007353166183839999
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1159, epoch_train_loss=0.0007353166183839999
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1160, epoch_train_loss=0.0007353166183839999
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1161, epoch_train_loss=0.0007353166183839999
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1162, epoch_train_loss=0.0007353166183839999
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1163, epoch_train_loss=0.0007353166183839999
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1164, epoch_train_loss=0.0007353166183839999
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1165, epoch_train_loss=0.0007353166183839999
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1166, epoch_train_loss=0.0007353166183839999
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1167, epoch_train_loss=0.0007353166183839999
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1168, epoch_train_loss=0.0007353166183839999
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1169, epoch_train_loss=0.0007353166183839999
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1170, epoch_train_loss=0.0007353166183839999
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1171, epoch_train_loss=0.0007353166183839999
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1172, epoch_train_loss=0.0007353166183839999
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1173, epoch_train_loss=0.0007353166183839999
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1174, epoch_train_loss=0.0007353166183839999
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1175, epoch_train_loss=0.0007353166183839999
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1176, epoch_train_loss=0.0007353166183839999
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1177, epoch_train_loss=0.0007353166183839999
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1178, epoch_train_loss=0.0007353166183839999
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1179, epoch_train_loss=0.0007353166183839999
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1180, epoch_train_loss=0.0007353166183839999
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1181, epoch_train_loss=0.0007353166183839999
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1182, epoch_train_loss=0.0007353166183839999
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1183, epoch_train_loss=0.0007353166183839999
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1184, epoch_train_loss=0.0007353166183839999
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1185, epoch_train_loss=0.0007353166183839999
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1186, epoch_train_loss=0.0007353166183839999
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1187, epoch_train_loss=0.0007353166183839999
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1188, epoch_train_loss=0.0007353166183839999
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1189, epoch_train_loss=0.0007353166183839999
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1190, epoch_train_loss=0.0007353166183839999
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1191, epoch_train_loss=0.0007353166183839999
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1192, epoch_train_loss=0.0007353166183839999
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1193, epoch_train_loss=0.0007353166183839999
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1194, epoch_train_loss=0.0007353166183839999
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1195, epoch_train_loss=0.0007353166183839999
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1196, epoch_train_loss=0.0007353166183839999
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1197, epoch_train_loss=0.0007353166183839999
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1198, epoch_train_loss=0.0007353166183839999
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1199, epoch_train_loss=0.0007353166183839999
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1200, epoch_train_loss=0.0007353166183839999
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1201, epoch_train_loss=0.0007353166183839999
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1202, epoch_train_loss=0.0007353166183839999
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1203, epoch_train_loss=0.0007353166183839999
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1204, epoch_train_loss=0.0007353166183839999
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1205, epoch_train_loss=0.0007353166183839999
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1206, epoch_train_loss=0.0007353166183839999
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1207, epoch_train_loss=0.0007353166183839999
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1208, epoch_train_loss=0.0007353166183839999
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1209, epoch_train_loss=0.0007353166183839999
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1210, epoch_train_loss=0.0007353166183839999
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1211, epoch_train_loss=0.0007353166183839999
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1212, epoch_train_loss=0.0007353166183839999
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1213, epoch_train_loss=0.0007353166183839999
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1214, epoch_train_loss=0.0007353166183839999
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1215, epoch_train_loss=0.0007353166183839999
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1216, epoch_train_loss=0.0007353166183839999
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1217, epoch_train_loss=0.0007353166183839999
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1218, epoch_train_loss=0.0007353166183839999
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1219, epoch_train_loss=0.0007353166183839999
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1220, epoch_train_loss=0.0007353166183839999
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1221, epoch_train_loss=0.0007353166183839999
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1222, epoch_train_loss=0.0007353166183839999
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1223, epoch_train_loss=0.0007353166183839999
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1224, epoch_train_loss=0.0007353166183839999
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1225, epoch_train_loss=0.0007353166183839999
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1226, epoch_train_loss=0.0007353166183839999
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1227, epoch_train_loss=0.0007353166183839999
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1228, epoch_train_loss=0.0007353166183839999
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1229, epoch_train_loss=0.0007353166183839999
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1230, epoch_train_loss=0.0007353166183839999
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1231, epoch_train_loss=0.0007353166183839999
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1232, epoch_train_loss=0.0007353166183839999
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1233, epoch_train_loss=0.0007353166183839999
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1234, epoch_train_loss=0.0007353166183839999
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1235, epoch_train_loss=0.0007353166183839999
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1236, epoch_train_loss=0.0007353166183839999
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1237, epoch_train_loss=0.0007353166183839999
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1238, epoch_train_loss=0.0007353166183839999
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1239, epoch_train_loss=0.0007353166183839999
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1240, epoch_train_loss=0.0007353166183839999
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1241, epoch_train_loss=0.0007353166183839999
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1242, epoch_train_loss=0.0007353166183839999
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1243, epoch_train_loss=0.0007353166183839999
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1244, epoch_train_loss=0.0007353166183839999
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1245, epoch_train_loss=0.0007353166183839999
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1246, epoch_train_loss=0.0007353166183839999
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1247, epoch_train_loss=0.0007353166183839999
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1248, epoch_train_loss=0.0007353166183839999
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1249, epoch_train_loss=0.0007353166183839999
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1250, epoch_train_loss=0.0007353166183839999
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1251, epoch_train_loss=0.0007353166183839999
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1252, epoch_train_loss=0.0007353166183839999
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1253, epoch_train_loss=0.0007353166183839999
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1254, epoch_train_loss=0.0007353166183839999
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1255, epoch_train_loss=0.0007353166183839999
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1256, epoch_train_loss=0.0007353166183839999
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1257, epoch_train_loss=0.0007353166183839999
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1258, epoch_train_loss=0.0007353166183839999
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1259, epoch_train_loss=0.0007353166183839999
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1260, epoch_train_loss=0.0007353166183839999
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1261, epoch_train_loss=0.0007353166183839999
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1262, epoch_train_loss=0.0007353166183839999
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1263, epoch_train_loss=0.0007353166183839999
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1264, epoch_train_loss=0.0007353166183839999
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1265, epoch_train_loss=0.0007353166183839999
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1266, epoch_train_loss=0.0007353166183839999
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1267, epoch_train_loss=0.0007353166183839999
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1268, epoch_train_loss=0.0007353166183839999
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1269, epoch_train_loss=0.0007353166183839999
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1270, epoch_train_loss=0.0007353166183839999
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1271, epoch_train_loss=0.0007353166183839999
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1272, epoch_train_loss=0.0007353166183839999
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1273, epoch_train_loss=0.0007353166183839999
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1274, epoch_train_loss=0.0007353166183839999
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1275, epoch_train_loss=0.0007353166183839999
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1276, epoch_train_loss=0.0007353166183839999
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1277, epoch_train_loss=0.0007353166183839999
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1278, epoch_train_loss=0.0007353166183839999
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1279, epoch_train_loss=0.0007353166183839999
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1280, epoch_train_loss=0.0007353166183839999
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1281, epoch_train_loss=0.0007353166183839999
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1282, epoch_train_loss=0.0007353166183839999
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1283, epoch_train_loss=0.0007353166183839999
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1284, epoch_train_loss=0.0007353166183839999
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1285, epoch_train_loss=0.0007353166183839999
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1286, epoch_train_loss=0.0007353166183839999
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1287, epoch_train_loss=0.0007353166183839999
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1288, epoch_train_loss=0.0007353166183839999
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1289, epoch_train_loss=0.0007353166183839999
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1290, epoch_train_loss=0.0007353166183839999
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1291, epoch_train_loss=0.0007353166183839999
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1292, epoch_train_loss=0.0007353166183839999
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1293, epoch_train_loss=0.0007353166183839999
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1294, epoch_train_loss=0.0007353166183839999
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1295, epoch_train_loss=0.0007353166183839999
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1296, epoch_train_loss=0.0007353166183839999
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1297, epoch_train_loss=0.0007353166183839999
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1298, epoch_train_loss=0.0007353166183839999
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1299, epoch_train_loss=0.0007353166183839999
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1300, epoch_train_loss=0.0007353166183839999
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1301, epoch_train_loss=0.0007353166183839999
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1302, epoch_train_loss=0.0007353166183839999
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1303, epoch_train_loss=0.0007353166183839999
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1304, epoch_train_loss=0.0007353166183839999
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1305, epoch_train_loss=0.0007353166183839999
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1306, epoch_train_loss=0.0007353166183839999
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1307, epoch_train_loss=0.0007353166183839999
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1308, epoch_train_loss=0.0007353166183839999
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1309, epoch_train_loss=0.0007353166183839999
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1310, epoch_train_loss=0.0007353166183839999
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1311, epoch_train_loss=0.0007353166183839999
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1312, epoch_train_loss=0.0007353166183839999
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1313, epoch_train_loss=0.0007353166183839999
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1314, epoch_train_loss=0.0007353166183839999
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1315, epoch_train_loss=0.0007353166183839999
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1316, epoch_train_loss=0.0007353166183839999
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1317, epoch_train_loss=0.0007353166183839999
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1318, epoch_train_loss=0.0007353166183839999
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1319, epoch_train_loss=0.0007353166183839999
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1320, epoch_train_loss=0.0007353166183839999
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1321, epoch_train_loss=0.0007353166183839999
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1322, epoch_train_loss=0.0007353166183839999
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1323, epoch_train_loss=0.0007353166183839999
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1324, epoch_train_loss=0.0007353166183839999
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1325, epoch_train_loss=0.0007353166183839999
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1326, epoch_train_loss=0.0007353166183839999
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1327, epoch_train_loss=0.0007353166183839999
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1328, epoch_train_loss=0.0007353166183839999
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1329, epoch_train_loss=0.0007353166183839999
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1330, epoch_train_loss=0.0007353166183839999
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1331, epoch_train_loss=0.0007353166183839999
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1332, epoch_train_loss=0.0007353166183839999
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1333, epoch_train_loss=0.0007353166183839999
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1334, epoch_train_loss=0.0007353166183839999
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1335, epoch_train_loss=0.0007353166183839999
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1336, epoch_train_loss=0.0007353166183839999
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1337, epoch_train_loss=0.0007353166183839999
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1338, epoch_train_loss=0.0007353166183839999
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1339, epoch_train_loss=0.0007353166183839999
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1340, epoch_train_loss=0.0007353166183839999
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1341, epoch_train_loss=0.0007353166183839999
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1342, epoch_train_loss=0.0007353166183839999
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1343, epoch_train_loss=0.0007353166183839999
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1344, epoch_train_loss=0.0007353166183839999
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1345, epoch_train_loss=0.0007353166183839999
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1346, epoch_train_loss=0.0007353166183839999
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1347, epoch_train_loss=0.0007353166183839999
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1348, epoch_train_loss=0.0007353166183839999
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1349, epoch_train_loss=0.0007353166183839999
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1350, epoch_train_loss=0.0007353166183839999
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1351, epoch_train_loss=0.0007353166183839999
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1352, epoch_train_loss=0.0007353166183839999
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1353, epoch_train_loss=0.0007353166183839999
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1354, epoch_train_loss=0.0007353166183839999
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1355, epoch_train_loss=0.0007353166183839999
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1356, epoch_train_loss=0.0007353166183839999
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1357, epoch_train_loss=0.0007353166183839999
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1358, epoch_train_loss=0.0007353166183839999
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1359, epoch_train_loss=0.0007353166183839999
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1360, epoch_train_loss=0.0007353166183839999
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1361, epoch_train_loss=0.0007353166183839999
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1362, epoch_train_loss=0.0007353166183839999
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1363, epoch_train_loss=0.0007353166183839999
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1364, epoch_train_loss=0.0007353166183839999
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1365, epoch_train_loss=0.0007353166183839999
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1366, epoch_train_loss=0.0007353166183839999
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1367, epoch_train_loss=0.0007353166183839999
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1368, epoch_train_loss=0.0007353166183839999
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1369, epoch_train_loss=0.0007353166183839999
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1370, epoch_train_loss=0.0007353166183839999
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1371, epoch_train_loss=0.0007353166183839999
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1372, epoch_train_loss=0.0007353166183839999
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1373, epoch_train_loss=0.0007353166183839999
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1374, epoch_train_loss=0.0007353166183839999
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1375, epoch_train_loss=0.0007353166183839999
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1376, epoch_train_loss=0.0007353166183839999
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1377, epoch_train_loss=0.0007353166183839999
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1378, epoch_train_loss=0.0007353166183839999
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1379, epoch_train_loss=0.0007353166183839999
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1380, epoch_train_loss=0.0007353166183839999
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1381, epoch_train_loss=0.0007353166183839999
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1382, epoch_train_loss=0.0007353166183839999
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1383, epoch_train_loss=0.0007353166183839999
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1384, epoch_train_loss=0.0007353166183839999
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1385, epoch_train_loss=0.0007353166183839999
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1386, epoch_train_loss=0.0007353166183839999
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1387, epoch_train_loss=0.0007353166183839999
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1388, epoch_train_loss=0.0007353166183839999
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1389, epoch_train_loss=0.0007353166183839999
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1390, epoch_train_loss=0.0007353166183839999
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1391, epoch_train_loss=0.0007353166183839999
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1392, epoch_train_loss=0.0007353166183839999
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1393, epoch_train_loss=0.0007353166183839999
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1394, epoch_train_loss=0.0007353166183839999
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1395, epoch_train_loss=0.0007353166183839999
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1396, epoch_train_loss=0.0007353166183839999
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1397, epoch_train_loss=0.0007353166183839999
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1398, epoch_train_loss=0.0007353166183839999
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1399, epoch_train_loss=0.0007353166183839999
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1400, epoch_train_loss=0.0007353166183839999
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1401, epoch_train_loss=0.0007353166183839999
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1402, epoch_train_loss=0.0007353166183839999
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1403, epoch_train_loss=0.0007353166183839999
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1404, epoch_train_loss=0.0007353166183839999
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1405, epoch_train_loss=0.0007353166183839999
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1406, epoch_train_loss=0.0007353166183839999
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1407, epoch_train_loss=0.0007353166183839999
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1408, epoch_train_loss=0.0007353166183839999
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1409, epoch_train_loss=0.0007353166183839999
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1410, epoch_train_loss=0.0007353166183839999
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1411, epoch_train_loss=0.0007353166183839999
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1412, epoch_train_loss=0.0007353166183839999
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1413, epoch_train_loss=0.0007353166183839999
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1414, epoch_train_loss=0.0007353166183839999
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1415, epoch_train_loss=0.0007353166183839999
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1416, epoch_train_loss=0.0007353166183839999
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1417, epoch_train_loss=0.0007353166183839999
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1418, epoch_train_loss=0.0007353166183839999
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1419, epoch_train_loss=0.0007353166183839999
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1420, epoch_train_loss=0.0007353166183839999
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1421, epoch_train_loss=0.0007353166183839999
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1422, epoch_train_loss=0.0007353166183839999
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1423, epoch_train_loss=0.0007353166183839999
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1424, epoch_train_loss=0.0007353166183839999
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1425, epoch_train_loss=0.0007353166183839999
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1426, epoch_train_loss=0.0007353166183839999
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1427, epoch_train_loss=0.0007353166183839999
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1428, epoch_train_loss=0.0007353166183839999
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1429, epoch_train_loss=0.0007353166183839999
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1430, epoch_train_loss=0.0007353166183839999
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1431, epoch_train_loss=0.0007353166183839999
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1432, epoch_train_loss=0.0007353166183839999
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1433, epoch_train_loss=0.0007353166183839999
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1434, epoch_train_loss=0.0007353166183839999
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1435, epoch_train_loss=0.0007353166183839999
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1436, epoch_train_loss=0.0007353166183839999
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1437, epoch_train_loss=0.0007353166183839999
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1438, epoch_train_loss=0.0007353166183839999
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1439, epoch_train_loss=0.0007353166183839999
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1440, epoch_train_loss=0.0007353166183839999
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1441, epoch_train_loss=0.0007353166183839999
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1442, epoch_train_loss=0.0007353166183839999
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1443, epoch_train_loss=0.0007353166183839999
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1444, epoch_train_loss=0.0007353166183839999
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1445, epoch_train_loss=0.0007353166183839999
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1446, epoch_train_loss=0.0007353166183839999
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1447, epoch_train_loss=0.0007353166183839999
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1448, epoch_train_loss=0.0007353166183839999
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1449, epoch_train_loss=0.0007353166183839999
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1450, epoch_train_loss=0.0007353166183839999
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1451, epoch_train_loss=0.0007353166183839999
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1452, epoch_train_loss=0.0007353166183839999
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1453, epoch_train_loss=0.0007353166183839999
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1454, epoch_train_loss=0.0007353166183839999
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1455, epoch_train_loss=0.0007353166183839999
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1456, epoch_train_loss=0.0007353166183839999
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1457, epoch_train_loss=0.0007353166183839999
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1458, epoch_train_loss=0.0007353166183839999
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1459, epoch_train_loss=0.0007353166183839999
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1460, epoch_train_loss=0.0007353166183839999
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1461, epoch_train_loss=0.0007353166183839999
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1462, epoch_train_loss=0.0007353166183839999
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1463, epoch_train_loss=0.0007353166183839999
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1464, epoch_train_loss=0.0007353166183839999
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1465, epoch_train_loss=0.0007353166183839999
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1466, epoch_train_loss=0.0007353166183839999
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1467, epoch_train_loss=0.0007353166183839999
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1468, epoch_train_loss=0.0007353166183839999
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1469, epoch_train_loss=0.0007353166183839999
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1470, epoch_train_loss=0.0007353166183839999
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1471, epoch_train_loss=0.0007353166183839999
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1472, epoch_train_loss=0.0007353166183839999
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1473, epoch_train_loss=0.0007353166183839999
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1474, epoch_train_loss=0.0007353166183839999
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1475, epoch_train_loss=0.0007353166183839999
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1476, epoch_train_loss=0.0007353166183839999
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1477, epoch_train_loss=0.0007353166183839999
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1478, epoch_train_loss=0.0007353166183839999
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1479, epoch_train_loss=0.0007353166183839999
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1480, epoch_train_loss=0.0007353166183839999
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1481, epoch_train_loss=0.0007353166183839999
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1482, epoch_train_loss=0.0007353166183839999
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1483, epoch_train_loss=0.0007353166183839999
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1484, epoch_train_loss=0.0007353166183839999
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1485, epoch_train_loss=0.0007353166183839999
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1486, epoch_train_loss=0.0007353166183839999
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1487, epoch_train_loss=0.0007353166183839999
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1488, epoch_train_loss=0.0007353166183839999
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1489, epoch_train_loss=0.0007353166183839999
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1490, epoch_train_loss=0.0007353166183839999
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1491, epoch_train_loss=0.0007353166183839999
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1492, epoch_train_loss=0.0007353166183839999
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1493, epoch_train_loss=0.0007353166183839999
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1494, epoch_train_loss=0.0007353166183839999
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1495, epoch_train_loss=0.0007353166183839999
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1496, epoch_train_loss=0.0007353166183839999
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1497, epoch_train_loss=0.0007353166183839999
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1498, epoch_train_loss=0.0007353166183839999
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1499, epoch_train_loss=0.0007353166183839999
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1500, epoch_train_loss=0.0007353166183839999
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1501, epoch_train_loss=0.0007353166183839999
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1502, epoch_train_loss=0.0007353166183839999
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1503, epoch_train_loss=0.0007353166183839999
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1504, epoch_train_loss=0.0007353166183839999
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1505, epoch_train_loss=0.0007353166183839999
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1506, epoch_train_loss=0.0007353166183839999
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1507, epoch_train_loss=0.0007353166183839999
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1508, epoch_train_loss=0.0007353166183839999
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1509, epoch_train_loss=0.0007353166183839999
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1510, epoch_train_loss=0.0007353166183839999
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1511, epoch_train_loss=0.0007353166183839999
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1512, epoch_train_loss=0.0007353166183839999
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1513, epoch_train_loss=0.0007353166183839999
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1514, epoch_train_loss=0.0007353166183839999
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1515, epoch_train_loss=0.0007353166183839999
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1516, epoch_train_loss=0.0007353166183839999
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1517, epoch_train_loss=0.0007353166183839999
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1518, epoch_train_loss=0.0007353166183839999
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1519, epoch_train_loss=0.0007353166183839999
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1520, epoch_train_loss=0.0007353166183839999
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1521, epoch_train_loss=0.0007353166183839999
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1522, epoch_train_loss=0.0007353166183839999
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1523, epoch_train_loss=0.0007353166183839999
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1524, epoch_train_loss=0.0007353166183839999
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1525, epoch_train_loss=0.0007353166183839999
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1526, epoch_train_loss=0.0007353166183839999
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1527, epoch_train_loss=0.0007353166183839999
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1528, epoch_train_loss=0.0007353166183839999
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1529, epoch_train_loss=0.0007353166183839999
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1530, epoch_train_loss=0.0007353166183839999
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1531, epoch_train_loss=0.0007353166183839999
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1532, epoch_train_loss=0.0007353166183839999
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1533, epoch_train_loss=0.0007353166183839999
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1534, epoch_train_loss=0.0007353166183839999
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1535, epoch_train_loss=0.0007353166183839999
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1536, epoch_train_loss=0.0007353166183839999
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1537, epoch_train_loss=0.0007353166183839999
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1538, epoch_train_loss=0.0007353166183839999
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1539, epoch_train_loss=0.0007353166183839999
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1540, epoch_train_loss=0.0007353166183839999
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1541, epoch_train_loss=0.0007353166183839999
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1542, epoch_train_loss=0.0007353166183839999
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1543, epoch_train_loss=0.0007353166183839999
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1544, epoch_train_loss=0.0007353166183839999
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1545, epoch_train_loss=0.0007353166183839999
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1546, epoch_train_loss=0.0007353166183839999
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1547, epoch_train_loss=0.0007353166183839999
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1548, epoch_train_loss=0.0007353166183839999
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1549, epoch_train_loss=0.0007353166183839999
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1550, epoch_train_loss=0.0007353166183839999
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1551, epoch_train_loss=0.0007353166183839999
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1552, epoch_train_loss=0.0007353166183839999
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1553, epoch_train_loss=0.0007353166183839999
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1554, epoch_train_loss=0.0007353166183839999
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1555, epoch_train_loss=0.0007353166183839999
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1556, epoch_train_loss=0.0007353166183839999
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1557, epoch_train_loss=0.0007353166183839999
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1558, epoch_train_loss=0.0007353166183839999
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1559, epoch_train_loss=0.0007353166183839999
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1560, epoch_train_loss=0.0007353166183839999
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1561, epoch_train_loss=0.0007353166183839999
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1562, epoch_train_loss=0.0007353166183839999
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1563, epoch_train_loss=0.0007353166183839999
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1564, epoch_train_loss=0.0007353166183839999
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1565, epoch_train_loss=0.0007353166183839999
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1566, epoch_train_loss=0.0007353166183839999
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1567, epoch_train_loss=0.0007353166183839999
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1568, epoch_train_loss=0.0007353166183839999
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1569, epoch_train_loss=0.0007353166183839999
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1570, epoch_train_loss=0.0007353166183839999
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1571, epoch_train_loss=0.0007353166183839999
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1572, epoch_train_loss=0.0007353166183839999
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1573, epoch_train_loss=0.0007353166183839999
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1574, epoch_train_loss=0.0007353166183839999
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1575, epoch_train_loss=0.0007353166183839999
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1576, epoch_train_loss=0.0007353166183839999
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1577, epoch_train_loss=0.0007353166183839999
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1578, epoch_train_loss=0.0007353166183839999
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1579, epoch_train_loss=0.0007353166183839999
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1580, epoch_train_loss=0.0007353166183839999
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1581, epoch_train_loss=0.0007353166183839999
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1582, epoch_train_loss=0.0007353166183839999
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1583, epoch_train_loss=0.0007353166183839999
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1584, epoch_train_loss=0.0007353166183839999
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1585, epoch_train_loss=0.0007353166183839999
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1586, epoch_train_loss=0.0007353166183839999
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1587, epoch_train_loss=0.0007353166183839999
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1588, epoch_train_loss=0.0007353166183839999
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1589, epoch_train_loss=0.0007353166183839999
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1590, epoch_train_loss=0.0007353166183839999
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1591, epoch_train_loss=0.0007353166183839999
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1592, epoch_train_loss=0.0007353166183839999
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1593, epoch_train_loss=0.0007353166183839999
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1594, epoch_train_loss=0.0007353166183839999
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1595, epoch_train_loss=0.0007353166183839999
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1596, epoch_train_loss=0.0007353166183839999
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1597, epoch_train_loss=0.0007353166183839999
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1598, epoch_train_loss=0.0007353166183839999
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1599, epoch_train_loss=0.0007353166183839999
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1600, epoch_train_loss=0.0007353166183839999
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1601, epoch_train_loss=0.0007353166183839999
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1602, epoch_train_loss=0.0007353166183839999
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1603, epoch_train_loss=0.0007353166183839999
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1604, epoch_train_loss=0.0007353166183839999
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1605, epoch_train_loss=0.0007353166183839999
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1606, epoch_train_loss=0.0007353166183839999
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1607, epoch_train_loss=0.0007353166183839999
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1608, epoch_train_loss=0.0007353166183839999
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1609, epoch_train_loss=0.0007353166183839999
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1610, epoch_train_loss=0.0007353166183839999
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1611, epoch_train_loss=0.0007353166183839999
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1612, epoch_train_loss=0.0007353166183839999
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1613, epoch_train_loss=0.0007353166183839999
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1614, epoch_train_loss=0.0007353166183839999
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1615, epoch_train_loss=0.0007353166183839999
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1616, epoch_train_loss=0.0007353166183839999
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1617, epoch_train_loss=0.0007353166183839999
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1618, epoch_train_loss=0.0007353166183839999
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1619, epoch_train_loss=0.0007353166183839999
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1620, epoch_train_loss=0.0007353166183839999
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1621, epoch_train_loss=0.0007353166183839999
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1622, epoch_train_loss=0.0007353166183839999
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1623, epoch_train_loss=0.0007353166183839999
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1624, epoch_train_loss=0.0007353166183839999
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1625, epoch_train_loss=0.0007353166183839999
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1626, epoch_train_loss=0.0007353166183839999
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1627, epoch_train_loss=0.0007353166183839999
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1628, epoch_train_loss=0.0007353166183839999
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1629, epoch_train_loss=0.0007353166183839999
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1630, epoch_train_loss=0.0007353166183839999
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1631, epoch_train_loss=0.0007353166183839999
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1632, epoch_train_loss=0.0007353166183839999
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1633, epoch_train_loss=0.0007353166183839999
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1634, epoch_train_loss=0.0007353166183839999
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1635, epoch_train_loss=0.0007353166183839999
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1636, epoch_train_loss=0.0007353166183839999
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1637, epoch_train_loss=0.0007353166183839999
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1638, epoch_train_loss=0.0007353166183839999
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1639, epoch_train_loss=0.0007353166183839999
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1640, epoch_train_loss=0.0007353166183839999
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1641, epoch_train_loss=0.0007353166183839999
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1642, epoch_train_loss=0.0007353166183839999
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1643, epoch_train_loss=0.0007353166183839999
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1644, epoch_train_loss=0.0007353166183839999
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1645, epoch_train_loss=0.0007353166183839999
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1646, epoch_train_loss=0.0007353166183839999
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1647, epoch_train_loss=0.0007353166183839999
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1648, epoch_train_loss=0.0007353166183839999
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1649, epoch_train_loss=0.0007353166183839999
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1650, epoch_train_loss=0.0007353166183839999
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1651, epoch_train_loss=0.0007353166183839999
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1652, epoch_train_loss=0.0007353166183839999
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1653, epoch_train_loss=0.0007353166183839999
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1654, epoch_train_loss=0.0007353166183839999
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1655, epoch_train_loss=0.0007353166183839999
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1656, epoch_train_loss=0.0007353166183839999
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1657, epoch_train_loss=0.0007353166183839999
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1658, epoch_train_loss=0.0007353166183839999
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1659, epoch_train_loss=0.0007353166183839999
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1660, epoch_train_loss=0.0007353166183839999
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1661, epoch_train_loss=0.0007353166183839999
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1662, epoch_train_loss=0.0007353166183839999
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1663, epoch_train_loss=0.0007353166183839999
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1664, epoch_train_loss=0.0007353166183839999
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1665, epoch_train_loss=0.0007353166183839999
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1666, epoch_train_loss=0.0007353166183839999
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1667, epoch_train_loss=0.0007353166183839999
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1668, epoch_train_loss=0.0007353166183839999
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1669, epoch_train_loss=0.0007353166183839999
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1670, epoch_train_loss=0.0007353166183839999
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1671, epoch_train_loss=0.0007353166183839999
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1672, epoch_train_loss=0.0007353166183839999
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1673, epoch_train_loss=0.0007353166183839999
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1674, epoch_train_loss=0.0007353166183839999
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1675, epoch_train_loss=0.0007353166183839999
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1676, epoch_train_loss=0.0007353166183839999
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1677, epoch_train_loss=0.0007353166183839999
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1678, epoch_train_loss=0.0007353166183839999
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1679, epoch_train_loss=0.0007353166183839999
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1680, epoch_train_loss=0.0007353166183839999
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1681, epoch_train_loss=0.0007353166183839999
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1682, epoch_train_loss=0.0007353166183839999
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1683, epoch_train_loss=0.0007353166183839999
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1684, epoch_train_loss=0.0007353166183839999
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1685, epoch_train_loss=0.0007353166183839999
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1686, epoch_train_loss=0.0007353166183839999
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1687, epoch_train_loss=0.0007353166183839999
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1688, epoch_train_loss=0.0007353166183839999
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1689, epoch_train_loss=0.0007353166183839999
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1690, epoch_train_loss=0.0007353166183839999
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1691, epoch_train_loss=0.0007353166183839999
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1692, epoch_train_loss=0.0007353166183839999
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1693, epoch_train_loss=0.0007353166183839999
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1694, epoch_train_loss=0.0007353166183839999
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1695, epoch_train_loss=0.0007353166183839999
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1696, epoch_train_loss=0.0007353166183839999
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1697, epoch_train_loss=0.0007353166183839999
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1698, epoch_train_loss=0.0007353166183839999
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1699, epoch_train_loss=0.0007353166183839999
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1700, epoch_train_loss=0.0007353166183839999
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1701, epoch_train_loss=0.0007353166183839999
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1702, epoch_train_loss=0.0007353166183839999
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1703, epoch_train_loss=0.0007353166183839999
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1704, epoch_train_loss=0.0007353166183839999
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1705, epoch_train_loss=0.0007353166183839999
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1706, epoch_train_loss=0.0007353166183839999
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1707, epoch_train_loss=0.0007353166183839999
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1708, epoch_train_loss=0.0007353166183839999
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1709, epoch_train_loss=0.0007353166183839999
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1710, epoch_train_loss=0.0007353166183839999
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1711, epoch_train_loss=0.0007353166183839999
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1712, epoch_train_loss=0.0007353166183839999
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1713, epoch_train_loss=0.0007353166183839999
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1714, epoch_train_loss=0.0007353166183839999
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1715, epoch_train_loss=0.0007353166183839999
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1716, epoch_train_loss=0.0007353166183839999
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1717, epoch_train_loss=0.0007353166183839999
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1718, epoch_train_loss=0.0007353166183839999
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1719, epoch_train_loss=0.0007353166183839999
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1720, epoch_train_loss=0.0007353166183839999
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1721, epoch_train_loss=0.0007353166183839999
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1722, epoch_train_loss=0.0007353166183839999
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1723, epoch_train_loss=0.0007353166183839999
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1724, epoch_train_loss=0.0007353166183839999
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1725, epoch_train_loss=0.0007353166183839999
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1726, epoch_train_loss=0.0007353166183839999
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1727, epoch_train_loss=0.0007353166183839999
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1728, epoch_train_loss=0.0007353166183839999
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1729, epoch_train_loss=0.0007353166183839999
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1730, epoch_train_loss=0.0007353166183839999
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1731, epoch_train_loss=0.0007353166183839999
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1732, epoch_train_loss=0.0007353166183839999
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1733, epoch_train_loss=0.0007353166183839999
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1734, epoch_train_loss=0.0007353166183839999
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1735, epoch_train_loss=0.0007353166183839999
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1736, epoch_train_loss=0.0007353166183839999
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1737, epoch_train_loss=0.0007353166183839999
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1738, epoch_train_loss=0.0007353166183839999
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1739, epoch_train_loss=0.0007353166183839999
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1740, epoch_train_loss=0.0007353166183839999
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1741, epoch_train_loss=0.0007353166183839999
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1742, epoch_train_loss=0.0007353166183839999
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1743, epoch_train_loss=0.0007353166183839999
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1744, epoch_train_loss=0.0007353166183839999
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1745, epoch_train_loss=0.0007353166183839999
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1746, epoch_train_loss=0.0007353166183839999
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1747, epoch_train_loss=0.0007353166183839999
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1748, epoch_train_loss=0.0007353166183839999
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1749, epoch_train_loss=0.0007353166183839999
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1750, epoch_train_loss=0.0007353166183839999
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1751, epoch_train_loss=0.0007353166183839999
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1752, epoch_train_loss=0.0007353166183839999
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1753, epoch_train_loss=0.0007353166183839999
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1754, epoch_train_loss=0.0007353166183839999
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1755, epoch_train_loss=0.0007353166183839999
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1756, epoch_train_loss=0.0007353166183839999
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1757, epoch_train_loss=0.0007353166183839999
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1758, epoch_train_loss=0.0007353166183839999
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1759, epoch_train_loss=0.0007353166183839999
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1760, epoch_train_loss=0.0007353166183839999
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1761, epoch_train_loss=0.0007353166183839999
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1762, epoch_train_loss=0.0007353166183839999
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1763, epoch_train_loss=0.0007353166183839999
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1764, epoch_train_loss=0.0007353166183839999
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1765, epoch_train_loss=0.0007353166183839999
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1766, epoch_train_loss=0.0007353166183839999
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1767, epoch_train_loss=0.0007353166183839999
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1768, epoch_train_loss=0.0007353166183839999
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1769, epoch_train_loss=0.0007353166183839999
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1770, epoch_train_loss=0.0007353166183839999
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1771, epoch_train_loss=0.0007353166183839999
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1772, epoch_train_loss=0.0007353166183839999
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1773, epoch_train_loss=0.0007353166183839999
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1774, epoch_train_loss=0.0007353166183839999
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1775, epoch_train_loss=0.0007353166183839999
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1776, epoch_train_loss=0.0007353166183839999
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1777, epoch_train_loss=0.0007353166183839999
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1778, epoch_train_loss=0.0007353166183839999
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1779, epoch_train_loss=0.0007353166183839999
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1780, epoch_train_loss=0.0007353166183839999
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1781, epoch_train_loss=0.0007353166183839999
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1782, epoch_train_loss=0.0007353166183839999
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1783, epoch_train_loss=0.0007353166183839999
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1784, epoch_train_loss=0.0007353166183839999
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1785, epoch_train_loss=0.0007353166183839999
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1786, epoch_train_loss=0.0007353166183839999
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1787, epoch_train_loss=0.0007353166183839999
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1788, epoch_train_loss=0.0007353166183839999
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1789, epoch_train_loss=0.0007353166183839999
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1790, epoch_train_loss=0.0007353166183839999
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1791, epoch_train_loss=0.0007353166183839999
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1792, epoch_train_loss=0.0007353166183839999
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1793, epoch_train_loss=0.0007353166183839999
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1794, epoch_train_loss=0.0007353166183839999
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1795, epoch_train_loss=0.0007353166183839999
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1796, epoch_train_loss=0.0007353166183839999
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1797, epoch_train_loss=0.0007353166183839999
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1798, epoch_train_loss=0.0007353166183839999
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1799, epoch_train_loss=0.0007353166183839999
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1800, epoch_train_loss=0.0007353166183839999
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1801, epoch_train_loss=0.0007353166183839999
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1802, epoch_train_loss=0.0007353166183839999
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1803, epoch_train_loss=0.0007353166183839999
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1804, epoch_train_loss=0.0007353166183839999
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1805, epoch_train_loss=0.0007353166183839999
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1806, epoch_train_loss=0.0007353166183839999
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1807, epoch_train_loss=0.0007353166183839999
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1808, epoch_train_loss=0.0007353166183839999
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1809, epoch_train_loss=0.0007353166183839999
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1810, epoch_train_loss=0.0007353166183839999
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1811, epoch_train_loss=0.0007353166183839999
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1812, epoch_train_loss=0.0007353166183839999
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1813, epoch_train_loss=0.0007353166183839999
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1814, epoch_train_loss=0.0007353166183839999
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1815, epoch_train_loss=0.0007353166183839999
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1816, epoch_train_loss=0.0007353166183839999
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1817, epoch_train_loss=0.0007353166183839999
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1818, epoch_train_loss=0.0007353166183839999
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1819, epoch_train_loss=0.0007353166183839999
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1820, epoch_train_loss=0.0007353166183839999
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1821, epoch_train_loss=0.0007353166183839999
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1822, epoch_train_loss=0.0007353166183839999
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1823, epoch_train_loss=0.0007353166183839999
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1824, epoch_train_loss=0.0007353166183839999
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1825, epoch_train_loss=0.0007353166183839999
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1826, epoch_train_loss=0.0007353166183839999
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1827, epoch_train_loss=0.0007353166183839999
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1828, epoch_train_loss=0.0007353166183839999
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1829, epoch_train_loss=0.0007353166183839999
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1830, epoch_train_loss=0.0007353166183839999
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1831, epoch_train_loss=0.0007353166183839999
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1832, epoch_train_loss=0.0007353166183839999
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1833, epoch_train_loss=0.0007353166183839999
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1834, epoch_train_loss=0.0007353166183839999
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1835, epoch_train_loss=0.0007353166183839999
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1836, epoch_train_loss=0.0007353166183839999
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1837, epoch_train_loss=0.0007353166183839999
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1838, epoch_train_loss=0.0007353166183839999
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1839, epoch_train_loss=0.0007353166183839999
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1840, epoch_train_loss=0.0007353166183839999
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1841, epoch_train_loss=0.0007353166183839999
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1842, epoch_train_loss=0.0007353166183839999
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1843, epoch_train_loss=0.0007353166183839999
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1844, epoch_train_loss=0.0007353166183839999
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1845, epoch_train_loss=0.0007353166183839999
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1846, epoch_train_loss=0.0007353166183839999
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1847, epoch_train_loss=0.0007353166183839999
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1848, epoch_train_loss=0.0007353166183839999
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1849, epoch_train_loss=0.0007353166183839999
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1850, epoch_train_loss=0.0007353166183839999
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1851, epoch_train_loss=0.0007353166183839999
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1852, epoch_train_loss=0.0007353166183839999
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1853, epoch_train_loss=0.0007353166183839999
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1854, epoch_train_loss=0.0007353166183839999
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1855, epoch_train_loss=0.0007353166183839999
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1856, epoch_train_loss=0.0007353166183839999
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1857, epoch_train_loss=0.0007353166183839999
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1858, epoch_train_loss=0.0007353166183839999
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1859, epoch_train_loss=0.0007353166183839999
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1860, epoch_train_loss=0.0007353166183839999
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1861, epoch_train_loss=0.0007353166183839999
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1862, epoch_train_loss=0.0007353166183839999
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1863, epoch_train_loss=0.0007353166183839999
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1864, epoch_train_loss=0.0007353166183839999
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1865, epoch_train_loss=0.0007353166183839999
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1866, epoch_train_loss=0.0007353166183839999
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1867, epoch_train_loss=0.0007353166183839999
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1868, epoch_train_loss=0.0007353166183839999
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1869, epoch_train_loss=0.0007353166183839999
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1870, epoch_train_loss=0.0007353166183839999
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1871, epoch_train_loss=0.0007353166183839999
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1872, epoch_train_loss=0.0007353166183839999
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1873, epoch_train_loss=0.0007353166183839999
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1874, epoch_train_loss=0.0007353166183839999
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1875, epoch_train_loss=0.0007353166183839999
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1876, epoch_train_loss=0.0007353166183839999
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1877, epoch_train_loss=0.0007353166183839999
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1878, epoch_train_loss=0.0007353166183839999
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1879, epoch_train_loss=0.0007353166183839999
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1880, epoch_train_loss=0.0007353166183839999
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1881, epoch_train_loss=0.0007353166183839999
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1882, epoch_train_loss=0.0007353166183839999
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1883, epoch_train_loss=0.0007353166183839999
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1884, epoch_train_loss=0.0007353166183839999
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1885, epoch_train_loss=0.0007353166183839999
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1886, epoch_train_loss=0.0007353166183839999
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1887, epoch_train_loss=0.0007353166183839999
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1888, epoch_train_loss=0.0007353166183839999
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1889, epoch_train_loss=0.0007353166183839999
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1890, epoch_train_loss=0.0007353166183839999
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1891, epoch_train_loss=0.0007353166183839999
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1892, epoch_train_loss=0.0007353166183839999
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1893, epoch_train_loss=0.0007353166183839999
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1894, epoch_train_loss=0.0007353166183839999
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1895, epoch_train_loss=0.0007353166183839999
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1896, epoch_train_loss=0.0007353166183839999
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1897, epoch_train_loss=0.0007353166183839999
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1898, epoch_train_loss=0.0007353166183839999
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1899, epoch_train_loss=0.0007353166183839999
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1900, epoch_train_loss=0.0007353166183839999
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1901, epoch_train_loss=0.0007353166183839999
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1902, epoch_train_loss=0.0007353166183839999
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1903, epoch_train_loss=0.0007353166183839999
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1904, epoch_train_loss=0.0007353166183839999
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1905, epoch_train_loss=0.0007353166183839999
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1906, epoch_train_loss=0.0007353166183839999
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1907, epoch_train_loss=0.0007353166183839999
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1908, epoch_train_loss=0.0007353166183839999
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1909, epoch_train_loss=0.0007353166183839999
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1910, epoch_train_loss=0.0007353166183839999
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1911, epoch_train_loss=0.0007353166183839999
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1912, epoch_train_loss=0.0007353166183839999
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1913, epoch_train_loss=0.0007353166183839999
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1914, epoch_train_loss=0.0007353166183839999
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1915, epoch_train_loss=0.0007353166183839999
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1916, epoch_train_loss=0.0007353166183839999
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1917, epoch_train_loss=0.0007353166183839999
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1918, epoch_train_loss=0.0007353166183839999
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1919, epoch_train_loss=0.0007353166183839999
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1920, epoch_train_loss=0.0007353166183839999
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1921, epoch_train_loss=0.0007353166183839999
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1922, epoch_train_loss=0.0007353166183839999
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1923, epoch_train_loss=0.0007353166183839999
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1924, epoch_train_loss=0.0007353166183839999
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1925, epoch_train_loss=0.0007353166183839999
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1926, epoch_train_loss=0.0007353166183839999
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1927, epoch_train_loss=0.0007353166183839999
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1928, epoch_train_loss=0.0007353166183839999
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1929, epoch_train_loss=0.0007353166183839999
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1930, epoch_train_loss=0.0007353166183839999
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1931, epoch_train_loss=0.0007353166183839999
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1932, epoch_train_loss=0.0007353166183839999
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1933, epoch_train_loss=0.0007353166183839999
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1934, epoch_train_loss=0.0007353166183839999
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1935, epoch_train_loss=0.0007353166183839999
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1936, epoch_train_loss=0.0007353166183839999
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1937, epoch_train_loss=0.0007353166183839999
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1938, epoch_train_loss=0.0007353166183839999
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1939, epoch_train_loss=0.0007353166183839999
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1940, epoch_train_loss=0.0007353166183839999
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1941, epoch_train_loss=0.0007353166183839999
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1942, epoch_train_loss=0.0007353166183839999
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1943, epoch_train_loss=0.0007353166183839999
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1944, epoch_train_loss=0.0007353166183839999
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1945, epoch_train_loss=0.0007353166183839999
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1946, epoch_train_loss=0.0007353166183839999
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1947, epoch_train_loss=0.0007353166183839999
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1948, epoch_train_loss=0.0007353166183839999
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1949, epoch_train_loss=0.0007353166183839999
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1950, epoch_train_loss=0.0007353166183839999
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1951, epoch_train_loss=0.0007353166183839999
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1952, epoch_train_loss=0.0007353166183839999
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1953, epoch_train_loss=0.0007353166183839999
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1954, epoch_train_loss=0.0007353166183839999
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1955, epoch_train_loss=0.0007353166183839999
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1956, epoch_train_loss=0.0007353166183839999
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1957, epoch_train_loss=0.0007353166183839999
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1958, epoch_train_loss=0.0007353166183839999
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1959, epoch_train_loss=0.0007353166183839999
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1960, epoch_train_loss=0.0007353166183839999
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1961, epoch_train_loss=0.0007353166183839999
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1962, epoch_train_loss=0.0007353166183839999
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1963, epoch_train_loss=0.0007353166183839999
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1964, epoch_train_loss=0.0007353166183839999
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1965, epoch_train_loss=0.0007353166183839999
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1966, epoch_train_loss=0.0007353166183839999
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1967, epoch_train_loss=0.0007353166183839999
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1968, epoch_train_loss=0.0007353166183839999
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1969, epoch_train_loss=0.0007353166183839999
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1970, epoch_train_loss=0.0007353166183839999
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1971, epoch_train_loss=0.0007353166183839999
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1972, epoch_train_loss=0.0007353166183839999
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1973, epoch_train_loss=0.0007353166183839999
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1974, epoch_train_loss=0.0007353166183839999
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1975, epoch_train_loss=0.0007353166183839999
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1976, epoch_train_loss=0.0007353166183839999
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1977, epoch_train_loss=0.0007353166183839999
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1978, epoch_train_loss=0.0007353166183839999
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1979, epoch_train_loss=0.0007353166183839999
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1980, epoch_train_loss=0.0007353166183839999
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1981, epoch_train_loss=0.0007353166183839999
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1982, epoch_train_loss=0.0007353166183839999
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1983, epoch_train_loss=0.0007353166183839999
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1984, epoch_train_loss=0.0007353166183839999
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1985, epoch_train_loss=0.0007353166183839999
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1986, epoch_train_loss=0.0007353166183839999
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1987, epoch_train_loss=0.0007353166183839999
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1988, epoch_train_loss=0.0007353166183839999
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1989, epoch_train_loss=0.0007353166183839999
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1990, epoch_train_loss=0.0007353166183839999
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1991, epoch_train_loss=0.0007353166183839999
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1992, epoch_train_loss=0.0007353166183839999
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1993, epoch_train_loss=0.0007353166183839999
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1994, epoch_train_loss=0.0007353166183839999
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1995, epoch_train_loss=0.0007353166183839999
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1996, epoch_train_loss=0.0007353166183839999
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1997, epoch_train_loss=0.0007353166183839999
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1998, epoch_train_loss=0.0007353166183839999
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 0.0007353166183839999
1999, epoch_train_loss=0.0007353166183839999
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2000, epoch_train_loss=0.0007353166183839999
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2001, epoch_train_loss=0.0007353166183839999
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2002, epoch_train_loss=0.0007353166183839999
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2003, epoch_train_loss=0.0007353166183839999
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2004, epoch_train_loss=0.0007353166183839999
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2005, epoch_train_loss=0.0007353166183839999
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2006, epoch_train_loss=0.0007353166183839999
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2007, epoch_train_loss=0.0007353166183839999
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2008, epoch_train_loss=0.0007353166183839999
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2009, epoch_train_loss=0.0007353166183839999
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2010, epoch_train_loss=0.0007353166183839999
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2011, epoch_train_loss=0.0007353166183839999
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2012, epoch_train_loss=0.0007353166183839999
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2013, epoch_train_loss=0.0007353166183839999
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2014, epoch_train_loss=0.0007353166183839999
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2015, epoch_train_loss=0.0007353166183839999
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2016, epoch_train_loss=0.0007353166183839999
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2017, epoch_train_loss=0.0007353166183839999
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2018, epoch_train_loss=0.0007353166183839999
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2019, epoch_train_loss=0.0007353166183839999
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2020, epoch_train_loss=0.0007353166183839999
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2021, epoch_train_loss=0.0007353166183839999
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2022, epoch_train_loss=0.0007353166183839999
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2023, epoch_train_loss=0.0007353166183839999
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2024, epoch_train_loss=0.0007353166183839999
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2025, epoch_train_loss=0.0007353166183839999
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2026, epoch_train_loss=0.0007353166183839999
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2027, epoch_train_loss=0.0007353166183839999
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2028, epoch_train_loss=0.0007353166183839999
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2029, epoch_train_loss=0.0007353166183839999
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2030, epoch_train_loss=0.0007353166183839999
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2031, epoch_train_loss=0.0007353166183839999
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2032, epoch_train_loss=0.0007353166183839999
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2033, epoch_train_loss=0.0007353166183839999
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2034, epoch_train_loss=0.0007353166183839999
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2035, epoch_train_loss=0.0007353166183839999
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2036, epoch_train_loss=0.0007353166183839999
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2037, epoch_train_loss=0.0007353166183839999
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2038, epoch_train_loss=0.0007353166183839999
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2039, epoch_train_loss=0.0007353166183839999
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2040, epoch_train_loss=0.0007353166183839999
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2041, epoch_train_loss=0.0007353166183839999
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2042, epoch_train_loss=0.0007353166183839999
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2043, epoch_train_loss=0.0007353166183839999
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2044, epoch_train_loss=0.0007353166183839999
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2045, epoch_train_loss=0.0007353166183839999
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2046, epoch_train_loss=0.0007353166183839999
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2047, epoch_train_loss=0.0007353166183839999
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2048, epoch_train_loss=0.0007353166183839999
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2049, epoch_train_loss=0.0007353166183839999
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2050, epoch_train_loss=0.0007353166183839999
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2051, epoch_train_loss=0.0007353166183839999
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2052, epoch_train_loss=0.0007353166183839999
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2053, epoch_train_loss=0.0007353166183839999
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2054, epoch_train_loss=0.0007353166183839999
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2055, epoch_train_loss=0.0007353166183839999
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2056, epoch_train_loss=0.0007353166183839999
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2057, epoch_train_loss=0.0007353166183839999
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2058, epoch_train_loss=0.0007353166183839999
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2059, epoch_train_loss=0.0007353166183839999
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2060, epoch_train_loss=0.0007353166183839999
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2061, epoch_train_loss=0.0007353166183839999
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2062, epoch_train_loss=0.0007353166183839999
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2063, epoch_train_loss=0.0007353166183839999
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2064, epoch_train_loss=0.0007353166183839999
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2065, epoch_train_loss=0.0007353166183839999
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2066, epoch_train_loss=0.0007353166183839999
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2067, epoch_train_loss=0.0007353166183839999
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2068, epoch_train_loss=0.0007353166183839999
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2069, epoch_train_loss=0.0007353166183839999
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2070, epoch_train_loss=0.0007353166183839999
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2071, epoch_train_loss=0.0007353166183839999
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2072, epoch_train_loss=0.0007353166183839999
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2073, epoch_train_loss=0.0007353166183839999
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2074, epoch_train_loss=0.0007353166183839999
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2075, epoch_train_loss=0.0007353166183839999
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2076, epoch_train_loss=0.0007353166183839999
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2077, epoch_train_loss=0.0007353166183839999
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2078, epoch_train_loss=0.0007353166183839999
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2079, epoch_train_loss=0.0007353166183839999
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2080, epoch_train_loss=0.0007353166183839999
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2081, epoch_train_loss=0.0007353166183839999
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2082, epoch_train_loss=0.0007353166183839999
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2083, epoch_train_loss=0.0007353166183839999
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2084, epoch_train_loss=0.0007353166183839999
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2085, epoch_train_loss=0.0007353166183839999
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2086, epoch_train_loss=0.0007353166183839999
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2087, epoch_train_loss=0.0007353166183839999
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2088, epoch_train_loss=0.0007353166183839999
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2089, epoch_train_loss=0.0007353166183839999
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2090, epoch_train_loss=0.0007353166183839999
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2091, epoch_train_loss=0.0007353166183839999
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2092, epoch_train_loss=0.0007353166183839999
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2093, epoch_train_loss=0.0007353166183839999
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2094, epoch_train_loss=0.0007353166183839999
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2095, epoch_train_loss=0.0007353166183839999
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2096, epoch_train_loss=0.0007353166183839999
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2097, epoch_train_loss=0.0007353166183839999
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2098, epoch_train_loss=0.0007353166183839999
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2099, epoch_train_loss=0.0007353166183839999
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2100, epoch_train_loss=0.0007353166183839999
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2101, epoch_train_loss=0.0007353166183839999
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2102, epoch_train_loss=0.0007353166183839999
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2103, epoch_train_loss=0.0007353166183839999
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2104, epoch_train_loss=0.0007353166183839999
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2105, epoch_train_loss=0.0007353166183839999
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2106, epoch_train_loss=0.0007353166183839999
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2107, epoch_train_loss=0.0007353166183839999
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2108, epoch_train_loss=0.0007353166183839999
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2109, epoch_train_loss=0.0007353166183839999
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2110, epoch_train_loss=0.0007353166183839999
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2111, epoch_train_loss=0.0007353166183839999
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2112, epoch_train_loss=0.0007353166183839999
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2113, epoch_train_loss=0.0007353166183839999
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2114, epoch_train_loss=0.0007353166183839999
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2115, epoch_train_loss=0.0007353166183839999
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2116, epoch_train_loss=0.0007353166183839999
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2117, epoch_train_loss=0.0007353166183839999
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2118, epoch_train_loss=0.0007353166183839999
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2119, epoch_train_loss=0.0007353166183839999
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2120, epoch_train_loss=0.0007353166183839999
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2121, epoch_train_loss=0.0007353166183839999
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2122, epoch_train_loss=0.0007353166183839999
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2123, epoch_train_loss=0.0007353166183839999
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2124, epoch_train_loss=0.0007353166183839999
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2125, epoch_train_loss=0.0007353166183839999
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2126, epoch_train_loss=0.0007353166183839999
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2127, epoch_train_loss=0.0007353166183839999
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2128, epoch_train_loss=0.0007353166183839999
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2129, epoch_train_loss=0.0007353166183839999
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2130, epoch_train_loss=0.0007353166183839999
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2131, epoch_train_loss=0.0007353166183839999
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2132, epoch_train_loss=0.0007353166183839999
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2133, epoch_train_loss=0.0007353166183839999
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2134, epoch_train_loss=0.0007353166183839999
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2135, epoch_train_loss=0.0007353166183839999
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2136, epoch_train_loss=0.0007353166183839999
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2137, epoch_train_loss=0.0007353166183839999
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2138, epoch_train_loss=0.0007353166183839999
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2139, epoch_train_loss=0.0007353166183839999
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2140, epoch_train_loss=0.0007353166183839999
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2141, epoch_train_loss=0.0007353166183839999
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2142, epoch_train_loss=0.0007353166183839999
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2143, epoch_train_loss=0.0007353166183839999
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2144, epoch_train_loss=0.0007353166183839999
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2145, epoch_train_loss=0.0007353166183839999
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2146, epoch_train_loss=0.0007353166183839999
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2147, epoch_train_loss=0.0007353166183839999
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2148, epoch_train_loss=0.0007353166183839999
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2149, epoch_train_loss=0.0007353166183839999
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2150, epoch_train_loss=0.0007353166183839999
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2151, epoch_train_loss=0.0007353166183839999
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2152, epoch_train_loss=0.0007353166183839999
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2153, epoch_train_loss=0.0007353166183839999
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2154, epoch_train_loss=0.0007353166183839999
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2155, epoch_train_loss=0.0007353166183839999
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2156, epoch_train_loss=0.0007353166183839999
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2157, epoch_train_loss=0.0007353166183839999
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2158, epoch_train_loss=0.0007353166183839999
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2159, epoch_train_loss=0.0007353166183839999
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2160, epoch_train_loss=0.0007353166183839999
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2161, epoch_train_loss=0.0007353166183839999
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2162, epoch_train_loss=0.0007353166183839999
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2163, epoch_train_loss=0.0007353166183839999
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2164, epoch_train_loss=0.0007353166183839999
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2165, epoch_train_loss=0.0007353166183839999
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2166, epoch_train_loss=0.0007353166183839999
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2167, epoch_train_loss=0.0007353166183839999
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2168, epoch_train_loss=0.0007353166183839999
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2169, epoch_train_loss=0.0007353166183839999
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2170, epoch_train_loss=0.0007353166183839999
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2171, epoch_train_loss=0.0007353166183839999
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2172, epoch_train_loss=0.0007353166183839999
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2173, epoch_train_loss=0.0007353166183839999
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2174, epoch_train_loss=0.0007353166183839999
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2175, epoch_train_loss=0.0007353166183839999
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2176, epoch_train_loss=0.0007353166183839999
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2177, epoch_train_loss=0.0007353166183839999
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2178, epoch_train_loss=0.0007353166183839999
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2179, epoch_train_loss=0.0007353166183839999
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2180, epoch_train_loss=0.0007353166183839999
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2181, epoch_train_loss=0.0007353166183839999
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2182, epoch_train_loss=0.0007353166183839999
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2183, epoch_train_loss=0.0007353166183839999
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2184, epoch_train_loss=0.0007353166183839999
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2185, epoch_train_loss=0.0007353166183839999
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2186, epoch_train_loss=0.0007353166183839999
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2187, epoch_train_loss=0.0007353166183839999
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2188, epoch_train_loss=0.0007353166183839999
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2189, epoch_train_loss=0.0007353166183839999
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2190, epoch_train_loss=0.0007353166183839999
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2191, epoch_train_loss=0.0007353166183839999
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2192, epoch_train_loss=0.0007353166183839999
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2193, epoch_train_loss=0.0007353166183839999
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2194, epoch_train_loss=0.0007353166183839999
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2195, epoch_train_loss=0.0007353166183839999
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2196, epoch_train_loss=0.0007353166183839999
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2197, epoch_train_loss=0.0007353166183839999
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2198, epoch_train_loss=0.0007353166183839999
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2199, epoch_train_loss=0.0007353166183839999
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2200, epoch_train_loss=0.0007353166183839999
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2201, epoch_train_loss=0.0007353166183839999
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2202, epoch_train_loss=0.0007353166183839999
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2203, epoch_train_loss=0.0007353166183839999
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2204, epoch_train_loss=0.0007353166183839999
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2205, epoch_train_loss=0.0007353166183839999
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2206, epoch_train_loss=0.0007353166183839999
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2207, epoch_train_loss=0.0007353166183839999
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2208, epoch_train_loss=0.0007353166183839999
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2209, epoch_train_loss=0.0007353166183839999
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2210, epoch_train_loss=0.0007353166183839999
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2211, epoch_train_loss=0.0007353166183839999
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2212, epoch_train_loss=0.0007353166183839999
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2213, epoch_train_loss=0.0007353166183839999
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2214, epoch_train_loss=0.0007353166183839999
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2215, epoch_train_loss=0.0007353166183839999
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2216, epoch_train_loss=0.0007353166183839999
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2217, epoch_train_loss=0.0007353166183839999
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2218, epoch_train_loss=0.0007353166183839999
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2219, epoch_train_loss=0.0007353166183839999
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2220, epoch_train_loss=0.0007353166183839999
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2221, epoch_train_loss=0.0007353166183839999
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2222, epoch_train_loss=0.0007353166183839999
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2223, epoch_train_loss=0.0007353166183839999
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2224, epoch_train_loss=0.0007353166183839999
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2225, epoch_train_loss=0.0007353166183839999
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2226, epoch_train_loss=0.0007353166183839999
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2227, epoch_train_loss=0.0007353166183839999
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2228, epoch_train_loss=0.0007353166183839999
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2229, epoch_train_loss=0.0007353166183839999
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2230, epoch_train_loss=0.0007353166183839999
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2231, epoch_train_loss=0.0007353166183839999
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2232, epoch_train_loss=0.0007353166183839999
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2233, epoch_train_loss=0.0007353166183839999
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2234, epoch_train_loss=0.0007353166183839999
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2235, epoch_train_loss=0.0007353166183839999
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2236, epoch_train_loss=0.0007353166183839999
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2237, epoch_train_loss=0.0007353166183839999
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2238, epoch_train_loss=0.0007353166183839999
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2239, epoch_train_loss=0.0007353166183839999
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2240, epoch_train_loss=0.0007353166183839999
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2241, epoch_train_loss=0.0007353166183839999
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2242, epoch_train_loss=0.0007353166183839999
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2243, epoch_train_loss=0.0007353166183839999
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2244, epoch_train_loss=0.0007353166183839999
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2245, epoch_train_loss=0.0007353166183839999
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2246, epoch_train_loss=0.0007353166183839999
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2247, epoch_train_loss=0.0007353166183839999
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2248, epoch_train_loss=0.0007353166183839999
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2249, epoch_train_loss=0.0007353166183839999
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2250, epoch_train_loss=0.0007353166183839999
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2251, epoch_train_loss=0.0007353166183839999
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2252, epoch_train_loss=0.0007353166183839999
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2253, epoch_train_loss=0.0007353166183839999
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2254, epoch_train_loss=0.0007353166183839999
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2255, epoch_train_loss=0.0007353166183839999
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2256, epoch_train_loss=0.0007353166183839999
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2257, epoch_train_loss=0.0007353166183839999
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2258, epoch_train_loss=0.0007353166183839999
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2259, epoch_train_loss=0.0007353166183839999
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2260, epoch_train_loss=0.0007353166183839999
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2261, epoch_train_loss=0.0007353166183839999
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2262, epoch_train_loss=0.0007353166183839999
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2263, epoch_train_loss=0.0007353166183839999
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2264, epoch_train_loss=0.0007353166183839999
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2265, epoch_train_loss=0.0007353166183839999
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2266, epoch_train_loss=0.0007353166183839999
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2267, epoch_train_loss=0.0007353166183839999
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2268, epoch_train_loss=0.0007353166183839999
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2269, epoch_train_loss=0.0007353166183839999
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2270, epoch_train_loss=0.0007353166183839999
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2271, epoch_train_loss=0.0007353166183839999
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2272, epoch_train_loss=0.0007353166183839999
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2273, epoch_train_loss=0.0007353166183839999
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2274, epoch_train_loss=0.0007353166183839999
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2275, epoch_train_loss=0.0007353166183839999
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2276, epoch_train_loss=0.0007353166183839999
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2277, epoch_train_loss=0.0007353166183839999
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2278, epoch_train_loss=0.0007353166183839999
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2279, epoch_train_loss=0.0007353166183839999
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2280, epoch_train_loss=0.0007353166183839999
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2281, epoch_train_loss=0.0007353166183839999
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2282, epoch_train_loss=0.0007353166183839999
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2283, epoch_train_loss=0.0007353166183839999
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2284, epoch_train_loss=0.0007353166183839999
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2285, epoch_train_loss=0.0007353166183839999
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2286, epoch_train_loss=0.0007353166183839999
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2287, epoch_train_loss=0.0007353166183839999
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2288, epoch_train_loss=0.0007353166183839999
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2289, epoch_train_loss=0.0007353166183839999
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2290, epoch_train_loss=0.0007353166183839999
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2291, epoch_train_loss=0.0007353166183839999
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2292, epoch_train_loss=0.0007353166183839999
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2293, epoch_train_loss=0.0007353166183839999
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2294, epoch_train_loss=0.0007353166183839999
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2295, epoch_train_loss=0.0007353166183839999
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2296, epoch_train_loss=0.0007353166183839999
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2297, epoch_train_loss=0.0007353166183839999
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2298, epoch_train_loss=0.0007353166183839999
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2299, epoch_train_loss=0.0007353166183839999
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2300, epoch_train_loss=0.0007353166183839999
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2301, epoch_train_loss=0.0007353166183839999
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2302, epoch_train_loss=0.0007353166183839999
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2303, epoch_train_loss=0.0007353166183839999
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2304, epoch_train_loss=0.0007353166183839999
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2305, epoch_train_loss=0.0007353166183839999
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2306, epoch_train_loss=0.0007353166183839999
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2307, epoch_train_loss=0.0007353166183839999
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2308, epoch_train_loss=0.0007353166183839999
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2309, epoch_train_loss=0.0007353166183839999
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2310, epoch_train_loss=0.0007353166183839999
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2311, epoch_train_loss=0.0007353166183839999
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2312, epoch_train_loss=0.0007353166183839999
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2313, epoch_train_loss=0.0007353166183839999
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2314, epoch_train_loss=0.0007353166183839999
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2315, epoch_train_loss=0.0007353166183839999
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2316, epoch_train_loss=0.0007353166183839999
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2317, epoch_train_loss=0.0007353166183839999
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2318, epoch_train_loss=0.0007353166183839999
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2319, epoch_train_loss=0.0007353166183839999
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2320, epoch_train_loss=0.0007353166183839999
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2321, epoch_train_loss=0.0007353166183839999
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2322, epoch_train_loss=0.0007353166183839999
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2323, epoch_train_loss=0.0007353166183839999
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2324, epoch_train_loss=0.0007353166183839999
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2325, epoch_train_loss=0.0007353166183839999
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2326, epoch_train_loss=0.0007353166183839999
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2327, epoch_train_loss=0.0007353166183839999
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2328, epoch_train_loss=0.0007353166183839999
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2329, epoch_train_loss=0.0007353166183839999
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2330, epoch_train_loss=0.0007353166183839999
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2331, epoch_train_loss=0.0007353166183839999
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2332, epoch_train_loss=0.0007353166183839999
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2333, epoch_train_loss=0.0007353166183839999
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2334, epoch_train_loss=0.0007353166183839999
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2335, epoch_train_loss=0.0007353166183839999
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2336, epoch_train_loss=0.0007353166183839999
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2337, epoch_train_loss=0.0007353166183839999
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2338, epoch_train_loss=0.0007353166183839999
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2339, epoch_train_loss=0.0007353166183839999
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2340, epoch_train_loss=0.0007353166183839999
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2341, epoch_train_loss=0.0007353166183839999
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2342, epoch_train_loss=0.0007353166183839999
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2343, epoch_train_loss=0.0007353166183839999
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2344, epoch_train_loss=0.0007353166183839999
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2345, epoch_train_loss=0.0007353166183839999
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2346, epoch_train_loss=0.0007353166183839999
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2347, epoch_train_loss=0.0007353166183839999
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2348, epoch_train_loss=0.0007353166183839999
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2349, epoch_train_loss=0.0007353166183839999
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2350, epoch_train_loss=0.0007353166183839999
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2351, epoch_train_loss=0.0007353166183839999
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2352, epoch_train_loss=0.0007353166183839999
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2353, epoch_train_loss=0.0007353166183839999
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2354, epoch_train_loss=0.0007353166183839999
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2355, epoch_train_loss=0.0007353166183839999
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2356, epoch_train_loss=0.0007353166183839999
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2357, epoch_train_loss=0.0007353166183839999
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2358, epoch_train_loss=0.0007353166183839999
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2359, epoch_train_loss=0.0007353166183839999
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2360, epoch_train_loss=0.0007353166183839999
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2361, epoch_train_loss=0.0007353166183839999
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2362, epoch_train_loss=0.0007353166183839999
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2363, epoch_train_loss=0.0007353166183839999
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2364, epoch_train_loss=0.0007353166183839999
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2365, epoch_train_loss=0.0007353166183839999
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2366, epoch_train_loss=0.0007353166183839999
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2367, epoch_train_loss=0.0007353166183839999
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2368, epoch_train_loss=0.0007353166183839999
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2369, epoch_train_loss=0.0007353166183839999
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2370, epoch_train_loss=0.0007353166183839999
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2371, epoch_train_loss=0.0007353166183839999
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2372, epoch_train_loss=0.0007353166183839999
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2373, epoch_train_loss=0.0007353166183839999
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2374, epoch_train_loss=0.0007353166183839999
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2375, epoch_train_loss=0.0007353166183839999
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2376, epoch_train_loss=0.0007353166183839999
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2377, epoch_train_loss=0.0007353166183839999
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2378, epoch_train_loss=0.0007353166183839999
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2379, epoch_train_loss=0.0007353166183839999
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2380, epoch_train_loss=0.0007353166183839999
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2381, epoch_train_loss=0.0007353166183839999
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2382, epoch_train_loss=0.0007353166183839999
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2383, epoch_train_loss=0.0007353166183839999
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2384, epoch_train_loss=0.0007353166183839999
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2385, epoch_train_loss=0.0007353166183839999
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2386, epoch_train_loss=0.0007353166183839999
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2387, epoch_train_loss=0.0007353166183839999
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2388, epoch_train_loss=0.0007353166183839999
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2389, epoch_train_loss=0.0007353166183839999
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2390, epoch_train_loss=0.0007353166183839999
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2391, epoch_train_loss=0.0007353166183839999
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2392, epoch_train_loss=0.0007353166183839999
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2393, epoch_train_loss=0.0007353166183839999
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2394, epoch_train_loss=0.0007353166183839999
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2395, epoch_train_loss=0.0007353166183839999
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2396, epoch_train_loss=0.0007353166183839999
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2397, epoch_train_loss=0.0007353166183839999
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2398, epoch_train_loss=0.0007353166183839999
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2399, epoch_train_loss=0.0007353166183839999
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2400, epoch_train_loss=0.0007353166183839999
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2401, epoch_train_loss=0.0007353166183839999
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2402, epoch_train_loss=0.0007353166183839999
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2403, epoch_train_loss=0.0007353166183839999
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2404, epoch_train_loss=0.0007353166183839999
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2405, epoch_train_loss=0.0007353166183839999
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2406, epoch_train_loss=0.0007353166183839999
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2407, epoch_train_loss=0.0007353166183839999
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2408, epoch_train_loss=0.0007353166183839999
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2409, epoch_train_loss=0.0007353166183839999
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2410, epoch_train_loss=0.0007353166183839999
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2411, epoch_train_loss=0.0007353166183839999
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2412, epoch_train_loss=0.0007353166183839999
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2413, epoch_train_loss=0.0007353166183839999
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2414, epoch_train_loss=0.0007353166183839999
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2415, epoch_train_loss=0.0007353166183839999
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2416, epoch_train_loss=0.0007353166183839999
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2417, epoch_train_loss=0.0007353166183839999
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2418, epoch_train_loss=0.0007353166183839999
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2419, epoch_train_loss=0.0007353166183839999
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2420, epoch_train_loss=0.0007353166183839999
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2421, epoch_train_loss=0.0007353166183839999
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2422, epoch_train_loss=0.0007353166183839999
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2423, epoch_train_loss=0.0007353166183839999
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2424, epoch_train_loss=0.0007353166183839999
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2425, epoch_train_loss=0.0007353166183839999
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2426, epoch_train_loss=0.0007353166183839999
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2427, epoch_train_loss=0.0007353166183839999
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2428, epoch_train_loss=0.0007353166183839999
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2429, epoch_train_loss=0.0007353166183839999
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2430, epoch_train_loss=0.0007353166183839999
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2431, epoch_train_loss=0.0007353166183839999
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2432, epoch_train_loss=0.0007353166183839999
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2433, epoch_train_loss=0.0007353166183839999
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2434, epoch_train_loss=0.0007353166183839999
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2435, epoch_train_loss=0.0007353166183839999
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2436, epoch_train_loss=0.0007353166183839999
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2437, epoch_train_loss=0.0007353166183839999
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2438, epoch_train_loss=0.0007353166183839999
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2439, epoch_train_loss=0.0007353166183839999
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2440, epoch_train_loss=0.0007353166183839999
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2441, epoch_train_loss=0.0007353166183839999
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2442, epoch_train_loss=0.0007353166183839999
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2443, epoch_train_loss=0.0007353166183839999
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2444, epoch_train_loss=0.0007353166183839999
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2445, epoch_train_loss=0.0007353166183839999
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2446, epoch_train_loss=0.0007353166183839999
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2447, epoch_train_loss=0.0007353166183839999
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2448, epoch_train_loss=0.0007353166183839999
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2449, epoch_train_loss=0.0007353166183839999
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2450, epoch_train_loss=0.0007353166183839999
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2451, epoch_train_loss=0.0007353166183839999
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2452, epoch_train_loss=0.0007353166183839999
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2453, epoch_train_loss=0.0007353166183839999
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2454, epoch_train_loss=0.0007353166183839999
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2455, epoch_train_loss=0.0007353166183839999
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2456, epoch_train_loss=0.0007353166183839999
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2457, epoch_train_loss=0.0007353166183839999
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2458, epoch_train_loss=0.0007353166183839999
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2459, epoch_train_loss=0.0007353166183839999
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2460, epoch_train_loss=0.0007353166183839999
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2461, epoch_train_loss=0.0007353166183839999
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2462, epoch_train_loss=0.0007353166183839999
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2463, epoch_train_loss=0.0007353166183839999
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2464, epoch_train_loss=0.0007353166183839999
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2465, epoch_train_loss=0.0007353166183839999
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2466, epoch_train_loss=0.0007353166183839999
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2467, epoch_train_loss=0.0007353166183839999
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2468, epoch_train_loss=0.0007353166183839999
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2469, epoch_train_loss=0.0007353166183839999
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2470, epoch_train_loss=0.0007353166183839999
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2471, epoch_train_loss=0.0007353166183839999
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2472, epoch_train_loss=0.0007353166183839999
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2473, epoch_train_loss=0.0007353166183839999
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2474, epoch_train_loss=0.0007353166183839999
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2475, epoch_train_loss=0.0007353166183839999
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2476, epoch_train_loss=0.0007353166183839999
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2477, epoch_train_loss=0.0007353166183839999
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2478, epoch_train_loss=0.0007353166183839999
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2479, epoch_train_loss=0.0007353166183839999
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2480, epoch_train_loss=0.0007353166183839999
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2481, epoch_train_loss=0.0007353166183839999
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2482, epoch_train_loss=0.0007353166183839999
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2483, epoch_train_loss=0.0007353166183839999
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2484, epoch_train_loss=0.0007353166183839999
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2485, epoch_train_loss=0.0007353166183839999
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2486, epoch_train_loss=0.0007353166183839999
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2487, epoch_train_loss=0.0007353166183839999
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2488, epoch_train_loss=0.0007353166183839999
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2489, epoch_train_loss=0.0007353166183839999
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2490, epoch_train_loss=0.0007353166183839999
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2491, epoch_train_loss=0.0007353166183839999
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2492, epoch_train_loss=0.0007353166183839999
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2493, epoch_train_loss=0.0007353166183839999
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2494, epoch_train_loss=0.0007353166183839999
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2495, epoch_train_loss=0.0007353166183839999
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2496, epoch_train_loss=0.0007353166183839999
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2497, epoch_train_loss=0.0007353166183839999
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2498, epoch_train_loss=0.0007353166183839999
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0007353166183839999
2499, epoch_train_loss=0.0007353166183839999
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0108ee0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0108ee0> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeb0108ee0> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb010aad0> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0108e50> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb01092d0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0108850> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0109900> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0109390> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0109f60> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb0109f90> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb0109780> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb010a5f0> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb010a380> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010a230> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010a710> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010a920> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb010a6b0> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010abc0> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010abf0> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010a860> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010ae90> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb010ada0> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb010ad10> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb010b250> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeb010b520> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb010b190> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992718  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010aad0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010aad0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051022 -0.00019156 -0.00051334 ... -0.02830887 -0.02830887
 -0.02830887] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046675  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0108e50> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0108e50> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-3.60081838e-04 -1.08775305e-04 -1.31917160e-05 ... -2.74817476e-02
 -2.74817476e-02 -2.74817476e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 4)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb01092d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb01092d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.92637327e-09 -1.31700807e-07 -9.61527370e-06 ... -7.35522754e-16
 -7.35522754e-16 -7.35522754e-16] = ,SCAN
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 4)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0108850> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0108850> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.31884219e-04 -2.81911891e-04 -2.81911891e-04 ... -1.27154711e-05
 -2.64861768e-02 -2.64861768e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 4)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.003383226351  <S^2> = 2.0027437  2S+1 = 3.0018286
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0109900> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0109900> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.35331669e-04 -4.40313412e-05 -2.36098301e-06 ... -2.76158592e-02
 -2.76158592e-02 -2.76158592e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 4)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121764  <S^2> = 0.75161941  2S+1 = 2.0016188
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0109390> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0109390> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.70773309e-04 -2.50216156e-04 -8.43674545e-05 ... -2.84484391e-02
 -2.84484391e-02 -2.84484391e-02] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 4)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560966115  <S^2> = 0.75226415  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0109f60> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0109f60> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.41125281e-03 -1.49798328e-03 -7.60396424e-04 ... -2.77629490e-05
 -3.12474764e-04 -3.67912927e-05] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 4)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786807125  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0109f90> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0109f90> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00038744 -0.00017488 -0.00023372 ... -0.02838402 -0.02838402
 -0.02838402] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 2.6645353e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb0109780> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb0109780> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00043469 -0.00024024 -0.00035532 ... -0.00047537 -0.03728133
 -0.03728133] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 4)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.3377924465131  <S^2> = 4.00731e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a5f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a5f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-9.02468888e-05 -7.92694658e-06 -9.80568469e-06 ... -4.33714150e-02
 -4.33714150e-02 -4.33714150e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 4)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322843  <S^2> = 1.5987212e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a380> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a380> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.48187338e-05 -6.19475249e-05 -2.61742784e-04 ... -8.70042314e-07
 -2.73391097e-02 -2.73391097e-02] = ,SCAN
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 4)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.00560888896  <S^2> = 4.8672177e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a230> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a230> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051559 -0.00027432 -0.00088583 ... -0.00027432 -0.04174728
 -0.04174728] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 4)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.1368684e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a710> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a710> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.53951178e-05 -5.93507199e-06 -3.10072916e-04 ... -5.94325581e-02
 -5.94325581e-02 -5.94325581e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 4)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894468362  <S^2> = 1.0018598  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a920> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a920> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.54414325e-04 -2.91254514e-05 -1.59104940e-06 ... -4.22396701e-02
 -4.22396701e-02 -4.22396701e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 4)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346373  <S^2> = 8.8817842e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a6b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a6b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.72190712e-05 -2.72190712e-05 -2.84904833e-04 ... -1.08108260e-05
 -1.03072478e-05 -1.03072478e-05] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 4)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5725203e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010abc0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010abc0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00015688 -0.00024669 -0.00068269 ... -0.03791166 -0.03791166
 -0.03791166] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 4)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374078  <S^2> = 7.1054274e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010abf0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010abf0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.28500681e-05 -5.65091132e-06 -7.37932132e-06 ... -4.76689214e-02
 -4.76689214e-02 -4.76689214e-02] = ,SCAN
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 4)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.571721e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010a860> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010a860> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003863  -0.00040095 -0.00040095 ... -0.0213199  -0.0213199
 -0.0213199 ] = ,SCAN
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 4)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5859314e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010ae90> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010ae90> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00088473 -0.00088473 -0.00116894 ... -0.00088473 -0.00088473
 -0.00116894] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 4)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.1712415e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010ada0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010ada0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.91408540e-05 -1.46971271e-04 -1.08734417e-03 ... -2.81566369e-02
 -2.81566369e-02 -2.81566369e-02] = ,SCAN
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 4)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5393021e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010ad10> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010ad10> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.39373335e-04 -1.31641332e-04 -1.15950750e-05 ... -7.32416564e-02
 -7.32416564e-02 -7.32416564e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 4)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565335802245  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010b250> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010b250> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.84669422e-05 -7.80542404e-05 -7.80534961e-05 ... -2.92531263e-02
 -2.92531263e-02 -2.92531263e-02] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 4)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864077  <S^2> = 3.2329694e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010b520> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010b520> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.56165538e-04 -7.34744214e-05 -5.30574304e-06 ... -7.93995702e-06
 -7.93995702e-06 -7.93995702e-06] = ,SCAN
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 4)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.2034822e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb010b190> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb010b190> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.28290753e-04 -1.41305449e-05 -6.13700492e-05 ... -2.47993463e-02
 -2.47993463e-02 -2.47993463e-02] = ,SCAN
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 4)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437818  <S^2> = 1.3152146e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.45512011e-04 -7.12775692e-05 -5.48666345e-06 ... -6.02613084e-06
 -6.02613084e-06 -6.02613084e-06] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 4)
PRE NAN FILT: tFxc.shape=(224159,), tdrho.shape=(224159, 4)
nan_filt_rho.shape=(224159,)
nan_filt_fxc.shape=(224159,)
tFxc.shape=(224159,), tdrho.shape=(224159, 4)
inp[0].shape = (224159, 4)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 0.3653243375871331
0, epoch_train_loss=0.3653243375871331
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 0.2700801325389282
1, epoch_train_loss=0.2700801325389282
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 0.19796192520649136
2, epoch_train_loss=0.19796192520649136
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 0.14873606327554192
3, epoch_train_loss=0.14873606327554192
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 0.09891942896494058
4, epoch_train_loss=0.09891942896494058
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 0.051400285144190594
5, epoch_train_loss=0.051400285144190594
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 0.020446563359952846
6, epoch_train_loss=0.020446563359952846
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.007015459149693003
7, epoch_train_loss=0.007015459149693003
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.0026424345966408465
8, epoch_train_loss=0.0026424345966408465
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.0013697190006580883
9, epoch_train_loss=0.0013697190006580883
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.0009823414657945473
10, epoch_train_loss=0.0009823414657945473
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.0008513239207823955
11, epoch_train_loss=0.0008513239207823955
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.0008024527763291106
12, epoch_train_loss=0.0008024527763291106
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.0007832299709091364
13, epoch_train_loss=0.0007832299709091364
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.0007762111433574649
14, epoch_train_loss=0.0007762111433574649
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.000774864187375019
15, epoch_train_loss=0.000774864187375019
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.0007761646563278972
16, epoch_train_loss=0.0007761646563278972
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.0007781420677090227
17, epoch_train_loss=0.0007781420677090227
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.0007791362825472065
18, epoch_train_loss=0.0007791362825472065
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.0007778640221283862
19, epoch_train_loss=0.0007778640221283862
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.0007738769038633901
20, epoch_train_loss=0.0007738769038633901
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.0007678157725505758
21, epoch_train_loss=0.0007678157725505758
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.0007609936017824266
22, epoch_train_loss=0.0007609936017824266
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.0007546247717590632
23, epoch_train_loss=0.0007546247717590632
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.0007493734540740551
24, epoch_train_loss=0.0007493734540740551
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.0007453797705285917
25, epoch_train_loss=0.0007453797705285917
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.000742489953043037
26, epoch_train_loss=0.000742489953043037
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0007404559841350474
27, epoch_train_loss=0.0007404559841350474
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.0007390418946465716
28, epoch_train_loss=0.0007390418946465716
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.0007380605368939155
29, epoch_train_loss=0.0007380605368939155
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0007373759468704577
30, epoch_train_loss=0.0007373759468704577
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.0007368937315792867
31, epoch_train_loss=0.0007368937315792867
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.0007365498136995981
32, epoch_train_loss=0.0007365498136995981
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.0007363010767275958
33, epoch_train_loss=0.0007363010767275958
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.0007361185180638882
34, epoch_train_loss=0.0007361185180638882
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.0007359825307798357
35, epoch_train_loss=0.0007359825307798357
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.0007358797480931128
36, epoch_train_loss=0.0007358797480931128
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.0007358009614670921
37, epoch_train_loss=0.0007358009614670921
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.0007357397525206249
38, epoch_train_loss=0.0007357397525206249
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.0007356915922655274
39, epoch_train_loss=0.0007356915922655274
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.0007356532446588419
40, epoch_train_loss=0.0007356532446588419
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.0007356223684684382
41, epoch_train_loss=0.0007356223684684382
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.0007355972489730777
42, epoch_train_loss=0.0007355972489730777
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.0007355766152695939
43, epoch_train_loss=0.0007355766152695939
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.000735559514516417
44, epoch_train_loss=0.000735559514516417
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.0007355452244105491
45, epoch_train_loss=0.0007355452244105491
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.0007355331916007283
46, epoch_train_loss=0.0007355331916007283
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.0007355229878787974
47, epoch_train_loss=0.0007355229878787974
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.0007355142786854534
48, epoch_train_loss=0.0007355142786854534
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.0007355068002347498
49, epoch_train_loss=0.0007355068002347498
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.0007355003427326421
50, epoch_train_loss=0.0007355003427326421
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.0007354947379475502
51, epoch_train_loss=0.0007354947379475502
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.0007354898501242615
52, epoch_train_loss=0.0007354898501242615
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.000735485568507454
53, epoch_train_loss=0.000735485568507454
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.0007354818022918629
54, epoch_train_loss=0.0007354818022918629
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.0007354784765317516
55, epoch_train_loss=0.0007354784765317516
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.0007354755289791289
56, epoch_train_loss=0.0007354755289791289
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.0007354729076235097
57, epoch_train_loss=0.0007354729076235097
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0007354705687628886
58, epoch_train_loss=0.0007354705687628886
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.0007354684754792757
59, epoch_train_loss=0.0007354684754792757
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.0007354665964289624
60, epoch_train_loss=0.0007354665964289624
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.0007354649048741411
61, epoch_train_loss=0.0007354649048741411
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.0007354633779045437
62, epoch_train_loss=0.0007354633779045437
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.000735461995806375
63, epoch_train_loss=0.000735461995806375
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.0007354607415498541
64, epoch_train_loss=0.0007354607415498541
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0007354596003692715
65, epoch_train_loss=0.0007354596003692715
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.000735458559418007
66, epoch_train_loss=0.000735458559418007
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0007354576074828479
67, epoch_train_loss=0.0007354576074828479
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.0007354567347469836
68, epoch_train_loss=0.0007354567347469836
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0007354559325921076
69, epoch_train_loss=0.0007354559325921076
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0007354551934324322
70, epoch_train_loss=0.0007354551934324322
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0007354545105751166
71, epoch_train_loss=0.0007354545105751166
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0007354538781019039
72, epoch_train_loss=0.0007354538781019039
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0007354532907687699
73, epoch_train_loss=0.0007354532907687699
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0007354527439204803
74, epoch_train_loss=0.0007354527439204803
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0007354522334172123
75, epoch_train_loss=0.0007354522334172123
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0007354517555716523
76, epoch_train_loss=0.0007354517555716523
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0007354513070948357
77, epoch_train_loss=0.0007354513070948357
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.0007354508850492281
78, epoch_train_loss=0.0007354508850492281
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0007354504868079528
79, epoch_train_loss=0.0007354504868079528
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0007354501100193682
80, epoch_train_loss=0.0007354501100193682
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.0007354497525762246
81, epoch_train_loss=0.0007354497525762246
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0007354494125884767
82, epoch_train_loss=0.0007354494125884767
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.0007354490883596292
83, epoch_train_loss=0.0007354490883596292
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0007354487783657269
84, epoch_train_loss=0.0007354487783657269
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0007354484812369927
85, epoch_train_loss=0.0007354484812369927
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.0007354481957415073
86, epoch_train_loss=0.0007354481957415073
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.000735447920770797
87, epoch_train_loss=0.000735447920770797
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0007354476553269674
88, epoch_train_loss=0.0007354476553269674
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0007354473985113837
89, epoch_train_loss=0.0007354473985113837
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0007354471495145336
90, epoch_train_loss=0.0007354471495145336
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0007354469076069351
91, epoch_train_loss=0.0007354469076069351
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0007354466721311225
92, epoch_train_loss=0.0007354466721311225
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0007354464424944139
93, epoch_train_loss=0.0007354464424944139
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.0007354462181624675
94, epoch_train_loss=0.0007354462181624675
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0007354459986534438
95, epoch_train_loss=0.0007354459986534438
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0007354457835328635
96, epoch_train_loss=0.0007354457835328635
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.0007354455724089281
97, epoch_train_loss=0.0007354455724089281
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0007354453649283311
98, epoch_train_loss=0.0007354453649283311
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0007354451607724888
99, epoch_train_loss=0.0007354451607724888
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0007354449596541503
100, epoch_train_loss=0.0007354449596541503
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.0007354447613143442
101, epoch_train_loss=0.0007354447613143442
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0007354445655196269
102, epoch_train_loss=0.0007354445655196269
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.000735444372059603
103, epoch_train_loss=0.000735444372059603
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.000735444180744689
104, epoch_train_loss=0.000735444180744689
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0007354439914040803
105, epoch_train_loss=0.0007354439914040803
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0007354438038839737
106, epoch_train_loss=0.0007354438038839737
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0007354436180458802
107, epoch_train_loss=0.0007354436180458802
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0007354434337651535
108, epoch_train_loss=0.0007354434337651535
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0007354432509296361
109, epoch_train_loss=0.0007354432509296361
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0007354430694384885
110, epoch_train_loss=0.0007354430694384885
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0007354428892010526
111, epoch_train_loss=0.0007354428892010526
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0007354427101358621
112, epoch_train_loss=0.0007354427101358621
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0007354425321697896
113, epoch_train_loss=0.0007354425321697896
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0007354423552371952
114, epoch_train_loss=0.0007354423552371952
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0007354421792792113
115, epoch_train_loss=0.0007354421792792113
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0007354420042430798
116, epoch_train_loss=0.0007354420042430798
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007354418300815423
117, epoch_train_loss=0.0007354418300815423
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.000735441656752326
118, epoch_train_loss=0.000735441656752326
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007354414842176536
119, epoch_train_loss=0.0007354414842176536
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.0007354413124437638
120, epoch_train_loss=0.0007354413124437638
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007354411414005633
121, epoch_train_loss=0.0007354411414005633
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007354409710612135
122, epoch_train_loss=0.0007354409710612135
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0007354408014018561
123, epoch_train_loss=0.0007354408014018561
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0007354406324012659
124, epoch_train_loss=0.0007354406324012659
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.000735440464040635
125, epoch_train_loss=0.000735440464040635
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0007354402963032812
126, epoch_train_loss=0.0007354402963032812
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0007354401291744683
127, epoch_train_loss=0.0007354401291744683
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.000735439962641195
128, epoch_train_loss=0.000735439962641195
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0007354397966920304
129, epoch_train_loss=0.0007354397966920304
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0007354396313169158
130, epoch_train_loss=0.0007354396313169158
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0007354394665070559
131, epoch_train_loss=0.0007354394665070559
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007354393022547765
132, epoch_train_loss=0.0007354393022547765
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007354391385534043
133, epoch_train_loss=0.0007354391385534043
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007354389753971736
134, epoch_train_loss=0.0007354389753971736
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0007354388127810925
135, epoch_train_loss=0.0007354388127810925
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007354386507008922
136, epoch_train_loss=0.0007354386507008922
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007354384891529367
137, epoch_train_loss=0.0007354384891529367
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0007354383281341518
138, epoch_train_loss=0.0007354383281341518
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007354381676419605
139, epoch_train_loss=0.0007354381676419605
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007354380076742266
140, epoch_train_loss=0.0007354380076742266
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007354378482292016
141, epoch_train_loss=0.0007354378482292016
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0007354376893054794
142, epoch_train_loss=0.0007354376893054794
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0007354375309019527
143, epoch_train_loss=0.0007354375309019527
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.000735437373017776
144, epoch_train_loss=0.000735437373017776
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.0007354372156523201
145, epoch_train_loss=0.0007354372156523201
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0007354370588051883
146, epoch_train_loss=0.0007354370588051883
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0007354369024761056
147, epoch_train_loss=0.0007354369024761056
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0007354367466649782
148, epoch_train_loss=0.0007354367466649782
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0007354365913718233
149, epoch_train_loss=0.0007354365913718233
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0007354364365967608
150, epoch_train_loss=0.0007354364365967608
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.000735436282339985
151, epoch_train_loss=0.000735436282339985
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0007354361286017827
152, epoch_train_loss=0.0007354361286017827
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0007354359753824841
153, epoch_train_loss=0.0007354359753824841
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0007354358226824513
154, epoch_train_loss=0.0007354358226824513
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.0007354356705021009
155, epoch_train_loss=0.0007354356705021009
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0007354355188418591
156, epoch_train_loss=0.0007354355188418591
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.0007354353677021537
157, epoch_train_loss=0.0007354353677021537
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0007354352170834397
158, epoch_train_loss=0.0007354352170834397
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0007354350669861589
159, epoch_train_loss=0.0007354350669861589
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.0007354349174107334
160, epoch_train_loss=0.0007354349174107334
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0007354347683575941
161, epoch_train_loss=0.0007354347683575941
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.000735434619827131
162, epoch_train_loss=0.000735434619827131
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0007354344718197225
163, epoch_train_loss=0.0007354344718197225
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.0007354343243357324
164, epoch_train_loss=0.0007354343243357324
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0007354341773754725
165, epoch_train_loss=0.0007354341773754725
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0007354340309392453
166, epoch_train_loss=0.0007354340309392453
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0007354338850272965
167, epoch_train_loss=0.0007354338850272965
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0007354337396398472
168, epoch_train_loss=0.0007354337396398472
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0007354335947770802
169, epoch_train_loss=0.0007354335947770802
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0007354334504391397
170, epoch_train_loss=0.0007354334504391397
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.00073543330662614
171, epoch_train_loss=0.00073543330662614
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.000735433163338133
172, epoch_train_loss=0.000735433163338133
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0007354330205751507
173, epoch_train_loss=0.0007354330205751507
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.0007354328783371505
174, epoch_train_loss=0.0007354328783371505
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0007354327366240898
175, epoch_train_loss=0.0007354327366240898
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0007354325954358523
176, epoch_train_loss=0.0007354325954358523
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.0007354324547722888
177, epoch_train_loss=0.0007354324547722888
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0007354323146332079
178, epoch_train_loss=0.0007354323146332079
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.0007354321750183759
179, epoch_train_loss=0.0007354321750183759
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0007354320359275167
180, epoch_train_loss=0.0007354320359275167
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0007354318973603123
181, epoch_train_loss=0.0007354318973603123
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.0007354317593164036
182, epoch_train_loss=0.0007354317593164036
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0007354316217953905
183, epoch_train_loss=0.0007354316217953905
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0007354314847968324
184, epoch_train_loss=0.0007354314847968324
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0007354313483202487
185, epoch_train_loss=0.0007354313483202487
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0007354312123651095
186, epoch_train_loss=0.0007354312123651095
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0007354310769308769
187, epoch_train_loss=0.0007354310769308769
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0007354309420169341
188, epoch_train_loss=0.0007354309420169341
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.0007354308076226578
189, epoch_train_loss=0.0007354308076226578
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0007354306737473676
190, epoch_train_loss=0.0007354306737473676
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0007354305403903676
191, epoch_train_loss=0.0007354305403903676
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.0007354304075509169
192, epoch_train_loss=0.0007354304075509169
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0007354302752282393
193, epoch_train_loss=0.0007354302752282393
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.0007354301434215262
194, epoch_train_loss=0.0007354301434215262
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0007354300121299251
195, epoch_train_loss=0.0007354300121299251
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.0007354298813525719
196, epoch_train_loss=0.0007354298813525719
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.0007354297510885512
197, epoch_train_loss=0.0007354297510885512
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.0007354296213369364
198, epoch_train_loss=0.0007354296213369364
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.0007354294920967617
199, epoch_train_loss=0.0007354294920967617
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0007354293633670219
200, epoch_train_loss=0.0007354293633670219
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.0007354292351467031
201, epoch_train_loss=0.0007354292351467031
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0007354291074347448
202, epoch_train_loss=0.0007354291074347448
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0007354289802300685
203, epoch_train_loss=0.0007354289802300685
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.0007354288535315798
204, epoch_train_loss=0.0007354288535315798
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0007354287273381394
205, epoch_train_loss=0.0007354287273381394
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0007354286016485924
206, epoch_train_loss=0.0007354286016485924
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0007354284764617702
207, epoch_train_loss=0.0007354284764617702
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.0007354283517764615
208, epoch_train_loss=0.0007354283517764615
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0007354282275914416
209, epoch_train_loss=0.0007354282275914416
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0007354281039054731
210, epoch_train_loss=0.0007354281039054731
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.000735427980717279
211, epoch_train_loss=0.000735427980717279
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.0007354278580255707
212, epoch_train_loss=0.0007354278580255707
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.0007354277358290487
213, epoch_train_loss=0.0007354277358290487
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0007354276141263756
214, epoch_train_loss=0.0007354276141263756
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0007354274929161956
215, epoch_train_loss=0.0007354274929161956
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.0007354273721971617
216, epoch_train_loss=0.0007354273721971617
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.0007354272519678823
217, epoch_train_loss=0.0007354272519678823
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0007354271322269573
218, epoch_train_loss=0.0007354271322269573
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0007354270129729712
219, epoch_train_loss=0.0007354270129729712
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.0007354268942044913
220, epoch_train_loss=0.0007354268942044913
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0007354267759200707
221, epoch_train_loss=0.0007354267759200707
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.000735426658118247
222, epoch_train_loss=0.000735426658118247
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.000735426540797544
223, epoch_train_loss=0.000735426540797544
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0007354264239564712
224, epoch_train_loss=0.0007354264239564712
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0007354263075935256
225, epoch_train_loss=0.0007354263075935256
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.0007354261917071912
226, epoch_train_loss=0.0007354261917071912
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.0007354260762959307
227, epoch_train_loss=0.0007354260762959307
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.0007354259613582129
228, epoch_train_loss=0.0007354259613582129
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0007354258468924862
229, epoch_train_loss=0.0007354258468924862
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.000735425732897189
230, epoch_train_loss=0.000735425732897189
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.0007354256193707481
231, epoch_train_loss=0.0007354256193707481
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.0007354255063115728
232, epoch_train_loss=0.0007354255063115728
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0007354253937180799
233, epoch_train_loss=0.0007354253937180799
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0007354252815886677
234, epoch_train_loss=0.0007354252815886677
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0007354251699217269
235, epoch_train_loss=0.0007354251699217269
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.0007354250587156393
236, epoch_train_loss=0.0007354250587156393
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0007354249479687708
237, epoch_train_loss=0.0007354249479687708
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.0007354248376794881
238, epoch_train_loss=0.0007354248376794881
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.0007354247278461589
239, epoch_train_loss=0.0007354247278461589
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.0007354246184671279
240, epoch_train_loss=0.0007354246184671279
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.0007354245095407496
241, epoch_train_loss=0.0007354245095407496
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0007354244010653643
242, epoch_train_loss=0.0007354244010653643
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.000735424293039299
243, epoch_train_loss=0.000735424293039299
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0007354241854608905
244, epoch_train_loss=0.0007354241854608905
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.0007354240783284556
245, epoch_train_loss=0.0007354240783284556
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.000735423971640314
246, epoch_train_loss=0.000735423971640314
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0007354238653947804
247, epoch_train_loss=0.0007354238653947804
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.0007354237595901744
248, epoch_train_loss=0.0007354237595901744
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.0007354236542247955
249, epoch_train_loss=0.0007354236542247955
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0007354235492969475
250, epoch_train_loss=0.0007354235492969475
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0007354234448049388
251, epoch_train_loss=0.0007354234448049388
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0007354233407470596
252, epoch_train_loss=0.0007354233407470596
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.000735423237121605
253, epoch_train_loss=0.000735423237121605
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.0007354231339268756
254, epoch_train_loss=0.0007354231339268756
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0007354230311611538
255, epoch_train_loss=0.0007354230311611538
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.0007354229288227287
256, epoch_train_loss=0.0007354229288227287
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0007354228269098875
257, epoch_train_loss=0.0007354228269098875
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.0007354227254209156
258, epoch_train_loss=0.0007354227254209156
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0007354226243540978
259, epoch_train_loss=0.0007354226243540978
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.0007354225237077177
260, epoch_train_loss=0.0007354225237077177
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.0007354224234800582
261, epoch_train_loss=0.0007354224234800582
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.0007354223236694017
262, epoch_train_loss=0.0007354223236694017
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.0007354222242740303
263, epoch_train_loss=0.0007354222242740303
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.0007354221252922264
264, epoch_train_loss=0.0007354221252922264
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.0007354220267222719
265, epoch_train_loss=0.0007354220267222719
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0007354219285624493
266, epoch_train_loss=0.0007354219285624493
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.0007354218308110418
267, epoch_train_loss=0.0007354218308110418
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0007354217334663331
268, epoch_train_loss=0.0007354217334663331
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.0007354216365266007
269, epoch_train_loss=0.0007354216365266007
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.0007354215399901373
270, epoch_train_loss=0.0007354215399901373
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.0007354214438552303
271, epoch_train_loss=0.0007354214438552303
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0007354213481201676
272, epoch_train_loss=0.0007354213481201676
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.0007354212527832321
273, epoch_train_loss=0.0007354212527832321
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0007354211578427227
274, epoch_train_loss=0.0007354211578427227
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0007354210632969256
275, epoch_train_loss=0.0007354210632969256
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.0007354209691441436
276, epoch_train_loss=0.0007354209691441436
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.0007354208753826743
277, epoch_train_loss=0.0007354208753826743
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0007354207820108177
278, epoch_train_loss=0.0007354207820108177
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.0007354206890268692
279, epoch_train_loss=0.0007354206890268692
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.0007354205964291412
280, epoch_train_loss=0.0007354205964291412
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.000735420504215934
281, epoch_train_loss=0.000735420504215934
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.0007354204123855655
282, epoch_train_loss=0.0007354204123855655
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.0007354203209363424
283, epoch_train_loss=0.0007354203209363424
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0007354202298665809
284, epoch_train_loss=0.0007354202298665809
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0007354201391746084
285, epoch_train_loss=0.0007354201391746084
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.0007354200488587479
286, epoch_train_loss=0.0007354200488587479
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.0007354199589173189
287, epoch_train_loss=0.0007354199589173189
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.0007354198693486518
288, epoch_train_loss=0.0007354198693486518
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0007354197801510803
289, epoch_train_loss=0.0007354197801510803
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.000735419691322949
290, epoch_train_loss=0.000735419691322949
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.000735419602862592
291, epoch_train_loss=0.000735419602862592
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.0007354195147683614
292, epoch_train_loss=0.0007354195147683614
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.0007354194270386003
293, epoch_train_loss=0.0007354194270386003
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.0007354193396716616
294, epoch_train_loss=0.0007354193396716616
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.000735419252665903
295, epoch_train_loss=0.000735419252665903
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.0007354191660196867
296, epoch_train_loss=0.0007354191660196867
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.0007354190797313851
297, epoch_train_loss=0.0007354190797313851
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.0007354189937993623
298, epoch_train_loss=0.0007354189937993623
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.0007354189082219874
299, epoch_train_loss=0.0007354189082219874
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.0007354188229976463
300, epoch_train_loss=0.0007354188229976463
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0007354187381247299
301, epoch_train_loss=0.0007354187381247299
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.000735418653601621
302, epoch_train_loss=0.000735418653601621
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.0007354185694267072
303, epoch_train_loss=0.0007354185694267072
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.0007354184855983933
304, epoch_train_loss=0.0007354184855983933
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.0007354184021150895
305, epoch_train_loss=0.0007354184021150895
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.0007354183189751918
306, epoch_train_loss=0.0007354183189751918
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.0007354182361771202
307, epoch_train_loss=0.0007354182361771202
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.0007354181537192933
308, epoch_train_loss=0.0007354181537192933
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.0007354180716001349
309, epoch_train_loss=0.0007354180716001349
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0007354179898180744
310, epoch_train_loss=0.0007354179898180744
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0007354179083715395
311, epoch_train_loss=0.0007354179083715395
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.0007354178272589824
312, epoch_train_loss=0.0007354178272589824
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.0007354177464788352
313, epoch_train_loss=0.0007354177464788352
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.0007354176660295485
314, epoch_train_loss=0.0007354176660295485
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.0007354175859095903
315, epoch_train_loss=0.0007354175859095903
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0007354175061174092
316, epoch_train_loss=0.0007354175061174092
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.000735417426651472
317, epoch_train_loss=0.000735417426651472
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.0007354173475102626
318, epoch_train_loss=0.0007354173475102626
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.0007354172686922467
319, epoch_train_loss=0.0007354172686922467
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.0007354171901959078
320, epoch_train_loss=0.0007354171901959078
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.0007354171120197405
321, epoch_train_loss=0.0007354171120197405
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.0007354170341622393
322, epoch_train_loss=0.0007354170341622393
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0007354169566218984
323, epoch_train_loss=0.0007354169566218984
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.0007354168793972295
324, epoch_train_loss=0.0007354168793972295
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.0007354168024867388
325, epoch_train_loss=0.0007354168024867388
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.0007354167258889488
326, epoch_train_loss=0.0007354167258889488
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.0007354166496023776
327, epoch_train_loss=0.0007354166496023776
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.0007354165736255534
328, epoch_train_loss=0.0007354165736255534
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.0007354164979570174
329, epoch_train_loss=0.0007354164979570174
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.0007354164225953041
330, epoch_train_loss=0.0007354164225953041
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0007354163475389601
331, epoch_train_loss=0.0007354163475389601
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0007354162727865373
332, epoch_train_loss=0.0007354162727865373
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0007354161983366002
333, epoch_train_loss=0.0007354161983366002
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.000735416124187707
334, epoch_train_loss=0.000735416124187707
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.0007354160503384278
335, epoch_train_loss=0.0007354160503384278
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.0007354159767873383
336, epoch_train_loss=0.0007354159767873383
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0007354159035330208
337, epoch_train_loss=0.0007354159035330208
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.0007354158305740686
338, epoch_train_loss=0.0007354158305740686
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0007354157579090644
339, epoch_train_loss=0.0007354157579090644
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.0007354156855366188
340, epoch_train_loss=0.0007354156855366188
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0007354156134553324
341, epoch_train_loss=0.0007354156134553324
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.000735415541663817
342, epoch_train_loss=0.000735415541663817
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.0007354154701606899
343, epoch_train_loss=0.0007354154701606899
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.0007354153989445751
344, epoch_train_loss=0.0007354153989445751
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.0007354153280140968
345, epoch_train_loss=0.0007354153280140968
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.0007354152573679018
346, epoch_train_loss=0.0007354152573679018
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0007354151870046209
347, epoch_train_loss=0.0007354151870046209
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0007354151169229122
348, epoch_train_loss=0.0007354151169229122
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.0007354150471214192
349, epoch_train_loss=0.0007354150471214192
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.0007354149775988069
350, epoch_train_loss=0.0007354149775988069
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0007354149083537406
351, epoch_train_loss=0.0007354149083537406
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.0007354148393848924
352, epoch_train_loss=0.0007354148393848924
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.00073541477069094
353, epoch_train_loss=0.00073541477069094
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.0007354147022705618
354, epoch_train_loss=0.0007354147022705618
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.0007354146341224527
355, epoch_train_loss=0.0007354146341224527
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.0007354145662453033
356, epoch_train_loss=0.0007354145662453033
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0007354144986378203
357, epoch_train_loss=0.0007354144986378203
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.0007354144312987116
358, epoch_train_loss=0.0007354144312987116
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.0007354143642266854
359, epoch_train_loss=0.0007354143642266854
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.0007354142974204665
360, epoch_train_loss=0.0007354142974204665
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.0007354142308787754
361, epoch_train_loss=0.0007354142308787754
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.0007354141646003486
362, epoch_train_loss=0.0007354141646003486
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0007354140985839235
363, epoch_train_loss=0.0007354140985839235
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.0007354140328282384
364, epoch_train_loss=0.0007354140328282384
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.0007354139673320476
365, epoch_train_loss=0.0007354139673320476
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007354139020941014
366, epoch_train_loss=0.0007354139020941014
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0007354138371131607
367, epoch_train_loss=0.0007354138371131607
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0007354137723879975
368, epoch_train_loss=0.0007354137723879975
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0007354137079173799
369, epoch_train_loss=0.0007354137079173799
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.0007354136437000911
370, epoch_train_loss=0.0007354136437000911
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.0007354135797349113
371, epoch_train_loss=0.0007354135797349113
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.0007354135160206304
372, epoch_train_loss=0.0007354135160206304
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.000735413452556045
373, epoch_train_loss=0.000735413452556045
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0007354133893399618
374, epoch_train_loss=0.0007354133893399618
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0007354133263711842
375, epoch_train_loss=0.0007354133263711842
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.0007354132636485254
376, epoch_train_loss=0.0007354132636485254
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.0007354132011708097
377, epoch_train_loss=0.0007354132011708097
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0007354131389368574
378, epoch_train_loss=0.0007354131389368574
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0007354130769454954
379, epoch_train_loss=0.0007354130769454954
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.0007354130151955688
380, epoch_train_loss=0.0007354130151955688
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.0007354129536859159
381, epoch_train_loss=0.0007354129536859159
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0007354128924153846
382, epoch_train_loss=0.0007354128924153846
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0007354128313828286
383, epoch_train_loss=0.0007354128313828286
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0007354127705871075
384, epoch_train_loss=0.0007354127705871075
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0007354127100270862
385, epoch_train_loss=0.0007354127100270862
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.0007354126497016353
386, epoch_train_loss=0.0007354126497016353
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0007354125896096267
387, epoch_train_loss=0.0007354125896096267
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.0007354125297499514
388, epoch_train_loss=0.0007354125297499514
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0007354124701214924
389, epoch_train_loss=0.0007354124701214924
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0007354124107231423
390, epoch_train_loss=0.0007354124107231423
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0007354123515537956
391, epoch_train_loss=0.0007354123515537956
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.000735412292612361
392, epoch_train_loss=0.000735412292612361
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.0007354122338977478
393, epoch_train_loss=0.0007354122338977478
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007354121754088711
394, epoch_train_loss=0.0007354121754088711
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0007354121171446517
395, epoch_train_loss=0.0007354121171446517
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.0007354120591040109
396, epoch_train_loss=0.0007354120591040109
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.0007354120012858804
397, epoch_train_loss=0.0007354120012858804
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.0007354119436892014
398, epoch_train_loss=0.0007354119436892014
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0007354118863129159
399, epoch_train_loss=0.0007354118863129159
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0007354118291559718
400, epoch_train_loss=0.0007354118291559718
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0007354117722173175
401, epoch_train_loss=0.0007354117722173175
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0007354117154959159
402, epoch_train_loss=0.0007354117154959159
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.000735411658990726
403, epoch_train_loss=0.000735411658990726
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.000735411602700717
404, epoch_train_loss=0.000735411602700717
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.0007354115466248668
405, epoch_train_loss=0.0007354115466248668
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0007354114907621555
406, epoch_train_loss=0.0007354114907621555
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.000735411435111563
407, epoch_train_loss=0.000735411435111563
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0007354113796720833
408, epoch_train_loss=0.0007354113796720833
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0007354113244427078
409, epoch_train_loss=0.0007354113244427078
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0007354112694224401
410, epoch_train_loss=0.0007354112694224401
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.0007354112146102821
411, epoch_train_loss=0.0007354112146102821
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.0007354111600052436
412, epoch_train_loss=0.0007354111600052436
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0007354111056063408
413, epoch_train_loss=0.0007354111056063408
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0007354110514125939
414, epoch_train_loss=0.0007354110514125939
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0007354109974230288
415, epoch_train_loss=0.0007354109974230288
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0007354109436366804
416, epoch_train_loss=0.0007354109436366804
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.0007354108900525802
417, epoch_train_loss=0.0007354108900525802
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.0007354108366697689
418, epoch_train_loss=0.0007354108366697689
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.0007354107834872923
419, epoch_train_loss=0.0007354107834872923
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.0007354107305042053
420, epoch_train_loss=0.0007354107305042053
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.0007354106777195595
421, epoch_train_loss=0.0007354106777195595
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.000735410625132415
422, epoch_train_loss=0.000735410625132415
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0007354105727418375
423, epoch_train_loss=0.0007354105727418375
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.0007354105205468972
424, epoch_train_loss=0.0007354105205468972
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.0007354104685466692
425, epoch_train_loss=0.0007354104685466692
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0007354104167402335
426, epoch_train_loss=0.0007354104167402335
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.0007354103651266748
427, epoch_train_loss=0.0007354103651266748
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.0007354103137050828
428, epoch_train_loss=0.0007354103137050828
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.0007354102624745472
429, epoch_train_loss=0.0007354102624745472
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.0007354102114341716
430, epoch_train_loss=0.0007354102114341716
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.0007354101605830596
431, epoch_train_loss=0.0007354101605830596
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.0007354101099203193
432, epoch_train_loss=0.0007354101099203193
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.000735410059445064
433, epoch_train_loss=0.000735410059445064
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0007354100091564075
434, epoch_train_loss=0.0007354100091564075
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.000735409959053476
435, epoch_train_loss=0.000735409959053476
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.0007354099091353964
436, epoch_train_loss=0.0007354099091353964
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.0007354098594013003
437, epoch_train_loss=0.0007354098594013003
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0007354098098503238
438, epoch_train_loss=0.0007354098098503238
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0007354097604816073
439, epoch_train_loss=0.0007354097604816073
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0007354097112942923
440, epoch_train_loss=0.0007354097112942923
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.0007354096622875321
441, epoch_train_loss=0.0007354096622875321
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0007354096134604772
442, epoch_train_loss=0.0007354096134604772
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0007354095648122862
443, epoch_train_loss=0.0007354095648122862
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.0007354095163421253
444, epoch_train_loss=0.0007354095163421253
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.000735409468049159
445, epoch_train_loss=0.000735409468049159
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0007354094199325622
446, epoch_train_loss=0.0007354094199325622
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.0007354093719915112
447, epoch_train_loss=0.0007354093719915112
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.0007354093242251826
448, epoch_train_loss=0.0007354093242251826
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.000735409276632765
449, epoch_train_loss=0.000735409276632765
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.0007354092292134439
450, epoch_train_loss=0.0007354092292134439
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0007354091819664127
451, epoch_train_loss=0.0007354091819664127
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.0007354091348908688
452, epoch_train_loss=0.0007354091348908688
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0007354090879860178
453, epoch_train_loss=0.0007354090879860178
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0007354090412510624
454, epoch_train_loss=0.0007354090412510624
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0007354089946852122
455, epoch_train_loss=0.0007354089946852122
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.0007354089482876861
456, epoch_train_loss=0.0007354089482876861
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0007354089020576984
457, epoch_train_loss=0.0007354089020576984
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.000735408855994472
458, epoch_train_loss=0.000735408855994472
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.0007354088100972375
459, epoch_train_loss=0.0007354088100972375
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.0007354087643652182
460, epoch_train_loss=0.0007354087643652182
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.0007354087187976531
461, epoch_train_loss=0.0007354087187976531
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0007354086733937812
462, epoch_train_loss=0.0007354086733937812
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0007354086281528486
463, epoch_train_loss=0.0007354086281528486
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.0007354085830740991
464, epoch_train_loss=0.0007354085830740991
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0007354085381567837
465, epoch_train_loss=0.0007354085381567837
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0007354084934001539
466, epoch_train_loss=0.0007354084934001539
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.0007354084488034755
467, epoch_train_loss=0.0007354084488034755
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.0007354084043660079
468, epoch_train_loss=0.0007354084043660079
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0007354083600870145
469, epoch_train_loss=0.0007354083600870145
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.000735408315965769
470, epoch_train_loss=0.000735408315965769
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.0007354082720015497
471, epoch_train_loss=0.0007354082720015497
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.0007354082281936277
472, epoch_train_loss=0.0007354082281936277
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.0007354081845412887
473, epoch_train_loss=0.0007354081845412887
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0007354081410438186
474, epoch_train_loss=0.0007354081410438186
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.000735408097700507
475, epoch_train_loss=0.000735408097700507
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.000735408054510644
476, epoch_train_loss=0.000735408054510644
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.0007354080114735304
477, epoch_train_loss=0.0007354080114735304
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.0007354079685884667
478, epoch_train_loss=0.0007354079685884667
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.0007354079258547545
479, epoch_train_loss=0.0007354079258547545
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.0007354078832717052
480, epoch_train_loss=0.0007354078832717052
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.0007354078408386305
481, epoch_train_loss=0.0007354078408386305
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.0007354077985548432
482, epoch_train_loss=0.0007354077985548432
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.0007354077564196652
483, epoch_train_loss=0.0007354077564196652
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.0007354077144324197
484, epoch_train_loss=0.0007354077144324197
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.0007354076725924295
485, epoch_train_loss=0.0007354076725924295
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.0007354076308990279
486, epoch_train_loss=0.0007354076308990279
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0007354075893515452
487, epoch_train_loss=0.0007354075893515452
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0007354075479493183
488, epoch_train_loss=0.0007354075479493183
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.0007354075066916908
489, epoch_train_loss=0.0007354075066916908
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0007354074655780035
490, epoch_train_loss=0.0007354074655780035
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0007354074246076073
491, epoch_train_loss=0.0007354074246076073
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.0007354073837798494
492, epoch_train_loss=0.0007354073837798494
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0007354073430940847
493, epoch_train_loss=0.0007354073430940847
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0007354073025496732
494, epoch_train_loss=0.0007354073025496732
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.0007354072621459735
495, epoch_train_loss=0.0007354072621459735
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0007354072218823531
496, epoch_train_loss=0.0007354072218823531
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0007354071817581734
497, epoch_train_loss=0.0007354071817581734
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.000735407141772812
498, epoch_train_loss=0.000735407141772812
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.00073540710192564
499, epoch_train_loss=0.00073540710192564
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.0007354070622160354
500, epoch_train_loss=0.0007354070622160354
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.000735407022643379
501, epoch_train_loss=0.000735407022643379
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.0007354069832070553
502, epoch_train_loss=0.0007354069832070553
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.0007354069439064548
503, epoch_train_loss=0.0007354069439064548
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0007354069047409624
504, epoch_train_loss=0.0007354069047409624
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.0007354068657099774
505, epoch_train_loss=0.0007354068657099774
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.0007354068268128919
506, epoch_train_loss=0.0007354068268128919
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.0007354067880491115
507, epoch_train_loss=0.0007354067880491115
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.0007354067494180342
508, epoch_train_loss=0.0007354067494180342
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.0007354067109190722
509, epoch_train_loss=0.0007354067109190722
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.0007354066725516295
510, epoch_train_loss=0.0007354066725516295
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.0007354066343151219
511, epoch_train_loss=0.0007354066343151219
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.0007354065962089652
512, epoch_train_loss=0.0007354065962089652
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.0007354065582325784
513, epoch_train_loss=0.0007354065582325784
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0007354065203853838
514, epoch_train_loss=0.0007354065203853838
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.0007354064826668062
515, epoch_train_loss=0.0007354064826668062
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.0007354064450762738
516, epoch_train_loss=0.0007354064450762738
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0007354064076132147
517, epoch_train_loss=0.0007354064076132147
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.000735406370277066
518, epoch_train_loss=0.000735406370277066
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.0007354063330672618
519, epoch_train_loss=0.0007354063330672618
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.0007354062959832448
520, epoch_train_loss=0.0007354062959832448
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.0007354062590244581
521, epoch_train_loss=0.0007354062590244581
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.0007354062221903475
522, epoch_train_loss=0.0007354062221903475
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0007354061854803617
523, epoch_train_loss=0.0007354061854803617
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.0007354061488939467
524, epoch_train_loss=0.0007354061488939467
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0007354061124305626
525, epoch_train_loss=0.0007354061124305626
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.0007354060760896669
526, epoch_train_loss=0.0007354060760896669
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.0007354060398707165
527, epoch_train_loss=0.0007354060398707165
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.0007354060037731777
528, epoch_train_loss=0.0007354060037731777
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0007354059677965133
529, epoch_train_loss=0.0007354059677965133
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.0007354059319401945
530, epoch_train_loss=0.0007354059319401945
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.000735405896203693
531, epoch_train_loss=0.000735405896203693
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.0007354058605864771
532, epoch_train_loss=0.0007354058605864771
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.0007354058250880294
533, epoch_train_loss=0.0007354058250880294
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.000735405789707829
534, epoch_train_loss=0.000735405789707829
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.0007354057544453534
535, epoch_train_loss=0.0007354057544453534
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0007354057193000924
536, epoch_train_loss=0.0007354057193000924
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.0007354056842715313
537, epoch_train_loss=0.0007354056842715313
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.0007354056493591605
538, epoch_train_loss=0.0007354056493591605
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.0007354056145624752
539, epoch_train_loss=0.0007354056145624752
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.0007354055798809688
540, epoch_train_loss=0.0007354055798809688
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.0007354055453141393
541, epoch_train_loss=0.0007354055453141393
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.0007354055108614876
542, epoch_train_loss=0.0007354055108614876
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0007354054765225171
543, epoch_train_loss=0.0007354054765225171
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.0007354054422967363
544, epoch_train_loss=0.0007354054422967363
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.0007354054081836488
545, epoch_train_loss=0.0007354054081836488
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.0007354053741827681
546, epoch_train_loss=0.0007354053741827681
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.0007354053402936105
547, epoch_train_loss=0.0007354053402936105
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.0007354053065156896
548, epoch_train_loss=0.0007354053065156896
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.0007354052728485213
549, epoch_train_loss=0.0007354052728485213
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.0007354052392916295
550, epoch_train_loss=0.0007354052392916295
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0007354052058445377
551, epoch_train_loss=0.0007354052058445377
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.0007354051725067744
552, epoch_train_loss=0.0007354051725067744
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0007354051392778634
553, epoch_train_loss=0.0007354051392778634
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.000735405106157338
554, epoch_train_loss=0.000735405106157338
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.0007354050731447315
555, epoch_train_loss=0.0007354050731447315
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0007354050402395797
556, epoch_train_loss=0.0007354050402395797
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.000735405007441421
557, epoch_train_loss=0.000735405007441421
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.000735404974749793
558, epoch_train_loss=0.000735404974749793
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.0007354049421642414
559, epoch_train_loss=0.0007354049421642414
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.0007354049096843115
560, epoch_train_loss=0.0007354049096843115
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.0007354048773095483
561, epoch_train_loss=0.0007354048773095483
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.0007354048450395046
562, epoch_train_loss=0.0007354048450395046
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.0007354048128737318
563, epoch_train_loss=0.0007354048128737318
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.0007354047808117828
564, epoch_train_loss=0.0007354047808117828
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.0007354047488532164
565, epoch_train_loss=0.0007354047488532164
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.0007354047169975893
566, epoch_train_loss=0.0007354047169975893
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0007354046852444655
567, epoch_train_loss=0.0007354046852444655
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0007354046535934085
568, epoch_train_loss=0.0007354046535934085
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.0007354046220439815
569, epoch_train_loss=0.0007354046220439815
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0007354045905957553
570, epoch_train_loss=0.0007354045905957553
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.0007354045592482976
571, epoch_train_loss=0.0007354045592482976
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.0007354045280011809
572, epoch_train_loss=0.0007354045280011809
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.0007354044968539797
573, epoch_train_loss=0.0007354044968539797
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.0007354044658062734
574, epoch_train_loss=0.0007354044658062734
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.0007354044348576382
575, epoch_train_loss=0.0007354044348576382
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.0007354044040076582
576, epoch_train_loss=0.0007354044040076582
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.0007354043732559141
577, epoch_train_loss=0.0007354043732559141
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.0007354043426019909
578, epoch_train_loss=0.0007354043426019909
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.0007354043120454786
579, epoch_train_loss=0.0007354043120454786
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0007354042815859646
580, epoch_train_loss=0.0007354042815859646
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.0007354042512230406
581, epoch_train_loss=0.0007354042512230406
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.0007354042209563001
582, epoch_train_loss=0.0007354042209563001
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.0007354041907853414
583, epoch_train_loss=0.0007354041907853414
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.0007354041607097597
584, epoch_train_loss=0.0007354041607097597
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.0007354041307291554
585, epoch_train_loss=0.0007354041307291554
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.00073540410084313
586, epoch_train_loss=0.00073540410084313
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.0007354040710512876
587, epoch_train_loss=0.0007354040710512876
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.0007354040413532343
588, epoch_train_loss=0.0007354040413532343
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.000735404011748578
589, epoch_train_loss=0.000735404011748578
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.0007354039822369282
590, epoch_train_loss=0.0007354039822369282
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0007354039528178973
591, epoch_train_loss=0.0007354039528178973
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.0007354039234910987
592, epoch_train_loss=0.0007354039234910987
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.0007354038942561485
593, epoch_train_loss=0.0007354038942561485
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.0007354038651126646
594, epoch_train_loss=0.0007354038651126646
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.000735403836060264
595, epoch_train_loss=0.000735403836060264
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.0007354038070985705
596, epoch_train_loss=0.0007354038070985705
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0007354037782272079
597, epoch_train_loss=0.0007354037782272079
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.0007354037494458015
598, epoch_train_loss=0.0007354037494458015
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.0007354037207539761
599, epoch_train_loss=0.0007354037207539761
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.0007354036921513633
600, epoch_train_loss=0.0007354036921513633
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.0007354036636375937
601, epoch_train_loss=0.0007354036636375937
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0007354036352122986
602, epoch_train_loss=0.0007354036352122986
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.0007354036068751144
603, epoch_train_loss=0.0007354036068751144
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.0007354035786256776
604, epoch_train_loss=0.0007354035786256776
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.0007354035504636245
605, epoch_train_loss=0.0007354035504636245
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.0007354035223885971
606, epoch_train_loss=0.0007354035223885971
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.0007354034944002378
607, epoch_train_loss=0.0007354034944002378
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.000735403466498188
608, epoch_train_loss=0.000735403466498188
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.0007354034386820951
609, epoch_train_loss=0.0007354034386820951
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.0007354034109516046
610, epoch_train_loss=0.0007354034109516046
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0007354033833063677
611, epoch_train_loss=0.0007354033833063677
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.0007354033557460325
612, epoch_train_loss=0.0007354033557460325
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.000735403328270252
613, epoch_train_loss=0.000735403328270252
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.0007354033008786826
614, epoch_train_loss=0.0007354033008786826
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.0007354032735709798
615, epoch_train_loss=0.0007354032735709798
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.0007354032463467997
616, epoch_train_loss=0.0007354032463467997
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.0007354032192058014
617, epoch_train_loss=0.0007354032192058014
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.0007354031921476461
618, epoch_train_loss=0.0007354031921476461
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.0007354031651719964
619, epoch_train_loss=0.0007354031651719964
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.0007354031382785192
620, epoch_train_loss=0.0007354031382785192
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.0007354031114668779
621, epoch_train_loss=0.0007354031114668779
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.0007354030847367406
622, epoch_train_loss=0.0007354030847367406
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.0007354030580877765
623, epoch_train_loss=0.0007354030580877765
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.0007354030315196569
624, epoch_train_loss=0.0007354030315196569
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.0007354030050320565
625, epoch_train_loss=0.0007354030050320565
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.000735402978624647
626, epoch_train_loss=0.000735402978624647
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.0007354029522971048
627, epoch_train_loss=0.0007354029522971048
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0007354029260491072
628, epoch_train_loss=0.0007354029260491072
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0007354028998803332
629, epoch_train_loss=0.0007354028998803332
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.0007354028737904633
630, epoch_train_loss=0.0007354028737904633
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.00073540284777918
631, epoch_train_loss=0.00073540284777918
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.0007354028218461669
632, epoch_train_loss=0.0007354028218461669
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.0007354027959911094
633, epoch_train_loss=0.0007354027959911094
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.0007354027702136942
634, epoch_train_loss=0.0007354027702136942
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.0007354027445136097
635, epoch_train_loss=0.0007354027445136097
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.0007354027188905442
636, epoch_train_loss=0.0007354027188905442
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.0007354026933441927
637, epoch_train_loss=0.0007354026933441927
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.0007354026678742442
638, epoch_train_loss=0.0007354026678742442
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.0007354026424803955
639, epoch_train_loss=0.0007354026424803955
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.0007354026171623422
640, epoch_train_loss=0.0007354026171623422
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.0007354025919197819
641, epoch_train_loss=0.0007354025919197819
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.0007354025667524115
642, epoch_train_loss=0.0007354025667524115
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.0007354025416599333
643, epoch_train_loss=0.0007354025416599333
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.0007354025166420493
644, epoch_train_loss=0.0007354025166420493
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0007354024916984607
645, epoch_train_loss=0.0007354024916984607
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0007354024668288742
646, epoch_train_loss=0.0007354024668288742
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.0007354024420329959
647, epoch_train_loss=0.0007354024420329959
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0007354024173105317
648, epoch_train_loss=0.0007354024173105317
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.0007354023926611924
649, epoch_train_loss=0.0007354023926611924
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.0007354023680846866
650, epoch_train_loss=0.0007354023680846866
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.000735402343580726
651, epoch_train_loss=0.000735402343580726
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.0007354023191490258
652, epoch_train_loss=0.0007354023191490258
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.0007354022947892989
653, epoch_train_loss=0.0007354022947892989
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.0007354022705012629
654, epoch_train_loss=0.0007354022705012629
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0007354022462846356
655, epoch_train_loss=0.0007354022462846356
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.0007354022221391332
656, epoch_train_loss=0.0007354022221391332
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.0007354021980644764
657, epoch_train_loss=0.0007354021980644764
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.0007354021740603862
658, epoch_train_loss=0.0007354021740603862
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.0007354021501265878
659, epoch_train_loss=0.0007354021501265878
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.0007354021262628032
660, epoch_train_loss=0.0007354021262628032
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0007354021024687577
661, epoch_train_loss=0.0007354021024687577
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.0007354020787441801
662, epoch_train_loss=0.0007354020787441801
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0007354020550887949
663, epoch_train_loss=0.0007354020550887949
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0007354020315023349
664, epoch_train_loss=0.0007354020315023349
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.0007354020079845293
665, epoch_train_loss=0.0007354020079845293
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.0007354019845351117
666, epoch_train_loss=0.0007354019845351117
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0007354019611538118
667, epoch_train_loss=0.0007354019611538118
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.0007354019378403676
668, epoch_train_loss=0.0007354019378403676
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.0007354019145945117
669, epoch_train_loss=0.0007354019145945117
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.0007354018914159846
670, epoch_train_loss=0.0007354018914159846
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.0007354018683045226
671, epoch_train_loss=0.0007354018683045226
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.0007354018452598657
672, epoch_train_loss=0.0007354018452598657
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.0007354018222817527
673, epoch_train_loss=0.0007354018222817527
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.0007354017993699294
674, epoch_train_loss=0.0007354017993699294
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.0007354017765241354
675, epoch_train_loss=0.0007354017765241354
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0007354017537441189
676, epoch_train_loss=0.0007354017537441189
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.0007354017310296219
677, epoch_train_loss=0.0007354017310296219
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.0007354017083803935
678, epoch_train_loss=0.0007354017083803935
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.0007354016857961813
679, epoch_train_loss=0.0007354016857961813
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0007354016632767352
680, epoch_train_loss=0.0007354016632767352
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0007354016408218037
681, epoch_train_loss=0.0007354016408218037
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0007354016184311403
682, epoch_train_loss=0.0007354016184311403
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.0007354015961044978
683, epoch_train_loss=0.0007354015961044978
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0007354015738416307
684, epoch_train_loss=0.0007354015738416307
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.0007354015516422936
685, epoch_train_loss=0.0007354015516422936
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.0007354015295062416
686, epoch_train_loss=0.0007354015295062416
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0007354015074332336
687, epoch_train_loss=0.0007354015074332336
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.0007354014854230272
688, epoch_train_loss=0.0007354014854230272
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.0007354014634753832
689, epoch_train_loss=0.0007354014634753832
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0007354014415900629
690, epoch_train_loss=0.0007354014415900629
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0007354014197668269
691, epoch_train_loss=0.0007354014197668269
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.0007354013980054395
692, epoch_train_loss=0.0007354013980054395
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.0007354013763056637
693, epoch_train_loss=0.0007354013763056637
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.0007354013546672652
694, epoch_train_loss=0.0007354013546672652
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0007354013330900116
695, epoch_train_loss=0.0007354013330900116
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0007354013115736692
696, epoch_train_loss=0.0007354013115736692
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.0007354012901180084
697, epoch_train_loss=0.0007354012901180084
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.0007354012687227971
698, epoch_train_loss=0.0007354012687227971
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0007354012473878063
699, epoch_train_loss=0.0007354012473878063
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0007354012261128096
700, epoch_train_loss=0.0007354012261128096
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.0007354012048975782
701, epoch_train_loss=0.0007354012048975782
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.0007354011837418863
702, epoch_train_loss=0.0007354011837418863
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.000735401162645509
703, epoch_train_loss=0.000735401162645509
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.0007354011416082243
704, epoch_train_loss=0.0007354011416082243
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.0007354011206298073
705, epoch_train_loss=0.0007354011206298073
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0007354010997100367
706, epoch_train_loss=0.0007354010997100367
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0007354010788486914
707, epoch_train_loss=0.0007354010788486914
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0007354010580455537
708, epoch_train_loss=0.0007354010580455537
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0007354010373004014
709, epoch_train_loss=0.0007354010373004014
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.0007354010166130187
710, epoch_train_loss=0.0007354010166130187
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.0007354009959831902
711, epoch_train_loss=0.0007354009959831902
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0007354009754106988
712, epoch_train_loss=0.0007354009754106988
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.0007354009548953286
713, epoch_train_loss=0.0007354009548953286
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.0007354009344368686
714, epoch_train_loss=0.0007354009344368686
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.0007354009140351049
715, epoch_train_loss=0.0007354009140351049
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.0007354008936898256
716, epoch_train_loss=0.0007354008936898256
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0007354008734008183
717, epoch_train_loss=0.0007354008734008183
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.0007354008531678753
718, epoch_train_loss=0.0007354008531678753
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0007354008329907877
719, epoch_train_loss=0.0007354008329907877
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.0007354008128693472
720, epoch_train_loss=0.0007354008128693472
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0007354007928033475
721, epoch_train_loss=0.0007354007928033475
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.000735400772792581
722, epoch_train_loss=0.000735400772792581
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.0007354007528368442
723, epoch_train_loss=0.0007354007528368442
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.0007354007329359331
724, epoch_train_loss=0.0007354007329359331
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.0007354007130896446
725, epoch_train_loss=0.0007354007130896446
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0007354006932977766
726, epoch_train_loss=0.0007354006932977766
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.0007354006735601263
727, epoch_train_loss=0.0007354006735601263
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0007354006538764951
728, epoch_train_loss=0.0007354006538764951
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0007354006342466819
729, epoch_train_loss=0.0007354006342466819
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.0007354006146704896
730, epoch_train_loss=0.0007354006146704896
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.0007354005951477211
731, epoch_train_loss=0.0007354005951477211
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.0007354005756781795
732, epoch_train_loss=0.0007354005756781795
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.0007354005562616672
733, epoch_train_loss=0.0007354005562616672
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.0007354005368979898
734, epoch_train_loss=0.0007354005368979898
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.0007354005175869532
735, epoch_train_loss=0.0007354005175869532
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.0007354004983283658
736, epoch_train_loss=0.0007354004983283658
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0007354004791220336
737, epoch_train_loss=0.0007354004791220336
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.000735400459967767
738, epoch_train_loss=0.000735400459967767
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.000735400440865374
739, epoch_train_loss=0.000735400440865374
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.0007354004218146664
740, epoch_train_loss=0.0007354004218146664
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.0007354004028154539
741, epoch_train_loss=0.0007354004028154539
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.0007354003838675503
742, epoch_train_loss=0.0007354003838675503
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.0007354003649707668
743, epoch_train_loss=0.0007354003649707668
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.0007354003461249172
744, epoch_train_loss=0.0007354003461249172
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.0007354003273298164
745, epoch_train_loss=0.0007354003273298164
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.0007354003085852795
746, epoch_train_loss=0.0007354003085852795
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.0007354002898911234
747, epoch_train_loss=0.0007354002898911234
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.0007354002712471645
748, epoch_train_loss=0.0007354002712471645
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0007354002526532211
749, epoch_train_loss=0.0007354002526532211
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0007354002341091134
750, epoch_train_loss=0.0007354002341091134
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0007354002156146595
751, epoch_train_loss=0.0007354002156146595
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.00073540019716968
752, epoch_train_loss=0.00073540019716968
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.0007354001787739957
753, epoch_train_loss=0.0007354001787739957
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.0007354001604274289
754, epoch_train_loss=0.0007354001604274289
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.0007354001421298024
755, epoch_train_loss=0.0007354001421298024
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.0007354001238809397
756, epoch_train_loss=0.0007354001238809397
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.000735400105680665
757, epoch_train_loss=0.000735400105680665
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.0007354000875288039
758, epoch_train_loss=0.0007354000875288039
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.0007354000694251821
759, epoch_train_loss=0.0007354000694251821
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.0007354000513696248
760, epoch_train_loss=0.0007354000513696248
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.0007354000333619614
761, epoch_train_loss=0.0007354000333619614
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.0007354000154020195
762, epoch_train_loss=0.0007354000154020195
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 0.0007353999974896283
763, epoch_train_loss=0.0007353999974896283
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 0.0007353999796246182
764, epoch_train_loss=0.0007353999796246182
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.000735399961806819
765, epoch_train_loss=0.000735399961806819
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 0.0007353999440360625
766, epoch_train_loss=0.0007353999440360625
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 0.0007353999263121791
767, epoch_train_loss=0.0007353999263121791
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 0.0007353999086350029
768, epoch_train_loss=0.0007353999086350029
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 0.0007353998910043677
769, epoch_train_loss=0.0007353998910043677
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 0.0007353998734201063
770, epoch_train_loss=0.0007353998734201063
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 0.0007353998558820551
771, epoch_train_loss=0.0007353998558820551
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 0.0007353998383900485
772, epoch_train_loss=0.0007353998383900485
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 0.0007353998209439244
773, epoch_train_loss=0.0007353998209439244
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 0.0007353998035435186
774, epoch_train_loss=0.0007353998035435186
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 0.00073539978618867
775, epoch_train_loss=0.00073539978618867
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 0.0007353997688792179
776, epoch_train_loss=0.0007353997688792179
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 0.0007353997516149995
777, epoch_train_loss=0.0007353997516149995
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 0.0007353997343958556
778, epoch_train_loss=0.0007353997343958556
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 0.0007353997172216278
779, epoch_train_loss=0.0007353997172216278
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 0.0007353997000921565
780, epoch_train_loss=0.0007353997000921565
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 0.0007353996830072833
781, epoch_train_loss=0.0007353996830072833
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 0.0007353996659668534
782, epoch_train_loss=0.0007353996659668534
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 0.0007353996489707081
783, epoch_train_loss=0.0007353996489707081
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 0.000735399632018693
784, epoch_train_loss=0.000735399632018693
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 0.0007353996151106522
785, epoch_train_loss=0.0007353996151106522
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 0.0007353995982464309
786, epoch_train_loss=0.0007353995982464309
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 0.0007353995814258752
787, epoch_train_loss=0.0007353995814258752
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 0.0007353995646488336
788, epoch_train_loss=0.0007353995646488336
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 0.0007353995479151525
789, epoch_train_loss=0.0007353995479151525
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 0.0007353995312246798
790, epoch_train_loss=0.0007353995312246798
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 0.0007353995145772647
791, epoch_train_loss=0.0007353995145772647
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 0.0007353994979727566
792, epoch_train_loss=0.0007353994979727566
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 0.0007353994814110059
793, epoch_train_loss=0.0007353994814110059
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 0.0007353994648918633
794, epoch_train_loss=0.0007353994648918633
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 0.0007353994484151804
795, epoch_train_loss=0.0007353994484151804
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 0.0007353994319808095
796, epoch_train_loss=0.0007353994319808095
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 0.0007353994155886032
797, epoch_train_loss=0.0007353994155886032
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 0.000735399399238415
798, epoch_train_loss=0.000735399399238415
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 0.0007353993829300991
799, epoch_train_loss=0.0007353993829300991
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 0.0007353993666635102
800, epoch_train_loss=0.0007353993666635102
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 0.0007353993504385033
801, epoch_train_loss=0.0007353993504385033
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 0.000735399334254935
802, epoch_train_loss=0.000735399334254935
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 0.0007353993181126601
803, epoch_train_loss=0.0007353993181126601
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 0.0007353993020115385
804, epoch_train_loss=0.0007353993020115385
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 0.0007353992859514256
805, epoch_train_loss=0.0007353992859514256
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 0.0007353992699321811
806, epoch_train_loss=0.0007353992699321811
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 0.000735399253953664
807, epoch_train_loss=0.000735399253953664
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 0.0007353992380157325
808, epoch_train_loss=0.0007353992380157325
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 0.0007353992221182486
809, epoch_train_loss=0.0007353992221182486
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 0.0007353992062610726
810, epoch_train_loss=0.0007353992062610726
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 0.0007353991904440652
811, epoch_train_loss=0.0007353991904440652
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 0.0007353991746670891
812, epoch_train_loss=0.0007353991746670891
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 0.0007353991589300077
813, epoch_train_loss=0.0007353991589300077
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 0.0007353991432326825
814, epoch_train_loss=0.0007353991432326825
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 0.0007353991275749774
815, epoch_train_loss=0.0007353991275749774
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 0.0007353991119567592
816, epoch_train_loss=0.0007353991119567592
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 0.0007353990963778904
817, epoch_train_loss=0.0007353990963778904
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 0.0007353990808382369
818, epoch_train_loss=0.0007353990808382369
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 0.0007353990653376657
819, epoch_train_loss=0.0007353990653376657
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 0.0007353990498760424
820, epoch_train_loss=0.0007353990498760424
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 0.0007353990344532355
821, epoch_train_loss=0.0007353990344532355
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 0.0007353990190691114
822, epoch_train_loss=0.0007353990190691114
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 0.0007353990037235388
823, epoch_train_loss=0.0007353990037235388
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 0.0007353989884163878
824, epoch_train_loss=0.0007353989884163878
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 0.0007353989731475265
825, epoch_train_loss=0.0007353989731475265
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 0.0007353989579168251
826, epoch_train_loss=0.0007353989579168251
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 0.0007353989427241542
827, epoch_train_loss=0.0007353989427241542
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 0.0007353989275693862
828, epoch_train_loss=0.0007353989275693862
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 0.0007353989124523917
829, epoch_train_loss=0.0007353989124523917
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 0.0007353988973730426
830, epoch_train_loss=0.0007353988973730426
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 0.0007353988823312118
831, epoch_train_loss=0.0007353988823312118
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 0.000735398867326773
832, epoch_train_loss=0.000735398867326773
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 0.000735398852359601
833, epoch_train_loss=0.000735398852359601
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 0.0007353988374295676
834, epoch_train_loss=0.0007353988374295676
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 0.0007353988225365505
835, epoch_train_loss=0.0007353988225365505
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 0.0007353988076804224
836, epoch_train_loss=0.0007353988076804224
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 0.0007353987928610618
837, epoch_train_loss=0.0007353987928610618
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 0.0007353987780783429
838, epoch_train_loss=0.0007353987780783429
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 0.0007353987633321448
839, epoch_train_loss=0.0007353987633321448
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 0.0007353987486223431
840, epoch_train_loss=0.0007353987486223431
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 0.0007353987339488178
841, epoch_train_loss=0.0007353987339488178
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 0.0007353987193114453
842, epoch_train_loss=0.0007353987193114453
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 0.000735398704710106
843, epoch_train_loss=0.000735398704710106
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 0.0007353986901446788
844, epoch_train_loss=0.0007353986901446788
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 0.0007353986756150445
845, epoch_train_loss=0.0007353986756150445
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 0.0007353986611210835
846, epoch_train_loss=0.0007353986611210835
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.0007353986466626766
847, epoch_train_loss=0.0007353986466626766
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.0007353986322397055
848, epoch_train_loss=0.0007353986322397055
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0007353986178520512
849, epoch_train_loss=0.0007353986178520512
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.0007353986034995974
850, epoch_train_loss=0.0007353986034995974
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0007353985891822256
851, epoch_train_loss=0.0007353985891822256
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.0007353985748998212
852, epoch_train_loss=0.0007353985748998212
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.0007353985606522675
853, epoch_train_loss=0.0007353985606522675
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.0007353985464394482
854, epoch_train_loss=0.0007353985464394482
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.0007353985322612492
855, epoch_train_loss=0.0007353985322612492
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.0007353985181175553
856, epoch_train_loss=0.0007353985181175553
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.0007353985040082528
857, epoch_train_loss=0.0007353985040082528
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.0007353984899332289
858, epoch_train_loss=0.0007353984899332289
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.0007353984758923687
859, epoch_train_loss=0.0007353984758923687
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.000735398461885561
860, epoch_train_loss=0.000735398461885561
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.0007353984479126922
861, epoch_train_loss=0.0007353984479126922
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.0007353984339736507
862, epoch_train_loss=0.0007353984339736507
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.0007353984200683264
863, epoch_train_loss=0.0007353984200683264
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.0007353984061966072
864, epoch_train_loss=0.0007353984061966072
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.0007353983923583841
865, epoch_train_loss=0.0007353983923583841
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.000735398378553546
866, epoch_train_loss=0.000735398378553546
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.0007353983647819831
867, epoch_train_loss=0.0007353983647819831
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.0007353983510435867
868, epoch_train_loss=0.0007353983510435867
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.0007353983373382494
869, epoch_train_loss=0.0007353983373382494
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0007353983236658618
870, epoch_train_loss=0.0007353983236658618
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.0007353983100263161
871, epoch_train_loss=0.0007353983100263161
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.0007353982964195054
872, epoch_train_loss=0.0007353982964195054
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0007353982828453238
873, epoch_train_loss=0.0007353982828453238
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.0007353982693036629
874, epoch_train_loss=0.0007353982693036629
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.0007353982557944187
875, epoch_train_loss=0.0007353982557944187
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.0007353982423174847
876, epoch_train_loss=0.0007353982423174847
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.000735398228872756
877, epoch_train_loss=0.000735398228872756
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.0007353982154601277
878, epoch_train_loss=0.0007353982154601277
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.0007353982020794959
879, epoch_train_loss=0.0007353982020794959
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.0007353981887307566
880, epoch_train_loss=0.0007353981887307566
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.0007353981754138065
881, epoch_train_loss=0.0007353981754138065
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.0007353981621285426
882, epoch_train_loss=0.0007353981621285426
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0007353981488748623
883, epoch_train_loss=0.0007353981488748623
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0007353981356526638
884, epoch_train_loss=0.0007353981356526638
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0007353981224618451
885, epoch_train_loss=0.0007353981224618451
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.0007353981093023039
886, epoch_train_loss=0.0007353981093023039
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0007353980961739405
887, epoch_train_loss=0.0007353980961739405
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0007353980830766543
888, epoch_train_loss=0.0007353980830766543
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0007353980700103455
889, epoch_train_loss=0.0007353980700103455
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.0007353980569749141
890, epoch_train_loss=0.0007353980569749141
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0007353980439702599
891, epoch_train_loss=0.0007353980439702599
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0007353980309962852
892, epoch_train_loss=0.0007353980309962852
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.0007353980180528913
893, epoch_train_loss=0.0007353980180528913
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.0007353980051399795
894, epoch_train_loss=0.0007353980051399795
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0007353979922574528
895, epoch_train_loss=0.0007353979922574528
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.0007353979794052141
896, epoch_train_loss=0.0007353979794052141
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.0007353979665831656
897, epoch_train_loss=0.0007353979665831656
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0007353979537912103
898, epoch_train_loss=0.0007353979537912103
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0007353979410292538
899, epoch_train_loss=0.0007353979410292538
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0007353979282971998
900, epoch_train_loss=0.0007353979282971998
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.0007353979155949523
901, epoch_train_loss=0.0007353979155949523
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0007353979029224172
902, epoch_train_loss=0.0007353979029224172
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.0007353978902794991
903, epoch_train_loss=0.0007353978902794991
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0007353978776661047
904, epoch_train_loss=0.0007353978776661047
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007353978650821389
905, epoch_train_loss=0.0007353978650821389
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.0007353978525275085
906, epoch_train_loss=0.0007353978525275085
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.0007353978400021203
907, epoch_train_loss=0.0007353978400021203
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.0007353978275058829
908, epoch_train_loss=0.0007353978275058829
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.0007353978150387026
909, epoch_train_loss=0.0007353978150387026
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.0007353978026004876
910, epoch_train_loss=0.0007353978026004876
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0007353977901911474
911, epoch_train_loss=0.0007353977901911474
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.0007353977778105894
912, epoch_train_loss=0.0007353977778105894
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.0007353977654587231
913, epoch_train_loss=0.0007353977654587231
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.0007353977531354588
914, epoch_train_loss=0.0007353977531354588
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0007353977408407052
915, epoch_train_loss=0.0007353977408407052
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.000735397728574373
916, epoch_train_loss=0.000735397728574373
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.000735397716336372
917, epoch_train_loss=0.000735397716336372
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.0007353977041266137
918, epoch_train_loss=0.0007353977041266137
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0007353976919450091
919, epoch_train_loss=0.0007353976919450091
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.00073539767979147
920, epoch_train_loss=0.00073539767979147
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.0007353976676659083
921, epoch_train_loss=0.0007353976676659083
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.0007353976555682359
922, epoch_train_loss=0.0007353976555682359
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.000735397643498366
923, epoch_train_loss=0.000735397643498366
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.0007353976314562113
924, epoch_train_loss=0.0007353976314562113
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.0007353976194416851
925, epoch_train_loss=0.0007353976194416851
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0007353976074547014
926, epoch_train_loss=0.0007353976074547014
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.0007353975954951738
927, epoch_train_loss=0.0007353975954951738
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.0007353975835630168
928, epoch_train_loss=0.0007353975835630168
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0007353975716581442
929, epoch_train_loss=0.0007353975716581442
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.0007353975597804719
930, epoch_train_loss=0.0007353975597804719
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.0007353975479299154
931, epoch_train_loss=0.0007353975479299154
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.000735397536106389
932, epoch_train_loss=0.000735397536106389
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.0007353975243098101
933, epoch_train_loss=0.0007353975243098101
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.0007353975125400952
934, epoch_train_loss=0.0007353975125400952
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.0007353975007971594
935, epoch_train_loss=0.0007353975007971594
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.000735397489080921
936, epoch_train_loss=0.000735397489080921
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.0007353974773912974
937, epoch_train_loss=0.0007353974773912974
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.000735397465728206
938, epoch_train_loss=0.000735397465728206
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.000735397454091564
939, epoch_train_loss=0.000735397454091564
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.0007353974424812905
940, epoch_train_loss=0.0007353974424812905
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.0007353974308973033
941, epoch_train_loss=0.0007353974308973033
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.000735397419339522
942, epoch_train_loss=0.000735397419339522
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.0007353974078078651
943, epoch_train_loss=0.0007353974078078651
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.000735397396302252
944, epoch_train_loss=0.000735397396302252
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.0007353973848226036
945, epoch_train_loss=0.0007353973848226036
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.0007353973733688401
946, epoch_train_loss=0.0007353973733688401
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.0007353973619408807
947, epoch_train_loss=0.0007353973619408807
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.0007353973505386467
948, epoch_train_loss=0.0007353973505386467
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.0007353973391620596
949, epoch_train_loss=0.0007353973391620596
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.0007353973278110401
950, epoch_train_loss=0.0007353973278110401
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0007353973164855099
951, epoch_train_loss=0.0007353973164855099
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.000735397305185392
952, epoch_train_loss=0.000735397305185392
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.0007353972939106075
953, epoch_train_loss=0.0007353972939106075
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.0007353972826610793
954, epoch_train_loss=0.0007353972826610793
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.0007353972714367299
955, epoch_train_loss=0.0007353972714367299
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.0007353972602374829
956, epoch_train_loss=0.0007353972602374829
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.0007353972490632624
957, epoch_train_loss=0.0007353972490632624
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.0007353972379139914
958, epoch_train_loss=0.0007353972379139914
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.0007353972267895939
959, epoch_train_loss=0.0007353972267895939
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0007353972156899933
960, epoch_train_loss=0.0007353972156899933
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0007353972046151161
961, epoch_train_loss=0.0007353972046151161
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.0007353971935648866
962, epoch_train_loss=0.0007353971935648866
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0007353971825392295
963, epoch_train_loss=0.0007353971825392295
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.0007353971715380707
964, epoch_train_loss=0.0007353971715380707
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.0007353971605613358
965, epoch_train_loss=0.0007353971605613358
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.000735397149608951
966, epoch_train_loss=0.000735397149608951
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.0007353971386808424
967, epoch_train_loss=0.0007353971386808424
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.0007353971277769362
968, epoch_train_loss=0.0007353971277769362
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0007353971168971605
969, epoch_train_loss=0.0007353971168971605
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.0007353971060414412
970, epoch_train_loss=0.0007353971060414412
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.0007353970952097065
971, epoch_train_loss=0.0007353970952097065
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.0007353970844018842
972, epoch_train_loss=0.0007353970844018842
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.0007353970736179022
973, epoch_train_loss=0.0007353970736179022
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.0007353970628576879
974, epoch_train_loss=0.0007353970628576879
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.0007353970521211707
975, epoch_train_loss=0.0007353970521211707
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.0007353970414082794
976, epoch_train_loss=0.0007353970414082794
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0007353970307189426
977, epoch_train_loss=0.0007353970307189426
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.0007353970200530902
978, epoch_train_loss=0.0007353970200530902
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.0007353970094106519
979, epoch_train_loss=0.0007353970094106519
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.0007353969987915568
980, epoch_train_loss=0.0007353969987915568
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0007353969881957357
981, epoch_train_loss=0.0007353969881957357
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.0007353969776231192
982, epoch_train_loss=0.0007353969776231192
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.0007353969670736373
983, epoch_train_loss=0.0007353969670736373
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0007353969565472216
984, epoch_train_loss=0.0007353969565472216
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.0007353969460438024
985, epoch_train_loss=0.0007353969460438024
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.0007353969355633112
986, epoch_train_loss=0.0007353969355633112
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.0007353969251056807
987, epoch_train_loss=0.0007353969251056807
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.000735396914670842
988, epoch_train_loss=0.000735396914670842
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.000735396904258728
989, epoch_train_loss=0.000735396904258728
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.0007353968938692708
990, epoch_train_loss=0.0007353968938692708
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0007353968835024026
991, epoch_train_loss=0.0007353968835024026
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0007353968731580574
992, epoch_train_loss=0.0007353968731580574
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0007353968628361678
993, epoch_train_loss=0.0007353968628361678
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.0007353968525366679
994, epoch_train_loss=0.0007353968525366679
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0007353968422594899
995, epoch_train_loss=0.0007353968422594899
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0007353968320045694
996, epoch_train_loss=0.0007353968320045694
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.0007353968217718398
997, epoch_train_loss=0.0007353968217718398
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.0007353968115612357
998, epoch_train_loss=0.0007353968115612357
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.0007353968013726917
999, epoch_train_loss=0.0007353968013726917
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.0007353967912061428
1000, epoch_train_loss=0.0007353967912061428
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.000735396781061525
1001, epoch_train_loss=0.000735396781061525
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.000735396770938772
1002, epoch_train_loss=0.000735396770938772
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0007353967608378215
1003, epoch_train_loss=0.0007353967608378215
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0007353967507586073
1004, epoch_train_loss=0.0007353967507586073
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.0007353967407010677
1005, epoch_train_loss=0.0007353967407010677
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.000735396730665137
1006, epoch_train_loss=0.000735396730665137
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0007353967206507537
1007, epoch_train_loss=0.0007353967206507537
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.000735396710657853
1008, epoch_train_loss=0.000735396710657853
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.000735396700686373
1009, epoch_train_loss=0.000735396700686373
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.0007353966907362508
1010, epoch_train_loss=0.0007353966907362508
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.0007353966808074239
1011, epoch_train_loss=0.0007353966808074239
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.0007353966708998304
1012, epoch_train_loss=0.0007353966708998304
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.000735396661013408
1013, epoch_train_loss=0.000735396661013408
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.0007353966511480952
1014, epoch_train_loss=0.0007353966511480952
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0007353966413038294
1015, epoch_train_loss=0.0007353966413038294
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.0007353966314805505
1016, epoch_train_loss=0.0007353966314805505
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.0007353966216781963
1017, epoch_train_loss=0.0007353966216781963
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0007353966118967076
1018, epoch_train_loss=0.0007353966118967076
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.0007353966021360225
1019, epoch_train_loss=0.0007353966021360225
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0007353965923960808
1020, epoch_train_loss=0.0007353965923960808
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0007353965826768228
1021, epoch_train_loss=0.0007353965826768228
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0007353965729781877
1022, epoch_train_loss=0.0007353965729781877
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.0007353965633001163
1023, epoch_train_loss=0.0007353965633001163
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.0007353965536425486
1024, epoch_train_loss=0.0007353965536425486
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.0007353965440054259
1025, epoch_train_loss=0.0007353965440054259
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.0007353965343886884
1026, epoch_train_loss=0.0007353965343886884
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0007353965247922772
1027, epoch_train_loss=0.0007353965247922772
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.0007353965152161342
1028, epoch_train_loss=0.0007353965152161342
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.0007353965056602014
1029, epoch_train_loss=0.0007353965056602014
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.0007353964961244195
1030, epoch_train_loss=0.0007353964961244195
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.0007353964866087304
1031, epoch_train_loss=0.0007353964866087304
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.0007353964771130774
1032, epoch_train_loss=0.0007353964771130774
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.0007353964676374019
1033, epoch_train_loss=0.0007353964676374019
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0007353964581816464
1034, epoch_train_loss=0.0007353964581816464
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.0007353964487457549
1035, epoch_train_loss=0.0007353964487457549
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.0007353964393296691
1036, epoch_train_loss=0.0007353964393296691
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.0007353964299333328
1037, epoch_train_loss=0.0007353964299333328
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.0007353964205566897
1038, epoch_train_loss=0.0007353964205566897
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.0007353964111996822
1039, epoch_train_loss=0.0007353964111996822
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.0007353964018622557
1040, epoch_train_loss=0.0007353964018622557
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 0.0007353963925443532
1041, epoch_train_loss=0.0007353963925443532
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.0007353963832459193
1042, epoch_train_loss=0.0007353963832459193
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.0007353963739668981
1043, epoch_train_loss=0.0007353963739668981
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.0007353963647072345
1044, epoch_train_loss=0.0007353963647072345
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 0.0007353963554668741
1045, epoch_train_loss=0.0007353963554668741
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 0.0007353963462457604
1046, epoch_train_loss=0.0007353963462457604
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 0.0007353963370438393
1047, epoch_train_loss=0.0007353963370438393
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 0.0007353963278610563
1048, epoch_train_loss=0.0007353963278610563
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 0.0007353963186973578
1049, epoch_train_loss=0.0007353963186973578
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 0.0007353963095526882
1050, epoch_train_loss=0.0007353963095526882
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 0.0007353963004269942
1051, epoch_train_loss=0.0007353963004269942
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 0.000735396291320222
1052, epoch_train_loss=0.000735396291320222
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 0.0007353962822323182
1053, epoch_train_loss=0.0007353962822323182
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 0.000735396273163229
1054, epoch_train_loss=0.000735396273163229
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 0.0007353962641129009
1055, epoch_train_loss=0.0007353962641129009
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 0.0007353962550812811
1056, epoch_train_loss=0.0007353962550812811
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 0.0007353962460683173
1057, epoch_train_loss=0.0007353962460683173
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 0.0007353962370739566
1058, epoch_train_loss=0.0007353962370739566
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 0.0007353962280981467
1059, epoch_train_loss=0.0007353962280981467
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 0.0007353962191408344
1060, epoch_train_loss=0.0007353962191408344
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 0.0007353962102019686
1061, epoch_train_loss=0.0007353962102019686
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 0.0007353962012814965
1062, epoch_train_loss=0.0007353962012814965
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 0.000735396192379367
1063, epoch_train_loss=0.000735396192379367
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 0.0007353961834955289
1064, epoch_train_loss=0.0007353961834955289
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 0.0007353961746299304
1065, epoch_train_loss=0.0007353961746299304
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 0.0007353961657825202
1066, epoch_train_loss=0.0007353961657825202
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 0.000735396156953247
1067, epoch_train_loss=0.000735396156953247
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 0.0007353961481420607
1068, epoch_train_loss=0.0007353961481420607
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 0.0007353961393489098
1069, epoch_train_loss=0.0007353961393489098
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 0.0007353961305737451
1070, epoch_train_loss=0.0007353961305737451
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 0.0007353961218165151
1071, epoch_train_loss=0.0007353961218165151
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 0.0007353961130771707
1072, epoch_train_loss=0.0007353961130771707
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 0.0007353961043556613
1073, epoch_train_loss=0.0007353961043556613
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 0.0007353960956519377
1074, epoch_train_loss=0.0007353960956519377
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 0.0007353960869659498
1075, epoch_train_loss=0.0007353960869659498
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 0.0007353960782976479
1076, epoch_train_loss=0.0007353960782976479
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 0.0007353960696469831
1077, epoch_train_loss=0.0007353960696469831
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 0.0007353960610139064
1078, epoch_train_loss=0.0007353960610139064
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 0.0007353960523983697
1079, epoch_train_loss=0.0007353960523983697
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 0.0007353960438003232
1080, epoch_train_loss=0.0007353960438003232
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 0.0007353960352197187
1081, epoch_train_loss=0.0007353960352197187
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 0.0007353960266565078
1082, epoch_train_loss=0.0007353960266565078
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 0.000735396018110643
1083, epoch_train_loss=0.000735396018110643
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 0.0007353960095820755
1084, epoch_train_loss=0.0007353960095820755
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 0.0007353960010707577
1085, epoch_train_loss=0.0007353960010707577
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 0.0007353959925766416
1086, epoch_train_loss=0.0007353959925766416
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 0.0007353959840996797
1087, epoch_train_loss=0.0007353959840996797
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 0.000735395975639825
1088, epoch_train_loss=0.000735395975639825
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 0.0007353959671970302
1089, epoch_train_loss=0.0007353959671970302
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 0.0007353959587712478
1090, epoch_train_loss=0.0007353959587712478
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 0.0007353959503624318
1091, epoch_train_loss=0.0007353959503624318
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 0.0007353959419705348
1092, epoch_train_loss=0.0007353959419705348
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 0.0007353959335955107
1093, epoch_train_loss=0.0007353959335955107
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 0.0007353959252373128
1094, epoch_train_loss=0.0007353959252373128
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 0.0007353959168958952
1095, epoch_train_loss=0.0007353959168958952
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 0.0007353959085712108
1096, epoch_train_loss=0.0007353959085712108
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 0.0007353959002632149
1097, epoch_train_loss=0.0007353959002632149
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 0.0007353958919718614
1098, epoch_train_loss=0.0007353958919718614
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 0.000735395883697105
1099, epoch_train_loss=0.000735395883697105
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 0.0007353958754388992
1100, epoch_train_loss=0.0007353958754388992
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 0.0007353958671971998
1101, epoch_train_loss=0.0007353958671971998
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 0.0007353958589719616
1102, epoch_train_loss=0.0007353958589719616
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 0.0007353958507631396
1103, epoch_train_loss=0.0007353958507631396
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 0.0007353958425706891
1104, epoch_train_loss=0.0007353958425706891
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 0.0007353958343945647
1105, epoch_train_loss=0.0007353958343945647
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 0.0007353958262347226
1106, epoch_train_loss=0.0007353958262347226
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 0.000735395818091118
1107, epoch_train_loss=0.000735395818091118
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 0.0007353958099637071
1108, epoch_train_loss=0.0007353958099637071
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 0.0007353958018524455
1109, epoch_train_loss=0.0007353958018524455
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 0.0007353957937572893
1110, epoch_train_loss=0.0007353957937572893
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 0.0007353957856781952
1111, epoch_train_loss=0.0007353957856781952
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 0.0007353957776151199
1112, epoch_train_loss=0.0007353957776151199
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 0.0007353957695680191
1113, epoch_train_loss=0.0007353957695680191
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 0.0007353957615368503
1114, epoch_train_loss=0.0007353957615368503
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 0.0007353957535215697
1115, epoch_train_loss=0.0007353957535215697
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 0.0007353957455221344
1116, epoch_train_loss=0.0007353957455221344
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 0.0007353957375385015
1117, epoch_train_loss=0.0007353957375385015
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 0.0007353957295706291
1118, epoch_train_loss=0.0007353957295706291
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 0.0007353957216184744
1119, epoch_train_loss=0.0007353957216184744
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 0.0007353957136819945
1120, epoch_train_loss=0.0007353957136819945
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 0.0007353957057611473
1121, epoch_train_loss=0.0007353957057611473
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 0.0007353956978558906
1122, epoch_train_loss=0.0007353956978558906
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 0.0007353956899661823
1123, epoch_train_loss=0.0007353956899661823
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 0.0007353956820919815
1124, epoch_train_loss=0.0007353956820919815
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 0.0007353956742332457
1125, epoch_train_loss=0.0007353956742332457
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 0.0007353956663899333
1126, epoch_train_loss=0.0007353956663899333
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 0.0007353956585620025
1127, epoch_train_loss=0.0007353956585620025
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 0.0007353956507494131
1128, epoch_train_loss=0.0007353956507494131
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 0.0007353956429521235
1129, epoch_train_loss=0.0007353956429521235
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 0.000735395635170093
1130, epoch_train_loss=0.000735395635170093
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 0.0007353956274032801
1131, epoch_train_loss=0.0007353956274032801
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 0.0007353956196516446
1132, epoch_train_loss=0.0007353956196516446
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 0.0007353956119151458
1133, epoch_train_loss=0.0007353956119151458
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 0.0007353956041937432
1134, epoch_train_loss=0.0007353956041937432
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 0.0007353955964873963
1135, epoch_train_loss=0.0007353955964873963
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 0.0007353955887960657
1136, epoch_train_loss=0.0007353955887960657
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 0.000735395581119711
1137, epoch_train_loss=0.000735395581119711
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 0.0007353955734582917
1138, epoch_train_loss=0.0007353955734582917
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 0.0007353955658117687
1139, epoch_train_loss=0.0007353955658117687
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 0.0007353955581801022
1140, epoch_train_loss=0.0007353955581801022
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 0.000735395550563253
1141, epoch_train_loss=0.000735395550563253
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 0.0007353955429611809
1142, epoch_train_loss=0.0007353955429611809
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 0.0007353955353738481
1143, epoch_train_loss=0.0007353955353738481
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 0.0007353955278012144
1144, epoch_train_loss=0.0007353955278012144
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 0.0007353955202432405
1145, epoch_train_loss=0.0007353955202432405
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 0.0007353955126998891
1146, epoch_train_loss=0.0007353955126998891
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 0.0007353955051711202
1147, epoch_train_loss=0.0007353955051711202
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 0.0007353954976568951
1148, epoch_train_loss=0.0007353954976568951
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 0.0007353954901571763
1149, epoch_train_loss=0.0007353954901571763
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 0.0007353954826719251
1150, epoch_train_loss=0.0007353954826719251
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 0.0007353954752011033
1151, epoch_train_loss=0.0007353954752011033
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 0.000735395467744673
1152, epoch_train_loss=0.000735395467744673
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 0.0007353954603025955
1153, epoch_train_loss=0.0007353954603025955
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 0.0007353954528748343
1154, epoch_train_loss=0.0007353954528748343
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 0.0007353954454613504
1155, epoch_train_loss=0.0007353954454613504
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 0.0007353954380621069
1156, epoch_train_loss=0.0007353954380621069
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 0.0007353954306770665
1157, epoch_train_loss=0.0007353954306770665
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 0.0007353954233061918
1158, epoch_train_loss=0.0007353954233061918
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 0.0007353954159494458
1159, epoch_train_loss=0.0007353954159494458
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 0.0007353954086067908
1160, epoch_train_loss=0.0007353954086067908
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 0.0007353954012781904
1161, epoch_train_loss=0.0007353954012781904
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 0.000735395393963608
1162, epoch_train_loss=0.000735395393963608
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 0.0007353953866630057
1163, epoch_train_loss=0.0007353953866630057
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 0.0007353953793763483
1164, epoch_train_loss=0.0007353953793763483
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 0.0007353953721035987
1165, epoch_train_loss=0.0007353953721035987
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 0.0007353953648447214
1166, epoch_train_loss=0.0007353953648447214
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 0.0007353953575996787
1167, epoch_train_loss=0.0007353953575996787
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 0.0007353953503684358
1168, epoch_train_loss=0.0007353953503684358
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 0.0007353953431509563
1169, epoch_train_loss=0.0007353953431509563
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 0.0007353953359472043
1170, epoch_train_loss=0.0007353953359472043
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 0.0007353953287571441
1171, epoch_train_loss=0.0007353953287571441
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 0.00073539532158074
1172, epoch_train_loss=0.00073539532158074
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 0.0007353953144179567
1173, epoch_train_loss=0.0007353953144179567
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 0.0007353953072687586
1174, epoch_train_loss=0.0007353953072687586
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 0.0007353953001331108
1175, epoch_train_loss=0.0007353953001331108
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 0.0007353952930109778
1176, epoch_train_loss=0.0007353952930109778
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 0.0007353952859023247
1177, epoch_train_loss=0.0007353952859023247
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 0.0007353952788071168
1178, epoch_train_loss=0.0007353952788071168
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 0.0007353952717253189
1179, epoch_train_loss=0.0007353952717253189
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 0.0007353952646568968
1180, epoch_train_loss=0.0007353952646568968
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 0.0007353952576018151
1181, epoch_train_loss=0.0007353952576018151
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 0.0007353952505600397
1182, epoch_train_loss=0.0007353952505600397
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 0.000735395243531537
1183, epoch_train_loss=0.000735395243531537
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 0.000735395236516272
1184, epoch_train_loss=0.000735395236516272
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 0.0007353952295142105
1185, epoch_train_loss=0.0007353952295142105
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 0.0007353952225253188
1186, epoch_train_loss=0.0007353952225253188
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 0.0007353952155495633
1187, epoch_train_loss=0.0007353952155495633
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 0.0007353952085869093
1188, epoch_train_loss=0.0007353952085869093
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 0.000735395201637324
1189, epoch_train_loss=0.000735395201637324
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 0.000735395194700773
1190, epoch_train_loss=0.000735395194700773
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 0.0007353951877772237
1191, epoch_train_loss=0.0007353951877772237
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 0.0007353951808666426
1192, epoch_train_loss=0.0007353951808666426
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 0.0007353951739689959
1193, epoch_train_loss=0.0007353951739689959
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 0.0007353951670842513
1194, epoch_train_loss=0.0007353951670842513
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 0.0007353951602123747
1195, epoch_train_loss=0.0007353951602123747
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 0.0007353951533533343
1196, epoch_train_loss=0.0007353951533533343
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 0.000735395146507097
1197, epoch_train_loss=0.000735395146507097
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 0.0007353951396736289
1198, epoch_train_loss=0.0007353951396736289
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 0.0007353951328528988
1199, epoch_train_loss=0.0007353951328528988
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 0.0007353951260448741
1200, epoch_train_loss=0.0007353951260448741
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 0.0007353951192495218
1201, epoch_train_loss=0.0007353951192495218
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 0.0007353951124668098
1202, epoch_train_loss=0.0007353951124668098
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 0.0007353951056967062
1203, epoch_train_loss=0.0007353951056967062
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 0.0007353950989391785
1204, epoch_train_loss=0.0007353950989391785
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 0.000735395092194195
1205, epoch_train_loss=0.000735395092194195
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 0.000735395085461724
1206, epoch_train_loss=0.000735395085461724
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 0.0007353950787417329
1207, epoch_train_loss=0.0007353950787417329
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 0.000735395072034191
1208, epoch_train_loss=0.000735395072034191
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 0.0007353950653390662
1209, epoch_train_loss=0.0007353950653390662
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 0.0007353950586563272
1210, epoch_train_loss=0.0007353950586563272
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 0.0007353950519859426
1211, epoch_train_loss=0.0007353950519859426
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 0.0007353950453278809
1212, epoch_train_loss=0.0007353950453278809
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.0007353950386821119
1213, epoch_train_loss=0.0007353950386821119
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.000735395032048603
1214, epoch_train_loss=0.000735395032048603
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.0007353950254273243
1215, epoch_train_loss=0.0007353950254273243
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.000735395018818245
1216, epoch_train_loss=0.000735395018818245
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.0007353950122213342
1217, epoch_train_loss=0.0007353950122213342
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.0007353950056365605
1218, epoch_train_loss=0.0007353950056365605
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0007353949990638939
1219, epoch_train_loss=0.0007353949990638939
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.000735394992503304
1220, epoch_train_loss=0.000735394992503304
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.0007353949859547604
1221, epoch_train_loss=0.0007353949859547604
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.0007353949794182328
1222, epoch_train_loss=0.0007353949794182328
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.0007353949728936904
1223, epoch_train_loss=0.0007353949728936904
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.0007353949663811042
1224, epoch_train_loss=0.0007353949663811042
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.0007353949598804435
1225, epoch_train_loss=0.0007353949598804435
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.0007353949533916789
1226, epoch_train_loss=0.0007353949533916789
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.0007353949469147803
1227, epoch_train_loss=0.0007353949469147803
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.0007353949404497176
1228, epoch_train_loss=0.0007353949404497176
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.0007353949339964618
1229, epoch_train_loss=0.0007353949339964618
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.0007353949275549833
1230, epoch_train_loss=0.0007353949275549833
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0007353949211252527
1231, epoch_train_loss=0.0007353949211252527
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0007353949147072409
1232, epoch_train_loss=0.0007353949147072409
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0007353949083009177
1233, epoch_train_loss=0.0007353949083009177
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007353949019062543
1234, epoch_train_loss=0.0007353949019062543
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.0007353948955232222
1235, epoch_train_loss=0.0007353948955232222
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.0007353948891517919
1236, epoch_train_loss=0.0007353948891517919
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.0007353948827919347
1237, epoch_train_loss=0.0007353948827919347
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0007353948764436224
1238, epoch_train_loss=0.0007353948764436224
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0007353948701068255
1239, epoch_train_loss=0.0007353948701068255
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.000735394863781516
1240, epoch_train_loss=0.000735394863781516
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0007353948574676648
1241, epoch_train_loss=0.0007353948574676648
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.0007353948511652434
1242, epoch_train_loss=0.0007353948511652434
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.000735394844874224
1243, epoch_train_loss=0.000735394844874224
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.0007353948385945781
1244, epoch_train_loss=0.0007353948385945781
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0007353948323262777
1245, epoch_train_loss=0.0007353948323262777
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0007353948260692945
1246, epoch_train_loss=0.0007353948260692945
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0007353948198236009
1247, epoch_train_loss=0.0007353948198236009
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0007353948135891688
1248, epoch_train_loss=0.0007353948135891688
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.0007353948073659703
1249, epoch_train_loss=0.0007353948073659703
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0007353948011539777
1250, epoch_train_loss=0.0007353948011539777
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0007353947949531638
1251, epoch_train_loss=0.0007353947949531638
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.0007353947887635007
1252, epoch_train_loss=0.0007353947887635007
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.0007353947825849608
1253, epoch_train_loss=0.0007353947825849608
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0007353947764175169
1254, epoch_train_loss=0.0007353947764175169
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0007353947702611418
1255, epoch_train_loss=0.0007353947702611418
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.0007353947641158081
1256, epoch_train_loss=0.0007353947641158081
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0007353947579814886
1257, epoch_train_loss=0.0007353947579814886
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0007353947518581565
1258, epoch_train_loss=0.0007353947518581565
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.000735394745745785
1259, epoch_train_loss=0.000735394745745785
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007353947396443471
1260, epoch_train_loss=0.0007353947396443471
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0007353947335538159
1261, epoch_train_loss=0.0007353947335538159
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0007353947274741648
1262, epoch_train_loss=0.0007353947274741648
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0007353947214053673
1263, epoch_train_loss=0.0007353947214053673
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0007353947153473968
1264, epoch_train_loss=0.0007353947153473968
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0007353947093002268
1265, epoch_train_loss=0.0007353947093002268
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0007353947032638306
1266, epoch_train_loss=0.0007353947032638306
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0007353946972381823
1267, epoch_train_loss=0.0007353946972381823
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0007353946912232558
1268, epoch_train_loss=0.0007353946912232558
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0007353946852190249
1269, epoch_train_loss=0.0007353946852190249
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0007353946792254633
1270, epoch_train_loss=0.0007353946792254633
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0007353946732425452
1271, epoch_train_loss=0.0007353946732425452
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.0007353946672702444
1272, epoch_train_loss=0.0007353946672702444
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.0007353946613085357
1273, epoch_train_loss=0.0007353946613085357
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.0007353946553573932
1274, epoch_train_loss=0.0007353946553573932
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.0007353946494167914
1275, epoch_train_loss=0.0007353946494167914
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0007353946434867048
1276, epoch_train_loss=0.0007353946434867048
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007353946375671073
1277, epoch_train_loss=0.0007353946375671073
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0007353946316579741
1278, epoch_train_loss=0.0007353946316579741
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0007353946257592792
1279, epoch_train_loss=0.0007353946257592792
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.0007353946198709976
1280, epoch_train_loss=0.0007353946198709976
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.0007353946139931046
1281, epoch_train_loss=0.0007353946139931046
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.0007353946081255745
1282, epoch_train_loss=0.0007353946081255745
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0007353946022683828
1283, epoch_train_loss=0.0007353946022683828
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.0007353945964215042
1284, epoch_train_loss=0.0007353945964215042
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0007353945905849142
1285, epoch_train_loss=0.0007353945905849142
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.0007353945847585877
1286, epoch_train_loss=0.0007353945847585877
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.0007353945789424997
1287, epoch_train_loss=0.0007353945789424997
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0007353945731366259
1288, epoch_train_loss=0.0007353945731366259
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0007353945673409422
1289, epoch_train_loss=0.0007353945673409422
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0007353945615554234
1290, epoch_train_loss=0.0007353945615554234
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0007353945557800451
1291, epoch_train_loss=0.0007353945557800451
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.0007353945500147834
1292, epoch_train_loss=0.0007353945500147834
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.0007353945442596136
1293, epoch_train_loss=0.0007353945442596136
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.0007353945385145121
1294, epoch_train_loss=0.0007353945385145121
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.0007353945327794545
1295, epoch_train_loss=0.0007353945327794545
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.0007353945270544166
1296, epoch_train_loss=0.0007353945270544166
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.0007353945213393743
1297, epoch_train_loss=0.0007353945213393743
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.0007353945156343041
1298, epoch_train_loss=0.0007353945156343041
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.0007353945099391822
1299, epoch_train_loss=0.0007353945099391822
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.0007353945042539844
1300, epoch_train_loss=0.0007353945042539844
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.0007353944985786871
1301, epoch_train_loss=0.0007353944985786871
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.0007353944929132671
1302, epoch_train_loss=0.0007353944929132671
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.0007353944872577008
1303, epoch_train_loss=0.0007353944872577008
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0007353944816119642
1304, epoch_train_loss=0.0007353944816119642
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.0007353944759760342
1305, epoch_train_loss=0.0007353944759760342
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0007353944703498877
1306, epoch_train_loss=0.0007353944703498877
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.0007353944647335012
1307, epoch_train_loss=0.0007353944647335012
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.0007353944591268518
1308, epoch_train_loss=0.0007353944591268518
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.0007353944535299158
1309, epoch_train_loss=0.0007353944535299158
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.0007353944479426709
1310, epoch_train_loss=0.0007353944479426709
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 0.0007353944423650936
1311, epoch_train_loss=0.0007353944423650936
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.0007353944367971606
1312, epoch_train_loss=0.0007353944367971606
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.0007353944312388503
1313, epoch_train_loss=0.0007353944312388503
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.0007353944256901387
1314, epoch_train_loss=0.0007353944256901387
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 0.0007353944201510035
1315, epoch_train_loss=0.0007353944201510035
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.0007353944146214228
1316, epoch_train_loss=0.0007353944146214228
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.000735394409101373
1317, epoch_train_loss=0.000735394409101373
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 0.0007353944035908319
1318, epoch_train_loss=0.0007353944035908319
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 0.0007353943980897776
1319, epoch_train_loss=0.0007353943980897776
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 0.0007353943925981874
1320, epoch_train_loss=0.0007353943925981874
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 0.0007353943871160383
1321, epoch_train_loss=0.0007353943871160383
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 0.0007353943816433091
1322, epoch_train_loss=0.0007353943816433091
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 0.0007353943761799771
1323, epoch_train_loss=0.0007353943761799771
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 0.0007353943707260205
1324, epoch_train_loss=0.0007353943707260205
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 0.0007353943652814169
1325, epoch_train_loss=0.0007353943652814169
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 0.0007353943598461444
1326, epoch_train_loss=0.0007353943598461444
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 0.0007353943544201815
1327, epoch_train_loss=0.0007353943544201815
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 0.0007353943490035058
1328, epoch_train_loss=0.0007353943490035058
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 0.0007353943435960962
1329, epoch_train_loss=0.0007353943435960962
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 0.0007353943381979306
1330, epoch_train_loss=0.0007353943381979306
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 0.0007353943328089872
1331, epoch_train_loss=0.0007353943328089872
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 0.0007353943274292449
1332, epoch_train_loss=0.0007353943274292449
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 0.0007353943220586813
1333, epoch_train_loss=0.0007353943220586813
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 0.0007353943166972758
1334, epoch_train_loss=0.0007353943166972758
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 0.000735394311345007
1335, epoch_train_loss=0.000735394311345007
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 0.0007353943060018533
1336, epoch_train_loss=0.0007353943060018533
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 0.0007353943006677934
1337, epoch_train_loss=0.0007353943006677934
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 0.0007353942953428062
1338, epoch_train_loss=0.0007353942953428062
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 0.0007353942900268706
1339, epoch_train_loss=0.0007353942900268706
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 0.0007353942847199656
1340, epoch_train_loss=0.0007353942847199656
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 0.0007353942794220699
1341, epoch_train_loss=0.0007353942794220699
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 0.0007353942741331628
1342, epoch_train_loss=0.0007353942741331628
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 0.0007353942688532232
1343, epoch_train_loss=0.0007353942688532232
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 0.0007353942635822306
1344, epoch_train_loss=0.0007353942635822306
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 0.000735394258320164
1345, epoch_train_loss=0.000735394258320164
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 0.0007353942530670025
1346, epoch_train_loss=0.0007353942530670025
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 0.0007353942478227261
1347, epoch_train_loss=0.0007353942478227261
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 0.0007353942425873138
1348, epoch_train_loss=0.0007353942425873138
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 0.0007353942373607447
1349, epoch_train_loss=0.0007353942373607447
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 0.0007353942321429993
1350, epoch_train_loss=0.0007353942321429993
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 0.0007353942269340562
1351, epoch_train_loss=0.0007353942269340562
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 0.0007353942217338959
1352, epoch_train_loss=0.0007353942217338959
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 0.000735394216542497
1353, epoch_train_loss=0.000735394216542497
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 0.0007353942113598411
1354, epoch_train_loss=0.0007353942113598411
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 0.0007353942061859062
1355, epoch_train_loss=0.0007353942061859062
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 0.0007353942010206733
1356, epoch_train_loss=0.0007353942010206733
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 0.0007353941958641222
1357, epoch_train_loss=0.0007353941958641222
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 0.0007353941907162323
1358, epoch_train_loss=0.0007353941907162323
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 0.0007353941855769843
1359, epoch_train_loss=0.0007353941855769843
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 0.000735394180446358
1360, epoch_train_loss=0.000735394180446358
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 0.0007353941753243339
1361, epoch_train_loss=0.0007353941753243339
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 0.0007353941702108924
1362, epoch_train_loss=0.0007353941702108924
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 0.0007353941651060131
1363, epoch_train_loss=0.0007353941651060131
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 0.000735394160009677
1364, epoch_train_loss=0.000735394160009677
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 0.000735394154921864
1365, epoch_train_loss=0.000735394154921864
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 0.000735394149842555
1366, epoch_train_loss=0.000735394149842555
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 0.0007353941447717305
1367, epoch_train_loss=0.0007353941447717305
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 0.0007353941397093707
1368, epoch_train_loss=0.0007353941397093707
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 0.0007353941346554567
1369, epoch_train_loss=0.0007353941346554567
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 0.0007353941296099695
1370, epoch_train_loss=0.0007353941296099695
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 0.0007353941245728887
1371, epoch_train_loss=0.0007353941245728887
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 0.0007353941195441962
1372, epoch_train_loss=0.0007353941195441962
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 0.0007353941145238726
1373, epoch_train_loss=0.0007353941145238726
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 0.0007353941095118984
1374, epoch_train_loss=0.0007353941095118984
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 0.0007353941045082551
1375, epoch_train_loss=0.0007353941045082551
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 0.0007353940995129234
1376, epoch_train_loss=0.0007353940995129234
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 0.0007353940945258846
1377, epoch_train_loss=0.0007353940945258846
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 0.0007353940895471196
1378, epoch_train_loss=0.0007353940895471196
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 0.00073539408457661
1379, epoch_train_loss=0.00073539408457661
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 0.000735394079614337
1380, epoch_train_loss=0.000735394079614337
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 0.0007353940746602816
1381, epoch_train_loss=0.0007353940746602816
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 0.0007353940697144252
1382, epoch_train_loss=0.0007353940697144252
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 0.0007353940647767494
1383, epoch_train_loss=0.0007353940647767494
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 0.0007353940598472355
1384, epoch_train_loss=0.0007353940598472355
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 0.0007353940549258652
1385, epoch_train_loss=0.0007353940549258652
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 0.0007353940500126198
1386, epoch_train_loss=0.0007353940500126198
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 0.0007353940451074818
1387, epoch_train_loss=0.0007353940451074818
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 0.0007353940402104316
1388, epoch_train_loss=0.0007353940402104316
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 0.0007353940353214516
1389, epoch_train_loss=0.0007353940353214516
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 0.0007353940304405237
1390, epoch_train_loss=0.0007353940304405237
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 0.0007353940255676295
1391, epoch_train_loss=0.0007353940255676295
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 0.000735394020702751
1392, epoch_train_loss=0.000735394020702751
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 0.0007353940158458698
1393, epoch_train_loss=0.0007353940158458698
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 0.0007353940109969685
1394, epoch_train_loss=0.0007353940109969685
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 0.0007353940061560287
1395, epoch_train_loss=0.0007353940061560287
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 0.0007353940013230328
1396, epoch_train_loss=0.0007353940013230328
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 0.0007353939964979629
1397, epoch_train_loss=0.0007353939964979629
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 0.0007353939916808007
1398, epoch_train_loss=0.0007353939916808007
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 0.0007353939868715291
1399, epoch_train_loss=0.0007353939868715291
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 0.0007353939820701301
1400, epoch_train_loss=0.0007353939820701301
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 0.000735393977276586
1401, epoch_train_loss=0.000735393977276586
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 0.0007353939724908793
1402, epoch_train_loss=0.0007353939724908793
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 0.0007353939677129928
1403, epoch_train_loss=0.0007353939677129928
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 0.0007353939629429082
1404, epoch_train_loss=0.0007353939629429082
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 0.000735393958180609
1405, epoch_train_loss=0.000735393958180609
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 0.0007353939534260769
1406, epoch_train_loss=0.0007353939534260769
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 0.0007353939486792952
1407, epoch_train_loss=0.0007353939486792952
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 0.000735393943940246
1408, epoch_train_loss=0.000735393943940246
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 0.0007353939392089129
1409, epoch_train_loss=0.0007353939392089129
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 0.0007353939344852783
1410, epoch_train_loss=0.0007353939344852783
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 0.0007353939297693248
1411, epoch_train_loss=0.0007353939297693248
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 0.0007353939250610352
1412, epoch_train_loss=0.0007353939250610352
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 0.0007353939203603927
1413, epoch_train_loss=0.0007353939203603927
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 0.00073539391566738
1414, epoch_train_loss=0.00073539391566738
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 0.0007353939109819809
1415, epoch_train_loss=0.0007353939109819809
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 0.0007353939063041777
1416, epoch_train_loss=0.0007353939063041777
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 0.0007353939016339541
1417, epoch_train_loss=0.0007353939016339541
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 0.000735393896971293
1418, epoch_train_loss=0.000735393896971293
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 0.0007353938923161776
1419, epoch_train_loss=0.0007353938923161776
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 0.0007353938876685913
1420, epoch_train_loss=0.0007353938876685913
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 0.0007353938830285175
1421, epoch_train_loss=0.0007353938830285175
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 0.0007353938783959394
1422, epoch_train_loss=0.0007353938783959394
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 0.0007353938737708404
1423, epoch_train_loss=0.0007353938737708404
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 0.000735393869153204
1424, epoch_train_loss=0.000735393869153204
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 0.0007353938645430137
1425, epoch_train_loss=0.0007353938645430137
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 0.0007353938599402531
1426, epoch_train_loss=0.0007353938599402531
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 0.0007353938553449058
1427, epoch_train_loss=0.0007353938553449058
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 0.0007353938507569553
1428, epoch_train_loss=0.0007353938507569553
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 0.0007353938461763856
1429, epoch_train_loss=0.0007353938461763856
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 0.0007353938416031801
1430, epoch_train_loss=0.0007353938416031801
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 0.0007353938370373228
1431, epoch_train_loss=0.0007353938370373228
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 0.0007353938324787978
1432, epoch_train_loss=0.0007353938324787978
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 0.0007353938279275885
1433, epoch_train_loss=0.0007353938279275885
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 0.0007353938233836791
1434, epoch_train_loss=0.0007353938233836791
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 0.0007353938188470535
1435, epoch_train_loss=0.0007353938188470535
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 0.0007353938143176957
1436, epoch_train_loss=0.0007353938143176957
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 0.0007353938097955895
1437, epoch_train_loss=0.0007353938097955895
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 0.0007353938052807195
1438, epoch_train_loss=0.0007353938052807195
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 0.0007353938007730694
1439, epoch_train_loss=0.0007353938007730694
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 0.0007353937962726233
1440, epoch_train_loss=0.0007353937962726233
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 0.000735393791779366
1441, epoch_train_loss=0.000735393791779366
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 0.0007353937872932816
1442, epoch_train_loss=0.0007353937872932816
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 0.0007353937828143539
1443, epoch_train_loss=0.0007353937828143539
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 0.0007353937783425679
1444, epoch_train_loss=0.0007353937783425679
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 0.0007353937738779078
1445, epoch_train_loss=0.0007353937738779078
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 0.0007353937694203582
1446, epoch_train_loss=0.0007353937694203582
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 0.0007353937649699034
1447, epoch_train_loss=0.0007353937649699034
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 0.0007353937605265281
1448, epoch_train_loss=0.0007353937605265281
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0007353937560902165
1449, epoch_train_loss=0.0007353937560902165
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.0007353937516609535
1450, epoch_train_loss=0.0007353937516609535
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.0007353937472387238
1451, epoch_train_loss=0.0007353937472387238
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0007353937428235117
1452, epoch_train_loss=0.0007353937428235117
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0007353937384153026
1453, epoch_train_loss=0.0007353937384153026
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.0007353937340140812
1454, epoch_train_loss=0.0007353937340140812
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.000735393729619832
1455, epoch_train_loss=0.000735393729619832
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.0007353937252325398
1456, epoch_train_loss=0.0007353937252325398
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.0007353937208521894
1457, epoch_train_loss=0.0007353937208521894
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.0007353937164787664
1458, epoch_train_loss=0.0007353937164787664
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.0007353937121122554
1459, epoch_train_loss=0.0007353937121122554
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.000735393707752642
1460, epoch_train_loss=0.000735393707752642
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.0007353937033999106
1461, epoch_train_loss=0.0007353937033999106
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.0007353936990540464
1462, epoch_train_loss=0.0007353936990540464
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.0007353936947150346
1463, epoch_train_loss=0.0007353936947150346
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.0007353936903828605
1464, epoch_train_loss=0.0007353936903828605
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0007353936860575096
1465, epoch_train_loss=0.0007353936860575096
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.000735393681738967
1466, epoch_train_loss=0.000735393681738967
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.0007353936774272178
1467, epoch_train_loss=0.0007353936774272178
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.0007353936731222473
1468, epoch_train_loss=0.0007353936731222473
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0007353936688240413
1469, epoch_train_loss=0.0007353936688240413
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.0007353936645325851
1470, epoch_train_loss=0.0007353936645325851
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0007353936602478642
1471, epoch_train_loss=0.0007353936602478642
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.0007353936559698637
1472, epoch_train_loss=0.0007353936559698637
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.0007353936516985701
1473, epoch_train_loss=0.0007353936516985701
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0007353936474339682
1474, epoch_train_loss=0.0007353936474339682
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007353936431760442
1475, epoch_train_loss=0.0007353936431760442
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.000735393638924783
1476, epoch_train_loss=0.000735393638924783
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.0007353936346801715
1477, epoch_train_loss=0.0007353936346801715
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.0007353936304421942
1478, epoch_train_loss=0.0007353936304421942
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.0007353936262108375
1479, epoch_train_loss=0.0007353936262108375
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0007353936219860874
1480, epoch_train_loss=0.0007353936219860874
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.0007353936177679299
1481, epoch_train_loss=0.0007353936177679299
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.00073539361355635
1482, epoch_train_loss=0.00073539361355635
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0007353936093513346
1483, epoch_train_loss=0.0007353936093513346
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0007353936051528694
1484, epoch_train_loss=0.0007353936051528694
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0007353936009609402
1485, epoch_train_loss=0.0007353936009609402
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0007353935967755335
1486, epoch_train_loss=0.0007353935967755335
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.0007353935925966349
1487, epoch_train_loss=0.0007353935925966349
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.0007353935884242311
1488, epoch_train_loss=0.0007353935884242311
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.0007353935842583077
1489, epoch_train_loss=0.0007353935842583077
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.0007353935800988516
1490, epoch_train_loss=0.0007353935800988516
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.0007353935759458485
1491, epoch_train_loss=0.0007353935759458485
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.0007353935717992851
1492, epoch_train_loss=0.0007353935717992851
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0007353935676591472
1493, epoch_train_loss=0.0007353935676591472
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0007353935635254214
1494, epoch_train_loss=0.0007353935635254214
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0007353935593980941
1495, epoch_train_loss=0.0007353935593980941
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.0007353935552771519
1496, epoch_train_loss=0.0007353935552771519
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0007353935511625815
1497, epoch_train_loss=0.0007353935511625815
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0007353935470543689
1498, epoch_train_loss=0.0007353935470543689
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0007353935429525005
1499, epoch_train_loss=0.0007353935429525005
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.0007353935388569638
1500, epoch_train_loss=0.0007353935388569638
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.0007353935347677445
1501, epoch_train_loss=0.0007353935347677445
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.00073539353068483
1502, epoch_train_loss=0.00073539353068483
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.0007353935266082066
1503, epoch_train_loss=0.0007353935266082066
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.0007353935225378607
1504, epoch_train_loss=0.0007353935225378607
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0007353935184737794
1505, epoch_train_loss=0.0007353935184737794
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0007353935144159496
1506, epoch_train_loss=0.0007353935144159496
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.0007353935103643583
1507, epoch_train_loss=0.0007353935103643583
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.000735393506318992
1508, epoch_train_loss=0.000735393506318992
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.0007353935022798378
1509, epoch_train_loss=0.0007353935022798378
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.0007353934982468824
1510, epoch_train_loss=0.0007353934982468824
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.0007353934942201131
1511, epoch_train_loss=0.0007353934942201131
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.0007353934901995166
1512, epoch_train_loss=0.0007353934901995166
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.0007353934861850805
1513, epoch_train_loss=0.0007353934861850805
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.0007353934821767911
1514, epoch_train_loss=0.0007353934821767911
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0007353934781746362
1515, epoch_train_loss=0.0007353934781746362
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.0007353934741786025
1516, epoch_train_loss=0.0007353934741786025
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.000735393470188677
1517, epoch_train_loss=0.000735393470188677
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 0.0007353934662048477
1518, epoch_train_loss=0.0007353934662048477
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 0.0007353934622271012
1519, epoch_train_loss=0.0007353934622271012
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0007353934582554251
1520, epoch_train_loss=0.0007353934582554251
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.0007353934542898066
1521, epoch_train_loss=0.0007353934542898066
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.0007353934503302327
1522, epoch_train_loss=0.0007353934503302327
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 0.0007353934463766915
1523, epoch_train_loss=0.0007353934463766915
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 0.00073539344242917
1524, epoch_train_loss=0.00073539344242917
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.0007353934384876558
1525, epoch_train_loss=0.0007353934384876558
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.0007353934345521364
1526, epoch_train_loss=0.0007353934345521364
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.000735393430622599
1527, epoch_train_loss=0.000735393430622599
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 0.0007353934266990315
1528, epoch_train_loss=0.0007353934266990315
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 0.0007353934227814211
1529, epoch_train_loss=0.0007353934227814211
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 0.0007353934188697558
1530, epoch_train_loss=0.0007353934188697558
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 0.0007353934149640235
1531, epoch_train_loss=0.0007353934149640235
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 0.0007353934110642111
1532, epoch_train_loss=0.0007353934110642111
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 0.0007353934071703069
1533, epoch_train_loss=0.0007353934071703069
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 0.0007353934032822983
1534, epoch_train_loss=0.0007353934032822983
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 0.0007353933994001735
1535, epoch_train_loss=0.0007353933994001735
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 0.0007353933955239202
1536, epoch_train_loss=0.0007353933955239202
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.0007353933916535261
1537, epoch_train_loss=0.0007353933916535261
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.0007353933877889791
1538, epoch_train_loss=0.0007353933877889791
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0007353933839302671
1539, epoch_train_loss=0.0007353933839302671
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.000735393380077378
1540, epoch_train_loss=0.000735393380077378
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.0007353933762302999
1541, epoch_train_loss=0.0007353933762302999
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.0007353933723890206
1542, epoch_train_loss=0.0007353933723890206
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.0007353933685535283
1543, epoch_train_loss=0.0007353933685535283
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0007353933647238112
1544, epoch_train_loss=0.0007353933647238112
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.0007353933608998573
1545, epoch_train_loss=0.0007353933608998573
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.0007353933570816544
1546, epoch_train_loss=0.0007353933570816544
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.0007353933532691913
1547, epoch_train_loss=0.0007353933532691913
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.0007353933494624557
1548, epoch_train_loss=0.0007353933494624557
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.0007353933456614358
1549, epoch_train_loss=0.0007353933456614358
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.0007353933418661199
1550, epoch_train_loss=0.0007353933418661199
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.0007353933380764969
1551, epoch_train_loss=0.0007353933380764969
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.0007353933342925541
1552, epoch_train_loss=0.0007353933342925541
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.0007353933305142804
1553, epoch_train_loss=0.0007353933305142804
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0007353933267416645
1554, epoch_train_loss=0.0007353933267416645
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.0007353933229746942
1555, epoch_train_loss=0.0007353933229746942
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.000735393319213358
1556, epoch_train_loss=0.000735393319213358
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0007353933154576448
1557, epoch_train_loss=0.0007353933154576448
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.0007353933117075429
1558, epoch_train_loss=0.0007353933117075429
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.0007353933079630407
1559, epoch_train_loss=0.0007353933079630407
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.0007353933042241265
1560, epoch_train_loss=0.0007353933042241265
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0007353933004907892
1561, epoch_train_loss=0.0007353933004907892
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.0007353932967630176
1562, epoch_train_loss=0.0007353932967630176
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.0007353932930408006
1563, epoch_train_loss=0.0007353932930408006
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.0007353932893241261
1564, epoch_train_loss=0.0007353932893241261
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.0007353932856129829
1565, epoch_train_loss=0.0007353932856129829
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0007353932819073603
1566, epoch_train_loss=0.0007353932819073603
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.0007353932782072469
1567, epoch_train_loss=0.0007353932782072469
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0007353932745126313
1568, epoch_train_loss=0.0007353932745126313
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.0007353932708235022
1569, epoch_train_loss=0.0007353932708235022
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0007353932671398483
1570, epoch_train_loss=0.0007353932671398483
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.000735393263461659
1571, epoch_train_loss=0.000735393263461659
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.0007353932597889231
1572, epoch_train_loss=0.0007353932597889231
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.0007353932561216293
1573, epoch_train_loss=0.0007353932561216293
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.000735393252459767
1574, epoch_train_loss=0.000735393252459767
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0007353932488033248
1575, epoch_train_loss=0.0007353932488033248
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0007353932451522916
1576, epoch_train_loss=0.0007353932451522916
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0007353932415066568
1577, epoch_train_loss=0.0007353932415066568
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.0007353932378664092
1578, epoch_train_loss=0.0007353932378664092
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.000735393234231538
1579, epoch_train_loss=0.000735393234231538
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.0007353932306020328
1580, epoch_train_loss=0.0007353932306020328
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.000735393226977882
1581, epoch_train_loss=0.000735393226977882
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.0007353932233590755
1582, epoch_train_loss=0.0007353932233590755
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0007353932197456019
1583, epoch_train_loss=0.0007353932197456019
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.0007353932161374506
1584, epoch_train_loss=0.0007353932161374506
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.0007353932125346108
1585, epoch_train_loss=0.0007353932125346108
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.0007353932089370724
1586, epoch_train_loss=0.0007353932089370724
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.000735393205344824
1587, epoch_train_loss=0.000735393205344824
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.0007353932017578553
1588, epoch_train_loss=0.0007353932017578553
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0007353931981761558
1589, epoch_train_loss=0.0007353931981761558
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.0007353931945997148
1590, epoch_train_loss=0.0007353931945997148
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.0007353931910285214
1591, epoch_train_loss=0.0007353931910285214
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.0007353931874625654
1592, epoch_train_loss=0.0007353931874625654
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.0007353931839018363
1593, epoch_train_loss=0.0007353931839018363
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.0007353931803463239
1594, epoch_train_loss=0.0007353931803463239
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.0007353931767960172
1595, epoch_train_loss=0.0007353931767960172
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.0007353931732509059
1596, epoch_train_loss=0.0007353931732509059
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.0007353931697109798
1597, epoch_train_loss=0.0007353931697109798
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.0007353931661762281
1598, epoch_train_loss=0.0007353931661762281
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.0007353931626466409
1599, epoch_train_loss=0.0007353931626466409
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.0007353931591222079
1600, epoch_train_loss=0.0007353931591222079
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.0007353931556029184
1601, epoch_train_loss=0.0007353931556029184
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.0007353931520887625
1602, epoch_train_loss=0.0007353931520887625
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.0007353931485797298
1603, epoch_train_loss=0.0007353931485797298
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.0007353931450758101
1604, epoch_train_loss=0.0007353931450758101
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 0.0007353931415769933
1605, epoch_train_loss=0.0007353931415769933
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.000735393138083269
1606, epoch_train_loss=0.000735393138083269
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.0007353931345946274
1607, epoch_train_loss=0.0007353931345946274
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.000735393131111058
1608, epoch_train_loss=0.000735393131111058
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 0.0007353931276325508
1609, epoch_train_loss=0.0007353931276325508
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.000735393124159096
1610, epoch_train_loss=0.000735393124159096
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.0007353931206906836
1611, epoch_train_loss=0.0007353931206906836
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.0007353931172273028
1612, epoch_train_loss=0.0007353931172273028
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0007353931137689444
1613, epoch_train_loss=0.0007353931137689444
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 0.0007353931103155981
1614, epoch_train_loss=0.0007353931103155981
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 0.0007353931068672544
1615, epoch_train_loss=0.0007353931068672544
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.0007353931034239029
1616, epoch_train_loss=0.0007353931034239029
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.000735393099985534
1617, epoch_train_loss=0.000735393099985534
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 0.000735393096552138
1618, epoch_train_loss=0.000735393096552138
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 0.0007353930931237047
1619, epoch_train_loss=0.0007353930931237047
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 0.0007353930897002241
1620, epoch_train_loss=0.0007353930897002241
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 0.0007353930862816869
1621, epoch_train_loss=0.0007353930862816869
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 0.0007353930828680828
1622, epoch_train_loss=0.0007353930828680828
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 0.0007353930794594026
1623, epoch_train_loss=0.0007353930794594026
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 0.0007353930760556365
1624, epoch_train_loss=0.0007353930760556365
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 0.0007353930726567746
1625, epoch_train_loss=0.0007353930726567746
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 0.0007353930692628072
1626, epoch_train_loss=0.0007353930692628072
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 0.0007353930658737251
1627, epoch_train_loss=0.0007353930658737251
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 0.0007353930624895182
1628, epoch_train_loss=0.0007353930624895182
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 0.0007353930591101768
1629, epoch_train_loss=0.0007353930591101768
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 0.0007353930557356918
1630, epoch_train_loss=0.0007353930557356918
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 0.0007353930523660534
1631, epoch_train_loss=0.0007353930523660534
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 0.0007353930490012523
1632, epoch_train_loss=0.0007353930490012523
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 0.0007353930456412786
1633, epoch_train_loss=0.0007353930456412786
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 0.0007353930422861232
1634, epoch_train_loss=0.0007353930422861232
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 0.0007353930389357766
1635, epoch_train_loss=0.0007353930389357766
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 0.0007353930355902292
1636, epoch_train_loss=0.0007353930355902292
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 0.0007353930322494717
1637, epoch_train_loss=0.0007353930322494717
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 0.0007353930289134947
1638, epoch_train_loss=0.0007353930289134947
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 0.0007353930255822888
1639, epoch_train_loss=0.0007353930255822888
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 0.0007353930222558446
1640, epoch_train_loss=0.0007353930222558446
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 0.0007353930189341533
1641, epoch_train_loss=0.0007353930189341533
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 0.0007353930156172051
1642, epoch_train_loss=0.0007353930156172051
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 0.0007353930123049907
1643, epoch_train_loss=0.0007353930123049907
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 0.000735393008997501
1644, epoch_train_loss=0.000735393008997501
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 0.000735393005694727
1645, epoch_train_loss=0.000735393005694727
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 0.0007353930023966594
1646, epoch_train_loss=0.0007353930023966594
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 0.0007353929991032887
1647, epoch_train_loss=0.0007353929991032887
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 0.000735392995814606
1648, epoch_train_loss=0.000735392995814606
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 0.000735392992530602
1649, epoch_train_loss=0.000735392992530602
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 0.0007353929892512682
1650, epoch_train_loss=0.0007353929892512682
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 0.0007353929859765946
1651, epoch_train_loss=0.0007353929859765946
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 0.0007353929827065729
1652, epoch_train_loss=0.0007353929827065729
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 0.0007353929794411936
1653, epoch_train_loss=0.0007353929794411936
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 0.0007353929761804481
1654, epoch_train_loss=0.0007353929761804481
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 0.0007353929729243271
1655, epoch_train_loss=0.0007353929729243271
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 0.0007353929696728217
1656, epoch_train_loss=0.0007353929696728217
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 0.000735392966425923
1657, epoch_train_loss=0.000735392966425923
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 0.0007353929631836219
1658, epoch_train_loss=0.0007353929631836219
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 0.00073539295994591
1659, epoch_train_loss=0.00073539295994591
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 0.0007353929567127777
1660, epoch_train_loss=0.0007353929567127777
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 0.0007353929534842167
1661, epoch_train_loss=0.0007353929534842167
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 0.0007353929502602176
1662, epoch_train_loss=0.0007353929502602176
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 0.0007353929470407723
1663, epoch_train_loss=0.0007353929470407723
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 0.0007353929438258717
1664, epoch_train_loss=0.0007353929438258717
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 0.0007353929406155067
1665, epoch_train_loss=0.0007353929406155067
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 0.0007353929374096688
1666, epoch_train_loss=0.0007353929374096688
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 0.0007353929342083495
1667, epoch_train_loss=0.0007353929342083495
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 0.0007353929310115397
1668, epoch_train_loss=0.0007353929310115397
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 0.0007353929278192312
1669, epoch_train_loss=0.0007353929278192312
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 0.0007353929246314148
1670, epoch_train_loss=0.0007353929246314148
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 0.0007353929214480821
1671, epoch_train_loss=0.0007353929214480821
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 0.0007353929182692244
1672, epoch_train_loss=0.0007353929182692244
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 0.0007353929150948333
1673, epoch_train_loss=0.0007353929150948333
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 0.0007353929119249004
1674, epoch_train_loss=0.0007353929119249004
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 0.0007353929087594165
1675, epoch_train_loss=0.0007353929087594165
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.0007353929055983734
1676, epoch_train_loss=0.0007353929055983734
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.0007353929024417626
1677, epoch_train_loss=0.0007353929024417626
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.0007353928992895755
1678, epoch_train_loss=0.0007353928992895755
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.0007353928961418037
1679, epoch_train_loss=0.0007353928961418037
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0007353928929984388
1680, epoch_train_loss=0.0007353928929984388
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.0007353928898594723
1681, epoch_train_loss=0.0007353928898594723
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.0007353928867248958
1682, epoch_train_loss=0.0007353928867248958
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.0007353928835947008
1683, epoch_train_loss=0.0007353928835947008
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.0007353928804688794
1684, epoch_train_loss=0.0007353928804688794
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.0007353928773474225
1685, epoch_train_loss=0.0007353928773474225
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0007353928742303222
1686, epoch_train_loss=0.0007353928742303222
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.0007353928711175702
1687, epoch_train_loss=0.0007353928711175702
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.000735392868009158
1688, epoch_train_loss=0.000735392868009158
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.0007353928649050776
1689, epoch_train_loss=0.0007353928649050776
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.0007353928618053209
1690, epoch_train_loss=0.0007353928618053209
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.000735392858709879
1691, epoch_train_loss=0.000735392858709879
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.000735392855618744
1692, epoch_train_loss=0.000735392855618744
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0007353928525319082
1693, epoch_train_loss=0.0007353928525319082
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.0007353928494493626
1694, epoch_train_loss=0.0007353928494493626
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.0007353928463710996
1695, epoch_train_loss=0.0007353928463710996
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.0007353928432971109
1696, epoch_train_loss=0.0007353928432971109
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.0007353928402273885
1697, epoch_train_loss=0.0007353928402273885
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0007353928371619244
1698, epoch_train_loss=0.0007353928371619244
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.00073539283410071
1699, epoch_train_loss=0.00073539283410071
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.0007353928310437378
1700, epoch_train_loss=0.0007353928310437378
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.0007353928279909994
1701, epoch_train_loss=0.0007353928279909994
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.000735392824942487
1702, epoch_train_loss=0.000735392824942487
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.0007353928218981925
1703, epoch_train_loss=0.0007353928218981925
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.0007353928188581079
1704, epoch_train_loss=0.0007353928188581079
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0007353928158222255
1705, epoch_train_loss=0.0007353928158222255
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.0007353928127905369
1706, epoch_train_loss=0.0007353928127905369
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.0007353928097630347
1707, epoch_train_loss=0.0007353928097630347
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.0007353928067397107
1708, epoch_train_loss=0.0007353928067397107
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.0007353928037205571
1709, epoch_train_loss=0.0007353928037205571
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.0007353928007055662
1710, epoch_train_loss=0.0007353928007055662
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.0007353927976947298
1711, epoch_train_loss=0.0007353927976947298
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.0007353927946880401
1712, epoch_train_loss=0.0007353927946880401
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0007353927916854895
1713, epoch_train_loss=0.0007353927916854895
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.00073539278868707
1714, epoch_train_loss=0.00073539278868707
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.000735392785692774
1715, epoch_train_loss=0.000735392785692774
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.0007353927827025941
1716, epoch_train_loss=0.0007353927827025941
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.000735392779716522
1717, epoch_train_loss=0.000735392779716522
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.00073539277673455
1718, epoch_train_loss=0.00073539277673455
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.0007353927737566707
1719, epoch_train_loss=0.0007353927737566707
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.0007353927707828765
1720, epoch_train_loss=0.0007353927707828765
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.0007353927678131593
1721, epoch_train_loss=0.0007353927678131593
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0007353927648475118
1722, epoch_train_loss=0.0007353927648475118
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.0007353927618859263
1723, epoch_train_loss=0.0007353927618859263
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.0007353927589283951
1724, epoch_train_loss=0.0007353927589283951
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.0007353927559749109
1725, epoch_train_loss=0.0007353927559749109
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0007353927530254661
1726, epoch_train_loss=0.0007353927530254661
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.0007353927500800526
1727, epoch_train_loss=0.0007353927500800526
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.0007353927471386634
1728, epoch_train_loss=0.0007353927471386634
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0007353927442012911
1729, epoch_train_loss=0.0007353927442012911
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0007353927412679275
1730, epoch_train_loss=0.0007353927412679275
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.0007353927383385658
1731, epoch_train_loss=0.0007353927383385658
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.0007353927354131984
1732, epoch_train_loss=0.0007353927354131984
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.0007353927324918176
1733, epoch_train_loss=0.0007353927324918176
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.0007353927295744164
1734, epoch_train_loss=0.0007353927295744164
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.0007353927266609871
1735, epoch_train_loss=0.0007353927266609871
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.0007353927237515221
1736, epoch_train_loss=0.0007353927237515221
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.0007353927208460142
1737, epoch_train_loss=0.0007353927208460142
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.0007353927179444565
1738, epoch_train_loss=0.0007353927179444565
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.000735392715046841
1739, epoch_train_loss=0.000735392715046841
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.000735392712153161
1740, epoch_train_loss=0.000735392712153161
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 0.0007353927092634085
1741, epoch_train_loss=0.0007353927092634085
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.0007353927063775768
1742, epoch_train_loss=0.0007353927063775768
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.0007353927034956584
1743, epoch_train_loss=0.0007353927034956584
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.0007353927006176461
1744, epoch_train_loss=0.0007353927006176461
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0007353926977435324
1745, epoch_train_loss=0.0007353926977435324
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 0.0007353926948733107
1746, epoch_train_loss=0.0007353926948733107
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 0.0007353926920069733
1747, epoch_train_loss=0.0007353926920069733
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0007353926891445129
1748, epoch_train_loss=0.0007353926891445129
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.0007353926862859226
1749, epoch_train_loss=0.0007353926862859226
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.0007353926834311954
1750, epoch_train_loss=0.0007353926834311954
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 0.0007353926805803239
1751, epoch_train_loss=0.0007353926805803239
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 0.0007353926777333012
1752, epoch_train_loss=0.0007353926777333012
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.0007353926748901202
1753, epoch_train_loss=0.0007353926748901202
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.0007353926720507734
1754, epoch_train_loss=0.0007353926720507734
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 0.000735392669215254
1755, epoch_train_loss=0.000735392669215254
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 0.0007353926663835552
1756, epoch_train_loss=0.0007353926663835552
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 0.0007353926635556696
1757, epoch_train_loss=0.0007353926635556696
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 0.0007353926607315903
1758, epoch_train_loss=0.0007353926607315903
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 0.0007353926579113105
1759, epoch_train_loss=0.0007353926579113105
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 0.000735392655094823
1760, epoch_train_loss=0.000735392655094823
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 0.000735392652282121
1761, epoch_train_loss=0.000735392652282121
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 0.0007353926494731973
1762, epoch_train_loss=0.0007353926494731973
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 0.0007353926466680453
1763, epoch_train_loss=0.0007353926466680453
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 0.0007353926438666577
1764, epoch_train_loss=0.0007353926438666577
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 0.0007353926410690281
1765, epoch_train_loss=0.0007353926410690281
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 0.0007353926382751492
1766, epoch_train_loss=0.0007353926382751492
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 0.0007353926354850142
1767, epoch_train_loss=0.0007353926354850142
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 0.0007353926326986162
1768, epoch_train_loss=0.0007353926326986162
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 0.0007353926299159485
1769, epoch_train_loss=0.0007353926299159485
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 0.0007353926271370042
1770, epoch_train_loss=0.0007353926271370042
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 0.0007353926243617764
1771, epoch_train_loss=0.0007353926243617764
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 0.0007353926215902587
1772, epoch_train_loss=0.0007353926215902587
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 0.0007353926188224439
1773, epoch_train_loss=0.0007353926188224439
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 0.0007353926160583253
1774, epoch_train_loss=0.0007353926160583253
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 0.0007353926132978965
1775, epoch_train_loss=0.0007353926132978965
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 0.0007353926105411504
1776, epoch_train_loss=0.0007353926105411504
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 0.0007353926077880805
1777, epoch_train_loss=0.0007353926077880805
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 0.00073539260503868
1778, epoch_train_loss=0.00073539260503868
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 0.0007353926022929424
1779, epoch_train_loss=0.0007353926022929424
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 0.0007353925995508607
1780, epoch_train_loss=0.0007353925995508607
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 0.0007353925968124288
1781, epoch_train_loss=0.0007353925968124288
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 0.0007353925940776393
1782, epoch_train_loss=0.0007353925940776393
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 0.000735392591346486
1783, epoch_train_loss=0.000735392591346486
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 0.0007353925886189625
1784, epoch_train_loss=0.0007353925886189625
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 0.0007353925858950618
1785, epoch_train_loss=0.0007353925858950618
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 0.0007353925831747775
1786, epoch_train_loss=0.0007353925831747775
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 0.0007353925804581032
1787, epoch_train_loss=0.0007353925804581032
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.000735392577745032
1788, epoch_train_loss=0.000735392577745032
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.000735392575035558
1789, epoch_train_loss=0.000735392575035558
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0007353925723296739
1790, epoch_train_loss=0.0007353925723296739
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0007353925696273738
1791, epoch_train_loss=0.0007353925696273738
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0007353925669286509
1792, epoch_train_loss=0.0007353925669286509
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.0007353925642334991
1793, epoch_train_loss=0.0007353925642334991
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.0007353925615419116
1794, epoch_train_loss=0.0007353925615419116
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.0007353925588538819
1795, epoch_train_loss=0.0007353925588538819
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.0007353925561694038
1796, epoch_train_loss=0.0007353925561694038
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.0007353925534884708
1797, epoch_train_loss=0.0007353925534884708
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.0007353925508110764
1798, epoch_train_loss=0.0007353925508110764
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.0007353925481372146
1799, epoch_train_loss=0.0007353925481372146
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.0007353925454668789
1800, epoch_train_loss=0.0007353925454668789
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.0007353925428000626
1801, epoch_train_loss=0.0007353925428000626
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.0007353925401367598
1802, epoch_train_loss=0.0007353925401367598
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.0007353925374769638
1803, epoch_train_loss=0.0007353925374769638
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.0007353925348206684
1804, epoch_train_loss=0.0007353925348206684
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.0007353925321678677
1805, epoch_train_loss=0.0007353925321678677
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.0007353925295185552
1806, epoch_train_loss=0.0007353925295185552
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.0007353925268727245
1807, epoch_train_loss=0.0007353925268727245
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0007353925242303694
1808, epoch_train_loss=0.0007353925242303694
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.0007353925215914835
1809, epoch_train_loss=0.0007353925215914835
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.0007353925189560609
1810, epoch_train_loss=0.0007353925189560609
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.0007353925163240951
1811, epoch_train_loss=0.0007353925163240951
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.0007353925136955802
1812, epoch_train_loss=0.0007353925136955802
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.0007353925110705099
1813, epoch_train_loss=0.0007353925110705099
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.0007353925084488779
1814, epoch_train_loss=0.0007353925084488779
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.0007353925058306784
1815, epoch_train_loss=0.0007353925058306784
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.0007353925032159051
1816, epoch_train_loss=0.0007353925032159051
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.0007353925006045517
1817, epoch_train_loss=0.0007353925006045517
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0007353924979966121
1818, epoch_train_loss=0.0007353924979966121
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0007353924953920805
1819, epoch_train_loss=0.0007353924953920805
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0007353924927909507
1820, epoch_train_loss=0.0007353924927909507
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0007353924901932164
1821, epoch_train_loss=0.0007353924901932164
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0007353924875988718
1822, epoch_train_loss=0.0007353924875988718
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.0007353924850079108
1823, epoch_train_loss=0.0007353924850079108
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.0007353924824203275
1824, epoch_train_loss=0.0007353924824203275
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0007353924798361155
1825, epoch_train_loss=0.0007353924798361155
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.0007353924772552695
1826, epoch_train_loss=0.0007353924772552695
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.0007353924746777827
1827, epoch_train_loss=0.0007353924746777827
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.0007353924721036497
1828, epoch_train_loss=0.0007353924721036497
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007353924695328643
1829, epoch_train_loss=0.0007353924695328643
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.0007353924669654208
1830, epoch_train_loss=0.0007353924669654208
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0007353924644013128
1831, epoch_train_loss=0.0007353924644013128
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.000735392461840535
1832, epoch_train_loss=0.000735392461840535
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.000735392459283081
1833, epoch_train_loss=0.000735392459283081
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0007353924567289451
1834, epoch_train_loss=0.0007353924567289451
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.0007353924541781215
1835, epoch_train_loss=0.0007353924541781215
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.0007353924516306042
1836, epoch_train_loss=0.0007353924516306042
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.0007353924490863873
1837, epoch_train_loss=0.0007353924490863873
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.0007353924465454652
1838, epoch_train_loss=0.0007353924465454652
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0007353924440078317
1839, epoch_train_loss=0.0007353924440078317
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.0007353924414734814
1840, epoch_train_loss=0.0007353924414734814
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0007353924389424085
1841, epoch_train_loss=0.0007353924389424085
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.000735392436414607
1842, epoch_train_loss=0.000735392436414607
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.0007353924338900712
1843, epoch_train_loss=0.0007353924338900712
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.0007353924313687954
1844, epoch_train_loss=0.0007353924313687954
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.0007353924288507737
1845, epoch_train_loss=0.0007353924288507737
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.0007353924263360002
1846, epoch_train_loss=0.0007353924263360002
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 0.0007353924238244695
1847, epoch_train_loss=0.0007353924238244695
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.0007353924213161759
1848, epoch_train_loss=0.0007353924213161759
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.0007353924188111138
1849, epoch_train_loss=0.0007353924188111138
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.0007353924163092775
1850, epoch_train_loss=0.0007353924163092775
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.0007353924138106609
1851, epoch_train_loss=0.0007353924138106609
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 0.0007353924113152586
1852, epoch_train_loss=0.0007353924113152586
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.0007353924088230652
1853, epoch_train_loss=0.0007353924088230652
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.0007353924063340749
1854, epoch_train_loss=0.0007353924063340749
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.0007353924038482817
1855, epoch_train_loss=0.0007353924038482817
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.0007353924013656805
1856, epoch_train_loss=0.0007353924013656805
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 0.0007353923988862656
1857, epoch_train_loss=0.0007353923988862656
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 0.0007353923964100313
1858, epoch_train_loss=0.0007353923964100313
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.0007353923939369723
1859, epoch_train_loss=0.0007353923939369723
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.0007353923914670825
1860, epoch_train_loss=0.0007353923914670825
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.0007353923890003572
1861, epoch_train_loss=0.0007353923890003572
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 0.0007353923865367901
1862, epoch_train_loss=0.0007353923865367901
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 0.0007353923840763759
1863, epoch_train_loss=0.0007353923840763759
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 0.0007353923816191092
1864, epoch_train_loss=0.0007353923816191092
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 0.0007353923791649845
1865, epoch_train_loss=0.0007353923791649845
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 0.0007353923767139963
1866, epoch_train_loss=0.0007353923767139963
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 0.0007353923742661391
1867, epoch_train_loss=0.0007353923742661391
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 0.0007353923718214076
1868, epoch_train_loss=0.0007353923718214076
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 0.0007353923693797959
1869, epoch_train_loss=0.0007353923693797959
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 0.0007353923669412996
1870, epoch_train_loss=0.0007353923669412996
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 0.0007353923645059119
1871, epoch_train_loss=0.0007353923645059119
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 0.0007353923620736282
1872, epoch_train_loss=0.0007353923620736282
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 0.0007353923596444431
1873, epoch_train_loss=0.0007353923596444431
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 0.0007353923572183509
1874, epoch_train_loss=0.0007353923572183509
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 0.0007353923547953465
1875, epoch_train_loss=0.0007353923547953465
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 0.0007353923523754245
1876, epoch_train_loss=0.0007353923523754245
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 0.0007353923499585792
1877, epoch_train_loss=0.0007353923499585792
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 0.0007353923475448058
1878, epoch_train_loss=0.0007353923475448058
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 0.0007353923451340987
1879, epoch_train_loss=0.0007353923451340987
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 0.0007353923427264528
1880, epoch_train_loss=0.0007353923427264528
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 0.0007353923403218625
1881, epoch_train_loss=0.0007353923403218625
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 0.0007353923379203226
1882, epoch_train_loss=0.0007353923379203226
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 0.0007353923355218278
1883, epoch_train_loss=0.0007353923355218278
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 0.0007353923331263731
1884, epoch_train_loss=0.0007353923331263731
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 0.000735392330733953
1885, epoch_train_loss=0.000735392330733953
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 0.0007353923283445621
1886, epoch_train_loss=0.0007353923283445621
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 0.0007353923259581954
1887, epoch_train_loss=0.0007353923259581954
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 0.000735392323574848
1888, epoch_train_loss=0.000735392323574848
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 0.0007353923211945139
1889, epoch_train_loss=0.0007353923211945139
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 0.0007353923188171884
1890, epoch_train_loss=0.0007353923188171884
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 0.0007353923164428666
1891, epoch_train_loss=0.0007353923164428666
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 0.0007353923140715427
1892, epoch_train_loss=0.0007353923140715427
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 0.0007353923117032118
1893, epoch_train_loss=0.0007353923117032118
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 0.0007353923093378688
1894, epoch_train_loss=0.0007353923093378688
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 0.0007353923069755087
1895, epoch_train_loss=0.0007353923069755087
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 0.0007353923046161259
1896, epoch_train_loss=0.0007353923046161259
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 0.0007353923022597159
1897, epoch_train_loss=0.0007353923022597159
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 0.0007353922999062731
1898, epoch_train_loss=0.0007353922999062731
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 0.0007353922975557924
1899, epoch_train_loss=0.0007353922975557924
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 0.0007353922952082691
1900, epoch_train_loss=0.0007353922952082691
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 0.000735392292863698
1901, epoch_train_loss=0.000735392292863698
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 0.0007353922905220739
1902, epoch_train_loss=0.0007353922905220739
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 0.0007353922881833917
1903, epoch_train_loss=0.0007353922881833917
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 0.0007353922858476465
1904, epoch_train_loss=0.0007353922858476465
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 0.0007353922835148333
1905, epoch_train_loss=0.0007353922835148333
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 0.0007353922811849471
1906, epoch_train_loss=0.0007353922811849471
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 0.0007353922788579829
1907, epoch_train_loss=0.0007353922788579829
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 0.0007353922765339354
1908, epoch_train_loss=0.0007353922765339354
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 0.0007353922742127999
1909, epoch_train_loss=0.0007353922742127999
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.0007353922718945715
1910, epoch_train_loss=0.0007353922718945715
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.0007353922695792449
1911, epoch_train_loss=0.0007353922695792449
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.0007353922672668153
1912, epoch_train_loss=0.0007353922672668153
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.0007353922649572781
1913, epoch_train_loss=0.0007353922649572781
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0007353922626506278
1914, epoch_train_loss=0.0007353922626506278
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0007353922603468599
1915, epoch_train_loss=0.0007353922603468599
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.0007353922580459693
1916, epoch_train_loss=0.0007353922580459693
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.0007353922557479512
1917, epoch_train_loss=0.0007353922557479512
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.0007353922534528005
1918, epoch_train_loss=0.0007353922534528005
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.0007353922511605125
1919, epoch_train_loss=0.0007353922511605125
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.0007353922488710826
1920, epoch_train_loss=0.0007353922488710826
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.0007353922465845055
1921, epoch_train_loss=0.0007353922465845055
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.0007353922443007765
1922, epoch_train_loss=0.0007353922443007765
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.0007353922420198905
1923, epoch_train_loss=0.0007353922420198905
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.0007353922397418432
1924, epoch_train_loss=0.0007353922397418432
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.0007353922374666293
1925, epoch_train_loss=0.0007353922374666293
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.0007353922351942445
1926, epoch_train_loss=0.0007353922351942445
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.0007353922329246838
1927, epoch_train_loss=0.0007353922329246838
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.0007353922306579423
1928, epoch_train_loss=0.0007353922306579423
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.0007353922283940154
1929, epoch_train_loss=0.0007353922283940154
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.000735392226132898
1930, epoch_train_loss=0.000735392226132898
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.0007353922238745855
1931, epoch_train_loss=0.0007353922238745855
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.0007353922216190733
1932, epoch_train_loss=0.0007353922216190733
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.0007353922193663566
1933, epoch_train_loss=0.0007353922193663566
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.0007353922171164308
1934, epoch_train_loss=0.0007353922171164308
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.0007353922148692908
1935, epoch_train_loss=0.0007353922148692908
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0007353922126249324
1936, epoch_train_loss=0.0007353922126249324
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0007353922103833507
1937, epoch_train_loss=0.0007353922103833507
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0007353922081445409
1938, epoch_train_loss=0.0007353922081445409
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.0007353922059084982
1939, epoch_train_loss=0.0007353922059084982
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.0007353922036752185
1940, epoch_train_loss=0.0007353922036752185
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0007353922014446967
1941, epoch_train_loss=0.0007353922014446967
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.0007353921992169283
1942, epoch_train_loss=0.0007353921992169283
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0007353921969919085
1943, epoch_train_loss=0.0007353921969919085
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.0007353921947696329
1944, epoch_train_loss=0.0007353921947696329
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.0007353921925500968
1945, epoch_train_loss=0.0007353921925500968
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.0007353921903332955
1946, epoch_train_loss=0.0007353921903332955
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0007353921881192246
1947, epoch_train_loss=0.0007353921881192246
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0007353921859078794
1948, epoch_train_loss=0.0007353921859078794
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0007353921836992554
1949, epoch_train_loss=0.0007353921836992554
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.0007353921814933478
1950, epoch_train_loss=0.0007353921814933478
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007353921792901525
1951, epoch_train_loss=0.0007353921792901525
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.0007353921770896645
1952, epoch_train_loss=0.0007353921770896645
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0007353921748918796
1953, epoch_train_loss=0.0007353921748918796
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0007353921726967932
1954, epoch_train_loss=0.0007353921726967932
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.0007353921705044005
1955, epoch_train_loss=0.0007353921705044005
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007353921683146973
1956, epoch_train_loss=0.0007353921683146973
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007353921661276792
1957, epoch_train_loss=0.0007353921661276792
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.0007353921639433414
1958, epoch_train_loss=0.0007353921639433414
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.0007353921617616794
1959, epoch_train_loss=0.0007353921617616794
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.000735392159582689
1960, epoch_train_loss=0.000735392159582689
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0007353921574063658
1961, epoch_train_loss=0.0007353921574063658
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0007353921552327051
1962, epoch_train_loss=0.0007353921552327051
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.0007353921530617025
1963, epoch_train_loss=0.0007353921530617025
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.0007353921508933537
1964, epoch_train_loss=0.0007353921508933537
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.0007353921487276543
1965, epoch_train_loss=0.0007353921487276543
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.0007353921465645997
1966, epoch_train_loss=0.0007353921465645997
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0007353921444041858
1967, epoch_train_loss=0.0007353921444041858
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.0007353921422464078
1968, epoch_train_loss=0.0007353921422464078
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 0.0007353921400912615
1969, epoch_train_loss=0.0007353921400912615
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.0007353921379387426
1970, epoch_train_loss=0.0007353921379387426
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0007353921357888466
1971, epoch_train_loss=0.0007353921357888466
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.0007353921336415696
1972, epoch_train_loss=0.0007353921336415696
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.0007353921314969066
1973, epoch_train_loss=0.0007353921314969066
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 0.0007353921293548538
1974, epoch_train_loss=0.0007353921293548538
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.0007353921272154066
1975, epoch_train_loss=0.0007353921272154066
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.0007353921250785605
1976, epoch_train_loss=0.0007353921250785605
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0007353921229443114
1977, epoch_train_loss=0.0007353921229443114
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.0007353921208126551
1978, epoch_train_loss=0.0007353921208126551
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 0.0007353921186835874
1979, epoch_train_loss=0.0007353921186835874
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 0.0007353921165571039
1980, epoch_train_loss=0.0007353921165571039
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.0007353921144332001
1981, epoch_train_loss=0.0007353921144332001
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.0007353921123118721
1982, epoch_train_loss=0.0007353921123118721
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.0007353921101931152
1983, epoch_train_loss=0.0007353921101931152
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 0.0007353921080769256
1984, epoch_train_loss=0.0007353921080769256
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 0.0007353921059632989
1985, epoch_train_loss=0.0007353921059632989
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 0.0007353921038522308
1986, epoch_train_loss=0.0007353921038522308
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.0007353921017437172
1987, epoch_train_loss=0.0007353921017437172
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 0.0007353920996377536
1988, epoch_train_loss=0.0007353920996377536
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 0.0007353920975343364
1989, epoch_train_loss=0.0007353920975343364
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 0.0007353920954334607
1990, epoch_train_loss=0.0007353920954334607
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 0.0007353920933351229
1991, epoch_train_loss=0.0007353920933351229
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 0.0007353920912393184
1992, epoch_train_loss=0.0007353920912393184
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 0.0007353920891460433
1993, epoch_train_loss=0.0007353920891460433
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 0.0007353920870552934
1994, epoch_train_loss=0.0007353920870552934
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 0.0007353920849670643
1995, epoch_train_loss=0.0007353920849670643
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 0.0007353920828813525
1996, epoch_train_loss=0.0007353920828813525
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 0.0007353920807981533
1997, epoch_train_loss=0.0007353920807981533
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 0.0007353920787174625
1998, epoch_train_loss=0.0007353920787174625
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 0.0007353920766392763
1999, epoch_train_loss=0.0007353920766392763
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 0.0007353920745635906
2000, epoch_train_loss=0.0007353920745635906
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 0.0007353920724904012
2001, epoch_train_loss=0.0007353920724904012
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 0.0007353920704197039
2002, epoch_train_loss=0.0007353920704197039
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 0.000735392068351495
2003, epoch_train_loss=0.000735392068351495
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 0.0007353920662857701
2004, epoch_train_loss=0.0007353920662857701
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.000735392064222525
2005, epoch_train_loss=0.000735392064222525
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.0007353920621617561
2006, epoch_train_loss=0.0007353920621617561
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.0007353920601034591
2007, epoch_train_loss=0.0007353920601034591
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.0007353920580476298
2008, epoch_train_loss=0.0007353920580476298
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0007353920559942646
2009, epoch_train_loss=0.0007353920559942646
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007353920539433591
2010, epoch_train_loss=0.0007353920539433591
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0007353920518949096
2011, epoch_train_loss=0.0007353920518949096
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0007353920498489118
2012, epoch_train_loss=0.0007353920498489118
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.0007353920478053617
2013, epoch_train_loss=0.0007353920478053617
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.0007353920457642556
2014, epoch_train_loss=0.0007353920457642556
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.0007353920437255894
2015, epoch_train_loss=0.0007353920437255894
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.0007353920416893589
2016, epoch_train_loss=0.0007353920416893589
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.0007353920396555604
2017, epoch_train_loss=0.0007353920396555604
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.0007353920376241901
2018, epoch_train_loss=0.0007353920376241901
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.0007353920355952436
2019, epoch_train_loss=0.0007353920355952436
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.0007353920335687173
2020, epoch_train_loss=0.0007353920335687173
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.0007353920315446072
2021, epoch_train_loss=0.0007353920315446072
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0007353920295229093
2022, epoch_train_loss=0.0007353920295229093
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.0007353920275036199
2023, epoch_train_loss=0.0007353920275036199
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.0007353920254867348
2024, epoch_train_loss=0.0007353920254867348
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.0007353920234722503
2025, epoch_train_loss=0.0007353920234722503
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.0007353920214601624
2026, epoch_train_loss=0.0007353920214601624
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.0007353920194504675
2027, epoch_train_loss=0.0007353920194504675
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.0007353920174431613
2028, epoch_train_loss=0.0007353920174431613
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.0007353920154382402
2029, epoch_train_loss=0.0007353920154382402
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.0007353920134357001
2030, epoch_train_loss=0.0007353920134357001
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.0007353920114355375
2031, epoch_train_loss=0.0007353920114355375
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0007353920094377484
2032, epoch_train_loss=0.0007353920094377484
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0007353920074423288
2033, epoch_train_loss=0.0007353920074423288
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0007353920054492753
2034, epoch_train_loss=0.0007353920054492753
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.0007353920034585838
2035, epoch_train_loss=0.0007353920034585838
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0007353920014702503
2036, epoch_train_loss=0.0007353920014702503
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0007353919994842713
2037, epoch_train_loss=0.0007353919994842713
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.0007353919975006431
2038, epoch_train_loss=0.0007353919975006431
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.0007353919955193615
2039, epoch_train_loss=0.0007353919955193615
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0007353919935404232
2040, epoch_train_loss=0.0007353919935404232
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.000735391991563824
2041, epoch_train_loss=0.000735391991563824
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.0007353919895895603
2042, epoch_train_loss=0.0007353919895895603
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.0007353919876176285
2043, epoch_train_loss=0.0007353919876176285
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.0007353919856480247
2044, epoch_train_loss=0.0007353919856480247
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.0007353919836807452
2045, epoch_train_loss=0.0007353919836807452
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007353919817157862
2046, epoch_train_loss=0.0007353919817157862
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.000735391979753144
2047, epoch_train_loss=0.000735391979753144
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.0007353919777928151
2048, epoch_train_loss=0.0007353919777928151
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.0007353919758347955
2049, epoch_train_loss=0.0007353919758347955
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.0007353919738790816
2050, epoch_train_loss=0.0007353919738790816
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.0007353919719256699
2051, epoch_train_loss=0.0007353919719256699
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0007353919699745564
2052, epoch_train_loss=0.0007353919699745564
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0007353919680257375
2053, epoch_train_loss=0.0007353919680257375
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.0007353919660792097
2054, epoch_train_loss=0.0007353919660792097
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.0007353919641349692
2055, epoch_train_loss=0.0007353919641349692
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0007353919621930123
2056, epoch_train_loss=0.0007353919621930123
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.0007353919602533356
2057, epoch_train_loss=0.0007353919602533356
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.000735391958315935
2058, epoch_train_loss=0.000735391958315935
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.0007353919563808074
2059, epoch_train_loss=0.0007353919563808074
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.0007353919544479486
2060, epoch_train_loss=0.0007353919544479486
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 0.0007353919525173556
2061, epoch_train_loss=0.0007353919525173556
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.0007353919505890244
2062, epoch_train_loss=0.0007353919505890244
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0007353919486629513
2063, epoch_train_loss=0.0007353919486629513
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.0007353919467391332
2064, epoch_train_loss=0.0007353919467391332
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.0007353919448175662
2065, epoch_train_loss=0.0007353919448175662
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 0.0007353919428982465
2066, epoch_train_loss=0.0007353919428982465
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 0.0007353919409811709
2067, epoch_train_loss=0.0007353919409811709
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.0007353919390663356
2068, epoch_train_loss=0.0007353919390663356
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0007353919371537369
2069, epoch_train_loss=0.0007353919371537369
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0007353919352433717
2070, epoch_train_loss=0.0007353919352433717
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.0007353919333352364
2071, epoch_train_loss=0.0007353919333352364
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 0.0007353919314293271
2072, epoch_train_loss=0.0007353919314293271
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 0.0007353919295256403
2073, epoch_train_loss=0.0007353919295256403
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 0.000735391927624173
2074, epoch_train_loss=0.000735391927624173
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.000735391925724921
2075, epoch_train_loss=0.000735391925724921
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.0007353919238278811
2076, epoch_train_loss=0.0007353919238278811
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 0.0007353919219330499
2077, epoch_train_loss=0.0007353919219330499
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 0.0007353919200404237
2078, epoch_train_loss=0.0007353919200404237
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 0.0007353919181499993
2079, epoch_train_loss=0.0007353919181499993
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 0.0007353919162617729
2080, epoch_train_loss=0.0007353919162617729
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 0.0007353919143757411
2081, epoch_train_loss=0.0007353919143757411
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 0.0007353919124919007
2082, epoch_train_loss=0.0007353919124919007
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 0.0007353919106102479
2083, epoch_train_loss=0.0007353919106102479
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 0.0007353919087307794
2084, epoch_train_loss=0.0007353919087307794
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 0.0007353919068534914
2085, epoch_train_loss=0.0007353919068534914
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 0.0007353919049783811
2086, epoch_train_loss=0.0007353919049783811
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 0.000735391903105445
2087, epoch_train_loss=0.000735391903105445
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 0.0007353919012346791
2088, epoch_train_loss=0.0007353919012346791
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 0.0007353918993660805
2089, epoch_train_loss=0.0007353918993660805
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 0.0007353918974996453
2090, epoch_train_loss=0.0007353918974996453
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 0.0007353918956353706
2091, epoch_train_loss=0.0007353918956353706
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 0.0007353918937732528
2092, epoch_train_loss=0.0007353918937732528
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 0.0007353918919132885
2093, epoch_train_loss=0.0007353918919132885
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 0.0007353918900554742
2094, epoch_train_loss=0.0007353918900554742
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 0.0007353918881998067
2095, epoch_train_loss=0.0007353918881998067
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 0.0007353918863462826
2096, epoch_train_loss=0.0007353918863462826
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 0.0007353918844948986
2097, epoch_train_loss=0.0007353918844948986
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 0.0007353918826456512
2098, epoch_train_loss=0.0007353918826456512
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 0.0007353918807985371
2099, epoch_train_loss=0.0007353918807985371
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 0.000735391878953553
2100, epoch_train_loss=0.000735391878953553
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 0.0007353918771106953
2101, epoch_train_loss=0.0007353918771106953
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 0.0007353918752699612
2102, epoch_train_loss=0.0007353918752699612
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 0.0007353918734313468
2103, epoch_train_loss=0.0007353918734313468
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 0.0007353918715948492
2104, epoch_train_loss=0.0007353918715948492
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 0.0007353918697604648
2105, epoch_train_loss=0.0007353918697604648
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 0.0007353918679281908
2106, epoch_train_loss=0.0007353918679281908
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 0.000735391866098023
2107, epoch_train_loss=0.000735391866098023
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 0.0007353918642699588
2108, epoch_train_loss=0.0007353918642699588
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 0.0007353918624439951
2109, epoch_train_loss=0.0007353918624439951
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 0.000735391860620128
2110, epoch_train_loss=0.000735391860620128
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 0.0007353918587983544
2111, epoch_train_loss=0.0007353918587983544
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 0.0007353918569786712
2112, epoch_train_loss=0.0007353918569786712
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 0.0007353918551610749
2113, epoch_train_loss=0.0007353918551610749
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 0.0007353918533455626
2114, epoch_train_loss=0.0007353918533455626
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 0.0007353918515321309
2115, epoch_train_loss=0.0007353918515321309
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 0.0007353918497207765
2116, epoch_train_loss=0.0007353918497207765
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 0.0007353918479114965
2117, epoch_train_loss=0.0007353918479114965
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 0.000735391846104287
2118, epoch_train_loss=0.000735391846104287
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 0.0007353918442991453
2119, epoch_train_loss=0.0007353918442991453
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 0.0007353918424960679
2120, epoch_train_loss=0.0007353918424960679
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 0.0007353918406950518
2121, epoch_train_loss=0.0007353918406950518
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 0.0007353918388960939
2122, epoch_train_loss=0.0007353918388960939
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 0.0007353918370991908
2123, epoch_train_loss=0.0007353918370991908
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 0.0007353918353043391
2124, epoch_train_loss=0.0007353918353043391
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 0.0007353918335115363
2125, epoch_train_loss=0.0007353918335115363
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 0.0007353918317207785
2126, epoch_train_loss=0.0007353918317207785
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 0.0007353918299320631
2127, epoch_train_loss=0.0007353918299320631
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 0.0007353918281453864
2128, epoch_train_loss=0.0007353918281453864
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 0.0007353918263607457
2129, epoch_train_loss=0.0007353918263607457
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 0.0007353918245781377
2130, epoch_train_loss=0.0007353918245781377
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 0.000735391822797559
2131, epoch_train_loss=0.000735391822797559
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 0.0007353918210190069
2132, epoch_train_loss=0.0007353918210190069
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 0.0007353918192424778
2133, epoch_train_loss=0.0007353918192424778
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 0.0007353918174679691
2134, epoch_train_loss=0.0007353918174679691
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 0.0007353918156954774
2135, epoch_train_loss=0.0007353918156954774
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 0.0007353918139249997
2136, epoch_train_loss=0.0007353918139249997
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.0007353918121565324
2137, epoch_train_loss=0.0007353918121565324
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.0007353918103900733
2138, epoch_train_loss=0.0007353918103900733
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0007353918086256185
2139, epoch_train_loss=0.0007353918086256185
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0007353918068631652
2140, epoch_train_loss=0.0007353918068631652
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0007353918051027104
2141, epoch_train_loss=0.0007353918051027104
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0007353918033442506
2142, epoch_train_loss=0.0007353918033442506
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.0007353918015877833
2143, epoch_train_loss=0.0007353918015877833
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0007353917998333051
2144, epoch_train_loss=0.0007353917998333051
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0007353917980808133
2145, epoch_train_loss=0.0007353917980808133
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.0007353917963303045
2146, epoch_train_loss=0.0007353917963303045
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.0007353917945817758
2147, epoch_train_loss=0.0007353917945817758
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.0007353917928352239
2148, epoch_train_loss=0.0007353917928352239
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.0007353917910906461
2149, epoch_train_loss=0.0007353917910906461
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.0007353917893480391
2150, epoch_train_loss=0.0007353917893480391
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.0007353917876074002
2151, epoch_train_loss=0.0007353917876074002
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.0007353917858687263
2152, epoch_train_loss=0.0007353917858687263
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.000735391784132014
2153, epoch_train_loss=0.000735391784132014
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0007353917823972606
2154, epoch_train_loss=0.0007353917823972606
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.0007353917806644631
2155, epoch_train_loss=0.0007353917806644631
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.0007353917789336187
2156, epoch_train_loss=0.0007353917789336187
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.000735391777204724
2157, epoch_train_loss=0.000735391777204724
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0007353917754777765
2158, epoch_train_loss=0.0007353917754777765
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0007353917737527729
2159, epoch_train_loss=0.0007353917737527729
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.00073539177202971
2160, epoch_train_loss=0.00073539177202971
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.0007353917703085852
2161, epoch_train_loss=0.0007353917703085852
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0007353917685893955
2162, epoch_train_loss=0.0007353917685893955
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.000735391766872138
2163, epoch_train_loss=0.000735391766872138
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.0007353917651568096
2164, epoch_train_loss=0.0007353917651568096
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.0007353917634434073
2165, epoch_train_loss=0.0007353917634434073
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.0007353917617319285
2166, epoch_train_loss=0.0007353917617319285
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.0007353917600223699
2167, epoch_train_loss=0.0007353917600223699
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0007353917583147288
2168, epoch_train_loss=0.0007353917583147288
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0007353917566090021
2169, epoch_train_loss=0.0007353917566090021
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.000735391754905187
2170, epoch_train_loss=0.000735391754905187
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.0007353917532032807
2171, epoch_train_loss=0.0007353917532032807
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.0007353917515032803
2172, epoch_train_loss=0.0007353917515032803
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.0007353917498051823
2173, epoch_train_loss=0.0007353917498051823
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0007353917481089848
2174, epoch_train_loss=0.0007353917481089848
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.0007353917464146842
2175, epoch_train_loss=0.0007353917464146842
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0007353917447222777
2176, epoch_train_loss=0.0007353917447222777
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.0007353917430317629
2177, epoch_train_loss=0.0007353917430317629
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.0007353917413431365
2178, epoch_train_loss=0.0007353917413431365
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.0007353917396563955
2179, epoch_train_loss=0.0007353917396563955
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.0007353917379715376
2180, epoch_train_loss=0.0007353917379715376
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.0007353917362885594
2181, epoch_train_loss=0.0007353917362885594
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.0007353917346074583
2182, epoch_train_loss=0.0007353917346074583
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007353917329282313
2183, epoch_train_loss=0.0007353917329282313
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007353917312508759
2184, epoch_train_loss=0.0007353917312508759
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.0007353917295753891
2185, epoch_train_loss=0.0007353917295753891
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.000735391727901768
2186, epoch_train_loss=0.000735391727901768
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0007353917262300097
2187, epoch_train_loss=0.0007353917262300097
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0007353917245601116
2188, epoch_train_loss=0.0007353917245601116
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0007353917228920709
2189, epoch_train_loss=0.0007353917228920709
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0007353917212258847
2190, epoch_train_loss=0.0007353917212258847
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0007353917195615502
2191, epoch_train_loss=0.0007353917195615502
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.0007353917178990646
2192, epoch_train_loss=0.0007353917178990646
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.000735391716238425
2193, epoch_train_loss=0.000735391716238425
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.0007353917145796289
2194, epoch_train_loss=0.0007353917145796289
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.0007353917129226734
2195, epoch_train_loss=0.0007353917129226734
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.0007353917112675557
2196, epoch_train_loss=0.0007353917112675557
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0007353917096142729
2197, epoch_train_loss=0.0007353917096142729
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.0007353917079628223
2198, epoch_train_loss=0.0007353917079628223
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.0007353917063132016
2199, epoch_train_loss=0.0007353917063132016
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.0007353917046654072
2200, epoch_train_loss=0.0007353917046654072
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.0007353917030194373
2201, epoch_train_loss=0.0007353917030194373
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.0007353917013752885
2202, epoch_train_loss=0.0007353917013752885
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.0007353916997329582
2203, epoch_train_loss=0.0007353916997329582
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0007353916980924438
2204, epoch_train_loss=0.0007353916980924438
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.0007353916964537424
2205, epoch_train_loss=0.0007353916964537424
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.0007353916948168517
2206, epoch_train_loss=0.0007353916948168517
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.0007353916931817682
2207, epoch_train_loss=0.0007353916931817682
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0007353916915484902
2208, epoch_train_loss=0.0007353916915484902
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.0007353916899170139
2209, epoch_train_loss=0.0007353916899170139
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.0007353916882873376
2210, epoch_train_loss=0.0007353916882873376
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0007353916866594582
2211, epoch_train_loss=0.0007353916866594582
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.0007353916850333729
2212, epoch_train_loss=0.0007353916850333729
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.0007353916834090791
2213, epoch_train_loss=0.0007353916834090791
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0007353916817865742
2214, epoch_train_loss=0.0007353916817865742
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.0007353916801658553
2215, epoch_train_loss=0.0007353916801658553
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.00073539167854692
2216, epoch_train_loss=0.00073539167854692
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0007353916769297656
2217, epoch_train_loss=0.0007353916769297656
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0007353916753143894
2218, epoch_train_loss=0.0007353916753143894
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0007353916737007887
2219, epoch_train_loss=0.0007353916737007887
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007353916720889608
2220, epoch_train_loss=0.0007353916720889608
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.0007353916704789035
2221, epoch_train_loss=0.0007353916704789035
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.0007353916688706134
2222, epoch_train_loss=0.0007353916688706134
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.0007353916672640886
2223, epoch_train_loss=0.0007353916672640886
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.0007353916656593259
2224, epoch_train_loss=0.0007353916656593259
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.000735391664056323
2225, epoch_train_loss=0.000735391664056323
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.0007353916624550773
2226, epoch_train_loss=0.0007353916624550773
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0007353916608555862
2227, epoch_train_loss=0.0007353916608555862
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.000735391659257847
2228, epoch_train_loss=0.000735391659257847
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.0007353916576618571
2229, epoch_train_loss=0.0007353916576618571
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0007353916560676137
2230, epoch_train_loss=0.0007353916560676137
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0007353916544751147
2231, epoch_train_loss=0.0007353916544751147
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.0007353916528843569
2232, epoch_train_loss=0.0007353916528843569
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.0007353916512953384
2233, epoch_train_loss=0.0007353916512953384
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.000735391649708056
2234, epoch_train_loss=0.000735391649708056
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.0007353916481225074
2235, epoch_train_loss=0.0007353916481225074
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.0007353916465386903
2236, epoch_train_loss=0.0007353916465386903
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0007353916449566019
2237, epoch_train_loss=0.0007353916449566019
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.0007353916433762394
2238, epoch_train_loss=0.0007353916433762394
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.0007353916417976005
2239, epoch_train_loss=0.0007353916417976005
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 0.0007353916402206827
2240, epoch_train_loss=0.0007353916402206827
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.0007353916386454833
2241, epoch_train_loss=0.0007353916386454833
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.0007353916370719998
2242, epoch_train_loss=0.0007353916370719998
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.0007353916355002299
2243, epoch_train_loss=0.0007353916355002299
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0007353916339301708
2244, epoch_train_loss=0.0007353916339301708
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.0007353916323618201
2245, epoch_train_loss=0.0007353916323618201
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 0.000735391630795175
2246, epoch_train_loss=0.000735391630795175
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 0.0007353916292302335
2247, epoch_train_loss=0.0007353916292302335
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 0.0007353916276669927
2248, epoch_train_loss=0.0007353916276669927
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.0007353916261054502
2249, epoch_train_loss=0.0007353916261054502
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.0007353916245456033
2250, epoch_train_loss=0.0007353916245456033
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.0007353916229874501
2251, epoch_train_loss=0.0007353916229874501
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 0.0007353916214309875
2252, epoch_train_loss=0.0007353916214309875
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 0.0007353916198762134
2253, epoch_train_loss=0.0007353916198762134
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 0.0007353916183231249
2254, epoch_train_loss=0.0007353916183231249
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 0.0007353916167717199
2255, epoch_train_loss=0.0007353916167717199
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 0.000735391615221996
2256, epoch_train_loss=0.000735391615221996
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 0.0007353916136739505
2257, epoch_train_loss=0.0007353916136739505
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 0.0007353916121275807
2258, epoch_train_loss=0.0007353916121275807
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 0.0007353916105828846
2259, epoch_train_loss=0.0007353916105828846
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 0.0007353916090398596
2260, epoch_train_loss=0.0007353916090398596
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 0.0007353916074985033
2261, epoch_train_loss=0.0007353916074985033
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 0.0007353916059588131
2262, epoch_train_loss=0.0007353916059588131
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 0.0007353916044207866
2263, epoch_train_loss=0.0007353916044207866
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 0.0007353916028844215
2264, epoch_train_loss=0.0007353916028844215
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 0.0007353916013497153
2265, epoch_train_loss=0.0007353916013497153
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 0.0007353915998166654
2266, epoch_train_loss=0.0007353915998166654
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 0.0007353915982852696
2267, epoch_train_loss=0.0007353915982852696
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 0.0007353915967555254
2268, epoch_train_loss=0.0007353915967555254
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 0.0007353915952274304
2269, epoch_train_loss=0.0007353915952274304
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 0.0007353915937009822
2270, epoch_train_loss=0.0007353915937009822
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 0.0007353915921761785
2271, epoch_train_loss=0.0007353915921761785
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 0.0007353915906530166
2272, epoch_train_loss=0.0007353915906530166
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 0.0007353915891314943
2273, epoch_train_loss=0.0007353915891314943
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 0.0007353915876116093
2274, epoch_train_loss=0.0007353915876116093
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 0.000735391586093359
2275, epoch_train_loss=0.000735391586093359
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 0.0007353915845767412
2276, epoch_train_loss=0.0007353915845767412
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 0.0007353915830617536
2277, epoch_train_loss=0.0007353915830617536
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 0.0007353915815483935
2278, epoch_train_loss=0.0007353915815483935
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 0.0007353915800366588
2279, epoch_train_loss=0.0007353915800366588
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 0.0007353915785265469
2280, epoch_train_loss=0.0007353915785265469
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 0.000735391577018056
2281, epoch_train_loss=0.000735391577018056
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 0.0007353915755111828
2282, epoch_train_loss=0.0007353915755111828
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 0.0007353915740059259
2283, epoch_train_loss=0.0007353915740059259
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 0.0007353915725022824
2284, epoch_train_loss=0.0007353915725022824
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 0.0007353915710002503
2285, epoch_train_loss=0.0007353915710002503
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 0.0007353915694998268
2286, epoch_train_loss=0.0007353915694998268
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 0.00073539156800101
2287, epoch_train_loss=0.00073539156800101
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 0.0007353915665037973
2288, epoch_train_loss=0.0007353915665037973
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 0.0007353915650081866
2289, epoch_train_loss=0.0007353915650081866
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 0.0007353915635141754
2290, epoch_train_loss=0.0007353915635141754
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 0.0007353915620217614
2291, epoch_train_loss=0.0007353915620217614
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 0.0007353915605309425
2292, epoch_train_loss=0.0007353915605309425
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 0.0007353915590417161
2293, epoch_train_loss=0.0007353915590417161
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 0.00073539155755408
2294, epoch_train_loss=0.00073539155755408
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 0.000735391556068032
2295, epoch_train_loss=0.000735391556068032
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 0.0007353915545835696
2296, epoch_train_loss=0.0007353915545835696
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 0.0007353915531006905
2297, epoch_train_loss=0.0007353915531006905
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 0.0007353915516193929
2298, epoch_train_loss=0.0007353915516193929
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 0.0007353915501396741
2299, epoch_train_loss=0.0007353915501396741
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 0.0007353915486615316
2300, epoch_train_loss=0.0007353915486615316
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 0.0007353915471849637
2301, epoch_train_loss=0.0007353915471849637
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 0.0007353915457099678
2302, epoch_train_loss=0.0007353915457099678
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 0.0007353915442365417
2303, epoch_train_loss=0.0007353915442365417
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 0.0007353915427646833
2304, epoch_train_loss=0.0007353915427646833
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 0.00073539154129439
2305, epoch_train_loss=0.00073539154129439
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 0.0007353915398256598
2306, epoch_train_loss=0.0007353915398256598
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 0.0007353915383584902
2307, epoch_train_loss=0.0007353915383584902
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 0.0007353915368928795
2308, epoch_train_loss=0.0007353915368928795
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 0.0007353915354288249
2309, epoch_train_loss=0.0007353915354288249
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 0.0007353915339663242
2310, epoch_train_loss=0.0007353915339663242
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 0.0007353915325053757
2311, epoch_train_loss=0.0007353915325053757
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 0.0007353915310459766
2312, epoch_train_loss=0.0007353915310459766
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 0.0007353915295881249
2313, epoch_train_loss=0.0007353915295881249
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 0.0007353915281318183
2314, epoch_train_loss=0.0007353915281318183
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 0.0007353915266770547
2315, epoch_train_loss=0.0007353915266770547
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 0.0007353915252238316
2316, epoch_train_loss=0.0007353915252238316
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 0.000735391523772147
2317, epoch_train_loss=0.000735391523772147
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 0.0007353915223219991
2318, epoch_train_loss=0.0007353915223219991
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 0.000735391520873385
2319, epoch_train_loss=0.000735391520873385
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 0.0007353915194263028
2320, epoch_train_loss=0.0007353915194263028
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 0.0007353915179807506
2321, epoch_train_loss=0.0007353915179807506
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 0.0007353915165367258
2322, epoch_train_loss=0.0007353915165367258
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 0.0007353915150942264
2323, epoch_train_loss=0.0007353915150942264
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 0.0007353915136532501
2324, epoch_train_loss=0.0007353915136532501
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 0.0007353915122137947
2325, epoch_train_loss=0.0007353915122137947
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 0.0007353915107758582
2326, epoch_train_loss=0.0007353915107758582
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 0.0007353915093394384
2327, epoch_train_loss=0.0007353915093394384
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 0.0007353915079045333
2328, epoch_train_loss=0.0007353915079045333
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 0.0007353915064711405
2329, epoch_train_loss=0.0007353915064711405
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 0.0007353915050392575
2330, epoch_train_loss=0.0007353915050392575
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 0.000735391503608883
2331, epoch_train_loss=0.000735391503608883
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 0.000735391502180014
2332, epoch_train_loss=0.000735391502180014
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 0.000735391500752649
2333, epoch_train_loss=0.000735391500752649
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 0.0007353914993267855
2334, epoch_train_loss=0.0007353914993267855
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 0.0007353914979024214
2335, epoch_train_loss=0.0007353914979024214
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 0.0007353914964795548
2336, epoch_train_loss=0.0007353914964795548
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 0.0007353914950581831
2337, epoch_train_loss=0.0007353914950581831
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 0.0007353914936383047
2338, epoch_train_loss=0.0007353914936383047
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 0.0007353914922199173
2339, epoch_train_loss=0.0007353914922199173
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.0007353914908030188
2340, epoch_train_loss=0.0007353914908030188
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.0007353914893876069
2341, epoch_train_loss=0.0007353914893876069
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.0007353914879736795
2342, epoch_train_loss=0.0007353914879736795
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.000735391486561235
2343, epoch_train_loss=0.000735391486561235
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.0007353914851502706
2344, epoch_train_loss=0.0007353914851502706
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0007353914837407846
2345, epoch_train_loss=0.0007353914837407846
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0007353914823327748
2346, epoch_train_loss=0.0007353914823327748
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.0007353914809262392
2347, epoch_train_loss=0.0007353914809262392
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0007353914795211756
2348, epoch_train_loss=0.0007353914795211756
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.000735391478117582
2349, epoch_train_loss=0.000735391478117582
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0007353914767154562
2350, epoch_train_loss=0.0007353914767154562
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.0007353914753147964
2351, epoch_train_loss=0.0007353914753147964
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.0007353914739156002
2352, epoch_train_loss=0.0007353914739156002
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.0007353914725178657
2353, epoch_train_loss=0.0007353914725178657
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.0007353914711215908
2354, epoch_train_loss=0.0007353914711215908
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.0007353914697267735
2355, epoch_train_loss=0.0007353914697267735
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.0007353914683334116
2356, epoch_train_loss=0.0007353914683334116
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.0007353914669415031
2357, epoch_train_loss=0.0007353914669415031
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.0007353914655510461
2358, epoch_train_loss=0.0007353914655510461
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007353914641620384
2359, epoch_train_loss=0.0007353914641620384
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.000735391462774478
2360, epoch_train_loss=0.000735391462774478
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.0007353914613883629
2361, epoch_train_loss=0.0007353914613883629
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.0007353914600036909
2362, epoch_train_loss=0.0007353914600036909
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0007353914586204601
2363, epoch_train_loss=0.0007353914586204601
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.0007353914572386688
2364, epoch_train_loss=0.0007353914572386688
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0007353914558583143
2365, epoch_train_loss=0.0007353914558583143
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0007353914544793952
2366, epoch_train_loss=0.0007353914544793952
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.000735391453101909
2367, epoch_train_loss=0.000735391453101909
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.0007353914517258539
2368, epoch_train_loss=0.0007353914517258539
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.0007353914503512282
2369, epoch_train_loss=0.0007353914503512282
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0007353914489780293
2370, epoch_train_loss=0.0007353914489780293
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0007353914476062555
2371, epoch_train_loss=0.0007353914476062555
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.000735391446235905
2372, epoch_train_loss=0.000735391446235905
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.0007353914448669755
2373, epoch_train_loss=0.0007353914448669755
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0007353914434994649
2374, epoch_train_loss=0.0007353914434994649
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0007353914421333716
2375, epoch_train_loss=0.0007353914421333716
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0007353914407686934
2376, epoch_train_loss=0.0007353914407686934
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0007353914394054282
2377, epoch_train_loss=0.0007353914394054282
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.0007353914380435745
2378, epoch_train_loss=0.0007353914380435745
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.0007353914366831298
2379, epoch_train_loss=0.0007353914366831298
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0007353914353240924
2380, epoch_train_loss=0.0007353914353240924
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.0007353914339664599
2381, epoch_train_loss=0.0007353914339664599
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0007353914326102312
2382, epoch_train_loss=0.0007353914326102312
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.0007353914312554036
2383, epoch_train_loss=0.0007353914312554036
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.0007353914299019755
2384, epoch_train_loss=0.0007353914299019755
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.0007353914285499448
2385, epoch_train_loss=0.0007353914285499448
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.0007353914271993095
2386, epoch_train_loss=0.0007353914271993095
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.0007353914258500678
2387, epoch_train_loss=0.0007353914258500678
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.0007353914245022177
2388, epoch_train_loss=0.0007353914245022177
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0007353914231557572
2389, epoch_train_loss=0.0007353914231557572
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0007353914218106845
2390, epoch_train_loss=0.0007353914218106845
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0007353914204669977
2391, epoch_train_loss=0.0007353914204669977
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.0007353914191246946
2392, epoch_train_loss=0.0007353914191246946
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.0007353914177837735
2393, epoch_train_loss=0.0007353914177837735
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.0007353914164442323
2394, epoch_train_loss=0.0007353914164442323
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0007353914151060695
2395, epoch_train_loss=0.0007353914151060695
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0007353914137692829
2396, epoch_train_loss=0.0007353914137692829
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.0007353914124338703
2397, epoch_train_loss=0.0007353914124338703
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0007353914110998301
2398, epoch_train_loss=0.0007353914110998301
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0007353914097671605
2399, epoch_train_loss=0.0007353914097671605
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.0007353914084358594
2400, epoch_train_loss=0.0007353914084358594
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.000735391407105925
2401, epoch_train_loss=0.000735391407105925
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0007353914057773551
2402, epoch_train_loss=0.0007353914057773551
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.0007353914044501487
2403, epoch_train_loss=0.0007353914044501487
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.0007353914031243028
2404, epoch_train_loss=0.0007353914031243028
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.000735391401799816
2405, epoch_train_loss=0.000735391401799816
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0007353914004766865
2406, epoch_train_loss=0.0007353914004766865
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0007353913991549125
2407, epoch_train_loss=0.0007353913991549125
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.0007353913978344919
2408, epoch_train_loss=0.0007353913978344919
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.000735391396515423
2409, epoch_train_loss=0.000735391396515423
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.0007353913951977037
2410, epoch_train_loss=0.0007353913951977037
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.0007353913938813322
2411, epoch_train_loss=0.0007353913938813322
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.000735391392566307
2412, epoch_train_loss=0.000735391392566307
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.0007353913912526258
2413, epoch_train_loss=0.0007353913912526258
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.0007353913899402869
2414, epoch_train_loss=0.0007353913899402869
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 0.0007353913886292884
2415, epoch_train_loss=0.0007353913886292884
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0007353913873196287
2416, epoch_train_loss=0.0007353913873196287
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.0007353913860113057
2417, epoch_train_loss=0.0007353913860113057
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0007353913847043174
2418, epoch_train_loss=0.0007353913847043174
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.0007353913833986625
2419, epoch_train_loss=0.0007353913833986625
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 0.0007353913820943387
2420, epoch_train_loss=0.0007353913820943387
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0007353913807913442
2421, epoch_train_loss=0.0007353913807913442
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0007353913794896776
2422, epoch_train_loss=0.0007353913794896776
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.0007353913781893364
2423, epoch_train_loss=0.0007353913781893364
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.0007353913768903194
2424, epoch_train_loss=0.0007353913768903194
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.0007353913755926244
2425, epoch_train_loss=0.0007353913755926244
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 0.0007353913742962497
2426, epoch_train_loss=0.0007353913742962497
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.0007353913730011935
2427, epoch_train_loss=0.0007353913730011935
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.0007353913717074538
2428, epoch_train_loss=0.0007353913717074538
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.0007353913704150293
2429, epoch_train_loss=0.0007353913704150293
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.0007353913691239177
2430, epoch_train_loss=0.0007353913691239177
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 0.0007353913678341174
2431, epoch_train_loss=0.0007353913678341174
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 0.0007353913665456266
2432, epoch_train_loss=0.0007353913665456266
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.0007353913652584435
2433, epoch_train_loss=0.0007353913652584435
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0007353913639725661
2434, epoch_train_loss=0.0007353913639725661
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.000735391362687993
2435, epoch_train_loss=0.000735391362687993
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 0.0007353913614047223
2436, epoch_train_loss=0.0007353913614047223
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 0.0007353913601227521
2437, epoch_train_loss=0.0007353913601227521
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 0.0007353913588420806
2438, epoch_train_loss=0.0007353913588420806
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.0007353913575627062
2439, epoch_train_loss=0.0007353913575627062
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.0007353913562846268
2440, epoch_train_loss=0.0007353913562846268
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 0.000735391355007841
2441, epoch_train_loss=0.000735391355007841
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 0.0007353913537323469
2442, epoch_train_loss=0.0007353913537323469
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 0.0007353913524581427
2443, epoch_train_loss=0.0007353913524581427
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 0.0007353913511852266
2444, epoch_train_loss=0.0007353913511852266
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 0.000735391349913597
2445, epoch_train_loss=0.000735391349913597
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 0.000735391348643252
2446, epoch_train_loss=0.000735391348643252
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 0.0007353913473741899
2447, epoch_train_loss=0.0007353913473741899
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 0.000735391346106409
2448, epoch_train_loss=0.000735391346106409
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 0.0007353913448399074
2449, epoch_train_loss=0.0007353913448399074
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 0.0007353913435746836
2450, epoch_train_loss=0.0007353913435746836
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 0.0007353913423107357
2451, epoch_train_loss=0.0007353913423107357
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 0.000735391341048062
2452, epoch_train_loss=0.000735391341048062
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 0.0007353913397866609
2453, epoch_train_loss=0.0007353913397866609
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 0.0007353913385265303
2454, epoch_train_loss=0.0007353913385265303
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 0.0007353913372676688
2455, epoch_train_loss=0.0007353913372676688
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 0.0007353913360100745
2456, epoch_train_loss=0.0007353913360100745
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 0.0007353913347537459
2457, epoch_train_loss=0.0007353913347537459
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 0.0007353913334986811
2458, epoch_train_loss=0.0007353913334986811
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 0.0007353913322448786
2459, epoch_train_loss=0.0007353913322448786
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 0.0007353913309923362
2460, epoch_train_loss=0.0007353913309923362
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 0.0007353913297410528
2461, epoch_train_loss=0.0007353913297410528
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 0.0007353913284910261
2462, epoch_train_loss=0.0007353913284910261
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 0.0007353913272422552
2463, epoch_train_loss=0.0007353913272422552
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 0.0007353913259947375
2464, epoch_train_loss=0.0007353913259947375
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 0.0007353913247484719
2465, epoch_train_loss=0.0007353913247484719
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 0.0007353913235034564
2466, epoch_train_loss=0.0007353913235034564
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 0.0007353913222596895
2467, epoch_train_loss=0.0007353913222596895
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 0.0007353913210171694
2468, epoch_train_loss=0.0007353913210171694
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 0.0007353913197758945
2469, epoch_train_loss=0.0007353913197758945
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 0.000735391318535863
2470, epoch_train_loss=0.000735391318535863
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 0.0007353913172970733
2471, epoch_train_loss=0.0007353913172970733
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 0.0007353913160595238
2472, epoch_train_loss=0.0007353913160595238
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 0.0007353913148232127
2473, epoch_train_loss=0.0007353913148232127
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.0007353913135881385
2474, epoch_train_loss=0.0007353913135881385
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.0007353913123542995
2475, epoch_train_loss=0.0007353913123542995
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.0007353913111216937
2476, epoch_train_loss=0.0007353913111216937
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.0007353913098903197
2477, epoch_train_loss=0.0007353913098903197
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.000735391308660176
2478, epoch_train_loss=0.000735391308660176
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0007353913074312608
2479, epoch_train_loss=0.0007353913074312608
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0007353913062035722
2480, epoch_train_loss=0.0007353913062035722
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007353913049771091
2481, epoch_train_loss=0.0007353913049771091
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.0007353913037518692
2482, epoch_train_loss=0.0007353913037518692
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.0007353913025278511
2483, epoch_train_loss=0.0007353913025278511
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.0007353913013050536
2484, epoch_train_loss=0.0007353913013050536
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.0007353913000834743
2485, epoch_train_loss=0.0007353913000834743
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.0007353912988631122
2486, epoch_train_loss=0.0007353912988631122
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.0007353912976439653
2487, epoch_train_loss=0.0007353912976439653
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.0007353912964260322
2488, epoch_train_loss=0.0007353912964260322
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.0007353912952093112
2489, epoch_train_loss=0.0007353912952093112
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.0007353912939938006
2490, epoch_train_loss=0.0007353912939938006
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.0007353912927794987
2491, epoch_train_loss=0.0007353912927794987
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.0007353912915664041
2492, epoch_train_loss=0.0007353912915664041
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.0007353912903545153
2493, epoch_train_loss=0.0007353912903545153
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0007353912891438304
2494, epoch_train_loss=0.0007353912891438304
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0007353912879343475
2495, epoch_train_loss=0.0007353912879343475
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0007353912867260657
2496, epoch_train_loss=0.0007353912867260657
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.000735391285518983
2497, epoch_train_loss=0.000735391285518983
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.0007353912843130978
2498, epoch_train_loss=0.0007353912843130978
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0007353912831084084
2499, epoch_train_loss=0.0007353912831084084
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e40a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e40a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeac1e40a0> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e4970> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e4c40> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e7520> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e5c30> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e6050> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e63b0> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e5720> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e62c0> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e7a30> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac1e7cd0> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac1e7370> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e4820> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e4cd0> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e4160> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac1e52a0> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e66b0> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e49a0> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e7160> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e6ef0> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac1e65c0> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac1e6560> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac074d90> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeac075810> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac076320> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e4970> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e4970> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-3.48053232e-03 -9.22981806e-04 -2.09507924e-03 ... -1.11294850e+01
 -1.11294850e+01 -1.11294850e+01] = SCAN,
rho_a.shape=(6, 6320), rho_b.shape=(6, 6320)
fxc_a.shape=(6320,), fxc_b.shape=(6320,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12640), fxc.shape=(12640,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(2, 6320, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12640, 3)
rho_filt.shape=(12640,)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046675  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e4c40> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e4c40> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.10256797e-03 -5.98013179e-04 -6.71209617e-05 ... -5.03581543e+00
 -5.03581543e+00 -5.03581543e+00] = SCAN,
rho_a.shape=(6, 5016), rho_b.shape=(6, 5016)
fxc_a.shape=(5016,), fxc_b.shape=(5016,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 10032), fxc.shape=(10032,)
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(2, 5016, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(10032, 3)
rho_filt.shape=(10032,)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e7520> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e7520> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.59173730e-03 -7.67300285e-04 -6.09330303e-05 ... -7.27736608e-01
 -7.27736608e-01 -7.27736608e-01] = SCAN,
rho_a.shape=(6, 2440), rho_b.shape=(6, 2440)
fxc_a.shape=(2440,), fxc_b.shape=(2440,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 2440), fxc.shape=(2440,)
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2, 2440, 3)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e5c30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e5c30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-6.71507910e-03 -1.45299376e-03 -1.45299376e-03 ... -1.46930969e-02
 -2.05021258e+00 -2.05021258e+00] = SCAN,
rho_a.shape=(6, 4592), rho_b.shape=(6, 4592)
fxc_a.shape=(4592,), fxc_b.shape=(4592,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 9184), fxc.shape=(9184,)
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(2, 4592, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(9184, 3)
rho_filt.shape=(9184,)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.003380292217  <S^2> = 2.0027446  2S+1 = 3.0018292
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e6050> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e6050> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-7.50862872e-04 -1.30793603e-04 -6.57493534e-06 ... -5.78388650e+00
 -5.78388650e+00 -5.78388650e+00] = SCAN,
rho_a.shape=(6, 5040), rho_b.shape=(6, 5040)
fxc_a.shape=(5040,), fxc_b.shape=(5040,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 10080), fxc.shape=(10080,)
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(2, 5040, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(10080, 3)
rho_filt.shape=(10080,)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121336  <S^2> = 0.75161941  2S+1 = 2.0016188
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e63b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e63b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-7.49158483e-04 -9.79939847e-04 -3.45846905e-04 ... -1.26646370e+01
 -1.26646370e+01 -1.26646370e+01] = SCAN,
rho_a.shape=(6, 6152), rho_b.shape=(6, 6152)
fxc_a.shape=(6152,), fxc_b.shape=(6152,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12304), fxc.shape=(12304,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(2, 6152, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12304, 3)
rho_filt.shape=(12304,)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560989246  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e5720> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e5720> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.39565697e-02 -8.69596418e-03 -4.30176653e-03 ... -1.39782503e-04
 -1.04898436e-03 -7.75345721e-05] = SCAN,
rho_a.shape=(6, 6088), rho_b.shape=(6, 6088)
fxc_a.shape=(6088,), fxc_b.shape=(6088,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12176), fxc.shape=(12176,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(2, 6088, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12176, 3)
rho_filt.shape=(12176,)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786814395  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e62c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e62c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.38675245e-03 -8.23622005e-04 -9.79799418e-04 ... -1.18982463e+01
 -1.18982463e+01 -1.18982463e+01] = SCAN,
rho_a.shape=(6, 6320), rho_b.shape=(6, 6320)
fxc_a.shape=(6320,), fxc_b.shape=(6320,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12640), fxc.shape=(12640,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(2, 6320, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12640, 3)
rho_filt.shape=(12640,)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 1.7763568e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e7a30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e7a30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.04987750e-03 -6.68953858e-04 -8.57556270e-04 ... -1.07485583e-03
 -8.01425698e-01 -8.01425698e-01] = SCAN,
rho_a.shape=(6, 9752), rho_b.shape=(6, 9752)
fxc_a.shape=(9752,), fxc_b.shape=(9752,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9752), fxc.shape=(9752,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(2, 9752, 3)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.3377924465131  <S^2> = 4.0073189e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e7cd0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e7cd0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.97917285e-04 -2.54412366e-05 -3.15182243e-05 ... -6.37386500e-01
 -6.37386500e-01 -6.37386500e-01] = SCAN,
rho_a.shape=(6, 12256), rho_b.shape=(6, 12256)
fxc_a.shape=(12256,), fxc_b.shape=(12256,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 12256), fxc.shape=(12256,)
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(2, 12256, 3)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322843  <S^2> = 1.9539925e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e7370> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e7370> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.50217115e-04 -2.07520066e-04 -9.23619896e-04 ... -2.74295208e-06
 -4.27559894e+00 -4.27559894e+00] = SCAN,
rho_a.shape=(6, 14920), rho_b.shape=(6, 14920)
fxc_a.shape=(14920,), fxc_b.shape=(14920,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 14920), fxc.shape=(14920,)
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(2, 14920, 3)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888959  <S^2> = 4.938272e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e4820> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e4820> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-0.00155834 -0.00091688 -0.00215831 ... -0.00091688 -0.41618507
 -0.41618507] = SCAN,
rho_a.shape=(6, 12208), rho_b.shape=(6, 12208)
fxc_a.shape=(12208,), fxc_b.shape=(12208,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 12208), fxc.shape=(12208,)
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(2, 12208, 3)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.2079227e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e4cd0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e4cd0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.92948614e-04 -1.95198688e-05 -1.16699802e-03 ... -4.89378340e-01
 -4.89378340e-01 -4.89378340e-01] = SCAN,
rho_a.shape=(6, 9824), rho_b.shape=(6, 9824)
fxc_a.shape=(9824,), fxc_b.shape=(9824,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9824), fxc.shape=(9824,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(2, 9824, 3)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894502658  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e4160> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e4160> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.02062734e-04 -1.43137772e-04 -7.39292322e-06 ... -6.59150624e-01
 -6.59150624e-01 -6.59150624e-01] = SCAN,
rho_a.shape=(6, 9912), rho_b.shape=(6, 9912)
fxc_a.shape=(9912,), fxc_b.shape=(9912,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9912), fxc.shape=(9912,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(2, 9912, 3)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346373  <S^2> = 8.8817842e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e52a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e52a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.83270456e-05 -8.83270456e-05 -9.75839850e-04 ... -3.46719667e-05
 -3.31708644e-05 -3.31708644e-05] = SCAN,
rho_a.shape=(6, 15208), rho_b.shape=(6, 15208)
fxc_a.shape=(15208,), fxc_b.shape=(15208,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 15208), fxc.shape=(15208,)
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(2, 15208, 3)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5902839e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e66b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e66b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-5.37000578e-04 -8.55494549e-04 -2.46853288e-03 ... -7.34251999e-01
 -7.34251999e-01 -7.34251999e-01] = SCAN,
rho_a.shape=(6, 10040), rho_b.shape=(6, 10040)
fxc_a.shape=(10040,), fxc_b.shape=(10040,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 10040), fxc.shape=(10040,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(2, 10040, 3)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374077  <S^2> = 6.5725203e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e49a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e49a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.38161177e-04 -1.81188367e-05 -2.37300299e-05 ... -2.83738108e+00
 -2.83738108e+00 -2.83738108e+00] = SCAN,
rho_a.shape=(6, 8552), rho_b.shape=(6, 8552)
fxc_a.shape=(8552,), fxc_b.shape=(8552,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 8552), fxc.shape=(8552,)
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(2, 8552, 3)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.7937656e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e7160> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e7160> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-0.00113445 -0.00118624 -0.00118624 ... -0.48434639 -0.48434639
 -0.48434639] = SCAN,
rho_a.shape=(6, 6936), rho_b.shape=(6, 6936)
fxc_a.shape=(6936,), fxc_b.shape=(6936,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 6936), fxc.shape=(6936,)
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(2, 6936, 3)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5862867e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e6ef0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e6ef0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-0.00297935 -0.00297935 -0.00407089 ... -0.00297935 -0.00297935
 -0.00407089] = SCAN,
rho_a.shape=(6, 11536), rho_b.shape=(6, 11536)
fxc_a.shape=(11536,), fxc_b.shape=(11536,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 11536), fxc.shape=(11536,)
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(2, 11536, 3)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.31335e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e65c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e65c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.61400996e-04 -4.90484900e-04 -2.56451718e-03 ... -9.59296113e+00
 -9.59296113e+00 -9.59296113e+00] = SCAN,
rho_a.shape=(6, 24512), rho_b.shape=(6, 24512)
fxc_a.shape=(24512,), fxc_b.shape=(24512,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 24512), fxc.shape=(24512,)
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(2, 24512, 3)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5394797e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e6560> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e6560> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.28637920e-03 -4.32383300e-04 -3.74057272e-05 ... -1.91722770e+00
 -1.91722770e+00 -1.91722770e+00] = SCAN,
rho_a.shape=(6, 13096), rho_b.shape=(6, 13096)
fxc_a.shape=(13096,), fxc_b.shape=(13096,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 13096), fxc.shape=(13096,)
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(2, 13096, 3)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336180875  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac074d90> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac074d90> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.59570403e-04 -2.59078681e-04 -2.60105975e-04 ... -3.86943992e-01
 -3.86943992e-01 -3.86943992e-01] = SCAN,
rho_a.shape=(6, 12384), rho_b.shape=(6, 12384)
fxc_a.shape=(12384,), fxc_b.shape=(12384,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 12384), fxc.shape=(12384,)
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(2, 12384, 3)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864077  <S^2> = 3.1885605e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac075810> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac075810> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.68439986e-04 -2.42462569e-04 -1.69927031e-05 ... -2.55230307e-05
 -2.55230307e-05 -2.55230307e-05] = SCAN,
rho_a.shape=(6, 13936), rho_b.shape=(6, 13936)
fxc_a.shape=(13936,), fxc_b.shape=(13936,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 13936), fxc.shape=(13936,)
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(2, 13936, 3)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.2030381e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac076320> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac076320> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-7.67688751e-04 -4.57393214e-05 -2.02834191e-04 ... -1.14928924e+00
 -1.14928924e+00 -1.14928924e+00] = SCAN,
rho_a.shape=(6, 9656), rho_b.shape=(6, 9656)
fxc_a.shape=(9656,), fxc_b.shape=(9656,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9656), fxc.shape=(9656,)
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(2, 9656, 3)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3159251e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.33850535e-04 -2.34903029e-04 -1.75623665e-05 ... -1.92891112e-05
 -1.92891112e-05 -1.92891112e-05] = SCAN,
rho_a.shape=(6, 15256), rho_b.shape=(6, 15256)
fxc_a.shape=(15256,), fxc_b.shape=(15256,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 15256), fxc.shape=(15256,)
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(2, 15256, 3)
localnet.spin_scaling: concatenating the data
first data shape = (10940, 3)
concatenated: tdrho.shape=(258861, 3)
PRE NAN FILT: tFxc.shape=(258861,), tdrho.shape=(258861, 3)
nan_filt_rho.shape=(258861,)
nan_filt_fxc.shape=(258861,)
tFxc.shape=(258861,), tdrho.shape=(258861, 3)
inp[0].shape = (258861, 2)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 5.73475350470164
0, epoch_train_loss=5.73475350470164
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 5.330913041877925
1, epoch_train_loss=5.330913041877925
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 4.9662714303410525
2, epoch_train_loss=4.9662714303410525
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 4.557016748272407
3, epoch_train_loss=4.557016748272407
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 4.246443393719767
4, epoch_train_loss=4.246443393719767
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 3.94940575860691
5, epoch_train_loss=3.94940575860691
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 3.7433513425643996
6, epoch_train_loss=3.7433513425643996
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 3.465980495657705
7, epoch_train_loss=3.465980495657705
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 3.2737919808728324
8, epoch_train_loss=3.2737919808728324
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 3.0965959033800328
9, epoch_train_loss=3.0965959033800328
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 2.927705863861653
10, epoch_train_loss=2.927705863861653
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 2.906122895539271
11, epoch_train_loss=2.906122895539271
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 3.100389061146763
12, epoch_train_loss=3.100389061146763
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 2.7887619708334412
13, epoch_train_loss=2.7887619708334412
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 2.8877442322353577
14, epoch_train_loss=2.8877442322353577
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 2.8814229985540205
15, epoch_train_loss=2.8814229985540205
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 2.812984727220899
16, epoch_train_loss=2.812984727220899
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 2.7982902548846083
17, epoch_train_loss=2.7982902548846083
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 2.7429167618389156
18, epoch_train_loss=2.7429167618389156
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 2.7496579385980673
19, epoch_train_loss=2.7496579385980673
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 2.761619808414324
20, epoch_train_loss=2.761619808414324
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 2.6777702116800897
21, epoch_train_loss=2.6777702116800897
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 2.7517194182158167
22, epoch_train_loss=2.7517194182158167
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 2.6647456689081976
23, epoch_train_loss=2.6647456689081976
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 2.718431580757487
24, epoch_train_loss=2.718431580757487
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 2.68983463707488
25, epoch_train_loss=2.68983463707488
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 2.671724244645197
26, epoch_train_loss=2.671724244645197
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 2.706565014214981
27, epoch_train_loss=2.706565014214981
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 2.6601398081571284
28, epoch_train_loss=2.6601398081571284
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 2.6899137818226784
29, epoch_train_loss=2.6899137818226784
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 2.6845022192728303
30, epoch_train_loss=2.6845022192728303
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 2.6640850783577075
31, epoch_train_loss=2.6640850783577075
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 2.6878775785821425
32, epoch_train_loss=2.6878775785821425
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 2.663407007342888
33, epoch_train_loss=2.663407007342888
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 2.669624230525829
34, epoch_train_loss=2.669624230525829
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 2.676035885558806
35, epoch_train_loss=2.676035885558806
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 2.6559131129683364
36, epoch_train_loss=2.6559131129683364
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 2.6687199715366803
37, epoch_train_loss=2.6687199715366803
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 2.661251790018244
38, epoch_train_loss=2.661251790018244
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 2.656435806030896
39, epoch_train_loss=2.656435806030896
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 2.6641575804213953
40, epoch_train_loss=2.6641575804213953
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 2.651912946996664
41, epoch_train_loss=2.651912946996664
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 2.6585465261019925
42, epoch_train_loss=2.6585465261019925
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 2.655838348979181
43, epoch_train_loss=2.655838348979181
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 2.6510231806813747
44, epoch_train_loss=2.6510231806813747
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 2.656502093162539
45, epoch_train_loss=2.656502093162539
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 2.648802082103137
46, epoch_train_loss=2.648802082103137
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 2.6531600316954913
47, epoch_train_loss=2.6531600316954913
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 2.6493259302784993
48, epoch_train_loss=2.6493259302784993
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 2.648347760428887
49, epoch_train_loss=2.648347760428887
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 2.650217839013214
50, epoch_train_loss=2.650217839013214
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 2.6457611541672486
51, epoch_train_loss=2.6457611541672486
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 2.64918668074281
52, epoch_train_loss=2.64918668074281
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 2.6448127231293737
53, epoch_train_loss=2.6448127231293737
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 2.647318313751731
54, epoch_train_loss=2.647318313751731
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 2.6449520681492245
55, epoch_train_loss=2.6449520681492245
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 2.645239612435395
56, epoch_train_loss=2.645239612435395
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 2.6446166771248243
57, epoch_train_loss=2.6446166771248243
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 2.6437271248079295
58, epoch_train_loss=2.6437271248079295
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 2.644174895420548
59, epoch_train_loss=2.644174895420548
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 2.6425247754663572
60, epoch_train_loss=2.6425247754663572
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 2.6435206359527874
61, epoch_train_loss=2.6435206359527874
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 2.641875679900198
62, epoch_train_loss=2.641875679900198
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 2.642780438895325
63, epoch_train_loss=2.642780438895325
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 2.6411799716733255
64, epoch_train_loss=2.6411799716733255
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 2.6420565498301363
65, epoch_train_loss=2.6420565498301363
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 2.6407443856917885
66, epoch_train_loss=2.6407443856917885
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 2.641312107809829
67, epoch_train_loss=2.641312107809829
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 2.640250058204933
68, epoch_train_loss=2.640250058204933
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 2.6406018261535524
69, epoch_train_loss=2.6406018261535524
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 2.6398521209715073
70, epoch_train_loss=2.6398521209715073
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 2.639829700263722
71, epoch_train_loss=2.639829700263722
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 2.639504772500691
72, epoch_train_loss=2.639504772500691
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 2.639138270741803
73, epoch_train_loss=2.639138270741803
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 2.6391655292067826
74, epoch_train_loss=2.6391655292067826
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 2.638546573573461
75, epoch_train_loss=2.638546573573461
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 2.6387806593555054
76, epoch_train_loss=2.6387806593555054
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 2.6380922324775047
77, epoch_train_loss=2.6380922324775047
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 2.6382414187009764
78, epoch_train_loss=2.6382414187009764
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 2.6377834263334115
79, epoch_train_loss=2.6377834263334115
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 2.637581204040401
80, epoch_train_loss=2.637581204040401
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 2.637527261383242
81, epoch_train_loss=2.637527261383242
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 2.6370576662131526
82, epoch_train_loss=2.6370576662131526
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 2.63713625280803
83, epoch_train_loss=2.63713625280803
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 2.6367784626700237
84, epoch_train_loss=2.6367784626700237
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 2.6365885634823707
85, epoch_train_loss=2.6365885634823707
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 2.636547420786019
86, epoch_train_loss=2.636547420786019
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 2.6361764606866287
87, epoch_train_loss=2.6361764606866287
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 2.6361145886060657
88, epoch_train_loss=2.6361145886060657
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 2.6359573887492895
89, epoch_train_loss=2.6359573887492895
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 2.635680742861152
90, epoch_train_loss=2.635680742861152
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 2.6356317418627504
91, epoch_train_loss=2.6356317418627504
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 2.6354642204572825
92, epoch_train_loss=2.6354642204572825
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 2.6352255638458337
93, epoch_train_loss=2.6352255638458337
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 2.6351642037219225
94, epoch_train_loss=2.6351642037219225
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 2.6350020331683903
95, epoch_train_loss=2.6350020331683903
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 2.6347960728803463
96, epoch_train_loss=2.6347960728803463
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 2.634706200541707
97, epoch_train_loss=2.634706200541707
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 2.6345905063153907
98, epoch_train_loss=2.6345905063153907
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 2.6343960162732345
99, epoch_train_loss=2.6343960162732345
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 2.634273697529655
100, epoch_train_loss=2.634273697529655
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 2.634182435918184
101, epoch_train_loss=2.634182435918184
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 2.6340263707354388
102, epoch_train_loss=2.6340263707354388
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 2.6338679993637344
103, epoch_train_loss=2.6338679993637344
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 2.6337621564517812
104, epoch_train_loss=2.6337621564517812
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 2.6336606833263385
105, epoch_train_loss=2.6336606833263385
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 2.6335142813933854
106, epoch_train_loss=2.6335142813933854
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 2.6333641690937846
107, epoch_train_loss=2.6333641690937846
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 2.6332507115031447
108, epoch_train_loss=2.6332507115031447
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 2.63314599949021
109, epoch_train_loss=2.63314599949021
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 2.6330186266344855
110, epoch_train_loss=2.6330186266344855
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 2.632875971626157
111, epoch_train_loss=2.632875971626157
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 2.6327406013971255
112, epoch_train_loss=2.6327406013971255
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 2.632620507964653
113, epoch_train_loss=2.632620507964653
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 2.63250666175368
114, epoch_train_loss=2.63250666175368
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 2.632385543639459
115, epoch_train_loss=2.632385543639459
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 2.632251868438028
116, epoch_train_loss=2.632251868438028
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 2.632112047868872
117, epoch_train_loss=2.632112047868872
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 2.6319730498080496
118, epoch_train_loss=2.6319730498080496
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 2.6318383769637452
119, epoch_train_loss=2.6318383769637452
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 2.6317074622311716
120, epoch_train_loss=2.6317074622311716
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 2.6315780944346154
121, epoch_train_loss=2.6315780944346154
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 2.631448794854229
122, epoch_train_loss=2.631448794854229
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 2.6313186204328716
123, epoch_train_loss=2.6313186204328716
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 2.6311898342145397
124, epoch_train_loss=2.6311898342145397
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 2.6310661058735723
125, epoch_train_loss=2.6310661058735723
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 2.630961003313334
126, epoch_train_loss=2.630961003313334
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 2.6309073231914497
127, epoch_train_loss=2.6309073231914497
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 2.63101490504645
128, epoch_train_loss=2.63101490504645
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 2.631462871988629
129, epoch_train_loss=2.631462871988629
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 2.6319780763937315
130, epoch_train_loss=2.6319780763937315
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 2.6322368627617423
131, epoch_train_loss=2.6322368627617423
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 2.634305830176073
132, epoch_train_loss=2.634305830176073
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 2.6408426479228027
133, epoch_train_loss=2.6408426479228027
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 2.6589325883378128
134, epoch_train_loss=2.6589325883378128
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 2.689495160529408
135, epoch_train_loss=2.689495160529408
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 2.765034005350659
136, epoch_train_loss=2.765034005350659
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 2.7084814324204785
137, epoch_train_loss=2.7084814324204785
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 2.6525655637049996
138, epoch_train_loss=2.6525655637049996
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 2.634014627623742
139, epoch_train_loss=2.634014627623742
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 2.671055034966037
140, epoch_train_loss=2.671055034966037
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 2.663996403217707
141, epoch_train_loss=2.663996403217707
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 2.6321778417137054
142, epoch_train_loss=2.6321778417137054
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 2.667885467053387
143, epoch_train_loss=2.667885467053387
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 2.647493034021778
144, epoch_train_loss=2.647493034021778
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 2.640699003837947
145, epoch_train_loss=2.640699003837947
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 2.6569637511792767
146, epoch_train_loss=2.6569637511792767
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 2.631193328103836
147, epoch_train_loss=2.631193328103836
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 2.648548627475781
148, epoch_train_loss=2.648548627475781
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 2.6331017815311935
149, epoch_train_loss=2.6331017815311935
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 2.6410300406011356
150, epoch_train_loss=2.6410300406011356
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 2.6370640508477665
151, epoch_train_loss=2.6370640508477665
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 2.6350720145984985
152, epoch_train_loss=2.6350720145984985
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 2.6380563536059345
153, epoch_train_loss=2.6380563536059345
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 2.631059432162231
154, epoch_train_loss=2.631059432162231
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 2.637252835058399
155, epoch_train_loss=2.637252835058399
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 2.6298511832400293
156, epoch_train_loss=2.6298511832400293
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 2.6357831203021034
157, epoch_train_loss=2.6357831203021034
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 2.6296008262617394
158, epoch_train_loss=2.6296008262617394
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 2.633028396467112
159, epoch_train_loss=2.633028396467112
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 2.6297750479299262
160, epoch_train_loss=2.6297750479299262
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 2.6304250698450113
161, epoch_train_loss=2.6304250698450113
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 2.630179924640508
162, epoch_train_loss=2.630179924640508
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 2.62827063697525
163, epoch_train_loss=2.62827063697525
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 2.6300974316508534
164, epoch_train_loss=2.6300974316508534
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 2.6266590249249835
165, epoch_train_loss=2.6266590249249835
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 2.629254766900151
166, epoch_train_loss=2.629254766900151
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 2.625971754215559
167, epoch_train_loss=2.625971754215559
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 2.6279142913950753
168, epoch_train_loss=2.6279142913950753
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 2.6259429093092352
169, epoch_train_loss=2.6259429093092352
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 2.626106749356153
170, epoch_train_loss=2.626106749356153
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 2.625965253582696
171, epoch_train_loss=2.625965253582696
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 2.624572766246035
172, epoch_train_loss=2.624572766246035
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 2.6253732302243122
173, epoch_train_loss=2.6253732302243122
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 2.6239254280393336
174, epoch_train_loss=2.6239254280393336
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 2.6239767528894142
175, epoch_train_loss=2.6239767528894142
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 2.623888442139571
176, epoch_train_loss=2.623888442139571
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 2.6225828770558595
177, epoch_train_loss=2.6225828770558595
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 2.6232123570366
178, epoch_train_loss=2.6232123570366
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 2.6222262096425446
179, epoch_train_loss=2.6222262096425446
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 2.6216803769602333
180, epoch_train_loss=2.6216803769602333
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 2.621890948530041
181, epoch_train_loss=2.621890948530041
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 2.621016289699546
182, epoch_train_loss=2.621016289699546
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 2.6204398474401764
183, epoch_train_loss=2.6204398474401764
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 2.6206237871803393
184, epoch_train_loss=2.6206237871803393
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 2.61985510856912
185, epoch_train_loss=2.61985510856912
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 2.6191693461042598
186, epoch_train_loss=2.6191693461042598
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 2.619086808549665
187, epoch_train_loss=2.619086808549665
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 2.6188497335251553
188, epoch_train_loss=2.6188497335251553
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 2.6179793765008057
189, epoch_train_loss=2.6179793765008057
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 2.6174072950469918
190, epoch_train_loss=2.6174072950469918
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 2.6171792586638656
191, epoch_train_loss=2.6171792586638656
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 2.616964825649606
192, epoch_train_loss=2.616964825649606
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 2.6164735983035774
193, epoch_train_loss=2.6164735983035774
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 2.615772478875422
194, epoch_train_loss=2.615772478875422
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 2.615073944716282
195, epoch_train_loss=2.615073944716282
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 2.6143740530339605
196, epoch_train_loss=2.6143740530339605
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 2.6137549517002743
197, epoch_train_loss=2.6137549517002743
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 2.6131042008162275
198, epoch_train_loss=2.6131042008162275
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 2.612485120026359
199, epoch_train_loss=2.612485120026359
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 2.611894327796082
200, epoch_train_loss=2.611894327796082
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 2.61157878268455
201, epoch_train_loss=2.61157878268455
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 2.6128680301374057
202, epoch_train_loss=2.6128680301374057
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 2.6229130742475415
203, epoch_train_loss=2.6229130742475415
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 2.671552348538442
204, epoch_train_loss=2.671552348538442
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 2.821797186354473
205, epoch_train_loss=2.821797186354473
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 2.781767238176511
206, epoch_train_loss=2.781767238176511
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 2.674169152240632
207, epoch_train_loss=2.674169152240632
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 2.6302255878147216
208, epoch_train_loss=2.6302255878147216
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 2.704510834748593
209, epoch_train_loss=2.704510834748593
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 2.6236057498142036
210, epoch_train_loss=2.6236057498142036
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 2.6652532222441048
211, epoch_train_loss=2.6652532222441048
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 2.6215007268641375
212, epoch_train_loss=2.6215007268641375
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 2.6522399212269496
213, epoch_train_loss=2.6522399212269496
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 2.625177119023756
214, epoch_train_loss=2.625177119023756
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 2.6485940631536145
215, epoch_train_loss=2.6485940631536145
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 2.6183056144033574
216, epoch_train_loss=2.6183056144033574
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 2.6440566545912527
217, epoch_train_loss=2.6440566545912527
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 2.6170224185911652
218, epoch_train_loss=2.6170224185911652
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 2.635337397690582
219, epoch_train_loss=2.635337397690582
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 2.619303253593926
220, epoch_train_loss=2.619303253593926
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 2.627024216320614
221, epoch_train_loss=2.627024216320614
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 2.619985683417335
222, epoch_train_loss=2.619985683417335
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 2.6207902921711903
223, epoch_train_loss=2.6207902921711903
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 2.621484737772555
224, epoch_train_loss=2.621484737772555
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 2.615094530159498
225, epoch_train_loss=2.615094530159498
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 2.61975994509055
226, epoch_train_loss=2.61975994509055
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 2.61202168657993
227, epoch_train_loss=2.61202168657993
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 2.617143288013551
228, epoch_train_loss=2.617143288013551
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 2.6086449796785476
229, epoch_train_loss=2.6086449796785476
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 2.61403277212851
230, epoch_train_loss=2.61403277212851
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 2.6064864487656556
231, epoch_train_loss=2.6064864487656556
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 2.6107130329892057
232, epoch_train_loss=2.6107130329892057
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 2.6044504331790117
233, epoch_train_loss=2.6044504331790117
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 2.607613517980483
234, epoch_train_loss=2.607613517980483
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 2.6030270788503675
235, epoch_train_loss=2.6030270788503675
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 2.6041291032012843
236, epoch_train_loss=2.6041291032012843
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 2.601848914050951
237, epoch_train_loss=2.601848914050951
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 2.6000060852342965
238, epoch_train_loss=2.6000060852342965
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 2.6007549749800662
239, epoch_train_loss=2.6007549749800662
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 2.5962957981241654
240, epoch_train_loss=2.5962957981241654
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 2.598272089486554
241, epoch_train_loss=2.598272089486554
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 2.59462216037106
242, epoch_train_loss=2.59462216037106
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 2.593205974035662
243, epoch_train_loss=2.593205974035662
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 2.593923131873184
244, epoch_train_loss=2.593923131873184
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 2.590111987805976
245, epoch_train_loss=2.590111987805976
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 2.5889176763783324
246, epoch_train_loss=2.5889176763783324
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 2.5894285009924745
247, epoch_train_loss=2.5894285009924745
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 2.5867982224726647
248, epoch_train_loss=2.5867982224726647
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 2.5837815672961635
249, epoch_train_loss=2.5837815672961635
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 2.5833782569369217
250, epoch_train_loss=2.5833782569369217
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 2.583604023844039
251, epoch_train_loss=2.583604023844039
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 2.5822209441021915
252, epoch_train_loss=2.5822209441021915
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 2.580607309438392
253, epoch_train_loss=2.580607309438392
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 2.5807420750266266
254, epoch_train_loss=2.5807420750266266
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 2.583325297739279
255, epoch_train_loss=2.583325297739279
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 2.5778972437313596
256, epoch_train_loss=2.5778972437313596
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 2.5725486197891456
257, epoch_train_loss=2.5725486197891456
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 2.5750236417457018
258, epoch_train_loss=2.5750236417457018
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 2.58307959234086
259, epoch_train_loss=2.58307959234086
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 2.6254149617092466
260, epoch_train_loss=2.6254149617092466
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 2.81367897202441
261, epoch_train_loss=2.81367897202441
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 2.9032002318696835
262, epoch_train_loss=2.9032002318696835
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 2.995830664813578
263, epoch_train_loss=2.995830664813578
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 2.616053121516496
264, epoch_train_loss=2.616053121516496
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 3.077623947079022
265, epoch_train_loss=3.077623947079022
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 2.6382122843117983
266, epoch_train_loss=2.6382122843117983
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 2.887987559681757
267, epoch_train_loss=2.887987559681757
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 2.6725681158047636
268, epoch_train_loss=2.6725681158047636
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 2.6619112512757894
269, epoch_train_loss=2.6619112512757894
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 2.7504215920425272
270, epoch_train_loss=2.7504215920425272
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 2.627481330636398
271, epoch_train_loss=2.627481330636398
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 2.7283600031729076
272, epoch_train_loss=2.7283600031729076
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 2.6956147145222698
273, epoch_train_loss=2.6956147145222698
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 2.6195448893782483
274, epoch_train_loss=2.6195448893782483
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 2.6585424040565293
275, epoch_train_loss=2.6585424040565293
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 2.6431025775152657
276, epoch_train_loss=2.6431025775152657
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 2.6123907698242776
277, epoch_train_loss=2.6123907698242776
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 2.6473499535488534
278, epoch_train_loss=2.6473499535488534
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 2.6416167983934056
279, epoch_train_loss=2.6416167983934056
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 2.6059332355104834
280, epoch_train_loss=2.6059332355104834
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 2.6236791939930555
281, epoch_train_loss=2.6236791939930555
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 2.6286310570101294
282, epoch_train_loss=2.6286310570101294
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 2.6013170762527054
283, epoch_train_loss=2.6013170762527054
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 2.613603977671048
284, epoch_train_loss=2.613603977671048
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 2.620163819732541
285, epoch_train_loss=2.620163819732541
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 2.6009038598483136
286, epoch_train_loss=2.6009038598483136
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 2.602752757845822
287, epoch_train_loss=2.602752757845822
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 2.6115593163177144
288, epoch_train_loss=2.6115593163177144
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 2.595879914625743
289, epoch_train_loss=2.595879914625743
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 2.5966221439469486
290, epoch_train_loss=2.5966221439469486
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 2.602908656254886
291, epoch_train_loss=2.602908656254886
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 2.5906751586098435
292, epoch_train_loss=2.5906751586098435
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 2.5900004661435743
293, epoch_train_loss=2.5900004661435743
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 2.593797802658783
294, epoch_train_loss=2.593797802658783
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 2.5829912636133927
295, epoch_train_loss=2.5829912636133927
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 2.5857086224800576
296, epoch_train_loss=2.5857086224800576
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 2.585206450210481
297, epoch_train_loss=2.585206450210481
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 2.5773055225637065
298, epoch_train_loss=2.5773055225637065
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 2.581284832008792
299, epoch_train_loss=2.581284832008792
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 2.5761796999457394
300, epoch_train_loss=2.5761796999457394
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 2.574104012695228
301, epoch_train_loss=2.574104012695228
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 2.5754350028248525
302, epoch_train_loss=2.5754350028248525
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 2.5691380841532028
303, epoch_train_loss=2.5691380841532028
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 2.5712619752461623
304, epoch_train_loss=2.5712619752461623
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 2.566620230460389
305, epoch_train_loss=2.566620230460389
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 2.5661181156080253
306, epoch_train_loss=2.5661181156080253
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 2.5645267430422414
307, epoch_train_loss=2.5645267430422414
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 2.561444811587035
308, epoch_train_loss=2.561444811587035
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 2.5616627089084734
309, epoch_train_loss=2.5616627089084734
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 2.557942402171837
310, epoch_train_loss=2.557942402171837
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 2.5585450358183492
311, epoch_train_loss=2.5585450358183492
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 2.554714103541984
312, epoch_train_loss=2.554714103541984
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 2.555206176782292
313, epoch_train_loss=2.555206176782292
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 2.55178972512135
314, epoch_train_loss=2.55178972512135
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 2.5519374756209157
315, epoch_train_loss=2.5519374756209157
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 2.5489166097359885
316, epoch_train_loss=2.5489166097359885
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 2.5487607924954703
317, epoch_train_loss=2.5487607924954703
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 2.5462184620891386
318, epoch_train_loss=2.5462184620891386
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 2.5455698758547785
319, epoch_train_loss=2.5455698758547785
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 2.5437649115186383
320, epoch_train_loss=2.5437649115186383
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 2.5422718607453816
321, epoch_train_loss=2.5422718607453816
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 2.5414956865846876
322, epoch_train_loss=2.5414956865846876
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 2.539331120515503
323, epoch_train_loss=2.539331120515503
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 2.5389738283790653
324, epoch_train_loss=2.5389738283790653
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 2.537141357510125
325, epoch_train_loss=2.537141357510125
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 2.535929058330979
326, epoch_train_loss=2.535929058330979
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 2.535187705472891
327, epoch_train_loss=2.535187705472891
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 2.5333553908609105
328, epoch_train_loss=2.5333553908609105
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 2.5324493151062133
329, epoch_train_loss=2.5324493151062133
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 2.531563003350941
330, epoch_train_loss=2.531563003350941
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 2.5299953610155743
331, epoch_train_loss=2.5299953610155743
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 2.528914718660258
332, epoch_train_loss=2.528914718660258
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 2.528194293381925
333, epoch_train_loss=2.528194293381925
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 2.527002313468556
334, epoch_train_loss=2.527002313468556
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 2.5256111591985997
335, epoch_train_loss=2.5256111591985997
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 2.524734983928746
336, epoch_train_loss=2.524734983928746
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 2.5240287907626686
337, epoch_train_loss=2.5240287907626686
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 2.523049887438035
338, epoch_train_loss=2.523049887438035
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 2.521887563483896
339, epoch_train_loss=2.521887563483896
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 2.520753484362552
340, epoch_train_loss=2.520753484362552
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 2.5197641566098468
341, epoch_train_loss=2.5197641566098468
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 2.518944511187284
342, epoch_train_loss=2.518944511187284
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 2.5182454622539967
343, epoch_train_loss=2.5182454622539967
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 2.5177408391793015
344, epoch_train_loss=2.5177408391793015
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 2.5176550943787657
345, epoch_train_loss=2.5176550943787657
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 2.5190355582651875
346, epoch_train_loss=2.5190355582651875
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 2.5240355792750595
347, epoch_train_loss=2.5240355792750595
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 2.5455549120912044
348, epoch_train_loss=2.5455549120912044
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 2.595048667073967
349, epoch_train_loss=2.595048667073967
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 2.7931073444055
350, epoch_train_loss=2.7931073444055
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 2.593179403127474
351, epoch_train_loss=2.593179403127474
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 2.5255658342222422
352, epoch_train_loss=2.5255658342222422
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 2.5204467293219417
353, epoch_train_loss=2.5204467293219417
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 2.561024805778794
354, epoch_train_loss=2.561024805778794
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 2.6125498063049366
355, epoch_train_loss=2.6125498063049366
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 2.528329230831153
356, epoch_train_loss=2.528329230831153
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 2.52627287168527
357, epoch_train_loss=2.52627287168527
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 2.5793912723887433
358, epoch_train_loss=2.5793912723887433
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 2.531984375039214
359, epoch_train_loss=2.531984375039214
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 2.5145484843355446
360, epoch_train_loss=2.5145484843355446
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 2.541863479802114
361, epoch_train_loss=2.541863479802114
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 2.5262663987119547
362, epoch_train_loss=2.5262663987119547
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 2.511651211777296
363, epoch_train_loss=2.511651211777296
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 2.523362982057444
364, epoch_train_loss=2.523362982057444
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 2.5213859281094684
365, epoch_train_loss=2.5213859281094684
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 2.5110328904180523
366, epoch_train_loss=2.5110328904180523
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 2.5137304828858125
367, epoch_train_loss=2.5137304828858125
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 2.5175163054148557
368, epoch_train_loss=2.5175163054148557
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 2.511969405240489
369, epoch_train_loss=2.511969405240489
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 2.508856385755694
370, epoch_train_loss=2.508856385755694
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 2.5133943675900734
371, epoch_train_loss=2.5133943675900734
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 2.5128821111846738
372, epoch_train_loss=2.5128821111846738
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 2.5069053351417754
373, epoch_train_loss=2.5069053351417754
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 2.5086054369416213
374, epoch_train_loss=2.5086054369416213
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 2.511650041978692
375, epoch_train_loss=2.511650041978692
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 2.5069433208022094
376, epoch_train_loss=2.5069433208022094
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 2.5040274664713262
377, epoch_train_loss=2.5040274664713262
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 2.5061485128349443
378, epoch_train_loss=2.5061485128349443
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 2.506783492894805
379, epoch_train_loss=2.506783492894805
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 2.504344152215038
380, epoch_train_loss=2.504344152215038
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 2.50140419698215
381, epoch_train_loss=2.50140419698215
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 2.5011030852038343
382, epoch_train_loss=2.5011030852038343
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 2.502340657998294
383, epoch_train_loss=2.502340657998294
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 2.502360078411431
384, epoch_train_loss=2.502360078411431
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 2.501139241541005
385, epoch_train_loss=2.501139241541005
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 2.498823515612614
386, epoch_train_loss=2.498823515612614
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 2.496798765466308
387, epoch_train_loss=2.496798765466308
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 2.495181332079361
388, epoch_train_loss=2.495181332079361
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 2.493848118763313
389, epoch_train_loss=2.493848118763313
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 2.492680247662222
390, epoch_train_loss=2.492680247662222
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 2.491590227542799
391, epoch_train_loss=2.491590227542799
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 2.4907007712321327
392, epoch_train_loss=2.4907007712321327
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 2.490847837678744
393, epoch_train_loss=2.490847837678744
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 2.496679838628578
394, epoch_train_loss=2.496679838628578
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 2.532703816482202
395, epoch_train_loss=2.532703816482202
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 2.743643760400544
396, epoch_train_loss=2.743643760400544
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 2.8174703896190074
397, epoch_train_loss=2.8174703896190074
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 3.124498877308732
398, epoch_train_loss=3.124498877308732
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 2.723884534591278
399, epoch_train_loss=2.723884534591278
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 3.5408866403888224
400, epoch_train_loss=3.5408866403888224
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 2.92047201318094
401, epoch_train_loss=2.92047201318094
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 3.309889725701295
402, epoch_train_loss=3.309889725701295
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 3.0668392695417017
403, epoch_train_loss=3.0668392695417017
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 2.720948312197844
404, epoch_train_loss=2.720948312197844
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 2.8347292533696438
405, epoch_train_loss=2.8347292533696438
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 2.885765560159867
406, epoch_train_loss=2.885765560159867
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 2.640584063480382
407, epoch_train_loss=2.640584063480382
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 2.7184990176149695
408, epoch_train_loss=2.7184990176149695
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 2.8469682274301977
409, epoch_train_loss=2.8469682274301977
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 3.166186786637525
410, epoch_train_loss=3.166186786637525
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 2.7138645801115726
411, epoch_train_loss=2.7138645801115726
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 2.739967265039403
412, epoch_train_loss=2.739967265039403
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 2.7888717892655484
413, epoch_train_loss=2.7888717892655484
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 2.761015382967762
414, epoch_train_loss=2.761015382967762
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 2.687438014117038
415, epoch_train_loss=2.687438014117038
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 2.733527163529142
416, epoch_train_loss=2.733527163529142
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 2.7429299485312435
417, epoch_train_loss=2.7429299485312435
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 2.741900848531765
418, epoch_train_loss=2.741900848531765
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 2.6947326468669295
419, epoch_train_loss=2.6947326468669295
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 2.6673271065791
420, epoch_train_loss=2.6673271065791
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 2.6741684950251963
421, epoch_train_loss=2.6741684950251963
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 2.6906277768480282
422, epoch_train_loss=2.6906277768480282
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 2.6628517325972965
423, epoch_train_loss=2.6628517325972965
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 2.6340439594989347
424, epoch_train_loss=2.6340439594989347
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 2.636030173971648
425, epoch_train_loss=2.636030173971648
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 2.644461676604363
426, epoch_train_loss=2.644461676604363
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 2.634777821489473
427, epoch_train_loss=2.634777821489473
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 2.611860074491744
428, epoch_train_loss=2.611860074491744
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 2.606941054373161
429, epoch_train_loss=2.606941054373161
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 2.6088739225678013
430, epoch_train_loss=2.6088739225678013
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 2.609557699638682
431, epoch_train_loss=2.609557699638682
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 2.5924757599018453
432, epoch_train_loss=2.5924757599018453
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 2.5916948880173347
433, epoch_train_loss=2.5916948880173347
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 2.5972288281864078
434, epoch_train_loss=2.5972288281864078
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 2.59941353113408
435, epoch_train_loss=2.59941353113408
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 2.590808543659217
436, epoch_train_loss=2.590808543659217
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 2.580251484905909
437, epoch_train_loss=2.580251484905909
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 2.5841448426327855
438, epoch_train_loss=2.5841448426327855
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 2.5819103070095606
439, epoch_train_loss=2.5819103070095606
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 2.5735483718290872
440, epoch_train_loss=2.5735483718290872
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 2.585202672925283
441, epoch_train_loss=2.585202672925283
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 2.576855720305295
442, epoch_train_loss=2.576855720305295
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 2.574200578334791
443, epoch_train_loss=2.574200578334791
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 2.5822830257309723
444, epoch_train_loss=2.5822830257309723
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 2.5653593601428986
445, epoch_train_loss=2.5653593601428986
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 2.570527636470379
446, epoch_train_loss=2.570527636470379
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 2.5660341474129535
447, epoch_train_loss=2.5660341474129535
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 2.562377664682514
448, epoch_train_loss=2.562377664682514
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 2.564716522487867
449, epoch_train_loss=2.564716522487867
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 2.5612124071631546
450, epoch_train_loss=2.5612124071631546
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 2.557193695239205
451, epoch_train_loss=2.557193695239205
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 2.5554697401791016
452, epoch_train_loss=2.5554697401791016
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 2.5549060894690836
453, epoch_train_loss=2.5549060894690836
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 2.548379026307634
454, epoch_train_loss=2.548379026307634
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 2.546883165242989
455, epoch_train_loss=2.546883165242989
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 2.5477874154818885
456, epoch_train_loss=2.5477874154818885
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 2.5489368347045223
457, epoch_train_loss=2.5489368347045223
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 2.5447440244264024
458, epoch_train_loss=2.5447440244264024
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 2.549086537052139
459, epoch_train_loss=2.549086537052139
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 2.55162439196376
460, epoch_train_loss=2.55162439196376
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 2.5559024097978753
461, epoch_train_loss=2.5559024097978753
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 2.5609241408188903
462, epoch_train_loss=2.5609241408188903
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 2.5446253323931884
463, epoch_train_loss=2.5446253323931884
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 2.5306997663305437
464, epoch_train_loss=2.5306997663305437
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 2.5461127093579257
465, epoch_train_loss=2.5461127093579257
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 2.530771473968613
466, epoch_train_loss=2.530771473968613
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 2.5264838576213
467, epoch_train_loss=2.5264838576213
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 2.5255732466500462
468, epoch_train_loss=2.5255732466500462
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 2.5243573386060816
469, epoch_train_loss=2.5243573386060816
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 2.521906659894165
470, epoch_train_loss=2.521906659894165
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 2.521469592786684
471, epoch_train_loss=2.521469592786684
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 2.5202437135853737
472, epoch_train_loss=2.5202437135853737
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 2.5175775243066387
473, epoch_train_loss=2.5175775243066387
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 2.515126127104727
474, epoch_train_loss=2.515126127104727
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 2.5142882102094934
475, epoch_train_loss=2.5142882102094934
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 2.5122160259700026
476, epoch_train_loss=2.5122160259700026
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 2.511445953089875
477, epoch_train_loss=2.511445953089875
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 2.5099061995487437
478, epoch_train_loss=2.5099061995487437
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 2.507738826959918
479, epoch_train_loss=2.507738826959918
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 2.5069213702677917
480, epoch_train_loss=2.5069213702677917
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 2.5053803445167175
481, epoch_train_loss=2.5053803445167175
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 2.504635779419851
482, epoch_train_loss=2.504635779419851
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 2.504370184844259
483, epoch_train_loss=2.504370184844259
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 2.503141730653606
484, epoch_train_loss=2.503141730653606
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 2.502713551036024
485, epoch_train_loss=2.502713551036024
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 2.5028484454108866
486, epoch_train_loss=2.5028484454108866
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 2.5022713223603
487, epoch_train_loss=2.5022713223603
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 2.501428031091176
488, epoch_train_loss=2.501428031091176
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 2.500904224245734
489, epoch_train_loss=2.500904224245734
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 2.500563977480887
490, epoch_train_loss=2.500563977480887
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 2.4996125796803503
491, epoch_train_loss=2.4996125796803503
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 2.4985874956966465
492, epoch_train_loss=2.4985874956966465
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 2.498031714776334
493, epoch_train_loss=2.498031714776334
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 2.4974590760020483
494, epoch_train_loss=2.4974590760020483
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 2.4967089081183245
495, epoch_train_loss=2.4967089081183245
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 2.495829050526685
496, epoch_train_loss=2.495829050526685
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 2.4951449159610153
497, epoch_train_loss=2.4951449159610153
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 2.4945241198337205
498, epoch_train_loss=2.4945241198337205
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 2.493841834994686
499, epoch_train_loss=2.493841834994686
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 2.4930468577360565
500, epoch_train_loss=2.4930468577360565
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 2.492283555032076
501, epoch_train_loss=2.492283555032076
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 2.4915678237910255
502, epoch_train_loss=2.4915678237910255
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 2.490837684464792
503, epoch_train_loss=2.490837684464792
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 2.4901497284477987
504, epoch_train_loss=2.4901497284477987
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 2.489484798962896
505, epoch_train_loss=2.489484798962896
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 2.4888208289316025
506, epoch_train_loss=2.4888208289316025
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 2.4880571744317206
507, epoch_train_loss=2.4880571744317206
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 2.4872953882382984
508, epoch_train_loss=2.4872953882382984
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 2.4865437454666726
509, epoch_train_loss=2.4865437454666726
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 2.4857707673776948
510, epoch_train_loss=2.4857707673776948
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 2.485001861222959
511, epoch_train_loss=2.485001861222959
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 2.4842745675593934
512, epoch_train_loss=2.4842745675593934
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 2.483639628063133
513, epoch_train_loss=2.483639628063133
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 2.4832631805217265
514, epoch_train_loss=2.4832631805217265
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 2.483636720276045
515, epoch_train_loss=2.483636720276045
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 2.4862321139446295
516, epoch_train_loss=2.4862321139446295
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 2.493994229874718
517, epoch_train_loss=2.493994229874718
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 2.518078411611918
518, epoch_train_loss=2.518078411611918
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 2.5614730105967913
519, epoch_train_loss=2.5614730105967913
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 2.6567630075475375
520, epoch_train_loss=2.6567630075475375
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 2.588188029611987
521, epoch_train_loss=2.588188029611987
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 2.5108099082951285
522, epoch_train_loss=2.5108099082951285
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 2.4832869631996055
523, epoch_train_loss=2.4832869631996055
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 2.5350315927635547
524, epoch_train_loss=2.5350315927635547
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 2.513600876935783
525, epoch_train_loss=2.513600876935783
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 2.4842472455127727
526, epoch_train_loss=2.4842472455127727
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 2.526966091244806
527, epoch_train_loss=2.526966091244806
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 2.485269288037478
528, epoch_train_loss=2.485269288037478
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 2.495557952290874
529, epoch_train_loss=2.495557952290874
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 2.4938231936702486
530, epoch_train_loss=2.4938231936702486
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 2.4736540949972117
531, epoch_train_loss=2.4736540949972117
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 2.491731991569759
532, epoch_train_loss=2.491731991569759
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 2.4673088697645174
533, epoch_train_loss=2.4673088697645174
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 2.4841828407373545
534, epoch_train_loss=2.4841828407373545
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 2.468931105186117
535, epoch_train_loss=2.468931105186117
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 2.4698588357843976
536, epoch_train_loss=2.4698588357843976
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 2.4705785495908805
537, epoch_train_loss=2.4705785495908805
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 2.457101050293081
538, epoch_train_loss=2.457101050293081
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 2.465961485719318
539, epoch_train_loss=2.465961485719318
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 2.452309761617582
540, epoch_train_loss=2.452309761617582
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 2.454571558801789
541, epoch_train_loss=2.454571558801789
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 2.451875620686125
542, epoch_train_loss=2.451875620686125
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 2.4418048486833035
543, epoch_train_loss=2.4418048486833035
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 2.445928677656139
544, epoch_train_loss=2.445928677656139
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 2.4358337061110222
545, epoch_train_loss=2.4358337061110222
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 2.4311166745937283
546, epoch_train_loss=2.4311166745937283
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 2.4304056550862896
547, epoch_train_loss=2.4304056550862896
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 2.4191762460701938
548, epoch_train_loss=2.4191762460701938
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 2.415863513696918
549, epoch_train_loss=2.415863513696918
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 2.4109654390593875
550, epoch_train_loss=2.4109654390593875
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 2.400333951817945
551, epoch_train_loss=2.400333951817945
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 2.3959374766601758
552, epoch_train_loss=2.3959374766601758
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 2.3897455730745065
553, epoch_train_loss=2.3897455730745065
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 2.379594599057326
554, epoch_train_loss=2.379594599057326
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 2.3730678977784723
555, epoch_train_loss=2.3730678977784723
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 2.366045342743096
556, epoch_train_loss=2.366045342743096
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 2.3551368174966716
557, epoch_train_loss=2.3551368174966716
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 2.344867119181112
558, epoch_train_loss=2.344867119181112
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 2.3364192621685285
559, epoch_train_loss=2.3364192621685285
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 2.329625897814868
560, epoch_train_loss=2.329625897814868
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 2.3231287337295417
561, epoch_train_loss=2.3231287337295417
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 2.317278386737552
562, epoch_train_loss=2.317278386737552
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 2.31750421666664
563, epoch_train_loss=2.31750421666664
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 2.34778378020784
564, epoch_train_loss=2.34778378020784
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 2.4785552232531938
565, epoch_train_loss=2.4785552232531938
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 2.7983219423683408
566, epoch_train_loss=2.7983219423683408
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 2.587682780824958
567, epoch_train_loss=2.587682780824958
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 2.404980402333826
568, epoch_train_loss=2.404980402333826
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 2.678269237653735
569, epoch_train_loss=2.678269237653735
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 2.3315324288385777
570, epoch_train_loss=2.3315324288385777
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 2.530321591404825
571, epoch_train_loss=2.530321591404825
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 2.363404122084067
572, epoch_train_loss=2.363404122084067
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 2.4786525597743245
573, epoch_train_loss=2.4786525597743245
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 2.3918180065449284
574, epoch_train_loss=2.3918180065449284
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 2.3549046224029424
575, epoch_train_loss=2.3549046224029424
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 2.4201615152256775
576, epoch_train_loss=2.4201615152256775
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 2.3285043375819723
577, epoch_train_loss=2.3285043375819723
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 2.360044418428933
578, epoch_train_loss=2.360044418428933
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 2.3603909616377297
579, epoch_train_loss=2.3603909616377297
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 2.2958275056818493
580, epoch_train_loss=2.2958275056818493
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 2.3067629787374107
581, epoch_train_loss=2.3067629787374107
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 2.3079098682506993
582, epoch_train_loss=2.3079098682506993
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 2.2669071562498666
583, epoch_train_loss=2.2669071562498666
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 2.2801364319734883
584, epoch_train_loss=2.2801364319734883
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 2.2884339834097194
585, epoch_train_loss=2.2884339834097194
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 2.257360843941269
586, epoch_train_loss=2.257360843941269
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 2.2514273945365226
587, epoch_train_loss=2.2514273945365226
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 2.255035666413275
588, epoch_train_loss=2.255035666413275
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 2.2479838715993825
589, epoch_train_loss=2.2479838715993825
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 2.246273878309568
590, epoch_train_loss=2.246273878309568
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 2.2680203560189196
591, epoch_train_loss=2.2680203560189196
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 2.3113102761979736
592, epoch_train_loss=2.3113102761979736
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 2.6692364575534886
593, epoch_train_loss=2.6692364575534886
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 2.555678458220792
594, epoch_train_loss=2.555678458220792
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 2.586851819902278
595, epoch_train_loss=2.586851819902278
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 2.6139590382394426
596, epoch_train_loss=2.6139590382394426
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 2.7123926355432784
597, epoch_train_loss=2.7123926355432784
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 2.499106697170738
598, epoch_train_loss=2.499106697170738
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 2.54157571223145
599, epoch_train_loss=2.54157571223145
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 2.425024892894833
600, epoch_train_loss=2.425024892894833
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 2.562477179585626
601, epoch_train_loss=2.562477179585626
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 2.4393746679430004
602, epoch_train_loss=2.4393746679430004
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 2.356005747412139
603, epoch_train_loss=2.356005747412139
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 2.45541934646771
604, epoch_train_loss=2.45541934646771
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 2.3666682701796975
605, epoch_train_loss=2.3666682701796975
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 2.350196126930516
606, epoch_train_loss=2.350196126930516
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 2.3955509161771964
607, epoch_train_loss=2.3955509161771964
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 2.3449316293249676
608, epoch_train_loss=2.3449316293249676
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 2.292402812101978
609, epoch_train_loss=2.292402812101978
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 2.3056493674122303
610, epoch_train_loss=2.3056493674122303
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 2.3317838290876436
611, epoch_train_loss=2.3317838290876436
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 2.31863903259231
612, epoch_train_loss=2.31863903259231
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 2.2728185721955168
613, epoch_train_loss=2.2728185721955168
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 2.27749116670011
614, epoch_train_loss=2.27749116670011
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 2.280491378369424
615, epoch_train_loss=2.280491378369424
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 2.2833435587878044
616, epoch_train_loss=2.2833435587878044
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 2.253286612931686
617, epoch_train_loss=2.253286612931686
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 2.2580180748632754
618, epoch_train_loss=2.2580180748632754
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 2.254084359672756
619, epoch_train_loss=2.254084359672756
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 2.230784428730994
620, epoch_train_loss=2.230784428730994
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 2.2485633960009896
621, epoch_train_loss=2.2485633960009896
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 2.2376316716844067
622, epoch_train_loss=2.2376316716844067
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 2.2210553517730176
623, epoch_train_loss=2.2210553517730176
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 2.2254802470123387
624, epoch_train_loss=2.2254802470123387
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 2.2237446029137886
625, epoch_train_loss=2.2237446029137886
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 2.214350145736623
626, epoch_train_loss=2.214350145736623
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 2.2074703277915253
627, epoch_train_loss=2.2074703277915253
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 2.207604420845175
628, epoch_train_loss=2.207604420845175
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 2.2229421192210324
629, epoch_train_loss=2.2229421192210324
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 2.2458981118485184
630, epoch_train_loss=2.2458981118485184
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 2.3430141168447913
631, epoch_train_loss=2.3430141168447913
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 2.2750949526721054
632, epoch_train_loss=2.2750949526721054
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 2.2588154898093347
633, epoch_train_loss=2.2588154898093347
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 2.189108948141712
634, epoch_train_loss=2.189108948141712
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 2.176397368211363
635, epoch_train_loss=2.176397368211363
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 2.213166866267248
636, epoch_train_loss=2.213166866267248
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 2.2756239227947685
637, epoch_train_loss=2.2756239227947685
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 2.4334598538546857
638, epoch_train_loss=2.4334598538546857
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 2.1931352176617938
639, epoch_train_loss=2.1931352176617938
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 2.318132559029417
640, epoch_train_loss=2.318132559029417
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 2.4879874687811143
641, epoch_train_loss=2.4879874687811143
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 2.255381994741561
642, epoch_train_loss=2.255381994741561
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 2.7738502364256545
643, epoch_train_loss=2.7738502364256545
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 2.405303962817192
644, epoch_train_loss=2.405303962817192
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 2.580589566365183
645, epoch_train_loss=2.580589566365183
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 2.3182966436261045
646, epoch_train_loss=2.3182966436261045
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 2.405781237969926
647, epoch_train_loss=2.405781237969926
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 2.3987634949713144
648, epoch_train_loss=2.3987634949713144
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 2.252117143227249
649, epoch_train_loss=2.252117143227249
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 2.406475583275151
650, epoch_train_loss=2.406475583275151
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 2.273959047428163
651, epoch_train_loss=2.273959047428163
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 2.3020799011745403
652, epoch_train_loss=2.3020799011745403
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 2.346735777617119
653, epoch_train_loss=2.346735777617119
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 2.2496353184548177
654, epoch_train_loss=2.2496353184548177
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 2.3085548406682417
655, epoch_train_loss=2.3085548406682417
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 2.296663344567907
656, epoch_train_loss=2.296663344567907
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 2.256591471582458
657, epoch_train_loss=2.256591471582458
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 2.261606487814154
658, epoch_train_loss=2.261606487814154
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 2.2638845197616844
659, epoch_train_loss=2.2638845197616844
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 2.2273279390571834
660, epoch_train_loss=2.2273279390571834
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 2.2585826033644913
661, epoch_train_loss=2.2585826033644913
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 2.222189134540599
662, epoch_train_loss=2.222189134540599
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 2.212828396617063
663, epoch_train_loss=2.212828396617063
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 2.231350996063418
664, epoch_train_loss=2.231350996063418
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 2.200865040246543
665, epoch_train_loss=2.200865040246543
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 2.2048378034782448
666, epoch_train_loss=2.2048378034782448
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 2.2031027366887126
667, epoch_train_loss=2.2031027366887126
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 2.1798702992095844
668, epoch_train_loss=2.1798702992095844
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 2.1914319865455023
669, epoch_train_loss=2.1914319865455023
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 2.17467932793408
670, epoch_train_loss=2.17467932793408
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 2.181200617634868
671, epoch_train_loss=2.181200617634868
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 2.159573704446592
672, epoch_train_loss=2.159573704446592
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 2.17199743222307
673, epoch_train_loss=2.17199743222307
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 2.1543138932299732
674, epoch_train_loss=2.1543138932299732
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 2.157733430581705
675, epoch_train_loss=2.157733430581705
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 2.1464429205435565
676, epoch_train_loss=2.1464429205435565
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 2.151588082231878
677, epoch_train_loss=2.151588082231878
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 2.1405586216816794
678, epoch_train_loss=2.1405586216816794
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 2.1402510721219254
679, epoch_train_loss=2.1402510721219254
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 2.1391740709127114
680, epoch_train_loss=2.1391740709127114
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 2.127479339800707
681, epoch_train_loss=2.127479339800707
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 2.1313678869810513
682, epoch_train_loss=2.1313678869810513
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 2.125722707581633
683, epoch_train_loss=2.125722707581633
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 2.117653397410682
684, epoch_train_loss=2.117653397410682
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 2.1201809365458297
685, epoch_train_loss=2.1201809365458297
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 2.117892765106165
686, epoch_train_loss=2.117892765106165
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 2.110051645396177
687, epoch_train_loss=2.110051645396177
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 2.105294522938392
688, epoch_train_loss=2.105294522938392
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 2.1065882949278225
689, epoch_train_loss=2.1065882949278225
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 2.1071514107129143
690, epoch_train_loss=2.1071514107129143
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 2.101267366088585
691, epoch_train_loss=2.101267366088585
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 2.0945193230617125
692, epoch_train_loss=2.0945193230617125
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 2.0896080302064433
693, epoch_train_loss=2.0896080302064433
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 2.086285056954481
694, epoch_train_loss=2.086285056954481
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 2.085344821529892
695, epoch_train_loss=2.085344821529892
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 2.0870894734424033
696, epoch_train_loss=2.0870894734424033
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 2.094951390443082
697, epoch_train_loss=2.094951390443082
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 2.1135992236681793
698, epoch_train_loss=2.1135992236681793
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 2.1617033675494515
699, epoch_train_loss=2.1617033675494515
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 2.1872968546598863
700, epoch_train_loss=2.1872968546598863
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 2.2261722340767953
701, epoch_train_loss=2.2261722340767953
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 2.121173041523417
702, epoch_train_loss=2.121173041523417
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 2.0652941215747704
703, epoch_train_loss=2.0652941215747704
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 2.09436924264104
704, epoch_train_loss=2.09436924264104
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 2.1532118488403316
705, epoch_train_loss=2.1532118488403316
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 2.1808383120485675
706, epoch_train_loss=2.1808383120485675
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 2.0901834028677073
707, epoch_train_loss=2.0901834028677073
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 2.0836017455086724
708, epoch_train_loss=2.0836017455086724
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 2.1619720416918073
709, epoch_train_loss=2.1619720416918073
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 2.135449955553629
710, epoch_train_loss=2.135449955553629
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 2.0767013031753314
711, epoch_train_loss=2.0767013031753314
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 2.05769422799292
712, epoch_train_loss=2.05769422799292
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 2.0993128025868653
713, epoch_train_loss=2.0993128025868653
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 2.1372441621524914
714, epoch_train_loss=2.1372441621524914
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 2.0791646691366608
715, epoch_train_loss=2.0791646691366608
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 2.0463555111237137
716, epoch_train_loss=2.0463555111237137
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 2.0609310869723703
717, epoch_train_loss=2.0609310869723703
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 2.096345641413145
718, epoch_train_loss=2.096345641413145
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 2.1307966869168737
719, epoch_train_loss=2.1307966869168737
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 2.103726098050236
720, epoch_train_loss=2.103726098050236
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 2.0616711216368624
721, epoch_train_loss=2.0616711216368624
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 2.030676633288035
722, epoch_train_loss=2.030676633288035
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 2.083470449173649
723, epoch_train_loss=2.083470449173649
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 2.2076189453818915
724, epoch_train_loss=2.2076189453818915
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 2.299537060396686
725, epoch_train_loss=2.299537060396686
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 2.3153604010433564
726, epoch_train_loss=2.3153604010433564
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 2.135224907519042
727, epoch_train_loss=2.135224907519042
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 2.4715882895278094
728, epoch_train_loss=2.4715882895278094
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 2.7093834368549
729, epoch_train_loss=2.7093834368549
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 2.3045124059793753
730, epoch_train_loss=2.3045124059793753
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 2.5283874000996325
731, epoch_train_loss=2.5283874000996325
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 2.6806292220234114
732, epoch_train_loss=2.6806292220234114
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 2.2686082862663213
733, epoch_train_loss=2.2686082862663213
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 2.534837708146585
734, epoch_train_loss=2.534837708146585
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 3.0605553904142675
735, epoch_train_loss=3.0605553904142675
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 2.1830724066385794
736, epoch_train_loss=2.1830724066385794
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 2.676778943803853
737, epoch_train_loss=2.676778943803853
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 2.5879880143689102
738, epoch_train_loss=2.5879880143689102
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 2.5573460075314354
739, epoch_train_loss=2.5573460075314354
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 2.4756548823577837
740, epoch_train_loss=2.4756548823577837
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 2.3295433479390906
741, epoch_train_loss=2.3295433479390906
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 2.2733252766227703
742, epoch_train_loss=2.2733252766227703
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 2.275186806530914
743, epoch_train_loss=2.275186806530914
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 2.2281416905870755
744, epoch_train_loss=2.2281416905870755
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 2.28667498293548
745, epoch_train_loss=2.28667498293548
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 2.2063823085128154
746, epoch_train_loss=2.2063823085128154
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 2.2778192462375593
747, epoch_train_loss=2.2778192462375593
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 2.208349363143755
748, epoch_train_loss=2.208349363143755
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 2.2447180394313064
749, epoch_train_loss=2.2447180394313064
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 2.2140937828612657
750, epoch_train_loss=2.2140937828612657
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 2.1775877618650425
751, epoch_train_loss=2.1775877618650425
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 2.2142412622015595
752, epoch_train_loss=2.2142412622015595
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 2.190576397803465
753, epoch_train_loss=2.190576397803465
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 2.2003263624108658
754, epoch_train_loss=2.2003263624108658
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 2.167064395383839
755, epoch_train_loss=2.167064395383839
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 2.147844369648215
756, epoch_train_loss=2.147844369648215
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 2.1688683803821096
757, epoch_train_loss=2.1688683803821096
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 2.141329960777523
758, epoch_train_loss=2.141329960777523
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 2.1393968706307844
759, epoch_train_loss=2.1393968706307844
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 2.1238682358675014
760, epoch_train_loss=2.1238682358675014
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 2.142207651363182
761, epoch_train_loss=2.142207651363182
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 2.124822210586762
762, epoch_train_loss=2.124822210586762
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 2.1182799286516016
763, epoch_train_loss=2.1182799286516016
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 2.1180681195831617
764, epoch_train_loss=2.1180681195831617
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 2.1184433597235164
765, epoch_train_loss=2.1184433597235164
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 2.106414457151468
766, epoch_train_loss=2.106414457151468
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 2.0995447840684336
767, epoch_train_loss=2.0995447840684336
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 2.097742362257232
768, epoch_train_loss=2.097742362257232
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 2.096756861771959
769, epoch_train_loss=2.096756861771959
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 2.086437823295837
770, epoch_train_loss=2.086437823295837
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 2.0845621637939917
771, epoch_train_loss=2.0845621637939917
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 2.078046864428548
772, epoch_train_loss=2.078046864428548
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 2.0810034325835187
773, epoch_train_loss=2.0810034325835187
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 2.0716428583064674
774, epoch_train_loss=2.0716428583064674
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 2.0662728912580905
775, epoch_train_loss=2.0662728912580905
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 2.066791062974775
776, epoch_train_loss=2.066791062974775
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 2.059823704205651
777, epoch_train_loss=2.059823704205651
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 2.058712405881201
778, epoch_train_loss=2.058712405881201
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 2.0519312670528564
779, epoch_train_loss=2.0519312670528564
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 2.05057519171238
780, epoch_train_loss=2.05057519171238
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 2.049460383801526
781, epoch_train_loss=2.049460383801526
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 2.044021107127168
782, epoch_train_loss=2.044021107127168
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 2.039521331340732
783, epoch_train_loss=2.039521331340732
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 2.0380670916501953
784, epoch_train_loss=2.0380670916501953
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 2.0337308410206285
785, epoch_train_loss=2.0337308410206285
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 2.0307484380365675
786, epoch_train_loss=2.0307484380365675
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 2.03317494259476
787, epoch_train_loss=2.03317494259476
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 2.038356520764989
788, epoch_train_loss=2.038356520764989
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 2.021673979516685
789, epoch_train_loss=2.021673979516685
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 2.021797557624235
790, epoch_train_loss=2.021797557624235
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 2.0175321889687483
791, epoch_train_loss=2.0175321889687483
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 2.0150187447269565
792, epoch_train_loss=2.0150187447269565
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 2.0109061518272187
793, epoch_train_loss=2.0109061518272187
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 2.0062989355300895
794, epoch_train_loss=2.0062989355300895
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 2.005996129049352
795, epoch_train_loss=2.005996129049352
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 2.002937978923575
796, epoch_train_loss=2.002937978923575
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 2.005719643914194
797, epoch_train_loss=2.005719643914194
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 2.0312952732000884
798, epoch_train_loss=2.0312952732000884
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 2.134157866833906
799, epoch_train_loss=2.134157866833906
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 2.663940501598431
800, epoch_train_loss=2.663940501598431
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 2.0354540977974986
801, epoch_train_loss=2.0354540977974986
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 2.77487417967201
802, epoch_train_loss=2.77487417967201
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 3.258071252054804
803, epoch_train_loss=3.258071252054804
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 3.529951511231795
804, epoch_train_loss=3.529951511231795
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 2.806468276583241
805, epoch_train_loss=2.806468276583241
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 2.782341503650461
806, epoch_train_loss=2.782341503650461
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 2.620898787774489
807, epoch_train_loss=2.620898787774489
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 3.3301770319582196
808, epoch_train_loss=3.3301770319582196
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 4.551355128861078
809, epoch_train_loss=4.551355128861078
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 3.690968016180147
810, epoch_train_loss=3.690968016180147
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 3.6426247342971494
811, epoch_train_loss=3.6426247342971494
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 3.2283763429007606
812, epoch_train_loss=3.2283763429007606
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 2.8393119831091904
813, epoch_train_loss=2.8393119831091904
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 2.859522880284268
814, epoch_train_loss=2.859522880284268
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 2.7662045372604505
815, epoch_train_loss=2.7662045372604505
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 2.867772211517805
816, epoch_train_loss=2.867772211517805
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 2.76913707559307
817, epoch_train_loss=2.76913707559307
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 2.8467767418616403
818, epoch_train_loss=2.8467767418616403
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 2.761533609024781
819, epoch_train_loss=2.761533609024781
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 2.8087220377920232
820, epoch_train_loss=2.8087220377920232
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 2.7055505337911367
821, epoch_train_loss=2.7055505337911367
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 2.7340503341622773
822, epoch_train_loss=2.7340503341622773
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 2.6572482614175787
823, epoch_train_loss=2.6572482614175787
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 2.6920654553945766
824, epoch_train_loss=2.6920654553945766
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 2.639226654379483
825, epoch_train_loss=2.639226654379483
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 2.6818446833607283
826, epoch_train_loss=2.6818446833607283
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 2.6475235260341683
827, epoch_train_loss=2.6475235260341683
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 2.6868786387009727
828, epoch_train_loss=2.6868786387009727
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 2.6490198735981183
829, epoch_train_loss=2.6490198735981183
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 2.6708839052847484
830, epoch_train_loss=2.6708839052847484
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 2.633115539584201
831, epoch_train_loss=2.633115539584201
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 2.6437702590559664
832, epoch_train_loss=2.6437702590559664
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 2.6136335616628776
833, epoch_train_loss=2.6136335616628776
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 2.608044554885254
834, epoch_train_loss=2.608044554885254
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 2.600791639273489
835, epoch_train_loss=2.600791639273489
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 2.5865741906525708
836, epoch_train_loss=2.5865741906525708
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 2.599965725107878
837, epoch_train_loss=2.599965725107878
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 2.582245160832905
838, epoch_train_loss=2.582245160832905
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 2.5916334258196736
839, epoch_train_loss=2.5916334258196736
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 2.577832658012625
840, epoch_train_loss=2.577832658012625
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 2.5672726901051193
841, epoch_train_loss=2.5672726901051193
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 2.5706112863323503
842, epoch_train_loss=2.5706112863323503
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 2.555397461123379
843, epoch_train_loss=2.555397461123379
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 2.550136348644566
844, epoch_train_loss=2.550136348644566
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 2.5553669802724785
845, epoch_train_loss=2.5553669802724785
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 2.5451582461612885
846, epoch_train_loss=2.5451582461612885
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 2.5351084118673444
847, epoch_train_loss=2.5351084118673444
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 2.5354396999491455
848, epoch_train_loss=2.5354396999491455
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 2.5333580866818894
849, epoch_train_loss=2.5333580866818894
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 2.527294675035612
850, epoch_train_loss=2.527294675035612
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 2.5133195443542307
851, epoch_train_loss=2.5133195443542307
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 2.50986077580605
852, epoch_train_loss=2.50986077580605
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 2.5111383000284975
853, epoch_train_loss=2.5111383000284975
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 2.512468752273995
854, epoch_train_loss=2.512468752273995
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 2.517978447065122
855, epoch_train_loss=2.517978447065122
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 2.5068321672379335
856, epoch_train_loss=2.5068321672379335
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 2.5013176245792854
857, epoch_train_loss=2.5013176245792854
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 2.4890443744324324
858, epoch_train_loss=2.4890443744324324
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 2.4806388270946536
859, epoch_train_loss=2.4806388270946536
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 2.4618924832588194
860, epoch_train_loss=2.4618924832588194
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 2.4489920168833814
861, epoch_train_loss=2.4489920168833814
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 2.442301079842332
862, epoch_train_loss=2.442301079842332
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 2.446215076562024
863, epoch_train_loss=2.446215076562024
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 2.464022175172205
864, epoch_train_loss=2.464022175172205
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 2.499924419276265
865, epoch_train_loss=2.499924419276265
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 2.5807923994983697
866, epoch_train_loss=2.5807923994983697
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 2.509095564013712
867, epoch_train_loss=2.509095564013712
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 2.4229726510503675
868, epoch_train_loss=2.4229726510503675
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 2.5066401730286447
869, epoch_train_loss=2.5066401730286447
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 2.55051398343498
870, epoch_train_loss=2.55051398343498
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 2.508193294230083
871, epoch_train_loss=2.508193294230083
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 2.417106024103071
872, epoch_train_loss=2.417106024103071
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 2.624407756205005
873, epoch_train_loss=2.624407756205005
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 2.603396652939018
874, epoch_train_loss=2.603396652939018
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 2.5851381210984865
875, epoch_train_loss=2.5851381210984865
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 2.4593256177850233
876, epoch_train_loss=2.4593256177850233
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 2.5846802399133506
877, epoch_train_loss=2.5846802399133506
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 2.4871106792429667
878, epoch_train_loss=2.4871106792429667
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 2.4679177059113218
879, epoch_train_loss=2.4679177059113218
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 2.52737068484291
880, epoch_train_loss=2.52737068484291
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 2.439398369355419
881, epoch_train_loss=2.439398369355419
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 2.5144778190011396
882, epoch_train_loss=2.5144778190011396
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 2.4282711173427862
883, epoch_train_loss=2.4282711173427862
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 2.397896729224404
884, epoch_train_loss=2.397896729224404
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 2.4261030075121686
885, epoch_train_loss=2.4261030075121686
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 2.433434835841261
886, epoch_train_loss=2.433434835841261
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 2.435808638680897
887, epoch_train_loss=2.435808638680897
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 2.378761722352994
888, epoch_train_loss=2.378761722352994
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 2.397951116634232
889, epoch_train_loss=2.397951116634232
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 2.383186225125343
890, epoch_train_loss=2.383186225125343
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 2.422233947464571
891, epoch_train_loss=2.422233947464571
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 2.3902546616525693
892, epoch_train_loss=2.3902546616525693
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 2.382242579962127
893, epoch_train_loss=2.382242579962127
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 2.368179564791609
894, epoch_train_loss=2.368179564791609
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 2.3615296061944413
895, epoch_train_loss=2.3615296061944413
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 2.3811247453848186
896, epoch_train_loss=2.3811247453848186
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 2.3592670180932185
897, epoch_train_loss=2.3592670180932185
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 2.362300323548894
898, epoch_train_loss=2.362300323548894
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 2.341081730066014
899, epoch_train_loss=2.341081730066014
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 2.3513036483647496
900, epoch_train_loss=2.3513036483647496
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 2.349827362186565
901, epoch_train_loss=2.349827362186565
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 2.3358769497762903
902, epoch_train_loss=2.3358769497762903
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 2.332517743241665
903, epoch_train_loss=2.332517743241665
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 2.3273732457260103
904, epoch_train_loss=2.3273732457260103
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 2.3246991936919437
905, epoch_train_loss=2.3246991936919437
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 2.3244836618947002
906, epoch_train_loss=2.3244836618947002
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 2.3133508453172094
907, epoch_train_loss=2.3133508453172094
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 2.310363766625911
908, epoch_train_loss=2.310363766625911
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 2.3114151953816764
909, epoch_train_loss=2.3114151953816764
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 2.3074998902408375
910, epoch_train_loss=2.3074998902408375
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 2.2974052807921903
911, epoch_train_loss=2.2974052807921903
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 2.2990252971832836
912, epoch_train_loss=2.2990252971832836
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 2.2954665905123126
913, epoch_train_loss=2.2954665905123126
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 2.29316174420267
914, epoch_train_loss=2.29316174420267
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 2.2863805041372505
915, epoch_train_loss=2.2863805041372505
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 2.2825533275923675
916, epoch_train_loss=2.2825533275923675
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 2.284781455131115
917, epoch_train_loss=2.284781455131115
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 2.2806738473955
918, epoch_train_loss=2.2806738473955
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 2.279394321020087
919, epoch_train_loss=2.279394321020087
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 2.279166605414073
920, epoch_train_loss=2.279166605414073
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 2.2762720728210506
921, epoch_train_loss=2.2762720728210506
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 2.274839483735963
922, epoch_train_loss=2.274839483735963
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 2.283278997207552
923, epoch_train_loss=2.283278997207552
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 2.2982970298332575
924, epoch_train_loss=2.2982970298332575
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 2.3722514825176524
925, epoch_train_loss=2.3722514825176524
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 2.4076742594027385
926, epoch_train_loss=2.4076742594027385
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 2.5960427942321878
927, epoch_train_loss=2.5960427942321878
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 2.2702679689113703
928, epoch_train_loss=2.2702679689113703
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 2.9304422008393813
929, epoch_train_loss=2.9304422008393813
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 3.01795383590398
930, epoch_train_loss=3.01795383590398
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 3.1289917760589825
931, epoch_train_loss=3.1289917760589825
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 4.069701634378358
932, epoch_train_loss=4.069701634378358
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 3.924722494792458
933, epoch_train_loss=3.924722494792458
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 3.879510210532037
934, epoch_train_loss=3.879510210532037
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 3.5436573293807516
935, epoch_train_loss=3.5436573293807516
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 3.612270289679331
936, epoch_train_loss=3.612270289679331
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 3.202634200349423
937, epoch_train_loss=3.202634200349423
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 3.324237412362614
938, epoch_train_loss=3.324237412362614
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 3.27716725102151
939, epoch_train_loss=3.27716725102151
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 2.9392017794489864
940, epoch_train_loss=2.9392017794489864
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 2.8036539605103967
941, epoch_train_loss=2.8036539605103967
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 3.168191011621232
942, epoch_train_loss=3.168191011621232
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 2.844300644590819
943, epoch_train_loss=2.844300644590819
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 2.9080239125997327
944, epoch_train_loss=2.9080239125997327
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 3.1186398736416705
945, epoch_train_loss=3.1186398736416705
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 2.8956283118896353
946, epoch_train_loss=2.8956283118896353
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 2.918816844911153
947, epoch_train_loss=2.918816844911153
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 3.0670497017225484
948, epoch_train_loss=3.0670497017225484
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 2.8353287504938187
949, epoch_train_loss=2.8353287504938187
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 2.988895228029815
950, epoch_train_loss=2.988895228029815
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 2.960256214381861
951, epoch_train_loss=2.960256214381861
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 2.8231799202298906
952, epoch_train_loss=2.8231799202298906
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 2.9579694485852808
953, epoch_train_loss=2.9579694485852808
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 2.837828462057594
954, epoch_train_loss=2.837828462057594
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 2.823345179263001
955, epoch_train_loss=2.823345179263001
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 2.8790026881362794
956, epoch_train_loss=2.8790026881362794
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 2.771984780185557
957, epoch_train_loss=2.771984780185557
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 2.788077155907601
958, epoch_train_loss=2.788077155907601
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 2.8031994554141884
959, epoch_train_loss=2.8031994554141884
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 2.726175954338167
960, epoch_train_loss=2.726175954338167
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 2.756016363212724
961, epoch_train_loss=2.756016363212724
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 2.753557720276554
962, epoch_train_loss=2.753557720276554
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 2.7035349144270326
963, epoch_train_loss=2.7035349144270326
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 2.7272058488655953
964, epoch_train_loss=2.7272058488655953
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 2.725565461039
965, epoch_train_loss=2.725565461039
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 2.693542907438426
966, epoch_train_loss=2.693542907438426
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 2.71475353220129
967, epoch_train_loss=2.71475353220129
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 2.7153363617420894
968, epoch_train_loss=2.7153363617420894
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 2.6938793306668063
969, epoch_train_loss=2.6938793306668063
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 2.708885369345709
970, epoch_train_loss=2.708885369345709
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 2.7123013501305464
971, epoch_train_loss=2.7123013501305464
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 2.6969066619339124
972, epoch_train_loss=2.6969066619339124
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 2.7078615139017286
973, epoch_train_loss=2.7078615139017286
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 2.7111814176209896
974, epoch_train_loss=2.7111814176209896
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 2.6993927109537146
975, epoch_train_loss=2.6993927109537146
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 2.705142158255342
976, epoch_train_loss=2.705142158255342
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 2.7082968675228387
977, epoch_train_loss=2.7082968675228387
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 2.698514136352998
978, epoch_train_loss=2.698514136352998
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 2.701602075817916
979, epoch_train_loss=2.701602075817916
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 2.703563152200771
980, epoch_train_loss=2.703563152200771
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 2.6959400220068828
981, epoch_train_loss=2.6959400220068828
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 2.6967701514372227
982, epoch_train_loss=2.6967701514372227
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 2.698533050014903
983, epoch_train_loss=2.698533050014903
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 2.6925682857466455
984, epoch_train_loss=2.6925682857466455
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 2.6927978166147177
985, epoch_train_loss=2.6927978166147177
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 2.6941546373167404
986, epoch_train_loss=2.6941546373167404
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 2.689967548124239
987, epoch_train_loss=2.689967548124239
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 2.6898536915903115
988, epoch_train_loss=2.6898536915903115
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 2.6912041762966754
989, epoch_train_loss=2.6912041762966754
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 2.688216251239456
990, epoch_train_loss=2.688216251239456
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 2.688223005228652
991, epoch_train_loss=2.688223005228652
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 2.6893360036393927
992, epoch_train_loss=2.6893360036393927
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 2.6872969719687196
993, epoch_train_loss=2.6872969719687196
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 2.6873387124823904
994, epoch_train_loss=2.6873387124823904
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 2.6882484270481943
995, epoch_train_loss=2.6882484270481943
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 2.6867400326693236
996, epoch_train_loss=2.6867400326693236
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 2.6868453458754322
997, epoch_train_loss=2.6868453458754322
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 2.687438727101679
998, epoch_train_loss=2.687438727101679
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 2.6862883803686866
999, epoch_train_loss=2.6862883803686866
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 2.686353933232739
1000, epoch_train_loss=2.686353933232739
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 2.6866823001659252
1001, epoch_train_loss=2.6866823001659252
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 2.6857302559393172
1002, epoch_train_loss=2.6857302559393172
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 2.6857724578995894
1003, epoch_train_loss=2.6857724578995894
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 2.685864147662776
1004, epoch_train_loss=2.685864147662776
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 2.685081088737438
1005, epoch_train_loss=2.685081088737438
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 2.6850924061415684
1006, epoch_train_loss=2.6850924061415684
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 2.685035928278542
1007, epoch_train_loss=2.685035928278542
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 2.6844025581719
1008, epoch_train_loss=2.6844025581719
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 2.6844174895761648
1009, epoch_train_loss=2.6844174895761648
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 2.684275056026241
1010, epoch_train_loss=2.684275056026241
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 2.683793994967334
1011, epoch_train_loss=2.683793994967334
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 2.6838186841140836
1012, epoch_train_loss=2.6838186841140836
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 2.6836428072393366
1013, epoch_train_loss=2.6836428072393366
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 2.68330011390315
1014, epoch_train_loss=2.68330011390315
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 2.6833314503490224
1015, epoch_train_loss=2.6833314503490224
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 2.6831463560397
1016, epoch_train_loss=2.6831463560397
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 2.682914037303613
1017, epoch_train_loss=2.682914037303613
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 2.6829353951543635
1018, epoch_train_loss=2.6829353951543635
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 2.6827500107868927
1019, epoch_train_loss=2.6827500107868927
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 2.6825944410032356
1020, epoch_train_loss=2.6825944410032356
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 2.6825871176913445
1021, epoch_train_loss=2.6825871176913445
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 2.68240587621724
1022, epoch_train_loss=2.68240587621724
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 2.6822957103246967
1023, epoch_train_loss=2.6822957103246967
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 2.682253645320551
1024, epoch_train_loss=2.682253645320551
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 2.6820805247790953
1025, epoch_train_loss=2.6820805247790953
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 2.681993913100806
1026, epoch_train_loss=2.681993913100806
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 2.681919041385829
1027, epoch_train_loss=2.681919041385829
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 2.6817619923724347
1028, epoch_train_loss=2.6817619923724347
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 2.6816873232374956
1029, epoch_train_loss=2.6816873232374956
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 2.681591644379069
1030, epoch_train_loss=2.681591644379069
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 2.6814553577357043
1031, epoch_train_loss=2.6814553577357043
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 2.6813852620118914
1032, epoch_train_loss=2.6813852620118914
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 2.6812806070313115
1033, epoch_train_loss=2.6812806070313115
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 2.681167679908455
1034, epoch_train_loss=2.681167679908455
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 2.68109961655084
1035, epoch_train_loss=2.68109961655084
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 2.680995498831842
1036, epoch_train_loss=2.680995498831842
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 2.6809021648590345
1037, epoch_train_loss=2.6809021648590345
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 2.680832823290647
1038, epoch_train_loss=2.680832823290647
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 2.6807347569500903
1039, epoch_train_loss=2.6807347569500903
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 2.680656133447168
1040, epoch_train_loss=2.680656133447168
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 2.6805847556274007
1041, epoch_train_loss=2.6805847556274007
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 2.680494208899853
1042, epoch_train_loss=2.680494208899853
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 2.6804235763864668
1043, epoch_train_loss=2.6804235763864668
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 2.68034973520416
1044, epoch_train_loss=2.68034973520416
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 2.6802670137288978
1045, epoch_train_loss=2.6802670137288978
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 2.6802002618983916
1046, epoch_train_loss=2.6802002618983916
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 2.6801252651230576
1047, epoch_train_loss=2.6801252651230576
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 2.6800490714175575
1048, epoch_train_loss=2.6800490714175575
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 2.679983211929666
1049, epoch_train_loss=2.679983211929666
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 2.6799089216281033
1050, epoch_train_loss=2.6799089216281033
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 2.6798384884132185
1051, epoch_train_loss=2.6798384884132185
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 2.679772999516659
1052, epoch_train_loss=2.679772999516659
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 2.6797011085013067
1053, epoch_train_loss=2.6797011085013067
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 2.679635012180417
1054, epoch_train_loss=2.679635012180417
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 2.6795699699597666
1055, epoch_train_loss=2.6795699699597666
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 2.6795017312521243
1056, epoch_train_loss=2.6795017312521243
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 2.6794391002690627
1057, epoch_train_loss=2.6794391002690627
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 2.679375193148873
1058, epoch_train_loss=2.679375193148873
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 2.6793107162149514
1059, epoch_train_loss=2.6793107162149514
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 2.679250365921468
1060, epoch_train_loss=2.679250365921468
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 2.679188092394908
1061, epoch_train_loss=2.679188092394908
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 2.6791271096798344
1062, epoch_train_loss=2.6791271096798344
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 2.6790684314814506
1063, epoch_train_loss=2.6790684314814506
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 2.679008066612026
1064, epoch_train_loss=2.679008066612026
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 2.678949721701304
1065, epoch_train_loss=2.678949721701304
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 2.678892224251107
1066, epoch_train_loss=2.678892224251107
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 2.678833924870785
1067, epoch_train_loss=2.678833924870785
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 2.6787776568042876
1068, epoch_train_loss=2.6787776568042876
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 2.678721312494356
1069, epoch_train_loss=2.678721312494356
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 2.6786649758199754
1070, epoch_train_loss=2.6786649758199754
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 2.678610218715965
1071, epoch_train_loss=2.678610218715965
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 2.6785551320043592
1072, epoch_train_loss=2.6785551320043592
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 2.6785007091219293
1073, epoch_train_loss=2.6785007091219293
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 2.6784472877647336
1074, epoch_train_loss=2.6784472877647336
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 2.678393599812388
1075, epoch_train_loss=2.678393599812388
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 2.6783408339999526
1076, epoch_train_loss=2.6783408339999526
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 2.6782886062125373
1077, epoch_train_loss=2.6782886062125373
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 2.678236417682891
1078, epoch_train_loss=2.678236417682891
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 2.678185152299434
1079, epoch_train_loss=2.678185152299434
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 2.678134107924784
1080, epoch_train_loss=2.678134107924784
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 2.678083344943094
1081, epoch_train_loss=2.678083344943094
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 2.6780333266877983
1082, epoch_train_loss=2.6780333266877983
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 2.677983438211317
1083, epoch_train_loss=2.677983438211317
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 2.6779340172481785
1084, epoch_train_loss=2.6779340172481785
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 2.6778851154455743
1085, epoch_train_loss=2.6778851154455743
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 2.677836342380372
1086, epoch_train_loss=2.677836342380372
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 2.6777880812355823
1087, epoch_train_loss=2.6777880812355823
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 2.677740169630909
1088, epoch_train_loss=2.677740169630909
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 2.6776924782718834
1089, epoch_train_loss=2.6776924782718834
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 2.6776452699106588
1090, epoch_train_loss=2.6776452699106588
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 2.6775982984309743
1091, epoch_train_loss=2.6775982984309743
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 2.6775516125697156
1092, epoch_train_loss=2.6775516125697156
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 2.6775053342729818
1093, epoch_train_loss=2.6775053342729818
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 2.67745926928039
1094, epoch_train_loss=2.67745926928039
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 2.677413541184556
1095, epoch_train_loss=2.677413541184556
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 2.6773681375790694
1096, epoch_train_loss=2.6773681375790694
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 2.677322947604188
1097, epoch_train_loss=2.677322947604188
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 2.67727809559935
1098, epoch_train_loss=2.67727809559935
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 2.6772335117295616
1099, epoch_train_loss=2.6772335117295616
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 2.6771891714965057
1100, epoch_train_loss=2.6771891714965057
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 2.677145147082966
1101, epoch_train_loss=2.677145147082966
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 2.6771013513580653
1102, epoch_train_loss=2.6771013513580653
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 2.677057812405694
1103, epoch_train_loss=2.677057812405694
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 2.6770145550371556
1104, epoch_train_loss=2.6770145550371556
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 2.676971519185932
1105, epoch_train_loss=2.676971519185932
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 2.6769287483516653
1106, epoch_train_loss=2.6769287483516653
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 2.6768862250990826
1107, epoch_train_loss=2.6768862250990826
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 2.6768439206534325
1108, epoch_train_loss=2.6768439206534325
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 2.676801873304585
1109, epoch_train_loss=2.676801873304585
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 2.676760054152199
1110, epoch_train_loss=2.676760054152199
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 2.6767184624053497
1111, epoch_train_loss=2.6767184624053497
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 2.6766771151206434
1112, epoch_train_loss=2.6766771151206434
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 2.676635982864582
1113, epoch_train_loss=2.676635982864582
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 2.6765950795308013
1114, epoch_train_loss=2.6765950795308013
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 2.676554407660874
1115, epoch_train_loss=2.676554407660874
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 2.6765139504980158
1116, epoch_train_loss=2.6765139504980158
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 2.6764737229125344
1117, epoch_train_loss=2.6764737229125344
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 2.676433714957891
1118, epoch_train_loss=2.676433714957891
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 2.676393920952041
1119, epoch_train_loss=2.676393920952041
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 2.6763543521016073
1120, epoch_train_loss=2.6763543521016073
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 2.676314997642583
1121, epoch_train_loss=2.676314997642583
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 2.676275859946136
1122, epoch_train_loss=2.676275859946136
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 2.676236941805003
1123, epoch_train_loss=2.676236941805003
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 2.676198233953802
1124, epoch_train_loss=2.676198233953802
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 2.6761597422268584
1125, epoch_train_loss=2.6761597422268584
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 2.676121465407604
1126, epoch_train_loss=2.676121465407604
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 2.6760833993108912
1127, epoch_train_loss=2.6760833993108912
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 2.676045548411523
1128, epoch_train_loss=2.676045548411523
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 2.676007908077126
1129, epoch_train_loss=2.676007908077126
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 2.6759704777344018
1130, epoch_train_loss=2.6759704777344018
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 2.675933260138109
1131, epoch_train_loss=2.675933260138109
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 2.67589625143909
1132, epoch_train_loss=2.67589625143909
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 2.6758594529376927
1133, epoch_train_loss=2.6758594529376927
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 2.6758228641958652
1134, epoch_train_loss=2.6758228641958652
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 2.675786482247848
1135, epoch_train_loss=2.675786482247848
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 2.6757503088904167
1136, epoch_train_loss=2.6757503088904167
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 2.6757143426484093
1137, epoch_train_loss=2.6757143426484093
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 2.6756785821751192
1138, epoch_train_loss=2.6756785821751192
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 2.6756430280219323
1139, epoch_train_loss=2.6756430280219323
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 2.6756076776907127
1140, epoch_train_loss=2.6756076776907127
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 2.6755725307001748
1141, epoch_train_loss=2.6755725307001748
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 2.675537586755878
1142, epoch_train_loss=2.675537586755878
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 2.675502843740898
1143, epoch_train_loss=2.675502843740898
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 2.6754683012150893
1144, epoch_train_loss=2.6754683012150893
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 2.6754339575661334
1145, epoch_train_loss=2.6754339575661334
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 2.675399810869717
1146, epoch_train_loss=2.675399810869717
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 2.6753658604638546
1147, epoch_train_loss=2.6753658604638546
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 2.6753321043740907
1148, epoch_train_loss=2.6753321043740907
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 2.675298540946736
1149, epoch_train_loss=2.675298540946736
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 2.675265168714683
1150, epoch_train_loss=2.675265168714683
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 2.6752319852664237
1151, epoch_train_loss=2.6752319852664237
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 2.675198988961662
1152, epoch_train_loss=2.675198988961662
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 2.6751661778786597
1153, epoch_train_loss=2.6751661778786597
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 2.6751335496250106
1154, epoch_train_loss=2.6751335496250106
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 2.6751011022396534
1155, epoch_train_loss=2.6751011022396534
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 2.675068833197158
1156, epoch_train_loss=2.675068833197158
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 2.675036740015851
1157, epoch_train_loss=2.675036740015851
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 2.6750048204548733
1158, epoch_train_loss=2.6750048204548733
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 2.674973071787299
1159, epoch_train_loss=2.674973071787299
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 2.67494149142428
1160, epoch_train_loss=2.67494149142428
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 2.67491007667303
1161, epoch_train_loss=2.67491007667303
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 2.674878824575035
1162, epoch_train_loss=2.674878824575035
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 2.67484773240278
1163, epoch_train_loss=2.67484773240278
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 2.6748167972396577
1164, epoch_train_loss=2.6748167972396577
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 2.6747860160499406
1165, epoch_train_loss=2.6747860160499406
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 2.674755385881227
1166, epoch_train_loss=2.674755385881227
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 2.6747249035542984
1167, epoch_train_loss=2.6747249035542984
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 2.674694565959189
1168, epoch_train_loss=2.674694565959189
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 2.6746643699996393
1169, epoch_train_loss=2.6746643699996393
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 2.6746343124278416
1170, epoch_train_loss=2.6746343124278416
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 2.674604390054861
1171, epoch_train_loss=2.674604390054861
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 2.674574599620901
1172, epoch_train_loss=2.674574599620901
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 2.6745449378186654
1173, epoch_train_loss=2.6745449378186654
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 2.6745154014227084
1174, epoch_train_loss=2.6745154014227084
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 2.674485987136508
1175, epoch_train_loss=2.674485987136508
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 2.6744566916650463
1176, epoch_train_loss=2.6744566916650463
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 2.674427511738182
1177, epoch_train_loss=2.674427511738182
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 2.674398444039499
1178, epoch_train_loss=2.674398444039499
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 2.67436948531235
1179, epoch_train_loss=2.67436948531235
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 2.6743406323171746
1180, epoch_train_loss=2.6743406323171746
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 2.6743118818008322
1181, epoch_train_loss=2.6743118818008322
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 2.6742832305663535
1182, epoch_train_loss=2.6742832305663535
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 2.674254675417247
1183, epoch_train_loss=2.674254675417247
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 2.6742262131918855
1184, epoch_train_loss=2.6742262131918855
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 2.6741978407873788
1185, epoch_train_loss=2.6741978407873788
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 2.674169555120289
1186, epoch_train_loss=2.674169555120289
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 2.6741413531542033
1187, epoch_train_loss=2.6741413531542033
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 2.6741132318953977
1188, epoch_train_loss=2.6741132318953977
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 2.6740851883888563
1189, epoch_train_loss=2.6740851883888563
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 2.674057219744308
1190, epoch_train_loss=2.674057219744308
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 2.674029323123586
1191, epoch_train_loss=2.674029323123586
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 2.6740014957344824
1192, epoch_train_loss=2.6740014957344824
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 2.673973734846315
1193, epoch_train_loss=2.673973734846315
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 2.6739460377811213
1194, epoch_train_loss=2.6739460377811213
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 2.6739184019216586
1195, epoch_train_loss=2.6739184019216586
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 2.6738908247218913
1196, epoch_train_loss=2.6738908247218913
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 2.673863303688042
1197, epoch_train_loss=2.673863303688042
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 2.6738358363884944
1198, epoch_train_loss=2.6738358363884944
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 2.673808420461391
1199, epoch_train_loss=2.673808420461391
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 2.6737810536024154
1200, epoch_train_loss=2.6737810536024154
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 2.67375373357607
1201, epoch_train_loss=2.67375373357607
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 2.673726458210624
1202, epoch_train_loss=2.673726458210624
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 2.673699225400067
1203, epoch_train_loss=2.673699225400067
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 2.673672033099563
1204, epoch_train_loss=2.673672033099563
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 2.6736448793271594
1205, epoch_train_loss=2.6736448793271594
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 2.6736177621695436
1206, epoch_train_loss=2.6736177621695436
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 2.673590679770843
1207, epoch_train_loss=2.673590679770843
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 2.6735636303435273
1208, epoch_train_loss=2.6735636303435273
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 2.6735366121559454
1209, epoch_train_loss=2.6735366121559454
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 2.6735096235372193
1210, epoch_train_loss=2.6735096235372193
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 2.6734826628757493
1211, epoch_train_loss=2.6734826628757493
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 2.6734557286199268
1212, epoch_train_loss=2.6734557286199268
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 2.6734288192756495
1213, epoch_train_loss=2.6734288192756495
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 2.673401933397734
1214, epoch_train_loss=2.673401933397734
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 2.673375069600996
1215, epoch_train_loss=2.673375069600996
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 2.6733482265518416
1216, epoch_train_loss=2.6733482265518416
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 2.6733214029647736
1217, epoch_train_loss=2.6733214029647736
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 2.673294597603667
1218, epoch_train_loss=2.673294597603667
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 2.6732678092837157
1219, epoch_train_loss=2.6732678092837157
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 2.6732410368642268
1220, epoch_train_loss=2.6732410368642268
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 2.6732142792482936
1221, epoch_train_loss=2.6732142792482936
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 2.6731875353822474
1222, epoch_train_loss=2.6731875353822474
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 2.6731608042520874
1223, epoch_train_loss=2.6731608042520874
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 2.6731340848869842
1224, epoch_train_loss=2.6731340848869842
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 2.6731073763517226
1225, epoch_train_loss=2.6731073763517226
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 2.6730806777468845
1226, epoch_train_loss=2.6730806777468845
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 2.673053988207424
1227, epoch_train_loss=2.673053988207424
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 2.6730273068996375
1228, epoch_train_loss=2.6730273068996375
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 2.6730006330251586
1229, epoch_train_loss=2.6730006330251586
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 2.672973965812958
1230, epoch_train_loss=2.672973965812958
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 2.6729473045199597
1231, epoch_train_loss=2.6729473045199597
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 2.672920648429439
1232, epoch_train_loss=2.672920648429439
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 2.6728939968479937
1233, epoch_train_loss=2.6728939968479937
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 2.6728673491081674
1234, epoch_train_loss=2.6728673491081674
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 2.672840704566662
1235, epoch_train_loss=2.672840704566662
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 2.6728140625967853
1236, epoch_train_loss=2.6728140625967853
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 2.6727874225954245
1237, epoch_train_loss=2.6727874225954245
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 2.6727607839757868
1238, epoch_train_loss=2.6727607839757868
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 2.672734146166361
1239, epoch_train_loss=2.672734146166361
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 2.6727075086157135
1240, epoch_train_loss=2.6727075086157135
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 2.672680870782944
1241, epoch_train_loss=2.672680870782944
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 2.6726542321428757
1242, epoch_train_loss=2.6726542321428757
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 2.6726275921830482
1243, epoch_train_loss=2.6726275921830482
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 2.672600950405076
1244, epoch_train_loss=2.672600950405076
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 2.6725743063173413
1245, epoch_train_loss=2.6725743063173413
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 2.672547659440238
1246, epoch_train_loss=2.672547659440238
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 2.6725210093053526
1247, epoch_train_loss=2.6725210093053526
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 2.6724943554484546
1248, epoch_train_loss=2.6724943554484546
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 2.6724676974152213
1249, epoch_train_loss=2.6724676974152213
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 2.672441034758505
1250, epoch_train_loss=2.672441034758505
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 2.6724143670396447
1251, epoch_train_loss=2.6724143670396447
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 2.672387693821562
1252, epoch_train_loss=2.672387693821562
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 2.672361014674504
1253, epoch_train_loss=2.672361014674504
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 2.6723343291735646
1254, epoch_train_loss=2.6723343291735646
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 2.6723076368983167
1255, epoch_train_loss=2.6723076368983167
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 2.672280937432304
1256, epoch_train_loss=2.672280937432304
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 2.6722542303625842
1257, epoch_train_loss=2.6722542303625842
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 2.6722275152793715
1258, epoch_train_loss=2.6722275152793715
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 2.672200791775787
1259, epoch_train_loss=2.672200791775787
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 2.672174059447674
1260, epoch_train_loss=2.672174059447674
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 2.672147317893327
1261, epoch_train_loss=2.672147317893327
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 2.6721205667131933
1262, epoch_train_loss=2.6721205667131933
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 2.6720938055096464
1263, epoch_train_loss=2.6720938055096464
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 2.6720670338868535
1264, epoch_train_loss=2.6720670338868535
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 2.6720402514507042
1265, epoch_train_loss=2.6720402514507042
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 2.672013457806606
1266, epoch_train_loss=2.672013457806606
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 2.67198665256564
1267, epoch_train_loss=2.67198665256564
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 2.6719598353381198
1268, epoch_train_loss=2.6719598353381198
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 2.67193300573564
1269, epoch_train_loss=2.67193300573564
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 2.6719061633689707
1270, epoch_train_loss=2.6719061633689707
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 2.6718793078543834
1271, epoch_train_loss=2.6718793078543834
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 2.6718524388051716
1272, epoch_train_loss=2.6718524388051716
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 2.6718255558400292
1273, epoch_train_loss=2.6718255558400292
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 2.6717986585767117
1274, epoch_train_loss=2.6717986585767117
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 2.671771746634182
1275, epoch_train_loss=2.671771746634182
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 2.6717448196326736
1276, epoch_train_loss=2.6717448196326736
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 2.6717178771915906
1277, epoch_train_loss=2.6717178771915906
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 2.6716909189358446
1278, epoch_train_loss=2.6716909189358446
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 2.6716639444874017
1279, epoch_train_loss=2.6716639444874017
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 2.6716369534716815
1280, epoch_train_loss=2.6716369534716815
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 2.6716099455176354
1281, epoch_train_loss=2.6716099455176354
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 2.671582920251437
1282, epoch_train_loss=2.671582920251437
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 2.67155587730498
1283, epoch_train_loss=2.67155587730498
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 2.671528816307403
1284, epoch_train_loss=2.671528816307403
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 2.671501736893628
1285, epoch_train_loss=2.671501736893628
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 2.6714746386959205
1286, epoch_train_loss=2.6714746386959205
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 2.6714475213503204
1287, epoch_train_loss=2.6714475213503204
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 2.6714203844945392
1288, epoch_train_loss=2.6714203844945392
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 2.671393227770101
1289, epoch_train_loss=2.671393227770101
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 2.6713660508159602
1290, epoch_train_loss=2.6713660508159602
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 2.6713388532749374
1291, epoch_train_loss=2.6713388532749374
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 2.671311634791625
1292, epoch_train_loss=2.671311634791625
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 2.6712843950123983
1293, epoch_train_loss=2.6712843950123983
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 2.6712571335875497
1294, epoch_train_loss=2.6712571335875497
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 2.671229850164851
1295, epoch_train_loss=2.671229850164851
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 2.6712025443959817
1296, epoch_train_loss=2.6712025443959817
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 2.671175215934399
1297, epoch_train_loss=2.671175215934399
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 2.6711478644353264
1298, epoch_train_loss=2.6711478644353264
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 2.6711204895578726
1299, epoch_train_loss=2.6711204895578726
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 2.6710930909563846
1300, epoch_train_loss=2.6710930909563846
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 2.671065668293328
1301, epoch_train_loss=2.671065668293328
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 2.671038221230652
1302, epoch_train_loss=2.671038221230652
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 2.6710107494340614
1303, epoch_train_loss=2.6710107494340614
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 2.670983252564323
1304, epoch_train_loss=2.670983252564323
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 2.6709557302901503
1305, epoch_train_loss=2.6709557302901503
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 2.670928182279499
1306, epoch_train_loss=2.670928182279499
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 2.670900608201662
1307, epoch_train_loss=2.670900608201662
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 2.670873007727199
1308, epoch_train_loss=2.670873007727199
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 2.670845380525683
1309, epoch_train_loss=2.670845380525683
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 2.670817726274283
1310, epoch_train_loss=2.670817726274283
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 2.670790044642457
1311, epoch_train_loss=2.670790044642457
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 2.670762335304889
1312, epoch_train_loss=2.670762335304889
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 2.6707345979414057
1313, epoch_train_loss=2.6707345979414057
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 2.670706832223776
1314, epoch_train_loss=2.670706832223776
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 2.670679037828669
1315, epoch_train_loss=2.670679037828669
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 2.670651214437533
1316, epoch_train_loss=2.670651214437533
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 2.670623361723336
1317, epoch_train_loss=2.670623361723336
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 2.6705954793635605
1318, epoch_train_loss=2.6705954793635605
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 2.670567567040073
1319, epoch_train_loss=2.670567567040073
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 2.670539624425801
1320, epoch_train_loss=2.670539624425801
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 2.670511651197736
1321, epoch_train_loss=2.670511651197736
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 2.6704836470345863
1322, epoch_train_loss=2.6704836470345863
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 2.67045561161
1323, epoch_train_loss=2.67045561161
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 2.670427544601213
1324, epoch_train_loss=2.670427544601213
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 2.6703994456800357
1325, epoch_train_loss=2.6703994456800357
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 2.6703713145192896
1326, epoch_train_loss=2.6703713145192896
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 2.670343150792615
1327, epoch_train_loss=2.670343150792615
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 2.6703149541676345
1328, epoch_train_loss=2.6703149541676345
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 2.6702867243146122
1329, epoch_train_loss=2.6702867243146122
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 2.6702584608973683
1330, epoch_train_loss=2.6702584608973683
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 2.6702301635797197
1331, epoch_train_loss=2.6702301635797197
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 2.670201832025263
1332, epoch_train_loss=2.670201832025263
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 2.670173465888227
1333, epoch_train_loss=2.670173465888227
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 2.670145064828853
1334, epoch_train_loss=2.670145064828853
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 2.670116628497534
1335, epoch_train_loss=2.670116628497534
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 2.6700881565457304
1336, epoch_train_loss=2.6700881565457304
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 2.670059648614516
1337, epoch_train_loss=2.670059648614516
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 2.6700311043500093
1338, epoch_train_loss=2.6700311043500093
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 2.670002523387402
1339, epoch_train_loss=2.670002523387402
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 2.6699739053596616
1340, epoch_train_loss=2.6699739053596616
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 2.6699452498949983
1341, epoch_train_loss=2.6699452498949983
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 2.669916556616574
1342, epoch_train_loss=2.669916556616574
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 2.6698878251422
1343, epoch_train_loss=2.6698878251422
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 2.6698590550840344
1344, epoch_train_loss=2.6698590550840344
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 2.669830246048265
1345, epoch_train_loss=2.669830246048265
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 2.6698013976347954
1346, epoch_train_loss=2.6698013976347954
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 2.6697725094369065
1347, epoch_train_loss=2.6697725094369065
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 2.6697435810409256
1348, epoch_train_loss=2.6697435810409256
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 2.6697146120236104
1349, epoch_train_loss=2.6697146120236104
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 2.669685601960932
1350, epoch_train_loss=2.669685601960932
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 2.669656550411751
1351, epoch_train_loss=2.669656550411751
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 2.669627456933468
1352, epoch_train_loss=2.669627456933468
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 2.669598321070244
1353, epoch_train_loss=2.669598321070244
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 2.6695691423641468
1354, epoch_train_loss=2.6695691423641468
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 2.669539920338761
1355, epoch_train_loss=2.669539920338761
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 2.6695106545149865
1356, epoch_train_loss=2.6695106545149865
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 2.6694813444015804
1357, epoch_train_loss=2.6694813444015804
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 2.6694519894949322
1358, epoch_train_loss=2.6694519894949322
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 2.669422589285833
1359, epoch_train_loss=2.669422589285833
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 2.6693931432501263
1360, epoch_train_loss=2.6693931432501263
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 2.669363650857969
1361, epoch_train_loss=2.669363650857969
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 2.6693341115669567
1362, epoch_train_loss=2.6693341115669567
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 2.6693045248223135
1363, epoch_train_loss=2.6693045248223135
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 2.6692748900642105
1364, epoch_train_loss=2.6692748900642105
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 2.669245206718929
1365, epoch_train_loss=2.669245206718929
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 2.6692154742088423
1366, epoch_train_loss=2.6692154742088423
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 2.669185691943878
1367, epoch_train_loss=2.669185691943878
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 2.669155859329542
1368, epoch_train_loss=2.669155859329542
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 2.669125975768117
1369, epoch_train_loss=2.669125975768117
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 2.669096040655324
1370, epoch_train_loss=2.669096040655324
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 2.6690660533794572
1371, epoch_train_loss=2.6690660533794572
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 2.6690360133372377
1372, epoch_train_loss=2.6690360133372377
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 2.6690059199214127
1373, epoch_train_loss=2.6690059199214127
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 2.6689757725225522
1374, epoch_train_loss=2.6689757725225522
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 2.6689455705451546
1375, epoch_train_loss=2.6689455705451546
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 2.6689153133927905
1376, epoch_train_loss=2.6689153133927905
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 2.6688850004792535
1377, epoch_train_loss=2.6688850004792535
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 2.6688546312275827
1378, epoch_train_loss=2.6688546312275827
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 2.668824205073509
1379, epoch_train_loss=2.668824205073509
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 2.668793721458818
1380, epoch_train_loss=2.668793721458818
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 2.6687631798384404
1381, epoch_train_loss=2.6687631798384404
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 2.6687325796771137
1382, epoch_train_loss=2.6687325796771137
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 2.6687019204473446
1383, epoch_train_loss=2.6687019204473446
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 2.668671201625998
1384, epoch_train_loss=2.668671201625998
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 2.6686404226892058
1385, epoch_train_loss=2.6686404226892058
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 2.6686095831052254
1386, epoch_train_loss=2.6686095831052254
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 2.66857868232735
1387, epoch_train_loss=2.66857868232735
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 2.668547719771922
1388, epoch_train_loss=2.668547719771922
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 2.6685166948178343
1389, epoch_train_loss=2.6685166948178343
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 2.668485606778738
1390, epoch_train_loss=2.668485606778738
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 2.6684544548847855
1391, epoch_train_loss=2.6684544548847855
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 2.668423238259902
1392, epoch_train_loss=2.668423238259902
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 2.668391955895567
1393, epoch_train_loss=2.668391955895567
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 2.668360606634837
1394, epoch_train_loss=2.668360606634837
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 2.668329189143645
1395, epoch_train_loss=2.668329189143645
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 2.6682977018958636
1396, epoch_train_loss=2.6682977018958636
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 2.6682661431615067
1397, epoch_train_loss=2.6682661431615067
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 2.6682345109993597
1398, epoch_train_loss=2.6682345109993597
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 2.6682028032671528
1399, epoch_train_loss=2.6682028032671528
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 2.6681710176241467
1400, epoch_train_loss=2.6681710176241467
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 2.668139151547421
1401, epoch_train_loss=2.668139151547421
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 2.6681072023601105
1402, epoch_train_loss=2.6681072023601105
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 2.668075167246455
1403, epoch_train_loss=2.668075167246455
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 2.668043043273578
1404, epoch_train_loss=2.668043043273578
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 2.668010827417527
1405, epoch_train_loss=2.668010827417527
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 2.6679785165659977
1406, epoch_train_loss=2.6679785165659977
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 2.6679461075341595
1407, epoch_train_loss=2.6679461075341595
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 2.667913597051803
1408, epoch_train_loss=2.667913597051803
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 2.6678809817619995
1409, epoch_train_loss=2.6678809817619995
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 2.6678482581925542
1410, epoch_train_loss=2.6678482581925542
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 2.6678154227254907
1411, epoch_train_loss=2.6678154227254907
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 2.667782471561568
1412, epoch_train_loss=2.667782471561568
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 2.667749400665923
1413, epoch_train_loss=2.667749400665923
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 2.66771620570366
1414, epoch_train_loss=2.66771620570366
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 2.667682881963428
1415, epoch_train_loss=2.667682881963428
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 2.6676494242535327
1416, epoch_train_loss=2.6676494242535327
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 2.6676158267976247
1417, epoch_train_loss=2.6676158267976247
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 2.6675820830903194
1418, epoch_train_loss=2.6675820830903194
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 2.6675481857569574
1419, epoch_train_loss=2.6675481857569574
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 2.667514126403027
1420, epoch_train_loss=2.667514126403027
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 2.667479895503766
1421, epoch_train_loss=2.667479895503766
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 2.6674454823890414
1422, epoch_train_loss=2.6674454823890414
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 2.6674108754851615
1423, epoch_train_loss=2.6674108754851615
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 2.667376063021279
1424, epoch_train_loss=2.667376063021279
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 2.6673410345843496
1425, epoch_train_loss=2.6673410345843496
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 2.6673057840213144
1426, epoch_train_loss=2.6673057840213144
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 2.667270314173466
1427, epoch_train_loss=2.667270314173466
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 2.6672346434390404
1428, epoch_train_loss=2.6672346434390404
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 2.667198812696571
1429, epoch_train_loss=2.667198812696571
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 2.6671628884136416
1430, epoch_train_loss=2.6671628884136416
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 2.6671269549478427
1431, epoch_train_loss=2.6671269549478427
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 2.6670910899412315
1432, epoch_train_loss=2.6670910899412315
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 2.6670553260674787
1433, epoch_train_loss=2.6670553260674787
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 2.6670196182592774
1434, epoch_train_loss=2.6670196182592774
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 2.666983843301389
1435, epoch_train_loss=2.666983843301389
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 2.666947843056553
1436, epoch_train_loss=2.666947843056553
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 2.6669114910750094
1437, epoch_train_loss=2.6669114910750094
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 2.6668747433789433
1438, epoch_train_loss=2.6668747433789433
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 2.6668376452446623
1439, epoch_train_loss=2.6668376452446623
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 2.6668002957895482
1440, epoch_train_loss=2.6668002957895482
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 2.66676279642163
1441, epoch_train_loss=2.66676279642163
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 2.6667252124050056
1442, epoch_train_loss=2.6667252124050056
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 2.6666875615655217
1443, epoch_train_loss=2.6666875615655217
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 2.666649825276677
1444, epoch_train_loss=2.666649825276677
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 2.666611967786821
1445, epoch_train_loss=2.666611967786821
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 2.666573952545089
1446, epoch_train_loss=2.666573952545089
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 2.666535751292093
1447, epoch_train_loss=2.666535751292093
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 2.666497346975082
1448, epoch_train_loss=2.666497346975082
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 2.6664587331721608
1449, epoch_train_loss=2.6664587331721608
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 2.6664199122664165
1450, epoch_train_loss=2.6664199122664165
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 2.666380893430526
1451, epoch_train_loss=2.666380893430526
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 2.6663416907373625
1452, epoch_train_loss=2.6663416907373625
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 2.6663023212172385
1453, epoch_train_loss=2.6663023212172385
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 2.6662628026585056
1454, epoch_train_loss=2.6662628026585056
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 2.6662231511656542
1455, epoch_train_loss=2.6662231511656542
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 2.6661833788289613
1456, epoch_train_loss=2.6661833788289613
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 2.6661434921526697
1457, epoch_train_loss=2.6661434921526697
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 2.6661034919492996
1458, epoch_train_loss=2.6661034919492996
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 2.666063375005136
1459, epoch_train_loss=2.666063375005136
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 2.6660231370989274
1460, epoch_train_loss=2.6660231370989274
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 2.6659827763214627
1461, epoch_train_loss=2.6659827763214627
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 2.6659422954307845
1462, epoch_train_loss=2.6659422954307845
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 2.6659017023896867
1463, epoch_train_loss=2.6659017023896867
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 2.6658610090802317
1464, epoch_train_loss=2.6658610090802317
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 2.665820228923814
1465, epoch_train_loss=2.665820228923814
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 2.6657793744192038
1466, epoch_train_loss=2.6657793744192038
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 2.6657384554503487
1467, epoch_train_loss=2.6657384554503487
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 2.665697478652888
1468, epoch_train_loss=2.665697478652888
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 2.66565644772617
1469, epoch_train_loss=2.66565644772617
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 2.6656153642352054
1470, epoch_train_loss=2.6656153642352054
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 2.665574228547794
1471, epoch_train_loss=2.665574228547794
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 2.6655330405637137
1472, epoch_train_loss=2.6655330405637137
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 2.66549180014475
1473, epoch_train_loss=2.66549180014475
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 2.66545050718699
1474, epoch_train_loss=2.66545050718699
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 2.6654091614630055
1475, epoch_train_loss=2.6654091614630055
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 2.665367762270725
1476, epoch_train_loss=2.665367762270725
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 2.665326308022414
1477, epoch_train_loss=2.665326308022414
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 2.665284795809478
1478, epoch_train_loss=2.665284795809478
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 2.6652432211085646
1479, epoch_train_loss=2.6652432211085646
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 2.6652015776126117
1480, epoch_train_loss=2.6652015776126117
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 2.665159857273232
1481, epoch_train_loss=2.665159857273232
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 2.665118050521755
1482, epoch_train_loss=2.665118050521755
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 2.6650761466346484
1483, epoch_train_loss=2.6650761466346484
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 2.665034134125686
1484, epoch_train_loss=2.665034134125686
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 2.664992001106024
1485, epoch_train_loss=2.664992001106024
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 2.6649497355482543
1486, epoch_train_loss=2.6649497355482543
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 2.6649073254036657
1487, epoch_train_loss=2.6649073254036657
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 2.664864758626508
1488, epoch_train_loss=2.664864758626508
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 2.664822023158168
1489, epoch_train_loss=2.664822023158168
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 2.6647791068985165
1490, epoch_train_loss=2.6647791068985165
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 2.6647359977359546
1491, epoch_train_loss=2.6647359977359546
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 2.6646926836508387
1492, epoch_train_loss=2.6646926836508387
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 2.664649152846876
1493, epoch_train_loss=2.664649152846876
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 2.664605393930796
1494, epoch_train_loss=2.664605393930796
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 2.6645613960739714
1495, epoch_train_loss=2.6645613960739714
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 2.6645171491283826
1496, epoch_train_loss=2.6645171491283826
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 2.664472643715074
1497, epoch_train_loss=2.664472643715074
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 2.664427871227764
1498, epoch_train_loss=2.664427871227764
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 2.6643828238094467
1499, epoch_train_loss=2.6643828238094467
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 2.6643374942792173
1500, epoch_train_loss=2.6643374942792173
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 2.6642918760244196
1501, epoch_train_loss=2.6642918760244196
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 2.6642459629093493
1502, epoch_train_loss=2.6642459629093493
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 2.664199749158721
1503, epoch_train_loss=2.664199749158721
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 2.6641532292772716
1504, epoch_train_loss=2.6641532292772716
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 2.664106397967426
1505, epoch_train_loss=2.664106397967426
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 2.664059250060202
1506, epoch_train_loss=2.664059250060202
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 2.6640117804540817
1507, epoch_train_loss=2.6640117804540817
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 2.663963984037599
1508, epoch_train_loss=2.663963984037599
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 2.6639158556299734
1509, epoch_train_loss=2.6639158556299734
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 2.663867389902569
1510, epoch_train_loss=2.663867389902569
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 2.6638185813034094
1511, epoch_train_loss=2.6638185813034094
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 2.663769423986698
1512, epoch_train_loss=2.663769423986698
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 2.66371991175721
1513, epoch_train_loss=2.66371991175721
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 2.6636700380105007
1514, epoch_train_loss=2.6636700380105007
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 2.6636197957338976
1515, epoch_train_loss=2.6636197957338976
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 2.6635691774651185
1516, epoch_train_loss=2.6635691774651185
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 2.6635181753243935
1517, epoch_train_loss=2.6635181753243935
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 2.663466781012831
1518, epoch_train_loss=2.663466781012831
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 2.6634149858365626
1519, epoch_train_loss=2.6634149858365626
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 2.663362780729278
1520, epoch_train_loss=2.663362780729278
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 2.6633101562747394
1521, epoch_train_loss=2.6633101562747394
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 2.6632571027238257
1522, epoch_train_loss=2.6632571027238257
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 2.663203610026859
1523, epoch_train_loss=2.663203610026859
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 2.6631496678394404
1524, epoch_train_loss=2.6631496678394404
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 2.66309526554396
1525, epoch_train_loss=2.66309526554396
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 2.663040392265899
1526, epoch_train_loss=2.663040392265899
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 2.662985036884255
1527, epoch_train_loss=2.662985036884255
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 2.6629291880572046
1528, epoch_train_loss=2.6629291880572046
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 2.662872834213623
1529, epoch_train_loss=2.662872834213623
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 2.6628159635754645
1530, epoch_train_loss=2.6628159635754645
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 2.6627585641438642
1531, epoch_train_loss=2.6627585641438642
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 2.662700623692965
1532, epoch_train_loss=2.662700623692965
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 2.6626421297726073
1533, epoch_train_loss=2.6626421297726073
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 2.6625830696746084
1534, epoch_train_loss=2.6625830696746084
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 2.6625234304329193
1535, epoch_train_loss=2.6625234304329193
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 2.6624631987893776
1536, epoch_train_loss=2.6624631987893776
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 2.6624023611724974
1537, epoch_train_loss=2.6624023611724974
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 2.6623409036911254
1538, epoch_train_loss=2.6623409036911254
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 2.6622788120951606
1539, epoch_train_loss=2.6622788120951606
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 2.66221607177138
1540, epoch_train_loss=2.66221607177138
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 2.662152667726428
1541, epoch_train_loss=2.662152667726428
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 2.662088584556117
1542, epoch_train_loss=2.662088584556117
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 2.6620238064464674
1543, epoch_train_loss=2.6620238064464674
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 2.6619583171617784
1544, epoch_train_loss=2.6619583171617784
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 2.661892100018695
1545, epoch_train_loss=2.661892100018695
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 2.661825137893123
1546, epoch_train_loss=2.661825137893123
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 2.661757413213625
1547, epoch_train_loss=2.661757413213625
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 2.6616889079399386
1548, epoch_train_loss=2.6616889079399386
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 2.661619603574708
1549, epoch_train_loss=2.661619603574708
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 2.6615494811545606
1550, epoch_train_loss=2.6615494811545606
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 2.6614785212522825
1551, epoch_train_loss=2.6614785212522825
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 2.6614067039503837
1552, epoch_train_loss=2.6614067039503837
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 2.661334008870243
1553, epoch_train_loss=2.661334008870243
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 2.6612604151496133
1554, epoch_train_loss=2.6612604151496133
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 2.661185901423548
1555, epoch_train_loss=2.661185901423548
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 2.6611104458271533
1556, epoch_train_loss=2.6611104458271533
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 2.6610340260039176
1557, epoch_train_loss=2.6610340260039176
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 2.6609566190586835
1558, epoch_train_loss=2.6609566190586835
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 2.660878201569689
1559, epoch_train_loss=2.660878201569689
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 2.6607987495637926
1560, epoch_train_loss=2.6607987495637926
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 2.6607182385226595
1561, epoch_train_loss=2.6607182385226595
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 2.660636643351372
1562, epoch_train_loss=2.660636643351372
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 2.6605539383789476
1563, epoch_train_loss=2.6605539383789476
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 2.6604700973202675
1564, epoch_train_loss=2.6604700973202675
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 2.660385093304547
1565, epoch_train_loss=2.660385093304547
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 2.6602988988389926
1566, epoch_train_loss=2.6602988988389926
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 2.660211485806243
1567, epoch_train_loss=2.660211485806243
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 2.660122825456245
1568, epoch_train_loss=2.660122825456245
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 2.660032888391917
1569, epoch_train_loss=2.660032888391917
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 2.659941644576969
1570, epoch_train_loss=2.659941644576969
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 2.659849063330865
1571, epoch_train_loss=2.659849063330865
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 2.659755113309469
1572, epoch_train_loss=2.659755113309469
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 2.6596597625078253
1573, epoch_train_loss=2.6596597625078253
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 2.659562978256197
1574, epoch_train_loss=2.659562978256197
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 2.6594647272085497
1575, epoch_train_loss=2.6594647272085497
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 2.6593649753545168
1576, epoch_train_loss=2.6593649753545168
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 2.659263688016734
1577, epoch_train_loss=2.659263688016734
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 2.6591608298238363
1578, epoch_train_loss=2.6591608298238363
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 2.659056364740093
1579, epoch_train_loss=2.659056364740093
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 2.65895025603897
1580, epoch_train_loss=2.65895025603897
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 2.6588424663009045
1581, epoch_train_loss=2.6588424663009045
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 2.6587329574379086
1582, epoch_train_loss=2.6587329574379086
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 2.6586216906590017
1583, epoch_train_loss=2.6586216906590017
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 2.6585086264966074
1584, epoch_train_loss=2.6585086264966074
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 2.6583937247995015
1585, epoch_train_loss=2.6583937247995015
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 2.658276944744627
1586, epoch_train_loss=2.658276944744627
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 2.658158244812846
1587, epoch_train_loss=2.658158244812846
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 2.6580375828210667
1588, epoch_train_loss=2.6580375828210667
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 2.657914915928632
1589, epoch_train_loss=2.657914915928632
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 2.657790200614987
1590, epoch_train_loss=2.657790200614987
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 2.6576633927165885
1591, epoch_train_loss=2.6576633927165885
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 2.6575344474265057
1592, epoch_train_loss=2.6575344474265057
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 2.657403319315292
1593, epoch_train_loss=2.657403319315292
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 2.6572699623114553
1594, epoch_train_loss=2.6572699623114553
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 2.6571343297453263
1595, epoch_train_loss=2.6571343297453263
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 2.6569963743531373
1596, epoch_train_loss=2.6569963743531373
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 2.6568560482927523
1597, epoch_train_loss=2.6568560482927523
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 2.6567133031608816
1598, epoch_train_loss=2.6567133031608816
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 2.6565680900118385
1599, epoch_train_loss=2.6565680900118385
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 2.6564203593779068
1600, epoch_train_loss=2.6564203593779068
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 2.656270061291364
1601, epoch_train_loss=2.656270061291364
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 2.656117145308189
1602, epoch_train_loss=2.656117145308189
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 2.655961560533485
1603, epoch_train_loss=2.655961560533485
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 2.6558032556486033
1604, epoch_train_loss=2.6558032556486033
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 2.655642178939948
1605, epoch_train_loss=2.655642178939948
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 2.6554782783294346
1606, epoch_train_loss=2.6554782783294346
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 2.6553115014065383
1607, epoch_train_loss=2.6553115014065383
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 2.6551417954483014
1608, epoch_train_loss=2.6551417954483014
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 2.6549691074947392
1609, epoch_train_loss=2.6549691074947392
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 2.6547933843452696
1610, epoch_train_loss=2.6547933843452696
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 2.654614572609716
1611, epoch_train_loss=2.654614572609716
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 2.654432618732793
1612, epoch_train_loss=2.654432618732793
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 2.6542474690776343
1613, epoch_train_loss=2.6542474690776343
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 2.6540590699092053
1614, epoch_train_loss=2.6540590699092053
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 2.6538673674958027
1615, epoch_train_loss=2.6538673674958027
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 2.65367230810814
1616, epoch_train_loss=2.65367230810814
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 2.65347383807853
1617, epoch_train_loss=2.65347383807853
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 2.653271903846271
1618, epoch_train_loss=2.653271903846271
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 2.6530664519874065
1619, epoch_train_loss=2.6530664519874065
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 2.6528574292938054
1620, epoch_train_loss=2.6528574292938054
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 2.652644782821966
1621, epoch_train_loss=2.652644782821966
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 2.6524284598904413
1622, epoch_train_loss=2.6524284598904413
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 2.652208408196042
1623, epoch_train_loss=2.652208408196042
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 2.651984575793492
1624, epoch_train_loss=2.651984575793492
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 2.6517569112143042
1625, epoch_train_loss=2.6517569112143042
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 2.651525363444041
1626, epoch_train_loss=2.651525363444041
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 2.6512898820432915
1627, epoch_train_loss=2.6512898820432915
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 2.651050417121801
1628, epoch_train_loss=2.651050417121801
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 2.6508069194414334
1629, epoch_train_loss=2.6508069194414334
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 2.650559340444383
1630, epoch_train_loss=2.650559340444383
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 2.6503076323189423
1631, epoch_train_loss=2.6503076323189423
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 2.6500517479840378
1632, epoch_train_loss=2.6500517479840378
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 2.649791641191808
1633, epoch_train_loss=2.649791641191808
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 2.649527266549529
1634, epoch_train_loss=2.649527266549529
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 2.6492585795809718
1635, epoch_train_loss=2.6492585795809718
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 2.6489855367003226
1636, epoch_train_loss=2.6489855367003226
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 2.648708095311467
1637, epoch_train_loss=2.648708095311467
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 2.648426213820472
1638, epoch_train_loss=2.648426213820472
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 2.648139851666579
1639, epoch_train_loss=2.648139851666579
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 2.6478489693505214
1640, epoch_train_loss=2.6478489693505214
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 2.6475535284836837
1641, epoch_train_loss=2.6475535284836837
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 2.6472534917402033
1642, epoch_train_loss=2.6472534917402033
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 2.646948822921855
1643, epoch_train_loss=2.646948822921855
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 2.646639487023721
1644, epoch_train_loss=2.646639487023721
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 2.6463254502000924
1645, epoch_train_loss=2.6463254502000924
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 2.6460066797228676
1646, epoch_train_loss=2.6460066797228676
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 2.6456831440358615
1647, epoch_train_loss=2.6456831440358615
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 2.645354812809708
1648, epoch_train_loss=2.645354812809708
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 2.645021656864044
1649, epoch_train_loss=2.645021656864044
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 2.6446836481879985
1650, epoch_train_loss=2.6446836481879985
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 2.644340759904245
1651, epoch_train_loss=2.644340759904245
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 2.6439929663665107
1652, epoch_train_loss=2.6439929663665107
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 2.643640242951452
1653, epoch_train_loss=2.643640242951452
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 2.6432825662327533
1654, epoch_train_loss=2.6432825662327533
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 2.6429199138474853
1655, epoch_train_loss=2.6429199138474853
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 2.642552264497509
1656, epoch_train_loss=2.642552264497509
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 2.6421795978900127
1657, epoch_train_loss=2.6421795978900127
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 2.641801894793567
1658, epoch_train_loss=2.641801894793567
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 2.641419136913795
1659, epoch_train_loss=2.641419136913795
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 2.6410313068525872
1660, epoch_train_loss=2.6410313068525872
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 2.6406383881588535
1661, epoch_train_loss=2.6406383881588535
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 2.6402403651602078
1662, epoch_train_loss=2.6402403651602078
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 2.6398372230414866
1663, epoch_train_loss=2.6398372230414866
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 2.6394289477010875
1664, epoch_train_loss=2.6394289477010875
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 2.6390155256977867
1665, epoch_train_loss=2.6390155256977867
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 2.6385969442626735
1666, epoch_train_loss=2.6385969442626735
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 2.6381731912460697
1667, epoch_train_loss=2.6381731912460697
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 2.6377442549599297
1668, epoch_train_loss=2.6377442549599297
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 2.6373101242555417
1669, epoch_train_loss=2.6373101242555417
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 2.636870788327813
1670, epoch_train_loss=2.636870788327813
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 2.6364262367588336
1671, epoch_train_loss=2.6364262367588336
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 2.635976459459643
1672, epoch_train_loss=2.635976459459643
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 2.6355214465022905
1673, epoch_train_loss=2.6355214465022905
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 2.6350611882028714
1674, epoch_train_loss=2.6350611882028714
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 2.634595674915502
1675, epoch_train_loss=2.634595674915502
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 2.634124897081226
1676, epoch_train_loss=2.634124897081226
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 2.633648845131713
1677, epoch_train_loss=2.633648845131713
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 2.6331675094297546
1678, epoch_train_loss=2.6331675094297546
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 2.632680880249455
1679, epoch_train_loss=2.632680880249455
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 2.6321889475625464
1680, epoch_train_loss=2.6321889475625464
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 2.6316917012545225
1681, epoch_train_loss=2.6316917012545225
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 2.631189130794563
1682, epoch_train_loss=2.631189130794563
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 2.630681225337836
1683, epoch_train_loss=2.630681225337836
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 2.630167973632832
1684, epoch_train_loss=2.630167973632832
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 2.629649363969229
1685, epoch_train_loss=2.629649363969229
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 2.629125384127104
1686, epoch_train_loss=2.629125384127104
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 2.6285960213275263
1687, epoch_train_loss=2.6285960213275263
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 2.6280612621845183
1688, epoch_train_loss=2.6280612621845183
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 2.627521092658396
1689, epoch_train_loss=2.627521092658396
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 2.6269754980104247
1690, epoch_train_loss=2.6269754980104247
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 2.6264244627587745
1691, epoch_train_loss=2.6264244627587745
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 2.625867970591075
1692, epoch_train_loss=2.625867970591075
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 2.625306004500878
1693, epoch_train_loss=2.625306004500878
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 2.624738546434584
1694, epoch_train_loss=2.624738546434584
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 2.624165577565175
1695, epoch_train_loss=2.624165577565175
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 2.623587078073759
1696, epoch_train_loss=2.623587078073759
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 2.62300302715609
1697, epoch_train_loss=2.62300302715609
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 2.6224134029847974
1698, epoch_train_loss=2.6224134029847974
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 2.6218181826242932
1699, epoch_train_loss=2.6218181826242932
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 2.6212173421360996
1700, epoch_train_loss=2.6212173421360996
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 2.620610856351445
1701, epoch_train_loss=2.620610856351445
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 2.619998699026426
1702, epoch_train_loss=2.619998699026426
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 2.6193808426603216
1703, epoch_train_loss=2.6193808426603216
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 2.61875725845603
1704, epoch_train_loss=2.61875725845603
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 2.6181279164314004
1705, epoch_train_loss=2.6181279164314004
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 2.617492785181223
1706, epoch_train_loss=2.617492785181223
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 2.616851832039391
1707, epoch_train_loss=2.616851832039391
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 2.6162050228874913
1708, epoch_train_loss=2.6162050228874913
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 2.6155523221115926
1709, epoch_train_loss=2.6155523221115926
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 2.614893692716214
1710, epoch_train_loss=2.614893692716214
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 2.6142290960716394
1711, epoch_train_loss=2.6142290960716394
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 2.61355849202534
1712, epoch_train_loss=2.61355849202534
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 2.612881838856462
1713, epoch_train_loss=2.612881838856462
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 2.612199093063564
1714, epoch_train_loss=2.612199093063564
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 2.6115102094726823
1715, epoch_train_loss=2.6115102094726823
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 2.610815141182706
1716, epoch_train_loss=2.610815141182706
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 2.610113839337738
1717, epoch_train_loss=2.610113839337738
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 2.609406253226664
1718, epoch_train_loss=2.609406253226664
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 2.6086923302134326
1719, epoch_train_loss=2.6086923302134326
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 2.6079720154873103
1720, epoch_train_loss=2.6079720154873103
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 2.607245252146788
1721, epoch_train_loss=2.607245252146788
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 2.606511981048143
1722, epoch_train_loss=2.606511981048143
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 2.6057721407603305
1723, epoch_train_loss=2.6057721407603305
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 2.6050256672128596
1724, epoch_train_loss=2.6050256672128596
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 2.6042724939852557
1725, epoch_train_loss=2.6042724939852557
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 2.603512551751496
1726, epoch_train_loss=2.603512551751496
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 2.602745768367321
1727, epoch_train_loss=2.602745768367321
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 2.6019720686455377
1728, epoch_train_loss=2.6019720686455377
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 2.6011913741766532
1729, epoch_train_loss=2.6011913741766532
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 2.6004036031346374
1730, epoch_train_loss=2.6004036031346374
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 2.599608670067259
1731, epoch_train_loss=2.599608670067259
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 2.5988064856704147
1732, epoch_train_loss=2.5988064856704147
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 2.597996956545857
1733, epoch_train_loss=2.597996956545857
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 2.597179984941615
1734, epoch_train_loss=2.597179984941615
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 2.596355468474367
1735, epoch_train_loss=2.596355468474367
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 2.5955232997660733
1736, epoch_train_loss=2.5955232997660733
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 2.5946833663270663
1737, epoch_train_loss=2.5946833663270663
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 2.593835550020216
1738, epoch_train_loss=2.593835550020216
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 2.5929797267674743
1739, epoch_train_loss=2.5929797267674743
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 2.59211576616739
1740, epoch_train_loss=2.59211576616739
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 2.591243531018294
1741, epoch_train_loss=2.591243531018294
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 2.590362877095405
1742, epoch_train_loss=2.590362877095405
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 2.589473652484576
1743, epoch_train_loss=2.589473652484576
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 2.5885756971663056
1744, epoch_train_loss=2.5885756971663056
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 2.587668842430573
1745, epoch_train_loss=2.587668842430573
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 2.5867529105546985
1746, epoch_train_loss=2.5867529105546985
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 2.585827713946271
1747, epoch_train_loss=2.585827713946271
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 2.584893054844676
1748, epoch_train_loss=2.584893054844676
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 2.5839487244087405
1749, epoch_train_loss=2.5839487244087405
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 2.5829945023801044
1750, epoch_train_loss=2.5829945023801044
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 2.5820301562059806
1751, epoch_train_loss=2.5820301562059806
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 2.581055440374463
1752, epoch_train_loss=2.581055440374463
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 2.5800700959875056
1753, epoch_train_loss=2.5800700959875056
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 2.5790738498003973
1754, epoch_train_loss=2.5790738498003973
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 2.5780664138378255
1755, epoch_train_loss=2.5780664138378255
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 2.5770474847473146
1756, epoch_train_loss=2.5770474847473146
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 2.576016743390299
1757, epoch_train_loss=2.576016743390299
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 2.5749738542130456
1758, epoch_train_loss=2.5749738542130456
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 2.5739184653456197
1759, epoch_train_loss=2.5739184653456197
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 2.572850208234859
1760, epoch_train_loss=2.572850208234859
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 2.571768698207121
1761, epoch_train_loss=2.571768698207121
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 2.570673534673948
1762, epoch_train_loss=2.570673534673948
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 2.569564302338869
1763, epoch_train_loss=2.569564302338869
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 2.5684405725476878
1764, epoch_train_loss=2.5684405725476878
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 2.567301905394989
1765, epoch_train_loss=2.567301905394989
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 2.5661478521416363
1766, epoch_train_loss=2.5661478521416363
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 2.5649779589468964
1767, epoch_train_loss=2.5649779589468964
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 2.563791771096534
1768, epoch_train_loss=2.563791771096534
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 2.5625888382442703
1769, epoch_train_loss=2.5625888382442703
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 2.5613687206175144
1770, epoch_train_loss=2.5613687206175144
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 2.5601309961743315
1771, epoch_train_loss=2.5601309961743315
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 2.5588752686978635
1772, epoch_train_loss=2.5588752686978635
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 2.5576011766050373
1773, epoch_train_loss=2.5576011766050373
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 2.5563084029738303
1774, epoch_train_loss=2.5563084029738303
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 2.5549966856903956
1775, epoch_train_loss=2.5549966856903956
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 2.553665861561439
1776, epoch_train_loss=2.553665861561439
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 2.552316429201642
1777, epoch_train_loss=2.552316429201642
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 2.5509634908812067
1778, epoch_train_loss=2.5509634908812067
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 2.549978421957279
1779, epoch_train_loss=2.549978421957279
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 2.560656256048941
1780, epoch_train_loss=2.560656256048941
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 2.822234850883922
1781, epoch_train_loss=2.822234850883922
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 2.8777565402281358
1782, epoch_train_loss=2.8777565402281358
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 4.6127605570639645
1783, epoch_train_loss=4.6127605570639645
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 4.0789291711107705
1784, epoch_train_loss=4.0789291711107705
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 4.12289485909271
1785, epoch_train_loss=4.12289485909271
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 2.8590266629365564
1786, epoch_train_loss=2.8590266629365564
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 6.99274453781888
1787, epoch_train_loss=6.99274453781888
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 4.23979716861063
1788, epoch_train_loss=4.23979716861063
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 4.812617482919488
1789, epoch_train_loss=4.812617482919488
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 4.807656104002542
1790, epoch_train_loss=4.807656104002542
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 4.781190499159623
1791, epoch_train_loss=4.781190499159623
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 4.740212683823309
1792, epoch_train_loss=4.740212683823309
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 7.046892442344103
1793, epoch_train_loss=7.046892442344103
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 4.64477805048296
1794, epoch_train_loss=4.64477805048296
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 4.608975113483259
1795, epoch_train_loss=4.608975113483259
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 4.588989437015688
1796, epoch_train_loss=4.588989437015688
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 4.584182039021836
1797, epoch_train_loss=4.584182039021836
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 4.591357129127367
1798, epoch_train_loss=4.591357129127367
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 4.605776657767887
1799, epoch_train_loss=4.605776657767887
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 4.622319050026118
1800, epoch_train_loss=4.622319050026118
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 4.636532778307258
1801, epoch_train_loss=4.636532778307258
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 4.645370376024802
1802, epoch_train_loss=4.645370376024802
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 4.647494681456712
1803, epoch_train_loss=4.647494681456712
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 4.643177400235116
1804, epoch_train_loss=4.643177400235116
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 4.633904830942356
1805, epoch_train_loss=4.633904830942356
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 4.6218413322111696
1806, epoch_train_loss=4.6218413322111696
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 4.609287289226398
1807, epoch_train_loss=4.609287289226398
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 4.598229756006463
1808, epoch_train_loss=4.598229756006463
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 4.590041400173607
1809, epoch_train_loss=4.590041400173607
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 4.5853467795278675
1810, epoch_train_loss=4.5853467795278675
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 4.5840460570095996
1811, epoch_train_loss=4.5840460570095996
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 4.585464118749294
1812, epoch_train_loss=4.585464118749294
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 4.588577747142645
1813, epoch_train_loss=4.588577747142645
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 4.5922666718123155
1814, epoch_train_loss=4.5922666718123155
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 4.595537619093739
1815, epoch_train_loss=4.595537619093739
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 4.597683440617961
1816, epoch_train_loss=4.597683440617961
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 4.598358589680725
1817, epoch_train_loss=4.598358589680725
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 4.597572334285329
1818, epoch_train_loss=4.597572334285329
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 4.595617114413605
1819, epoch_train_loss=4.595617114413605
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 4.592958471729891
1820, epoch_train_loss=4.592958471729891
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 4.59011469263447
1821, epoch_train_loss=4.59011469263447
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 4.587550254634046
1822, epoch_train_loss=4.587550254634046
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 4.585599686401516
1823, epoch_train_loss=4.585599686401516
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 4.584429715336607
1824, epoch_train_loss=4.584429715336607
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 4.58403929924885
1825, epoch_train_loss=4.58403929924885
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 4.584290500252802
1826, epoch_train_loss=4.584290500252802
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 4.584958902424877
1827, epoch_train_loss=4.584958902424877
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 4.58579072607915
1828, epoch_train_loss=4.58579072607915
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 4.586554828799004
1829, epoch_train_loss=4.586554828799004
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 4.5870808461069155
1830, epoch_train_loss=4.5870808461069155
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 4.587278918396159
1831, epoch_train_loss=4.587278918396159
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 4.587140766614368
1832, epoch_train_loss=4.587140766614368
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 4.586725436660664
1833, epoch_train_loss=4.586725436660664
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 4.586135276644765
1834, epoch_train_loss=4.586135276644765
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 4.585488463607008
1835, epoch_train_loss=4.585488463607008
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 4.584893821686849
1836, epoch_train_loss=4.584893821686849
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 4.584432150929451
1837, epoch_train_loss=4.584432150929451
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 4.584146285806352
1838, epoch_train_loss=4.584146285806352
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 4.584040080555278
1839, epoch_train_loss=4.584040080555278
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 4.5840848392384315
1840, epoch_train_loss=4.5840848392384315
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 4.584230609144484
1841, epoch_train_loss=4.584230609144484
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 4.58441933278063
1842, epoch_train_loss=4.58441933278063
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 4.584597062218452
1843, epoch_train_loss=4.584597062218452
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 4.584723131564721
1844, epoch_train_loss=4.584723131564721
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 4.584775141794538
1845, epoch_train_loss=4.584775141794538
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 4.584749609598348
1846, epoch_train_loss=4.584749609598348
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 4.584658971126871
1847, epoch_train_loss=4.584658971126871
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 4.584526184020216
1848, epoch_train_loss=4.584526184020216
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 4.584378386353832
1849, epoch_train_loss=4.584378386353832
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 4.584240973216108
1850, epoch_train_loss=4.584240973216108
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 4.584133117932557
1851, epoch_train_loss=4.584133117932557
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 4.584065303218717
1852, epoch_train_loss=4.584065303218717
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 4.584038946576873
1853, epoch_train_loss=4.584038946576873
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 4.5840477977359395
1854, epoch_train_loss=4.5840477977359395
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 4.58408051480275
1855, epoch_train_loss=4.58408051480275
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 4.584123715782935
1856, epoch_train_loss=4.584123715782935
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 4.584164844056071
1857, epoch_train_loss=4.584164844056071
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 4.5841943445154865
1858, epoch_train_loss=4.5841943445154865
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 4.584206870358394
1859, epoch_train_loss=4.584206870358394
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 4.584201474930105
1860, epoch_train_loss=4.584201474930105
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 4.58418094234389
1861, epoch_train_loss=4.58418094234389
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 4.584150543856474
1862, epoch_train_loss=4.584150543856474
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 4.584116561342183
1863, epoch_train_loss=4.584116561342183
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 4.584084899171094
1864, epoch_train_loss=4.584084899171094
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 4.584060029147036
1865, epoch_train_loss=4.584060029147036
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 4.584044404730354
1866, epoch_train_loss=4.584044404730354
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 4.584038366973059
1867, epoch_train_loss=4.584038366973059
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 4.5840404677682125
1868, epoch_train_loss=4.5840404677682125
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 4.5840480712308755
1869, epoch_train_loss=4.5840480712308755
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 4.5840580675276845
1870, epoch_train_loss=4.5840580675276845
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 4.584067543179794
1871, epoch_train_loss=4.584067543179794
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 4.584074289177593
1872, epoch_train_loss=4.584074289177593
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 4.584077081094881
1873, epoch_train_loss=4.584077081094881
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 4.584075720789187
1874, epoch_train_loss=4.584075720789187
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 4.584070876369035
1875, epoch_train_loss=4.584070876369035
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 4.584063788453346
1876, epoch_train_loss=4.584063788453346
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 4.584055923388103
1877, epoch_train_loss=4.584055923388103
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 4.584048649065994
1878, epoch_train_loss=4.584048649065994
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 4.584042990596074
1879, epoch_train_loss=4.584042990596074
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 4.584039497218624
1880, epoch_train_loss=4.584039497218624
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 4.584038224897261
1881, epoch_train_loss=4.584038224897261
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 4.584038816216975
1882, epoch_train_loss=4.584038816216975
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 4.584040644159683
1883, epoch_train_loss=4.584040644159683
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 4.584042980427878
1884, epoch_train_loss=4.584042980427878
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 4.584045151660386
1885, epoch_train_loss=4.584045151660386
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 4.584046656033284
1886, epoch_train_loss=4.584046656033284
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 4.5840472254248175
1887, epoch_train_loss=4.5840472254248175
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 4.584046831464931
1888, epoch_train_loss=4.584046831464931
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 4.584045644804595
1889, epoch_train_loss=4.584045644804595
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 4.584043964125185
1890, epoch_train_loss=4.584043964125185
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 4.5840421340975
1891, epoch_train_loss=4.5840421340975
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 4.584040470026501
1892, epoch_train_loss=4.584040470026501
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 4.5840392023292145
1893, epoch_train_loss=4.5840392023292145
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 4.584038447743823
1894, epoch_train_loss=4.584038447743823
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 4.5840382077728155
1895, epoch_train_loss=4.5840382077728155
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 4.584038389552777
1896, epoch_train_loss=4.584038389552777
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 4.584038840949749
1897, epoch_train_loss=4.584038840949749
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 4.584039390484748
1898, epoch_train_loss=4.584039390484748
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 4.584039883522653
1899, epoch_train_loss=4.584039883522653
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 4.584040208474684
1900, epoch_train_loss=4.584040208474684
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 4.584040309849244
1901, epoch_train_loss=4.584040309849244
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 4.584040188101404
1902, epoch_train_loss=4.584040188101404
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 4.584039888778407
1903, epoch_train_loss=4.584039888778407
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 4.584039485049381
1904, epoch_train_loss=4.584039485049381
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 4.584039058216892
1905, epoch_train_loss=4.584039058216892
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 4.584038680338006
1906, epoch_train_loss=4.584038680338006
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 4.584038401905753
1907, epoch_train_loss=4.584038401905753
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 4.584038246016254
1908, epoch_train_loss=4.584038246016254
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 4.584038208930755
1909, epoch_train_loss=4.584038208930755
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 4.584038265725666
1910, epoch_train_loss=4.584038265725666
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 4.5840383789862456
1911, epoch_train_loss=4.5840383789862456
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 4.58403850829377
1912, epoch_train_loss=4.58403850829377
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 4.5840386185232305
1913, epoch_train_loss=4.5840386185232305
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 4.5840386855687365
1914, epoch_train_loss=4.5840386855687365
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 4.584038698869587
1915, epoch_train_loss=4.584038698869587
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 4.584038660846132
1916, epoch_train_loss=4.584038660846132
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 4.584038583932405
1917, epoch_train_loss=4.584038583932405
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 4.584038486229739
1918, epoch_train_loss=4.584038486229739
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 4.584038386881641
1919, epoch_train_loss=4.584038386881641
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 4.584038302118746
1920, epoch_train_loss=4.584038302118746
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 4.584038242615638
1921, epoch_train_loss=4.584038242615638
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 4.584038212426835
1922, epoch_train_loss=4.584038212426835
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 4.584038209412714
1923, epoch_train_loss=4.584038209412714
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 4.584038226793336
1924, epoch_train_loss=4.584038226793336
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 4.584038255316498
1925, epoch_train_loss=4.584038255316498
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 4.584038285502875
1926, epoch_train_loss=4.584038285502875
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 4.584038309516381
1927, epoch_train_loss=4.584038309516381
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 4.584038322365302
1928, epoch_train_loss=4.584038322365302
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 4.584038322325142
1929, epoch_train_loss=4.584038322325142
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 4.58403831064623
1930, epoch_train_loss=4.58403831064623
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 4.584038290736852
1931, epoch_train_loss=4.584038290736852
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 4.58403826707944
1932, epoch_train_loss=4.58403826707944
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 4.584038244141354
1933, epoch_train_loss=4.584038244141354
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 4.584038225494045
1934, epoch_train_loss=4.584038225494045
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 4.584038213273743
1935, epoch_train_loss=4.584038213273743
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 4.584038208025146
1936, epoch_train_loss=4.584038208025146
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 4.5840382088869465
1937, epoch_train_loss=4.5840382088869465
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 4.584038214018778
1938, epoch_train_loss=4.584038214018778
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 4.584038221140659
1939, epoch_train_loss=4.584038221140659
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 4.584038228058025
1940, epoch_train_loss=4.584038228058025
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 4.584038233072012
1941, epoch_train_loss=4.584038233072012
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 4.584038235215853
1942, epoch_train_loss=4.584038235215853
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 4.5840382343035
1943, epoch_train_loss=4.5840382343035
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 4.584038230816006
1944, epoch_train_loss=4.584038230816006
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 4.5840382256783405
1945, epoch_train_loss=4.5840382256783405
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 4.584038219991024
1946, epoch_train_loss=4.584038219991024
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 4.58403821477782
1947, epoch_train_loss=4.58403821477782
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 4.5840382107961375
1948, epoch_train_loss=4.5840382107961375
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 4.584038208435738
1949, epoch_train_loss=4.584038208435738
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 4.584038207709152
1950, epoch_train_loss=4.584038207709152
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 4.584038208318527
1951, epoch_train_loss=4.584038208318527
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 4.58403820977137
1952, epoch_train_loss=4.58403820977137
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 4.584038211513159
1953, epoch_train_loss=4.584038211513159
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 4.5840382130474895
1954, epoch_train_loss=4.5840382130474895
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 4.584038214022275
1955, epoch_train_loss=4.584038214022275
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 4.584038214271345
1956, epoch_train_loss=4.584038214271345
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 4.584038213811522
1957, epoch_train_loss=4.584038213811522
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 4.584038212804087
1958, epoch_train_loss=4.584038212804087
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 4.584038211494923
1959, epoch_train_loss=4.584038211494923
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 4.5840382101492
1960, epoch_train_loss=4.5840382101492
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 4.584038208994527
1961, epoch_train_loss=4.584038208994527
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 4.584038208182308
1962, epoch_train_loss=4.584038208182308
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 4.584038207771525
1963, epoch_train_loss=4.584038207771525
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 4.584038207733968
1964, epoch_train_loss=4.584038207733968
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 4.584038207975877
1965, epoch_train_loss=4.584038207975877
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 4.5840382083685824
1966, epoch_train_loss=4.5840382083685824
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 4.58403820878039
1967, epoch_train_loss=4.58403820878039
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 4.584038209103111
1968, epoch_train_loss=4.584038209103111
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 4.584038209268959
1969, epoch_train_loss=4.584038209268959
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 4.584038209256245
1970, epoch_train_loss=4.584038209256245
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 4.584038209084836
1971, epoch_train_loss=4.584038209084836
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 4.584038208804193
1972, epoch_train_loss=4.584038208804193
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 4.584038208477757
1973, epoch_train_loss=4.584038208477757
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 4.584038208167498
1974, epoch_train_loss=4.584038208167498
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 4.5840382079216635
1975, epoch_train_loss=4.5840382079216635
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 4.584038207767588
1976, epoch_train_loss=4.584038207767588
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 4.584038207710043
1977, epoch_train_loss=4.584038207710043
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 4.584038207734436
1978, epoch_train_loss=4.584038207734436
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 4.584038207813282
1979, epoch_train_loss=4.584038207813282
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 4.584038207914064
1980, epoch_train_loss=4.584038207914064
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 4.584038208006631
1981, epoch_train_loss=4.584038208006631
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 4.58403820806874
1982, epoch_train_loss=4.58403820806874
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 4.58403820808898
1983, epoch_train_loss=4.58403820808898
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 4.584038208066977
1984, epoch_train_loss=4.584038208066977
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 4.584038208011341
1985, epoch_train_loss=4.584038208011341
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 4.584038207936208
1986, epoch_train_loss=4.584038207936208
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 4.584038207857318
1987, epoch_train_loss=4.584038207857318
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 4.5840382077885025
1988, epoch_train_loss=4.5840382077885025
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 4.5840382077392405
1989, epoch_train_loss=4.5840382077392405
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 4.5840382077135216
1990, epoch_train_loss=4.5840382077135216
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 4.584038207710063
1991, epoch_train_loss=4.584038207710063
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 4.58403820772353
1992, epoch_train_loss=4.58403820772353
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 4.584038207746359
1993, epoch_train_loss=4.584038207746359
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 4.58403820777068
1994, epoch_train_loss=4.58403820777068
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 4.584038207789959
1995, epoch_train_loss=4.584038207789959
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 4.584038207800042
1996, epoch_train_loss=4.584038207800042
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 4.584038207799541
1997, epoch_train_loss=4.584038207799541
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 4.584038207789582
1998, epoch_train_loss=4.584038207789582
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 4.584038207773091
1999, epoch_train_loss=4.584038207773091
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 4.584038207753856
2000, epoch_train_loss=4.584038207753856
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 4.584038207735587
2001, epoch_train_loss=4.584038207735587
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 4.584038207721166
2002, epoch_train_loss=4.584038207721166
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 4.5840382077122195
2003, epoch_train_loss=4.5840382077122195
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 4.584038207709009
2004, epoch_train_loss=4.584038207709009
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 4.584038207710632
2005, epoch_train_loss=4.584038207710632
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 4.584038207715426
2006, epoch_train_loss=4.584038207715426
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 4.584038207721433
2007, epoch_train_loss=4.584038207721433
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 4.584038207726854
2008, epoch_train_loss=4.584038207726854
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 4.584038207730391
2009, epoch_train_loss=4.584038207730391
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 4.584038207731395
2010, epoch_train_loss=4.584038207731395
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 4.584038207729892
2011, epoch_train_loss=4.584038207729892
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 4.584038207726435
2012, epoch_train_loss=4.584038207726435
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 4.584038207721895
2013, epoch_train_loss=4.584038207721895
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 4.584038207717223
2014, epoch_train_loss=4.584038207717223
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 4.58403820771323
2015, epoch_train_loss=4.58403820771323
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 4.584038207710459
2016, epoch_train_loss=4.584038207710459
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 4.58403820770911
2017, epoch_train_loss=4.58403820770911
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 4.584038207709069
2018, epoch_train_loss=4.584038207709069
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 4.58403820770999
2019, epoch_train_loss=4.58403820770999
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 4.584038207711403
2020, epoch_train_loss=4.584038207711403
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 4.584038207712838
2021, epoch_train_loss=4.584038207712838
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 4.584038207713914
2022, epoch_train_loss=4.584038207713914
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 4.584038207714409
2023, epoch_train_loss=4.584038207714409
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 4.584038207714264
2024, epoch_train_loss=4.584038207714264
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 4.584038207713571
2025, epoch_train_loss=4.584038207713571
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 4.584038207712526
2026, epoch_train_loss=4.584038207712526
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 4.584038207711361
2027, epoch_train_loss=4.584038207711361
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 4.584038207710296
2028, epoch_train_loss=4.584038207710296
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 4.584038207709491
2029, epoch_train_loss=4.584038207709491
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 4.584038207709032
2030, epoch_train_loss=4.584038207709032
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 4.584038207708914
2031, epoch_train_loss=4.584038207708914
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 4.584038207709068
2032, epoch_train_loss=4.584038207709068
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 4.584038207709387
2033, epoch_train_loss=4.584038207709387
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 4.5840382077097495
2034, epoch_train_loss=4.5840382077097495
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 4.584038207710052
2035, epoch_train_loss=4.584038207710052
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 4.5840382077102255
2036, epoch_train_loss=4.5840382077102255
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 4.58403820771024
2037, epoch_train_loss=4.58403820771024
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 4.584038207710107
2038, epoch_train_loss=4.584038207710107
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 4.584038207709869
2039, epoch_train_loss=4.584038207709869
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 4.5840382077095825
2040, epoch_train_loss=4.5840382077095825
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 4.5840382077093045
2041, epoch_train_loss=4.5840382077093045
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 4.58403820770908
2042, epoch_train_loss=4.58403820770908
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 4.584038207708938
2043, epoch_train_loss=4.584038207708938
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 4.584038207708881
2044, epoch_train_loss=4.584038207708881
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 4.5840382077088995
2045, epoch_train_loss=4.5840382077088995
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 4.584038207708968
2046, epoch_train_loss=4.584038207708968
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 4.584038207709056
2047, epoch_train_loss=4.584038207709056
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 4.584038207709136
2048, epoch_train_loss=4.584038207709136
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 4.584038207709187
2049, epoch_train_loss=4.584038207709187
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 4.584038207709201
2050, epoch_train_loss=4.584038207709201
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 4.584038207709176
2051, epoch_train_loss=4.584038207709176
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 4.584038207709121
2052, epoch_train_loss=4.584038207709121
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 4.584038207709049
2053, epoch_train_loss=4.584038207709049
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 4.584038207708976
2054, epoch_train_loss=4.584038207708976
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 4.584038207708914
2055, epoch_train_loss=4.584038207708914
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 4.584038207708871
2056, epoch_train_loss=4.584038207708871
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 4.584038207708849
2057, epoch_train_loss=4.584038207708849
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 4.584038207708849
2058, epoch_train_loss=4.584038207708849
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 4.584038207708861
2059, epoch_train_loss=4.584038207708861
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 4.584038207708882
2060, epoch_train_loss=4.584038207708882
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 4.5840382077088995
2061, epoch_train_loss=4.5840382077088995
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 4.584038207708913
2062, epoch_train_loss=4.584038207708913
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 4.584038207708917
2063, epoch_train_loss=4.584038207708917
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 4.58403820770891
2064, epoch_train_loss=4.58403820770891
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 4.584038207708897
2065, epoch_train_loss=4.584038207708897
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 4.584038207708878
2066, epoch_train_loss=4.584038207708878
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 4.584038207708857
2067, epoch_train_loss=4.584038207708857
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 4.58403820770884
2068, epoch_train_loss=4.58403820770884
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 4.584038207708826
2069, epoch_train_loss=4.584038207708826
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 4.584038207708818
2070, epoch_train_loss=4.584038207708818
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 4.584038207708814
2071, epoch_train_loss=4.584038207708814
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 4.584038207708815
2072, epoch_train_loss=4.584038207708815
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 4.584038207708819
2073, epoch_train_loss=4.584038207708819
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 4.584038207708821
2074, epoch_train_loss=4.584038207708821
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 4.584038207708823
2075, epoch_train_loss=4.584038207708823
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 4.584038207708822
2076, epoch_train_loss=4.584038207708822
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 4.5840382077088195
2077, epoch_train_loss=4.5840382077088195
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 4.584038207708815
2078, epoch_train_loss=4.584038207708815
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 4.584038207708808
2079, epoch_train_loss=4.584038207708808
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 4.584038207708801
2080, epoch_train_loss=4.584038207708801
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 4.5840382077087956
2081, epoch_train_loss=4.5840382077087956
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 4.584038207708789
2082, epoch_train_loss=4.584038207708789
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 4.584038207708785
2083, epoch_train_loss=4.584038207708785
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 4.584038207708781
2084, epoch_train_loss=4.584038207708781
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 4.5840382077087805
2085, epoch_train_loss=4.5840382077087805
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 4.584038207708779
2086, epoch_train_loss=4.584038207708779
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 4.584038207708778
2087, epoch_train_loss=4.584038207708778
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 4.584038207708777
2088, epoch_train_loss=4.584038207708777
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 4.584038207708774
2089, epoch_train_loss=4.584038207708774
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 4.584038207708772
2090, epoch_train_loss=4.584038207708772
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 4.584038207708769
2091, epoch_train_loss=4.584038207708769
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 4.584038207708766
2092, epoch_train_loss=4.584038207708766
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 4.584038207708762
2093, epoch_train_loss=4.584038207708762
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 4.584038207708759
2094, epoch_train_loss=4.584038207708759
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 4.584038207708756
2095, epoch_train_loss=4.584038207708756
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 4.584038207708752
2096, epoch_train_loss=4.584038207708752
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 4.584038207708749
2097, epoch_train_loss=4.584038207708749
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 4.584038207708748
2098, epoch_train_loss=4.584038207708748
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 4.584038207708745
2099, epoch_train_loss=4.584038207708745
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 4.584038207708743
2100, epoch_train_loss=4.584038207708743
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 4.584038207708741
2101, epoch_train_loss=4.584038207708741
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 4.584038207708739
2102, epoch_train_loss=4.584038207708739
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 4.584038207708737
2103, epoch_train_loss=4.584038207708737
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 4.584038207708733
2104, epoch_train_loss=4.584038207708733
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 4.584038207708731
2105, epoch_train_loss=4.584038207708731
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 4.584038207708729
2106, epoch_train_loss=4.584038207708729
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 4.584038207708725
2107, epoch_train_loss=4.584038207708725
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 4.584038207708722
2108, epoch_train_loss=4.584038207708722
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 4.584038207708719
2109, epoch_train_loss=4.584038207708719
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 4.584038207708717
2110, epoch_train_loss=4.584038207708717
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 4.584038207708714
2111, epoch_train_loss=4.584038207708714
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 4.584038207708712
2112, epoch_train_loss=4.584038207708712
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 4.58403820770871
2113, epoch_train_loss=4.58403820770871
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 4.584038207708708
2114, epoch_train_loss=4.584038207708708
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 4.584038207708705
2115, epoch_train_loss=4.584038207708705
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 4.584038207708702
2116, epoch_train_loss=4.584038207708702
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 4.5840382077087
2117, epoch_train_loss=4.5840382077087
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 4.584038207708698
2118, epoch_train_loss=4.584038207708698
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 4.584038207708696
2119, epoch_train_loss=4.584038207708696
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 4.5840382077086925
2120, epoch_train_loss=4.5840382077086925
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 4.58403820770869
2121, epoch_train_loss=4.58403820770869
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 4.584038207708687
2122, epoch_train_loss=4.584038207708687
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 4.5840382077086845
2123, epoch_train_loss=4.5840382077086845
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 4.584038207708682
2124, epoch_train_loss=4.584038207708682
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 4.58403820770868
2125, epoch_train_loss=4.58403820770868
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 4.584038207708677
2126, epoch_train_loss=4.584038207708677
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 4.584038207708675
2127, epoch_train_loss=4.584038207708675
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 4.584038207708673
2128, epoch_train_loss=4.584038207708673
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 4.584038207708669
2129, epoch_train_loss=4.584038207708669
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 4.584038207708668
2130, epoch_train_loss=4.584038207708668
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 4.584038207708664
2131, epoch_train_loss=4.584038207708664
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 4.584038207708662
2132, epoch_train_loss=4.584038207708662
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 4.5840382077086606
2133, epoch_train_loss=4.5840382077086606
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 4.584038207708657
2134, epoch_train_loss=4.584038207708657
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 4.584038207708655
2135, epoch_train_loss=4.584038207708655
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 4.584038207708652
2136, epoch_train_loss=4.584038207708652
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 4.584038207708649
2137, epoch_train_loss=4.584038207708649
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 4.584038207708647
2138, epoch_train_loss=4.584038207708647
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 4.584038207708644
2139, epoch_train_loss=4.584038207708644
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 4.584038207708642
2140, epoch_train_loss=4.584038207708642
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 4.584038207708639
2141, epoch_train_loss=4.584038207708639
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 4.584038207708637
2142, epoch_train_loss=4.584038207708637
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 4.584038207708634
2143, epoch_train_loss=4.584038207708634
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 4.584038207708631
2144, epoch_train_loss=4.584038207708631
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 4.5840382077086295
2145, epoch_train_loss=4.5840382077086295
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 4.584038207708626
2146, epoch_train_loss=4.584038207708626
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 4.584038207708624
2147, epoch_train_loss=4.584038207708624
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 4.5840382077086215
2148, epoch_train_loss=4.5840382077086215
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 4.584038207708619
2149, epoch_train_loss=4.584038207708619
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 4.584038207708616
2150, epoch_train_loss=4.584038207708616
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 4.584038207708614
2151, epoch_train_loss=4.584038207708614
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 4.584038207708612
2152, epoch_train_loss=4.584038207708612
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 4.584038207708608
2153, epoch_train_loss=4.584038207708608
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 4.584038207708606
2154, epoch_train_loss=4.584038207708606
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 4.584038207708604
2155, epoch_train_loss=4.584038207708604
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 4.584038207708601
2156, epoch_train_loss=4.584038207708601
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 4.584038207708599
2157, epoch_train_loss=4.584038207708599
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 4.584038207708597
2158, epoch_train_loss=4.584038207708597
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 4.584038207708593
2159, epoch_train_loss=4.584038207708593
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 4.58403820770859
2160, epoch_train_loss=4.58403820770859
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 4.584038207708589
2161, epoch_train_loss=4.584038207708589
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 4.584038207708586
2162, epoch_train_loss=4.584038207708586
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 4.584038207708583
2163, epoch_train_loss=4.584038207708583
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 4.58403820770858
2164, epoch_train_loss=4.58403820770858
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 4.584038207708577
2165, epoch_train_loss=4.584038207708577
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 4.584038207708575
2166, epoch_train_loss=4.584038207708575
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 4.584038207708573
2167, epoch_train_loss=4.584038207708573
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 4.58403820770857
2168, epoch_train_loss=4.58403820770857
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 4.584038207708567
2169, epoch_train_loss=4.584038207708567
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 4.584038207708565
2170, epoch_train_loss=4.584038207708565
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 4.584038207708562
2171, epoch_train_loss=4.584038207708562
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 4.584038207708559
2172, epoch_train_loss=4.584038207708559
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 4.5840382077085575
2173, epoch_train_loss=4.5840382077085575
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 4.584038207708555
2174, epoch_train_loss=4.584038207708555
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 4.584038207708552
2175, epoch_train_loss=4.584038207708552
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 4.5840382077085495
2176, epoch_train_loss=4.5840382077085495
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 4.584038207708547
2177, epoch_train_loss=4.584038207708547
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 4.584038207708544
2178, epoch_train_loss=4.584038207708544
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 4.5840382077085415
2179, epoch_train_loss=4.5840382077085415
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 4.58403820770854
2180, epoch_train_loss=4.58403820770854
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 4.584038207708537
2181, epoch_train_loss=4.584038207708537
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 4.584038207708534
2182, epoch_train_loss=4.584038207708534
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 4.584038207708532
2183, epoch_train_loss=4.584038207708532
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 4.584038207708529
2184, epoch_train_loss=4.584038207708529
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 4.584038207708526
2185, epoch_train_loss=4.584038207708526
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 4.584038207708524
2186, epoch_train_loss=4.584038207708524
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 4.584038207708521
2187, epoch_train_loss=4.584038207708521
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 4.584038207708518
2188, epoch_train_loss=4.584038207708518
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 4.584038207708517
2189, epoch_train_loss=4.584038207708517
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 4.584038207708513
2190, epoch_train_loss=4.584038207708513
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 4.584038207708511
2191, epoch_train_loss=4.584038207708511
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 4.584038207708507
2192, epoch_train_loss=4.584038207708507
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 4.584038207708505
2193, epoch_train_loss=4.584038207708505
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 4.5840382077085025
2194, epoch_train_loss=4.5840382077085025
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 4.5840382077085
2195, epoch_train_loss=4.5840382077085
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 4.584038207708498
2196, epoch_train_loss=4.584038207708498
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 4.5840382077084945
2197, epoch_train_loss=4.5840382077084945
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 4.584038207708493
2198, epoch_train_loss=4.584038207708493
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 4.584038207708489
2199, epoch_train_loss=4.584038207708489
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 4.584038207708487
2200, epoch_train_loss=4.584038207708487
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 4.584038207708485
2201, epoch_train_loss=4.584038207708485
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 4.584038207708482
2202, epoch_train_loss=4.584038207708482
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 4.584038207708479
2203, epoch_train_loss=4.584038207708479
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 4.584038207708477
2204, epoch_train_loss=4.584038207708477
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 4.584038207708474
2205, epoch_train_loss=4.584038207708474
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 4.584038207708471
2206, epoch_train_loss=4.584038207708471
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 4.584038207708469
2207, epoch_train_loss=4.584038207708469
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 4.584038207708466
2208, epoch_train_loss=4.584038207708466
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 4.584038207708464
2209, epoch_train_loss=4.584038207708464
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 4.584038207708461
2210, epoch_train_loss=4.584038207708461
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 4.584038207708459
2211, epoch_train_loss=4.584038207708459
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 4.584038207708455
2212, epoch_train_loss=4.584038207708455
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 4.584038207708454
2213, epoch_train_loss=4.584038207708454
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 4.58403820770845
2214, epoch_train_loss=4.58403820770845
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 4.584038207708448
2215, epoch_train_loss=4.584038207708448
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 4.584038207708446
2216, epoch_train_loss=4.584038207708446
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 4.584038207708443
2217, epoch_train_loss=4.584038207708443
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 4.58403820770844
2218, epoch_train_loss=4.58403820770844
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 4.584038207708437
2219, epoch_train_loss=4.584038207708437
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 4.584038207708434
2220, epoch_train_loss=4.584038207708434
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 4.584038207708431
2221, epoch_train_loss=4.584038207708431
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 4.584038207708429
2222, epoch_train_loss=4.584038207708429
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 4.584038207708426
2223, epoch_train_loss=4.584038207708426
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 4.584038207708424
2224, epoch_train_loss=4.584038207708424
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 4.584038207708421
2225, epoch_train_loss=4.584038207708421
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 4.584038207708419
2226, epoch_train_loss=4.584038207708419
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 4.584038207708415
2227, epoch_train_loss=4.584038207708415
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 4.584038207708414
2228, epoch_train_loss=4.584038207708414
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 4.58403820770841
2229, epoch_train_loss=4.58403820770841
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 4.584038207708408
2230, epoch_train_loss=4.584038207708408
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 4.584038207708405
2231, epoch_train_loss=4.584038207708405
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 4.584038207708403
2232, epoch_train_loss=4.584038207708403
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 4.5840382077084
2233, epoch_train_loss=4.5840382077084
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 4.584038207708398
2234, epoch_train_loss=4.584038207708398
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 4.584038207708395
2235, epoch_train_loss=4.584038207708395
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 4.584038207708392
2236, epoch_train_loss=4.584038207708392
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 4.58403820770839
2237, epoch_train_loss=4.58403820770839
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 4.584038207708387
2238, epoch_train_loss=4.584038207708387
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 4.584038207708384
2239, epoch_train_loss=4.584038207708384
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 4.584038207708382
2240, epoch_train_loss=4.584038207708382
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 4.584038207708379
2241, epoch_train_loss=4.584038207708379
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 4.584038207708376
2242, epoch_train_loss=4.584038207708376
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 4.584038207708374
2243, epoch_train_loss=4.584038207708374
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 4.584038207708371
2244, epoch_train_loss=4.584038207708371
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 4.5840382077083675
2245, epoch_train_loss=4.5840382077083675
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 4.584038207708365
2246, epoch_train_loss=4.584038207708365
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 4.584038207708363
2247, epoch_train_loss=4.584038207708363
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 4.5840382077083595
2248, epoch_train_loss=4.5840382077083595
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 4.584038207708358
2249, epoch_train_loss=4.584038207708358
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 4.584038207708354
2250, epoch_train_loss=4.584038207708354
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 4.5840382077083515
2251, epoch_train_loss=4.5840382077083515
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 4.584038207708349
2252, epoch_train_loss=4.584038207708349
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 4.584038207708346
2253, epoch_train_loss=4.584038207708346
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 4.5840382077083435
2254, epoch_train_loss=4.5840382077083435
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 4.584038207708342
2255, epoch_train_loss=4.584038207708342
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 4.584038207708338
2256, epoch_train_loss=4.584038207708338
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 4.5840382077083355
2257, epoch_train_loss=4.5840382077083355
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 4.584038207708333
2258, epoch_train_loss=4.584038207708333
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 4.58403820770833
2259, epoch_train_loss=4.58403820770833
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 4.584038207708328
2260, epoch_train_loss=4.584038207708328
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 4.584038207708326
2261, epoch_train_loss=4.584038207708326
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 4.584038207708322
2262, epoch_train_loss=4.584038207708322
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 4.58403820770832
2263, epoch_train_loss=4.58403820770832
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 4.584038207708318
2264, epoch_train_loss=4.584038207708318
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 4.584038207708314
2265, epoch_train_loss=4.584038207708314
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 4.5840382077083115
2266, epoch_train_loss=4.5840382077083115
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 4.58403820770831
2267, epoch_train_loss=4.58403820770831
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 4.584038207708306
2268, epoch_train_loss=4.584038207708306
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 4.584038207708304
2269, epoch_train_loss=4.584038207708304
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 4.584038207708301
2270, epoch_train_loss=4.584038207708301
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 4.584038207708297
2271, epoch_train_loss=4.584038207708297
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 4.584038207708295
2272, epoch_train_loss=4.584038207708295
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 4.584038207708292
2273, epoch_train_loss=4.584038207708292
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 4.584038207708289
2274, epoch_train_loss=4.584038207708289
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 4.5840382077082875
2275, epoch_train_loss=4.5840382077082875
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 4.584038207708284
2276, epoch_train_loss=4.584038207708284
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 4.584038207708281
2277, epoch_train_loss=4.584038207708281
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 4.584038207708279
2278, epoch_train_loss=4.584038207708279
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 4.584038207708277
2279, epoch_train_loss=4.584038207708277
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 4.584038207708273
2280, epoch_train_loss=4.584038207708273
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 4.5840382077082715
2281, epoch_train_loss=4.5840382077082715
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 4.584038207708268
2282, epoch_train_loss=4.584038207708268
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 4.584038207708265
2283, epoch_train_loss=4.584038207708265
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 4.584038207708263
2284, epoch_train_loss=4.584038207708263
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 4.58403820770826
2285, epoch_train_loss=4.58403820770826
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 4.584038207708257
2286, epoch_train_loss=4.584038207708257
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 4.584038207708255
2287, epoch_train_loss=4.584038207708255
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 4.584038207708252
2288, epoch_train_loss=4.584038207708252
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 4.584038207708249
2289, epoch_train_loss=4.584038207708249
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 4.584038207708247
2290, epoch_train_loss=4.584038207708247
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 4.584038207708244
2291, epoch_train_loss=4.584038207708244
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 4.584038207708241
2292, epoch_train_loss=4.584038207708241
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 4.584038207708239
2293, epoch_train_loss=4.584038207708239
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 4.584038207708236
2294, epoch_train_loss=4.584038207708236
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 4.584038207708233
2295, epoch_train_loss=4.584038207708233
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 4.584038207708231
2296, epoch_train_loss=4.584038207708231
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 4.584038207708228
2297, epoch_train_loss=4.584038207708228
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 4.584038207708224
2298, epoch_train_loss=4.584038207708224
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 4.584038207708221
2299, epoch_train_loss=4.584038207708221
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 4.584038207708219
2300, epoch_train_loss=4.584038207708219
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 4.584038207708216
2301, epoch_train_loss=4.584038207708216
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 4.584038207708214
2302, epoch_train_loss=4.584038207708214
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 4.58403820770821
2303, epoch_train_loss=4.58403820770821
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 4.584038207708208
2304, epoch_train_loss=4.584038207708208
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 4.584038207708205
2305, epoch_train_loss=4.584038207708205
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 4.584038207708202
2306, epoch_train_loss=4.584038207708202
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 4.5840382077082
2307, epoch_train_loss=4.5840382077082
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 4.584038207708197
2308, epoch_train_loss=4.584038207708197
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 4.584038207708194
2309, epoch_train_loss=4.584038207708194
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 4.584038207708191
2310, epoch_train_loss=4.584038207708191
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 4.584038207708189
2311, epoch_train_loss=4.584038207708189
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 4.584038207708185
2312, epoch_train_loss=4.584038207708185
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 4.584038207708184
2313, epoch_train_loss=4.584038207708184
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 4.58403820770818
2314, epoch_train_loss=4.58403820770818
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 4.584038207708177
2315, epoch_train_loss=4.584038207708177
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 4.584038207708175
2316, epoch_train_loss=4.584038207708175
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 4.584038207708172
2317, epoch_train_loss=4.584038207708172
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 4.584038207708169
2318, epoch_train_loss=4.584038207708169
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 4.584038207708168
2319, epoch_train_loss=4.584038207708168
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 4.584038207708164
2320, epoch_train_loss=4.584038207708164
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 4.584038207708161
2321, epoch_train_loss=4.584038207708161
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 4.584038207708159
2322, epoch_train_loss=4.584038207708159
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 4.584038207708155
2323, epoch_train_loss=4.584038207708155
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 4.5840382077081525
2324, epoch_train_loss=4.5840382077081525
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 4.584038207708149
2325, epoch_train_loss=4.584038207708149
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 4.584038207708146
2326, epoch_train_loss=4.584038207708146
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 4.584038207708144
2327, epoch_train_loss=4.584038207708144
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 4.584038207708141
2328, epoch_train_loss=4.584038207708141
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 4.584038207708138
2329, epoch_train_loss=4.584038207708138
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 4.584038207708136
2330, epoch_train_loss=4.584038207708136
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 4.584038207708133
2331, epoch_train_loss=4.584038207708133
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 4.58403820770813
2332, epoch_train_loss=4.58403820770813
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 4.584038207708128
2333, epoch_train_loss=4.584038207708128
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 4.584038207708125
2334, epoch_train_loss=4.584038207708125
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 4.584038207708122
2335, epoch_train_loss=4.584038207708122
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 4.584038207708119
2336, epoch_train_loss=4.584038207708119
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 4.584038207708116
2337, epoch_train_loss=4.584038207708116
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 4.584038207708113
2338, epoch_train_loss=4.584038207708113
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 4.584038207708111
2339, epoch_train_loss=4.584038207708111
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 4.584038207708108
2340, epoch_train_loss=4.584038207708108
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 4.5840382077081046
2341, epoch_train_loss=4.5840382077081046
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 4.584038207708103
2342, epoch_train_loss=4.584038207708103
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 4.584038207708099
2343, epoch_train_loss=4.584038207708099
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 4.584038207708097
2344, epoch_train_loss=4.584038207708097
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 4.584038207708094
2345, epoch_train_loss=4.584038207708094
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 4.584038207708091
2346, epoch_train_loss=4.584038207708091
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 4.584038207708089
2347, epoch_train_loss=4.584038207708089
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 4.584038207708086
2348, epoch_train_loss=4.584038207708086
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 4.584038207708082
2349, epoch_train_loss=4.584038207708082
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 4.584038207708079
2350, epoch_train_loss=4.584038207708079
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 4.584038207708077
2351, epoch_train_loss=4.584038207708077
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 4.584038207708074
2352, epoch_train_loss=4.584038207708074
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 4.584038207708072
2353, epoch_train_loss=4.584038207708072
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 4.584038207708068
2354, epoch_train_loss=4.584038207708068
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 4.5840382077080655
2355, epoch_train_loss=4.5840382077080655
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 4.584038207708063
2356, epoch_train_loss=4.584038207708063
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 4.584038207708059
2357, epoch_train_loss=4.584038207708059
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 4.5840382077080575
2358, epoch_train_loss=4.5840382077080575
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 4.584038207708055
2359, epoch_train_loss=4.584038207708055
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 4.584038207708052
2360, epoch_train_loss=4.584038207708052
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 4.584038207708049
2361, epoch_train_loss=4.584038207708049
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 4.584038207708046
2362, epoch_train_loss=4.584038207708046
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 4.584038207708043
2363, epoch_train_loss=4.584038207708043
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 4.5840382077080415
2364, epoch_train_loss=4.5840382077080415
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 4.584038207708037
2365, epoch_train_loss=4.584038207708037
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 4.584038207708035
2366, epoch_train_loss=4.584038207708035
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 4.584038207708032
2367, epoch_train_loss=4.584038207708032
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 4.584038207708029
2368, epoch_train_loss=4.584038207708029
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 4.584038207708026
2369, epoch_train_loss=4.584038207708026
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 4.584038207708024
2370, epoch_train_loss=4.584038207708024
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 4.584038207708021
2371, epoch_train_loss=4.584038207708021
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 4.5840382077080175
2372, epoch_train_loss=4.5840382077080175
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 4.584038207708015
2373, epoch_train_loss=4.584038207708015
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 4.584038207708011
2374, epoch_train_loss=4.584038207708011
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 4.584038207708009
2375, epoch_train_loss=4.584038207708009
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 4.584038207708006
2376, epoch_train_loss=4.584038207708006
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 4.584038207708003
2377, epoch_train_loss=4.584038207708003
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 4.584038207708
2378, epoch_train_loss=4.584038207708
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 4.584038207707998
2379, epoch_train_loss=4.584038207707998
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 4.584038207707994
2380, epoch_train_loss=4.584038207707994
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 4.584038207707992
2381, epoch_train_loss=4.584038207707992
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 4.584038207707989
2382, epoch_train_loss=4.584038207707989
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 4.5840382077079855
2383, epoch_train_loss=4.5840382077079855
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 4.584038207707984
2384, epoch_train_loss=4.584038207707984
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 4.58403820770798
2385, epoch_train_loss=4.58403820770798
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 4.584038207707978
2386, epoch_train_loss=4.584038207707978
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 4.584038207707975
2387, epoch_train_loss=4.584038207707975
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 4.584038207707972
2388, epoch_train_loss=4.584038207707972
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 4.5840382077079695
2389, epoch_train_loss=4.5840382077079695
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 4.584038207707967
2390, epoch_train_loss=4.584038207707967
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 4.584038207707963
2391, epoch_train_loss=4.584038207707963
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 4.584038207707961
2392, epoch_train_loss=4.584038207707961
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 4.584038207707958
2393, epoch_train_loss=4.584038207707958
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 4.584038207707955
2394, epoch_train_loss=4.584038207707955
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 4.584038207707952
2395, epoch_train_loss=4.584038207707952
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 4.58403820770795
2396, epoch_train_loss=4.58403820770795
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 4.5840382077079465
2397, epoch_train_loss=4.5840382077079465
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 4.584038207707944
2398, epoch_train_loss=4.584038207707944
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 4.58403820770794
2399, epoch_train_loss=4.58403820770794
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 4.584038207707937
2400, epoch_train_loss=4.584038207707937
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 4.584038207707934
2401, epoch_train_loss=4.584038207707934
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 4.584038207707931
2402, epoch_train_loss=4.584038207707931
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 4.584038207707929
2403, epoch_train_loss=4.584038207707929
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 4.584038207707926
2404, epoch_train_loss=4.584038207707926
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 4.5840382077079225
2405, epoch_train_loss=4.5840382077079225
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 4.58403820770792
2406, epoch_train_loss=4.58403820770792
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 4.584038207707917
2407, epoch_train_loss=4.584038207707917
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 4.584038207707914
2408, epoch_train_loss=4.584038207707914
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 4.584038207707912
2409, epoch_train_loss=4.584038207707912
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 4.584038207707908
2410, epoch_train_loss=4.584038207707908
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 4.584038207707906
2411, epoch_train_loss=4.584038207707906
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 4.584038207707903
2412, epoch_train_loss=4.584038207707903
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 4.584038207707899
2413, epoch_train_loss=4.584038207707899
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 4.584038207707897
2414, epoch_train_loss=4.584038207707897
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 4.584038207707894
2415, epoch_train_loss=4.584038207707894
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 4.584038207707891
2416, epoch_train_loss=4.584038207707891
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 4.584038207707889
2417, epoch_train_loss=4.584038207707889
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 4.584038207707886
2418, epoch_train_loss=4.584038207707886
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 4.584038207707882
2419, epoch_train_loss=4.584038207707882
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 4.58403820770788
2420, epoch_train_loss=4.58403820770788
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 4.584038207707876
2421, epoch_train_loss=4.584038207707876
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 4.584038207707874
2422, epoch_train_loss=4.584038207707874
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 4.58403820770787
2423, epoch_train_loss=4.58403820770787
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 4.5840382077078665
2424, epoch_train_loss=4.5840382077078665
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 4.584038207707865
2425, epoch_train_loss=4.584038207707865
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 4.584038207707861
2426, epoch_train_loss=4.584038207707861
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 4.5840382077078585
2427, epoch_train_loss=4.5840382077078585
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 4.584038207707856
2428, epoch_train_loss=4.584038207707856
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 4.584038207707853
2429, epoch_train_loss=4.584038207707853
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 4.5840382077078505
2430, epoch_train_loss=4.5840382077078505
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 4.584038207707847
2431, epoch_train_loss=4.584038207707847
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 4.584038207707843
2432, epoch_train_loss=4.584038207707843
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 4.584038207707842
2433, epoch_train_loss=4.584038207707842
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 4.584038207707839
2434, epoch_train_loss=4.584038207707839
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 4.584038207707835
2435, epoch_train_loss=4.584038207707835
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 4.584038207707833
2436, epoch_train_loss=4.584038207707833
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 4.58403820770783
2437, epoch_train_loss=4.58403820770783
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 4.584038207707827
2438, epoch_train_loss=4.584038207707827
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 4.584038207707824
2439, epoch_train_loss=4.584038207707824
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 4.584038207707821
2440, epoch_train_loss=4.584038207707821
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 4.584038207707819
2441, epoch_train_loss=4.584038207707819
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 4.584038207707816
2442, epoch_train_loss=4.584038207707816
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 4.584038207707812
2443, epoch_train_loss=4.584038207707812
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 4.58403820770781
2444, epoch_train_loss=4.58403820770781
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 4.584038207707806
2445, epoch_train_loss=4.584038207707806
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 4.5840382077078035
2446, epoch_train_loss=4.5840382077078035
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 4.5840382077078
2447, epoch_train_loss=4.5840382077078
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 4.584038207707797
2448, epoch_train_loss=4.584038207707797
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 4.584038207707794
2449, epoch_train_loss=4.584038207707794
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 4.584038207707791
2450, epoch_train_loss=4.584038207707791
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 4.584038207707788
2451, epoch_train_loss=4.584038207707788
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 4.584038207707786
2452, epoch_train_loss=4.584038207707786
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 4.584038207707782
2453, epoch_train_loss=4.584038207707782
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 4.5840382077077795
2454, epoch_train_loss=4.5840382077077795
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 4.584038207707777
2455, epoch_train_loss=4.584038207707777
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 4.584038207707773
2456, epoch_train_loss=4.584038207707773
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 4.584038207707771
2457, epoch_train_loss=4.584038207707771
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 4.584038207707768
2458, epoch_train_loss=4.584038207707768
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 4.584038207707764
2459, epoch_train_loss=4.584038207707764
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 4.584038207707762
2460, epoch_train_loss=4.584038207707762
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 4.584038207707759
2461, epoch_train_loss=4.584038207707759
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 4.5840382077077555
2462, epoch_train_loss=4.5840382077077555
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 4.584038207707753
2463, epoch_train_loss=4.584038207707753
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 4.58403820770775
2464, epoch_train_loss=4.58403820770775
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 4.5840382077077475
2465, epoch_train_loss=4.5840382077077475
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 4.584038207707745
2466, epoch_train_loss=4.584038207707745
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 4.584038207707741
2467, epoch_train_loss=4.584038207707741
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 4.584038207707738
2468, epoch_train_loss=4.584038207707738
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 4.584038207707736
2469, epoch_train_loss=4.584038207707736
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 4.584038207707733
2470, epoch_train_loss=4.584038207707733
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 4.584038207707729
2471, epoch_train_loss=4.584038207707729
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 4.584038207707726
2472, epoch_train_loss=4.584038207707726
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 4.584038207707723
2473, epoch_train_loss=4.584038207707723
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 4.58403820770772
2474, epoch_train_loss=4.58403820770772
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 4.584038207707717
2475, epoch_train_loss=4.584038207707717
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 4.584038207707714
2476, epoch_train_loss=4.584038207707714
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 4.584038207707711
2477, epoch_train_loss=4.584038207707711
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 4.584038207707708
2478, epoch_train_loss=4.584038207707708
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 4.584038207707705
2479, epoch_train_loss=4.584038207707705
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 4.584038207707702
2480, epoch_train_loss=4.584038207707702
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 4.5840382077076995
2481, epoch_train_loss=4.5840382077076995
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 4.584038207707696
2482, epoch_train_loss=4.584038207707696
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 4.584038207707693
2483, epoch_train_loss=4.584038207707693
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 4.584038207707691
2484, epoch_train_loss=4.584038207707691
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 4.584038207707687
2485, epoch_train_loss=4.584038207707687
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 4.584038207707684
2486, epoch_train_loss=4.584038207707684
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 4.584038207707682
2487, epoch_train_loss=4.584038207707682
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 4.584038207707678
2488, epoch_train_loss=4.584038207707678
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 4.584038207707676
2489, epoch_train_loss=4.584038207707676
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 4.584038207707673
2490, epoch_train_loss=4.584038207707673
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 4.584038207707669
2491, epoch_train_loss=4.584038207707669
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 4.584038207707668
2492, epoch_train_loss=4.584038207707668
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 4.584038207707664
2493, epoch_train_loss=4.584038207707664
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 4.5840382077076605
2494, epoch_train_loss=4.5840382077076605
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 4.584038207707657
2495, epoch_train_loss=4.584038207707657
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 4.584038207707653
2496, epoch_train_loss=4.584038207707653
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 4.584038207707652
2497, epoch_train_loss=4.584038207707652
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 4.584038207707648
2498, epoch_train_loss=4.584038207707648
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 4.5840382077076445
2499, epoch_train_loss=4.5840382077076445
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e9750> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e9750> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeac1e9750> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e8e20> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1ea260> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e95a0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e80d0> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1ea200> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1ebbb0> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1e9210> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac1ea410> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1eb8b0> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac1eb4c0> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac1ebac0> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1eb4f0> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e9d80> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e8af0> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac1e9360> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e88e0> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1ebe50> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1ebe20> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac1e8100> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac1e8910> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac1ea380> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac07ded0> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeac07dcc0> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac07e350> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992718  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e8e20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e8e20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-3.48053232e-03 -9.22981806e-04 -2.09507924e-03 ... -1.11294850e+01
 -1.11294850e+01 -1.11294850e+01] = SCAN,
rho_a.shape=(6, 6320), rho_b.shape=(6, 6320)
fxc_a.shape=(6320,), fxc_b.shape=(6320,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12640), fxc.shape=(12640,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(2, 6320, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12640, 3)
rho_filt.shape=(12640,)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046675  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ea260> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ea260> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.10256797e-03 -5.98013179e-04 -6.71209617e-05 ... -5.03581543e+00
 -5.03581543e+00 -5.03581543e+00] = SCAN,
rho_a.shape=(6, 5016), rho_b.shape=(6, 5016)
fxc_a.shape=(5016,), fxc_b.shape=(5016,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 10032), fxc.shape=(10032,)
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(2, 5016, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(10032, 3)
rho_filt.shape=(10032,)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e95a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e95a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.59173730e-03 -7.67300285e-04 -6.09330303e-05 ... -7.27736608e-01
 -7.27736608e-01 -7.27736608e-01] = SCAN,
rho_a.shape=(6, 2440), rho_b.shape=(6, 2440)
fxc_a.shape=(2440,), fxc_b.shape=(2440,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 2440), fxc.shape=(2440,)
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2, 2440, 3)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627841  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e80d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e80d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-6.71507910e-03 -1.45299376e-03 -1.45299376e-03 ... -1.46930969e-02
 -2.05021258e+00 -2.05021258e+00] = SCAN,
rho_a.shape=(6, 4592), rho_b.shape=(6, 4592)
fxc_a.shape=(4592,), fxc_b.shape=(4592,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 9184), fxc.shape=(9184,)
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(2, 4592, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(9184, 3)
rho_filt.shape=(9184,)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033774427828  <S^2> = 2.0027452  2S+1 = 3.0018296
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ea200> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ea200> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-7.09691652e-04 -1.23398274e-04 -6.19401081e-06 ... -5.78388655e+00
 -5.78388655e+00 -5.78388655e+00] = SCAN,
rho_a.shape=(6, 5040), rho_b.shape=(6, 5040)
fxc_a.shape=(5040,), fxc_b.shape=(5040,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 10080), fxc.shape=(10080,)
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(2, 5040, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(10080, 3)
rho_filt.shape=(10080,)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121336  <S^2> = 0.75161941  2S+1 = 2.0016188
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ebbb0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ebbb0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-9.44782437e-04 -1.01991647e-03 -3.62319459e-04 ... -1.26646370e+01
 -1.26646370e+01 -1.26646370e+01] = SCAN,
rho_a.shape=(6, 6152), rho_b.shape=(6, 6152)
fxc_a.shape=(6152,), fxc_b.shape=(6152,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12304), fxc.shape=(12304,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(2, 6152, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12304, 3)
rho_filt.shape=(12304,)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.22656098928  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e9210> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e9210> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.39566757e-02 -8.69603390e-03 -4.30180232e-03 ... -1.39784131e-04
 -1.04894578e-03 -7.75317699e-05] = SCAN,
rho_a.shape=(6, 6088), rho_b.shape=(6, 6088)
fxc_a.shape=(6088,), fxc_b.shape=(6088,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12176), fxc.shape=(12176,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(2, 6088, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12176, 3)
rho_filt.shape=(12176,)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786807091  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ea410> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ea410> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.43010404e-03 -7.97631460e-04 -9.75922385e-04 ... -1.18982463e+01
 -1.18982463e+01 -1.18982463e+01] = SCAN,
rho_a.shape=(6, 6320), rho_b.shape=(6, 6320)
fxc_a.shape=(6320,), fxc_b.shape=(6320,)
mol.spin != 0 and sum(mol.nelec) > 1
rho.shape=(6, 12640), fxc.shape=(12640,)
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(2, 6320, 3)
mol.spin != 0 and sum(mol.nelec) > 1
concatenating spin channels along axis=0
tdrho.shape=(12640, 3)
rho_filt.shape=(12640,)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 7.1054274e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1eb8b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1eb8b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.04987750e-03 -6.68953858e-04 -8.57556270e-04 ... -1.07485583e-03
 -8.01425698e-01 -8.01425698e-01] = SCAN,
rho_a.shape=(6, 9752), rho_b.shape=(6, 9752)
fxc_a.shape=(9752,), fxc_b.shape=(9752,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9752), fxc.shape=(9752,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(2, 9752, 3)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.3377924465131  <S^2> = 4.0073012e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1eb4c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1eb4c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.97917285e-04 -2.54412366e-05 -3.15182243e-05 ... -6.37386500e-01
 -6.37386500e-01 -6.37386500e-01] = SCAN,
rho_a.shape=(6, 12256), rho_b.shape=(6, 12256)
fxc_a.shape=(12256,), fxc_b.shape=(12256,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 12256), fxc.shape=(12256,)
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(2, 12256, 3)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322844  <S^2> = 1.7763568e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ebac0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ebac0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.50217115e-04 -2.07520066e-04 -9.23619896e-04 ... -2.74295208e-06
 -4.27559894e+00 -4.27559894e+00] = SCAN,
rho_a.shape=(6, 14920), rho_b.shape=(6, 14920)
fxc_a.shape=(14920,), fxc_b.shape=(14920,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 14920), fxc.shape=(14920,)
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(2, 14920, 3)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888959  <S^2> = 5.0803806e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1eb4f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1eb4f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-0.00155834 -0.00091688 -0.00215831 ... -0.00091688 -0.41618507
 -0.41618507] = SCAN,
rho_a.shape=(6, 12208), rho_b.shape=(6, 12208)
fxc_a.shape=(12208,), fxc_b.shape=(12208,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 12208), fxc.shape=(12208,)
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(2, 12208, 3)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.2079227e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e9d80> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e9d80> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.92948614e-04 -1.95198688e-05 -1.16699802e-03 ... -4.89378340e-01
 -4.89378340e-01 -4.89378340e-01] = SCAN,
rho_a.shape=(6, 9824), rho_b.shape=(6, 9824)
fxc_a.shape=(9824,), fxc_b.shape=(9824,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9824), fxc.shape=(9824,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(2, 9824, 3)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894551844  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e8af0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e8af0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-5.64370031e-04 -9.92738314e-05 -5.07343544e-06 ... -6.59150586e-01
 -6.59150586e-01 -6.59150586e-01] = SCAN,
rho_a.shape=(6, 9912), rho_b.shape=(6, 9912)
fxc_a.shape=(9912,), fxc_b.shape=(9912,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9912), fxc.shape=(9912,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(2, 9912, 3)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346371  <S^2> = 1.4210855e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e9360> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e9360> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.83270456e-05 -8.83270456e-05 -9.75839850e-04 ... -3.46719667e-05
 -3.31708644e-05 -3.31708644e-05] = SCAN,
rho_a.shape=(6, 15208), rho_b.shape=(6, 15208)
fxc_a.shape=(15208,), fxc_b.shape=(15208,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 15208), fxc.shape=(15208,)
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(2, 15208, 3)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5636385e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e88e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e88e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-5.37000578e-04 -8.55494549e-04 -2.46853288e-03 ... -7.34251999e-01
 -7.34251999e-01 -7.34251999e-01] = SCAN,
rho_a.shape=(6, 10040), rho_b.shape=(6, 10040)
fxc_a.shape=(10040,), fxc_b.shape=(10040,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 10040), fxc.shape=(10040,)
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(2, 10040, 3)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374078  <S^2> = 7.4606987e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ebe50> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ebe50> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-2.38161177e-04 -1.81188367e-05 -2.37300299e-05 ... -2.83738108e+00
 -2.83738108e+00 -2.83738108e+00] = SCAN,
rho_a.shape=(6, 8552), rho_b.shape=(6, 8552)
fxc_a.shape=(8552,), fxc_b.shape=(8552,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 8552), fxc.shape=(8552,)
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(2, 8552, 3)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.4606987e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ebe20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ebe20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-0.00113445 -0.00118624 -0.00118624 ... -0.48434639 -0.48434639
 -0.48434639] = SCAN,
rho_a.shape=(6, 6936), rho_b.shape=(6, 6936)
fxc_a.shape=(6936,), fxc_b.shape=(6936,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 6936), fxc.shape=(6936,)
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(2, 6936, 3)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506579  <S^2> = 1.5859314e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e8100> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e8100> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-0.00297935 -0.00297935 -0.00407089 ... -0.00297935 -0.00297935
 -0.00407089] = SCAN,
rho_a.shape=(6, 11536), rho_b.shape=(6, 11536)
fxc_a.shape=(11536,), fxc_b.shape=(11536,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 11536), fxc.shape=(11536,)
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(2, 11536, 3)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.3844043e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1e8910> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1e8910> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.61400996e-04 -4.90484900e-04 -2.56451718e-03 ... -9.59296113e+00
 -9.59296113e+00 -9.59296113e+00] = SCAN,
rho_a.shape=(6, 24512), rho_b.shape=(6, 24512)
fxc_a.shape=(24512,), fxc_b.shape=(24512,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 24512), fxc.shape=(24512,)
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(2, 24512, 3)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469576  <S^2> = 2.5391245e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac1ea380> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac1ea380> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.28637920e-03 -4.32383300e-04 -3.74057272e-05 ... -1.91722770e+00
 -1.91722770e+00 -1.91722770e+00] = SCAN,
rho_a.shape=(6, 13096), rho_b.shape=(6, 13096)
fxc_a.shape=(13096,), fxc_b.shape=(13096,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 13096), fxc.shape=(13096,)
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(2, 13096, 3)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336125344  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac07ded0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac07ded0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-1.59505974e-04 -2.59076798e-04 -2.59978780e-04 ... -3.86944047e-01
 -3.86944047e-01 -3.86944047e-01] = SCAN,
rho_a.shape=(6, 12384), rho_b.shape=(6, 12384)
fxc_a.shape=(12384,), fxc_b.shape=(12384,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 12384), fxc.shape=(12384,)
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(2, 12384, 3)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864076  <S^2> = 3.1530334e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac07dcc0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac07dcc0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.68439986e-04 -2.42462569e-04 -1.69927031e-05 ... -2.55230307e-05
 -2.55230307e-05 -2.55230307e-05] = SCAN,
rho_a.shape=(6, 13936), rho_b.shape=(6, 13936)
fxc_a.shape=(13936,), fxc_b.shape=(13936,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 13936), fxc.shape=(13936,)
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(2, 13936, 3)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483505  <S^2> = 6.1932681e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac07e350> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac07e350> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-7.67688751e-04 -4.57393214e-05 -2.02834191e-04 ... -1.14928924e+00
 -1.14928924e+00 -1.14928924e+00] = SCAN,
rho_a.shape=(6, 9656), rho_b.shape=(6, 9656)
fxc_a.shape=(9656,), fxc_b.shape=(9656,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 9656), fxc.shape=(9656,)
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(2, 9656, 3)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3152146e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Exchange contribution only
SCAN,
spin scaling
fxc with xc_func = [-8.33850535e-04 -2.34903029e-04 -1.75623665e-05 ... -1.92891112e-05
 -1.92891112e-05 -1.92891112e-05] = SCAN,
rho_a.shape=(6, 15256), rho_b.shape=(6, 15256)
fxc_a.shape=(15256,), fxc_b.shape=(15256,)
NOT (mol.spin != 0 and sum(mol.nelec) > 1)
rho.shape=(6, 15256), fxc.shape=(15256,)
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(2, 15256, 3)
localnet.spin_scaling: concatenating the data
first data shape = (10940, 3)
concatenated: tdrho.shape=(258865, 3)
PRE NAN FILT: tFxc.shape=(258865,), tdrho.shape=(258865, 3)
nan_filt_rho.shape=(258865,)
nan_filt_fxc.shape=(258865,)
tFxc.shape=(258865,), tdrho.shape=(258865, 3)
inp[0].shape = (258865, 2)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 5.17777097652608
0, epoch_train_loss=5.17777097652608
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 4.884949382849235
1, epoch_train_loss=4.884949382849235
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 4.663667232123323
2, epoch_train_loss=4.663667232123323
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 4.562867561769796
3, epoch_train_loss=4.562867561769796
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 4.467923416098074
4, epoch_train_loss=4.467923416098074
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 4.282469831031646
5, epoch_train_loss=4.282469831031646
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 4.068319499588049
6, epoch_train_loss=4.068319499588049
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 3.7917351208997947
7, epoch_train_loss=3.7917351208997947
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 3.550574543728887
8, epoch_train_loss=3.550574543728887
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 3.2743281630714756
9, epoch_train_loss=3.2743281630714756
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 3.2690288857434204
10, epoch_train_loss=3.2690288857434204
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 3.146873298839932
11, epoch_train_loss=3.146873298839932
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 3.1910217217099794
12, epoch_train_loss=3.1910217217099794
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 3.0118236326019545
13, epoch_train_loss=3.0118236326019545
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 2.9693703165394525
14, epoch_train_loss=2.9693703165394525
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 2.7839158110064526
15, epoch_train_loss=2.7839158110064526
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 2.914067057312435
16, epoch_train_loss=2.914067057312435
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 2.7335481680509104
17, epoch_train_loss=2.7335481680509104
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 2.758311842486933
18, epoch_train_loss=2.758311842486933
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 2.7373621878281504
19, epoch_train_loss=2.7373621878281504
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 2.7538780286840727
20, epoch_train_loss=2.7538780286840727
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 2.682183050948182
21, epoch_train_loss=2.682183050948182
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 2.7345580305418946
22, epoch_train_loss=2.7345580305418946
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 2.705066685082934
23, epoch_train_loss=2.705066685082934
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 2.705712305390559
24, epoch_train_loss=2.705712305390559
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 2.668391589052495
25, epoch_train_loss=2.668391589052495
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 2.702055279652386
26, epoch_train_loss=2.702055279652386
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 2.676459984966291
27, epoch_train_loss=2.676459984966291
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 2.6864547969242123
28, epoch_train_loss=2.6864547969242123
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 2.6543057785914037
29, epoch_train_loss=2.6543057785914037
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 2.67384091110228
30, epoch_train_loss=2.67384091110228
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 2.661748473811049
31, epoch_train_loss=2.661748473811049
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 2.668986453585336
32, epoch_train_loss=2.668986453585336
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 2.6549102396036273
33, epoch_train_loss=2.6549102396036273
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 2.6565900855195874
34, epoch_train_loss=2.6565900855195874
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 2.6623276104204696
35, epoch_train_loss=2.6623276104204696
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 2.657644960725614
36, epoch_train_loss=2.657644960725614
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 2.657896109087415
37, epoch_train_loss=2.657896109087415
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 2.6471297633422686
38, epoch_train_loss=2.6471297633422686
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 2.654657912820529
39, epoch_train_loss=2.654657912820529
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 2.6487276233905943
40, epoch_train_loss=2.6487276233905943
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 2.651078336830818
41, epoch_train_loss=2.651078336830818
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 2.6428117353712772
42, epoch_train_loss=2.6428117353712772
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 2.6460318507218914
43, epoch_train_loss=2.6460318507218914
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 2.643462718923679
44, epoch_train_loss=2.643462718923679
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 2.6466566568757948
45, epoch_train_loss=2.6466566568757948
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 2.6421606427048956
46, epoch_train_loss=2.6421606427048956
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 2.643349976172039
47, epoch_train_loss=2.643349976172039
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 2.6401524933731593
48, epoch_train_loss=2.6401524933731593
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 2.6436711985515995
49, epoch_train_loss=2.6436711985515995
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 2.6408194085168253
50, epoch_train_loss=2.6408194085168253
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 2.6421771148106297
51, epoch_train_loss=2.6421771148106297
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 2.639140673432803
52, epoch_train_loss=2.639140673432803
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 2.6405560715560226
53, epoch_train_loss=2.6405560715560226
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 2.640036152405527
54, epoch_train_loss=2.640036152405527
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 2.639262542778888
55, epoch_train_loss=2.639262542778888
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 2.6392380735357714
56, epoch_train_loss=2.6392380735357714
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 2.637356231879728
57, epoch_train_loss=2.637356231879728
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 2.6387877673241666
58, epoch_train_loss=2.6387877673241666
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 2.637740314272963
59, epoch_train_loss=2.637740314272963
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 2.637645837836585
60, epoch_train_loss=2.637645837836585
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 2.6374119654710433
61, epoch_train_loss=2.6374119654710433
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 2.636462731189404
62, epoch_train_loss=2.636462731189404
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 2.637343706997577
63, epoch_train_loss=2.637343706997577
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 2.6366259298351147
64, epoch_train_loss=2.6366259298351147
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 2.6360448968401453
65, epoch_train_loss=2.6360448968401453
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 2.6363028118480205
66, epoch_train_loss=2.6363028118480205
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 2.6356765640620288
67, epoch_train_loss=2.6356765640620288
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 2.6356760542968534
68, epoch_train_loss=2.6356760542968534
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 2.6357683017455757
69, epoch_train_loss=2.6357683017455757
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 2.6350266740385058
70, epoch_train_loss=2.6350266740385058
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 2.6349193368207637
71, epoch_train_loss=2.6349193368207637
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 2.635193292889205
72, epoch_train_loss=2.635193292889205
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 2.6347129197966175
73, epoch_train_loss=2.6347129197966175
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 2.6342525717900975
74, epoch_train_loss=2.6342525717900975
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 2.634332488799823
75, epoch_train_loss=2.634332488799823
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 2.634179156354882
76, epoch_train_loss=2.634179156354882
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 2.633732177841181
77, epoch_train_loss=2.633732177841181
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 2.6335508185913614
78, epoch_train_loss=2.6335508185913614
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 2.6334845212955083
79, epoch_train_loss=2.6334845212955083
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 2.633229487393167
80, epoch_train_loss=2.633229487393167
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 2.632983479577325
81, epoch_train_loss=2.632983479577325
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 2.6328957393823345
82, epoch_train_loss=2.6328957393823345
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 2.6327328322134176
83, epoch_train_loss=2.6327328322134176
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 2.632462105544965
84, epoch_train_loss=2.632462105544965
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 2.632275084181813
85, epoch_train_loss=2.632275084181813
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 2.6321354667425636
86, epoch_train_loss=2.6321354667425636
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 2.6319188583151143
87, epoch_train_loss=2.6319188583151143
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 2.6316813495086815
88, epoch_train_loss=2.6316813495086815
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 2.631508066501884
89, epoch_train_loss=2.631508066501884
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 2.631368194714153
90, epoch_train_loss=2.631368194714153
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 2.6311907320884935
91, epoch_train_loss=2.6311907320884935
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 2.630956664219568
92, epoch_train_loss=2.630956664219568
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 2.6307169565365953
93, epoch_train_loss=2.6307169565365953
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 2.63052120618804
94, epoch_train_loss=2.63052120618804
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 2.630353821808706
95, epoch_train_loss=2.630353821808706
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 2.6301551751610073
96, epoch_train_loss=2.6301551751610073
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 2.629895035377484
97, epoch_train_loss=2.629895035377484
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 2.629622242085255
98, epoch_train_loss=2.629622242085255
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 2.6293729431648343
99, epoch_train_loss=2.6293729431648343
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 2.62913003783891
100, epoch_train_loss=2.62913003783891
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 2.62887114250817
101, epoch_train_loss=2.62887114250817
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 2.6285967141800533
102, epoch_train_loss=2.6285967141800533
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 2.6283018798473425
103, epoch_train_loss=2.6283018798473425
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 2.627971642407208
104, epoch_train_loss=2.627971642407208
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 2.627617153274639
105, epoch_train_loss=2.627617153274639
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 2.6272546960071064
106, epoch_train_loss=2.6272546960071064
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 2.6268802713430666
107, epoch_train_loss=2.6268802713430666
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 2.6264812433910474
108, epoch_train_loss=2.6264812433910474
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 2.626061540714157
109, epoch_train_loss=2.626061540714157
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 2.625623160448925
110, epoch_train_loss=2.625623160448925
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 2.6251602635231706
111, epoch_train_loss=2.6251602635231706
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 2.6246714915794587
112, epoch_train_loss=2.6246714915794587
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 2.6241553275855387
113, epoch_train_loss=2.6241553275855387
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 2.623603956184019
114, epoch_train_loss=2.623603956184019
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 2.623018016636098
115, epoch_train_loss=2.623018016636098
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 2.622401934334281
116, epoch_train_loss=2.622401934334281
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 2.6217513634642917
117, epoch_train_loss=2.6217513634642917
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 2.6210685545349928
118, epoch_train_loss=2.6210685545349928
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 2.6203807185514876
119, epoch_train_loss=2.6203807185514876
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 2.619737116433271
120, epoch_train_loss=2.619737116433271
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 2.619260689766926
121, epoch_train_loss=2.619260689766926
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 2.6192637526485014
122, epoch_train_loss=2.6192637526485014
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 2.6203426785044153
123, epoch_train_loss=2.6203426785044153
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 2.623452274514617
124, epoch_train_loss=2.623452274514617
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 2.6282323931604354
125, epoch_train_loss=2.6282323931604354
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 2.6308612421146766
126, epoch_train_loss=2.6308612421146766
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 2.623151589897236
127, epoch_train_loss=2.623151589897236
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 2.612554157362747
128, epoch_train_loss=2.612554157362747
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 2.612955941916541
129, epoch_train_loss=2.612955941916541
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 2.6179471718640057
130, epoch_train_loss=2.6179471718640057
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 2.61347811619808
131, epoch_train_loss=2.61347811619808
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 2.6074141753309776
132, epoch_train_loss=2.6074141753309776
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 2.6107384813872865
133, epoch_train_loss=2.6107384813872865
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 2.6100112227826724
134, epoch_train_loss=2.6100112227826724
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 2.6036147200665942
135, epoch_train_loss=2.6036147200665942
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 2.605616698868087
136, epoch_train_loss=2.605616698868087
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 2.605090835024332
137, epoch_train_loss=2.605090835024332
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 2.600689039114328
138, epoch_train_loss=2.600689039114328
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 2.600911381167539
139, epoch_train_loss=2.600911381167539
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 2.601779628643124
140, epoch_train_loss=2.601779628643124
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 2.6000739899600833
141, epoch_train_loss=2.6000739899600833
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 2.5964963066350237
142, epoch_train_loss=2.5964963066350237
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 2.596183763720304
143, epoch_train_loss=2.596183763720304
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 2.5990610234922213
144, epoch_train_loss=2.5990610234922213
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 2.601201272470409
145, epoch_train_loss=2.601201272470409
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 2.6052641331806536
146, epoch_train_loss=2.6052641331806536
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 2.6093536031538336
147, epoch_train_loss=2.6093536031538336
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 2.6090215531499776
148, epoch_train_loss=2.6090215531499776
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 2.604506932280671
149, epoch_train_loss=2.604506932280671
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 2.5959141164193644
150, epoch_train_loss=2.5959141164193644
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 2.5897364148232356
151, epoch_train_loss=2.5897364148232356
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 2.5879310928785615
152, epoch_train_loss=2.5879310928785615
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 2.58935686144021
153, epoch_train_loss=2.58935686144021
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 2.591250376466263
154, epoch_train_loss=2.591250376466263
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 2.590862595308327
155, epoch_train_loss=2.590862595308327
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 2.591597063676287
156, epoch_train_loss=2.591597063676287
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 2.591748429352255
157, epoch_train_loss=2.591748429352255
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 2.5903523631479217
158, epoch_train_loss=2.5903523631479217
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 2.58884897813038
159, epoch_train_loss=2.58884897813038
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 2.5885786464770844
160, epoch_train_loss=2.5885786464770844
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 2.5864185714298493
161, epoch_train_loss=2.5864185714298493
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 2.585870949726866
162, epoch_train_loss=2.585870949726866
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 2.5853413813885786
163, epoch_train_loss=2.5853413813885786
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 2.586719857460667
164, epoch_train_loss=2.586719857460667
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 2.5897732788679435
165, epoch_train_loss=2.5897732788679435
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 2.5939671034942484
166, epoch_train_loss=2.5939671034942484
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 2.5940256780210906
167, epoch_train_loss=2.5940256780210906
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 2.5937462182588638
168, epoch_train_loss=2.5937462182588638
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 2.579557443854102
169, epoch_train_loss=2.579557443854102
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 2.573077415382073
170, epoch_train_loss=2.573077415382073
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 2.5713232664576804
171, epoch_train_loss=2.5713232664576804
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 2.5727761099797033
172, epoch_train_loss=2.5727761099797033
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 2.5775434179778087
173, epoch_train_loss=2.5775434179778087
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 2.5794642856037955
174, epoch_train_loss=2.5794642856037955
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 2.585076510970425
175, epoch_train_loss=2.585076510970425
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 2.574309075341952
176, epoch_train_loss=2.574309075341952
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 2.5722600513910385
177, epoch_train_loss=2.5722600513910385
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 2.577232438670017
178, epoch_train_loss=2.577232438670017
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 2.588746065829637
179, epoch_train_loss=2.588746065829637
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 2.594587491184599
180, epoch_train_loss=2.594587491184599
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 2.597887395129344
181, epoch_train_loss=2.597887395129344
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 2.581370871354067
182, epoch_train_loss=2.581370871354067
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 2.5694015533572636
183, epoch_train_loss=2.5694015533572636
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 2.5686401068359537
184, epoch_train_loss=2.5686401068359537
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 2.5725284050441655
185, epoch_train_loss=2.5725284050441655
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 2.5816959500963264
186, epoch_train_loss=2.5816959500963264
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 2.5664076015540482
187, epoch_train_loss=2.5664076015540482
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 2.5649763976761912
188, epoch_train_loss=2.5649763976761912
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 2.5772772078677133
189, epoch_train_loss=2.5772772078677133
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 2.5595140139823713
190, epoch_train_loss=2.5595140139823713
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 2.5609706168040858
191, epoch_train_loss=2.5609706168040858
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 2.5750444202653875
192, epoch_train_loss=2.5750444202653875
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 2.5581407810530084
193, epoch_train_loss=2.5581407810530084
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 2.5633348221966368
194, epoch_train_loss=2.5633348221966368
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 2.566291742560396
195, epoch_train_loss=2.566291742560396
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 2.5532773686252113
196, epoch_train_loss=2.5532773686252113
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 2.5726158956129725
197, epoch_train_loss=2.5726158956129725
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 2.5772276830213925
198, epoch_train_loss=2.5772276830213925
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 2.5898060951438118
199, epoch_train_loss=2.5898060951438118
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 2.7104601311783183
200, epoch_train_loss=2.7104601311783183
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 2.729116350388031
201, epoch_train_loss=2.729116350388031
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 2.714501416715384
202, epoch_train_loss=2.714501416715384
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 2.6276246636656424
203, epoch_train_loss=2.6276246636656424
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 2.6212199495167
204, epoch_train_loss=2.6212199495167
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 2.5797238481955542
205, epoch_train_loss=2.5797238481955542
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 2.6094219676949155
206, epoch_train_loss=2.6094219676949155
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 2.575661587148137
207, epoch_train_loss=2.575661587148137
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 2.606583823967505
208, epoch_train_loss=2.606583823967505
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 2.567665703040193
209, epoch_train_loss=2.567665703040193
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 2.5854034381269897
210, epoch_train_loss=2.5854034381269897
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 2.5793577873113223
211, epoch_train_loss=2.5793577873113223
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 2.560405420435855
212, epoch_train_loss=2.560405420435855
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 2.58404777524465
213, epoch_train_loss=2.58404777524465
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 2.5589210499361377
214, epoch_train_loss=2.5589210499361377
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 2.5673158709039425
215, epoch_train_loss=2.5673158709039425
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 2.568428352009778
216, epoch_train_loss=2.568428352009778
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 2.5544026125144916
217, epoch_train_loss=2.5544026125144916
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 2.565293913406328
218, epoch_train_loss=2.565293913406328
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 2.55453681454885
219, epoch_train_loss=2.55453681454885
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 2.5525358244803424
220, epoch_train_loss=2.5525358244803424
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 2.5572554347237406
221, epoch_train_loss=2.5572554347237406
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 2.5448477192680103
222, epoch_train_loss=2.5448477192680103
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 2.554117543422678
223, epoch_train_loss=2.554117543422678
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 2.5433984276555206
224, epoch_train_loss=2.5433984276555206
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 2.546998355507284
225, epoch_train_loss=2.546998355507284
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 2.54261300902362
226, epoch_train_loss=2.54261300902362
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 2.5399917757733768
227, epoch_train_loss=2.5399917757733768
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 2.540174105718613
228, epoch_train_loss=2.540174105718613
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 2.5339018730197598
229, epoch_train_loss=2.5339018730197598
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 2.5361622974638545
230, epoch_train_loss=2.5361622974638545
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 2.52916235289828
231, epoch_train_loss=2.52916235289828
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 2.530821057685509
232, epoch_train_loss=2.530821057685509
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 2.523948529201328
233, epoch_train_loss=2.523948529201328
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 2.524785382510613
234, epoch_train_loss=2.524785382510613
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 2.519065954790681
235, epoch_train_loss=2.519065954790681
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 2.5168179098508228
236, epoch_train_loss=2.5168179098508228
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 2.5143180408339356
237, epoch_train_loss=2.5143180408339356
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 2.50767033446386
238, epoch_train_loss=2.50767033446386
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 2.5073462393163073
239, epoch_train_loss=2.5073462393163073
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 2.502155265386952
240, epoch_train_loss=2.502155265386952
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 2.4964193809569832
241, epoch_train_loss=2.4964193809569832
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 2.4930573638901654
242, epoch_train_loss=2.4930573638901654
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 2.491790062831669
243, epoch_train_loss=2.491790062831669
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 2.489788486577565
244, epoch_train_loss=2.489788486577565
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 2.4904214455089186
245, epoch_train_loss=2.4904214455089186
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 2.5097742700560866
246, epoch_train_loss=2.5097742700560866
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 2.5654741873618225
247, epoch_train_loss=2.5654741873618225
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 2.745905799216372
248, epoch_train_loss=2.745905799216372
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 2.6297041838705324
249, epoch_train_loss=2.6297041838705324
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 2.707805904824573
250, epoch_train_loss=2.707805904824573
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 2.692264005189058
251, epoch_train_loss=2.692264005189058
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 2.7068058248061284
252, epoch_train_loss=2.7068058248061284
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 2.733223429926299
253, epoch_train_loss=2.733223429926299
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 2.7293290875139276
254, epoch_train_loss=2.7293290875139276
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 2.6223642085097203
255, epoch_train_loss=2.6223642085097203
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 2.705799733005363
256, epoch_train_loss=2.705799733005363
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 2.612846364107174
257, epoch_train_loss=2.612846364107174
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 2.637171891169268
258, epoch_train_loss=2.637171891169268
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 2.5984181077667974
259, epoch_train_loss=2.5984181077667974
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 2.634312332116326
260, epoch_train_loss=2.634312332116326
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 2.593262308587535
261, epoch_train_loss=2.593262308587535
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 2.6010316640717406
262, epoch_train_loss=2.6010316640717406
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 2.6019268081109637
263, epoch_train_loss=2.6019268081109637
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 2.579231325853655
264, epoch_train_loss=2.579231325853655
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 2.5868497354351923
265, epoch_train_loss=2.5868497354351923
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 2.573815325217422
266, epoch_train_loss=2.573815325217422
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 2.577484033969524
267, epoch_train_loss=2.577484033969524
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 2.5742845823977847
268, epoch_train_loss=2.5742845823977847
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 2.566935467100133
269, epoch_train_loss=2.566935467100133
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 2.574606475746745
270, epoch_train_loss=2.574606475746745
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 2.5683164734909383
271, epoch_train_loss=2.5683164734909383
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 2.5671607413150825
272, epoch_train_loss=2.5671607413150825
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 2.568639419110074
273, epoch_train_loss=2.568639419110074
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 2.5645106325162565
274, epoch_train_loss=2.5645106325162565
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 2.5637291560843036
275, epoch_train_loss=2.5637291560843036
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 2.562793529699287
276, epoch_train_loss=2.562793529699287
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 2.5597833393707514
277, epoch_train_loss=2.5597833393707514
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 2.560887396645981
278, epoch_train_loss=2.560887396645981
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 2.5567363128994582
279, epoch_train_loss=2.5567363128994582
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 2.5540744108870554
280, epoch_train_loss=2.5540744108870554
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 2.554776776146466
281, epoch_train_loss=2.554776776146466
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 2.5494835642137206
282, epoch_train_loss=2.5494835642137206
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 2.54897150616699
283, epoch_train_loss=2.54897150616699
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 2.5466947344729816
284, epoch_train_loss=2.5466947344729816
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 2.5441471412681524
285, epoch_train_loss=2.5441471412681524
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 2.5427558889028505
286, epoch_train_loss=2.5427558889028505
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 2.5388991129688594
287, epoch_train_loss=2.5388991129688594
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 2.5382973406379654
288, epoch_train_loss=2.5382973406379654
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 2.5344819576821482
289, epoch_train_loss=2.5344819576821482
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 2.532628003147149
290, epoch_train_loss=2.532628003147149
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 2.5299177234170944
291, epoch_train_loss=2.5299177234170944
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 2.527617557999882
292, epoch_train_loss=2.527617557999882
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 2.524926722348861
293, epoch_train_loss=2.524926722348861
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 2.521684168413229
294, epoch_train_loss=2.521684168413229
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 2.5194261866942775
295, epoch_train_loss=2.5194261866942775
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 2.5157121168985612
296, epoch_train_loss=2.5157121168985612
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 2.513020059266047
297, epoch_train_loss=2.513020059266047
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 2.509341755549121
298, epoch_train_loss=2.509341755549121
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 2.5062669975134404
299, epoch_train_loss=2.5062669975134404
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 2.502349270409108
300, epoch_train_loss=2.502349270409108
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 2.4989949288257143
301, epoch_train_loss=2.4989949288257143
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 2.4952150869210588
302, epoch_train_loss=2.4952150869210588
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 2.4912804488939972
303, epoch_train_loss=2.4912804488939972
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 2.4876868695192074
304, epoch_train_loss=2.4876868695192074
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 2.483509350994514
305, epoch_train_loss=2.483509350994514
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 2.479764311152787
306, epoch_train_loss=2.479764311152787
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 2.475520976709742
307, epoch_train_loss=2.475520976709742
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 2.4717117573201564
308, epoch_train_loss=2.4717117573201564
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 2.4677985296426375
309, epoch_train_loss=2.4677985296426375
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 2.4640211675517683
310, epoch_train_loss=2.4640211675517683
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 2.4600293041460315
311, epoch_train_loss=2.4600293041460315
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 2.456747386259075
312, epoch_train_loss=2.456747386259075
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 2.4534458375386214
313, epoch_train_loss=2.4534458375386214
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 2.450653972857565
314, epoch_train_loss=2.450653972857565
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 2.4484295404667864
315, epoch_train_loss=2.4484295404667864
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 2.4496239156234734
316, epoch_train_loss=2.4496239156234734
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 2.4682886327202134
317, epoch_train_loss=2.4682886327202134
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 2.5940351722784274
318, epoch_train_loss=2.5940351722784274
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 3.073465825955404
319, epoch_train_loss=3.073465825955404
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 3.02753991703696
320, epoch_train_loss=3.02753991703696
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 2.682604602184474
321, epoch_train_loss=2.682604602184474
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 2.741546376511708
322, epoch_train_loss=2.741546376511708
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 2.862086865545287
323, epoch_train_loss=2.862086865545287
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 2.5521909758706887
324, epoch_train_loss=2.5521909758706887
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 2.705210416324837
325, epoch_train_loss=2.705210416324837
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 2.7218521813383356
326, epoch_train_loss=2.7218521813383356
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 2.53320772831034
327, epoch_train_loss=2.53320772831034
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 2.5223058902108764
328, epoch_train_loss=2.5223058902108764
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 2.6610613434129653
329, epoch_train_loss=2.6610613434129653
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 2.5397617407956874
330, epoch_train_loss=2.5397617407956874
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 2.504770960567821
331, epoch_train_loss=2.504770960567821
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 2.572378142865655
332, epoch_train_loss=2.572378142865655
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 2.5750665906710006
333, epoch_train_loss=2.5750665906710006
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 2.5490413817811683
334, epoch_train_loss=2.5490413817811683
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 2.5067288139943247
335, epoch_train_loss=2.5067288139943247
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 2.5145936633133066
336, epoch_train_loss=2.5145936633133066
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 2.5398007095198736
337, epoch_train_loss=2.5398007095198736
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 2.5337372167888415
338, epoch_train_loss=2.5337372167888415
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 2.518604201314563
339, epoch_train_loss=2.518604201314563
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 2.493313528792189
340, epoch_train_loss=2.493313528792189
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 2.498477206552773
341, epoch_train_loss=2.498477206552773
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 2.5184307287829517
342, epoch_train_loss=2.5184307287829517
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 2.4931155326873813
343, epoch_train_loss=2.4931155326873813
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 2.4757540440436467
344, epoch_train_loss=2.4757540440436467
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 2.4860660068484286
345, epoch_train_loss=2.4860660068484286
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 2.489082715438861
346, epoch_train_loss=2.489082715438861
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 2.4754437455591054
347, epoch_train_loss=2.4754437455591054
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 2.4602832897070526
348, epoch_train_loss=2.4602832897070526
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 2.4617301096608384
349, epoch_train_loss=2.4617301096608384
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 2.4641485096117464
350, epoch_train_loss=2.4641485096117464
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 2.455695902804157
351, epoch_train_loss=2.455695902804157
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 2.443396586041225
352, epoch_train_loss=2.443396586041225
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 2.4469522985618877
353, epoch_train_loss=2.4469522985618877
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 2.4474851344778763
354, epoch_train_loss=2.4474851344778763
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 2.433727116390074
355, epoch_train_loss=2.433727116390074
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 2.4345109555103797
356, epoch_train_loss=2.4345109555103797
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 2.4330324770558183
357, epoch_train_loss=2.4330324770558183
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 2.42893174826782
358, epoch_train_loss=2.42893174826782
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 2.420728241506792
359, epoch_train_loss=2.420728241506792
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 2.423415358934194
360, epoch_train_loss=2.423415358934194
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 2.420091821575147
361, epoch_train_loss=2.420091821575147
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 2.4136662839491305
362, epoch_train_loss=2.4136662839491305
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 2.412480544066619
363, epoch_train_loss=2.412480544066619
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 2.412227616082141
364, epoch_train_loss=2.412227616082141
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 2.4057126818370103
365, epoch_train_loss=2.4057126818370103
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 2.406022633349976
366, epoch_train_loss=2.406022633349976
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 2.402483153379266
367, epoch_train_loss=2.402483153379266
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 2.399645392563203
368, epoch_train_loss=2.399645392563203
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 2.3978919048939793
369, epoch_train_loss=2.3978919048939793
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 2.3949095407829506
370, epoch_train_loss=2.3949095407829506
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 2.3930089972985797
371, epoch_train_loss=2.3930089972985797
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 2.390594290323302
372, epoch_train_loss=2.390594290323302
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 2.3873238309232065
373, epoch_train_loss=2.3873238309232065
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 2.38583215276459
374, epoch_train_loss=2.38583215276459
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 2.3834107095917143
375, epoch_train_loss=2.3834107095917143
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 2.379678333313476
376, epoch_train_loss=2.379678333313476
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 2.3784207905261376
377, epoch_train_loss=2.3784207905261376
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 2.375957799012362
378, epoch_train_loss=2.375957799012362
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 2.3723032539084077
379, epoch_train_loss=2.3723032539084077
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 2.370350362536618
380, epoch_train_loss=2.370350362536618
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 2.3674632916926397
381, epoch_train_loss=2.3674632916926397
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 2.3647033914331703
382, epoch_train_loss=2.3647033914331703
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 2.3616468672200135
383, epoch_train_loss=2.3616468672200135
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 2.3582554661487123
384, epoch_train_loss=2.3582554661487123
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 2.3556915273202628
385, epoch_train_loss=2.3556915273202628
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 2.351944230325223
386, epoch_train_loss=2.351944230325223
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 2.3481863185879637
387, epoch_train_loss=2.3481863185879637
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 2.344694735999591
388, epoch_train_loss=2.344694735999591
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 2.340835460018133
389, epoch_train_loss=2.340835460018133
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 2.3368399969710234
390, epoch_train_loss=2.3368399969710234
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 2.331981007551201
391, epoch_train_loss=2.331981007551201
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 2.3274098466850393
392, epoch_train_loss=2.3274098466850393
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 2.3222819435485085
393, epoch_train_loss=2.3222819435485085
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 2.317440250040153
394, epoch_train_loss=2.317440250040153
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 2.3118967549676075
395, epoch_train_loss=2.3118967549676075
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 2.306430021194404
396, epoch_train_loss=2.306430021194404
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 2.300309172915993
397, epoch_train_loss=2.300309172915993
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 2.2940665782607383
398, epoch_train_loss=2.2940665782607383
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 2.287663531362879
399, epoch_train_loss=2.287663531362879
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 2.2813792380833005
400, epoch_train_loss=2.2813792380833005
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 2.2796636638941394
401, epoch_train_loss=2.2796636638941394
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 2.2975493315520508
402, epoch_train_loss=2.2975493315520508
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 2.3620226322980677
403, epoch_train_loss=2.3620226322980677
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 2.3234779713747535
404, epoch_train_loss=2.3234779713747535
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 2.281469084707472
405, epoch_train_loss=2.281469084707472
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 2.305698252609297
406, epoch_train_loss=2.305698252609297
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 2.28538437668318
407, epoch_train_loss=2.28538437668318
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 2.322311370618318
408, epoch_train_loss=2.322311370618318
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 2.3431062199802377
409, epoch_train_loss=2.3431062199802377
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 2.277661847462827
410, epoch_train_loss=2.277661847462827
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 2.4134129100688346
411, epoch_train_loss=2.4134129100688346
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 2.274279666885814
412, epoch_train_loss=2.274279666885814
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 2.344375703065344
413, epoch_train_loss=2.344375703065344
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 2.2991964949487715
414, epoch_train_loss=2.2991964949487715
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 2.2817692573569084
415, epoch_train_loss=2.2817692573569084
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 2.3656899397187767
416, epoch_train_loss=2.3656899397187767
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 2.3737155023936003
417, epoch_train_loss=2.3737155023936003
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 2.39059279554333
418, epoch_train_loss=2.39059279554333
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 2.269412456494413
419, epoch_train_loss=2.269412456494413
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 2.3775932023889568
420, epoch_train_loss=2.3775932023889568
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 2.3057646758391064
421, epoch_train_loss=2.3057646758391064
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 2.3268417577199467
422, epoch_train_loss=2.3268417577199467
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 2.3045518503086937
423, epoch_train_loss=2.3045518503086937
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 2.24939189617619
424, epoch_train_loss=2.24939189617619
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 2.3208228939123203
425, epoch_train_loss=2.3208228939123203
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 2.2479985201821013
426, epoch_train_loss=2.2479985201821013
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 2.2727764748300574
427, epoch_train_loss=2.2727764748300574
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 2.2633917674903805
428, epoch_train_loss=2.2633917674903805
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 2.2335560998474615
429, epoch_train_loss=2.2335560998474615
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 2.251663816225023
430, epoch_train_loss=2.251663816225023
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 2.2287121670045504
431, epoch_train_loss=2.2287121670045504
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 2.2211585538375784
432, epoch_train_loss=2.2211585538375784
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 2.2350862817461117
433, epoch_train_loss=2.2350862817461117
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 2.1974722256049666
434, epoch_train_loss=2.1974722256049666
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 2.2276581501730153
435, epoch_train_loss=2.2276581501730153
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 2.195663916045378
436, epoch_train_loss=2.195663916045378
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 2.2008100515866937
437, epoch_train_loss=2.2008100515866937
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 2.1929006755336595
438, epoch_train_loss=2.1929006755336595
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 2.192084629137827
439, epoch_train_loss=2.192084629137827
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 2.1943473470536743
440, epoch_train_loss=2.1943473470536743
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 2.170488117668471
441, epoch_train_loss=2.170488117668471
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 2.1851129144980206
442, epoch_train_loss=2.1851129144980206
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 2.1691608644879246
443, epoch_train_loss=2.1691608644879246
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 2.1625792724055475
444, epoch_train_loss=2.1625792724055475
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 2.1732600416640064
445, epoch_train_loss=2.1732600416640064
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 2.1738474552484024
446, epoch_train_loss=2.1738474552484024
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 2.146199544412827
447, epoch_train_loss=2.146199544412827
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 2.1690177932369137
448, epoch_train_loss=2.1690177932369137
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 2.1809657095432735
449, epoch_train_loss=2.1809657095432735
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 2.183538559107758
450, epoch_train_loss=2.183538559107758
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 2.129294405953376
451, epoch_train_loss=2.129294405953376
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 2.179380954590225
452, epoch_train_loss=2.179380954590225
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 2.249734059882735
453, epoch_train_loss=2.249734059882735
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 2.267716614861541
454, epoch_train_loss=2.267716614861541
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 2.1786540464556103
455, epoch_train_loss=2.1786540464556103
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 2.4201456888796473
456, epoch_train_loss=2.4201456888796473
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 2.5367340698410503
457, epoch_train_loss=2.5367340698410503
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 2.579056788197407
458, epoch_train_loss=2.579056788197407
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 2.395995281367191
459, epoch_train_loss=2.395995281367191
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 2.2409517967516988
460, epoch_train_loss=2.2409517967516988
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 2.4663221512896483
461, epoch_train_loss=2.4663221512896483
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 2.269098097185689
462, epoch_train_loss=2.269098097185689
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 2.318687932927974
463, epoch_train_loss=2.318687932927974
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 2.243653091459785
464, epoch_train_loss=2.243653091459785
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 2.254902127919973
465, epoch_train_loss=2.254902127919973
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 2.3116530745561064
466, epoch_train_loss=2.3116530745561064
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 2.2639529524122897
467, epoch_train_loss=2.2639529524122897
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 2.197856577446302
468, epoch_train_loss=2.197856577446302
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 2.2630426579026297
469, epoch_train_loss=2.2630426579026297
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 2.2230470597871954
470, epoch_train_loss=2.2230470597871954
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 2.206171821849775
471, epoch_train_loss=2.206171821849775
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 2.219823733506928
472, epoch_train_loss=2.219823733506928
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 2.2010258883263685
473, epoch_train_loss=2.2010258883263685
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 2.2088074029645246
474, epoch_train_loss=2.2088074029645246
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 2.1740568391783484
475, epoch_train_loss=2.1740568391783484
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 2.1864321469608194
476, epoch_train_loss=2.1864321469608194
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 2.1749861424911967
477, epoch_train_loss=2.1749861424911967
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 2.161270746536338
478, epoch_train_loss=2.161270746536338
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 2.160708454700526
479, epoch_train_loss=2.160708454700526
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 2.164080184078821
480, epoch_train_loss=2.164080184078821
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 2.143000588605379
481, epoch_train_loss=2.143000588605379
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 2.1515177662701936
482, epoch_train_loss=2.1515177662701936
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 2.136070473983454
483, epoch_train_loss=2.136070473983454
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 2.140430582679939
484, epoch_train_loss=2.140430582679939
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 2.137670692848602
485, epoch_train_loss=2.137670692848602
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 2.129112304564968
486, epoch_train_loss=2.129112304564968
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 2.1279241495313888
487, epoch_train_loss=2.1279241495313888
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 2.1254025286574363
488, epoch_train_loss=2.1254025286574363
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 2.1147036216947526
489, epoch_train_loss=2.1147036216947526
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 2.1177214949999046
490, epoch_train_loss=2.1177214949999046
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 2.1128164978000217
491, epoch_train_loss=2.1128164978000217
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 2.108837850624922
492, epoch_train_loss=2.108837850624922
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 2.1053381237491573
493, epoch_train_loss=2.1053381237491573
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 2.1007064013090275
494, epoch_train_loss=2.1007064013090275
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 2.0988325063381827
495, epoch_train_loss=2.0988325063381827
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 2.09317816404855
496, epoch_train_loss=2.09317816404855
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 2.093497769732784
497, epoch_train_loss=2.093497769732784
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 2.088631128586948
498, epoch_train_loss=2.088631128586948
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 2.084288687870447
499, epoch_train_loss=2.084288687870447
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 2.082364256291398
500, epoch_train_loss=2.082364256291398
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 2.078439569050854
501, epoch_train_loss=2.078439569050854
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 2.0766470427531085
502, epoch_train_loss=2.0766470427531085
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 2.072025129723041
503, epoch_train_loss=2.072025129723041
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 2.070277847544629
504, epoch_train_loss=2.070277847544629
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 2.0674278054815187
505, epoch_train_loss=2.0674278054815187
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 2.0634019007067277
506, epoch_train_loss=2.0634019007067277
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 2.0620133417907143
507, epoch_train_loss=2.0620133417907143
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 2.0581145401775687
508, epoch_train_loss=2.0581145401775687
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 2.0557571959974847
509, epoch_train_loss=2.0557571959974847
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 2.05239704861746
510, epoch_train_loss=2.05239704861746
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 2.050007130454239
511, epoch_train_loss=2.050007130454239
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 2.0473120838733645
512, epoch_train_loss=2.0473120838733645
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 2.0441560312543148
513, epoch_train_loss=2.0441560312543148
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 2.041855070605249
514, epoch_train_loss=2.041855070605249
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 2.0387471592603448
515, epoch_train_loss=2.0387471592603448
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 2.0359362145190394
516, epoch_train_loss=2.0359362145190394
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 2.0332020853209722
517, epoch_train_loss=2.0332020853209722
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 2.030887146167514
518, epoch_train_loss=2.030887146167514
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 2.028005095744118
519, epoch_train_loss=2.028005095744118
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 2.0261061726687077
520, epoch_train_loss=2.0261061726687077
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 2.0248090362465287
521, epoch_train_loss=2.0248090362465287
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 2.029259152637518
522, epoch_train_loss=2.029259152637518
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 2.0573819629228876
523, epoch_train_loss=2.0573819629228876
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 2.2027157590110447
524, epoch_train_loss=2.2027157590110447
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 2.9487076295721275
525, epoch_train_loss=2.9487076295721275
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 2.714085666200149
526, epoch_train_loss=2.714085666200149
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 2.6254763541739745
527, epoch_train_loss=2.6254763541739745
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 2.7483099861859532
528, epoch_train_loss=2.7483099861859532
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 2.9361574744310035
529, epoch_train_loss=2.9361574744310035
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 2.317414169757928
530, epoch_train_loss=2.317414169757928
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 2.5746340682459032
531, epoch_train_loss=2.5746340682459032
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 2.289562427423691
532, epoch_train_loss=2.289562427423691
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 2.492794027839878
533, epoch_train_loss=2.492794027839878
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 2.2741823548422175
534, epoch_train_loss=2.2741823548422175
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 2.2097839546214932
535, epoch_train_loss=2.2097839546214932
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 2.3671468721745703
536, epoch_train_loss=2.3671468721745703
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 2.2817083183492937
537, epoch_train_loss=2.2817083183492937
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 2.3009324326085547
538, epoch_train_loss=2.3009324326085547
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 2.3152380813942837
539, epoch_train_loss=2.3152380813942837
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 2.23950131275723
540, epoch_train_loss=2.23950131275723
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 2.1994061050210294
541, epoch_train_loss=2.1994061050210294
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 2.1845323977023154
542, epoch_train_loss=2.1845323977023154
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 2.1852239412675134
543, epoch_train_loss=2.1852239412675134
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 2.137500433368066
544, epoch_train_loss=2.137500433368066
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 2.176685492629611
545, epoch_train_loss=2.176685492629611
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 2.1828323286224194
546, epoch_train_loss=2.1828323286224194
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 2.1526506095103723
547, epoch_train_loss=2.1526506095103723
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 2.178938677075408
548, epoch_train_loss=2.178938677075408
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 2.139900739223997
549, epoch_train_loss=2.139900739223997
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 2.132012068467264
550, epoch_train_loss=2.132012068467264
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 2.134864441980536
551, epoch_train_loss=2.134864441980536
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 2.1118908687980986
552, epoch_train_loss=2.1118908687980986
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 2.1246407005364083
553, epoch_train_loss=2.1246407005364083
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 2.124111157318106
554, epoch_train_loss=2.124111157318106
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 2.111440188410293
555, epoch_train_loss=2.111440188410293
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 2.1162465278442903
556, epoch_train_loss=2.1162465278442903
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 2.1046280501229813
557, epoch_train_loss=2.1046280501229813
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 2.086958044338082
558, epoch_train_loss=2.086958044338082
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 2.092719636482852
559, epoch_train_loss=2.092719636482852
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 2.0800162238875397
560, epoch_train_loss=2.0800162238875397
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 2.0878012530634584
561, epoch_train_loss=2.0878012530634584
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 2.0841795283000626
562, epoch_train_loss=2.0841795283000626
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 2.079085571352889
563, epoch_train_loss=2.079085571352889
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 2.075384789009973
564, epoch_train_loss=2.075384789009973
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 2.0678584163533564
565, epoch_train_loss=2.0678584163533564
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 2.0659554281643837
566, epoch_train_loss=2.0659554281643837
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 2.0627600492848566
567, epoch_train_loss=2.0627600492848566
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 2.0642428430978024
568, epoch_train_loss=2.0642428430978024
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 2.0591022136990262
569, epoch_train_loss=2.0591022136990262
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 2.058944758668256
570, epoch_train_loss=2.058944758668256
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 2.0537448260427196
571, epoch_train_loss=2.0537448260427196
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 2.0515024156616666
572, epoch_train_loss=2.0515024156616666
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 2.0471392882070107
573, epoch_train_loss=2.0471392882070107
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 2.0482070322765367
574, epoch_train_loss=2.0482070322765367
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 2.043737498783984
575, epoch_train_loss=2.043737498783984
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 2.0438014411428096
576, epoch_train_loss=2.0438014411428096
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 2.0397883216325345
577, epoch_train_loss=2.0397883216325345
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 2.0375123207150785
578, epoch_train_loss=2.0375123207150785
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 2.0347999164429655
579, epoch_train_loss=2.0347999164429655
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 2.0336648419615564
580, epoch_train_loss=2.0336648419615564
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 2.0307665277474296
581, epoch_train_loss=2.0307665277474296
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 2.0297266764953434
582, epoch_train_loss=2.0297266764953434
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 2.027101797955757
583, epoch_train_loss=2.027101797955757
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 2.0252438222962144
584, epoch_train_loss=2.0252438222962144
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 2.0236234596368714
585, epoch_train_loss=2.0236234596368714
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 2.021432098868228
586, epoch_train_loss=2.021432098868228
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 2.020586912891282
587, epoch_train_loss=2.020586912891282
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 2.018217290248284
588, epoch_train_loss=2.018217290248284
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 2.016732325289151
589, epoch_train_loss=2.016732325289151
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 2.015093313155566
590, epoch_train_loss=2.015093313155566
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 2.0130470963798386
591, epoch_train_loss=2.0130470963798386
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 2.0118222659343044
592, epoch_train_loss=2.0118222659343044
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 2.0099515114500783
593, epoch_train_loss=2.0099515114500783
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 2.0082143410284785
594, epoch_train_loss=2.0082143410284785
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 2.006606643379299
595, epoch_train_loss=2.006606643379299
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 2.004996452505732
596, epoch_train_loss=2.004996452505732
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 2.0030978909640913
597, epoch_train_loss=2.0030978909640913
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 2.0017640813019826
598, epoch_train_loss=2.0017640813019826
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 2.000010307304176
599, epoch_train_loss=2.000010307304176
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 1.9982602780943257
600, epoch_train_loss=1.9982602780943257
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 1.9966157234200308
601, epoch_train_loss=1.9966157234200308
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 1.9950681744349377
602, epoch_train_loss=1.9950681744349377
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 1.9932780510476773
603, epoch_train_loss=1.9932780510476773
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 1.991565899357191
604, epoch_train_loss=1.991565899357191
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 1.9900730107513094
605, epoch_train_loss=1.9900730107513094
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 1.9883625721042018
606, epoch_train_loss=1.9883625721042018
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 1.9866022494677937
607, epoch_train_loss=1.9866022494677937
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 1.9849436344977336
608, epoch_train_loss=1.9849436344977336
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 1.9833974041105726
609, epoch_train_loss=1.9833974041105726
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 1.9817517886218683
610, epoch_train_loss=1.9817517886218683
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 1.9800569738302545
611, epoch_train_loss=1.9800569738302545
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 1.9783550885877756
612, epoch_train_loss=1.9783550885877756
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 1.9767611436661165
613, epoch_train_loss=1.9767611436661165
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 1.9751455411362009
614, epoch_train_loss=1.9751455411362009
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 1.973499016195147
615, epoch_train_loss=1.973499016195147
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 1.97182507594032
616, epoch_train_loss=1.97182507594032
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 1.970127373964744
617, epoch_train_loss=1.970127373964744
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 1.9684782783613701
618, epoch_train_loss=1.9684782783613701
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 1.9668311948845454
619, epoch_train_loss=1.9668311948845454
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 1.965212206909244
620, epoch_train_loss=1.965212206909244
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 1.9635583622091195
621, epoch_train_loss=1.9635583622091195
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 1.9619031397181965
622, epoch_train_loss=1.9619031397181965
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 1.9602155624277167
623, epoch_train_loss=1.9602155624277167
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 1.9585783162759796
624, epoch_train_loss=1.9585783162759796
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 1.9569631234970726
625, epoch_train_loss=1.9569631234970726
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 1.9554754278222435
626, epoch_train_loss=1.9554754278222435
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 1.9542554998694817
627, epoch_train_loss=1.9542554998694817
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 1.953761335752563
628, epoch_train_loss=1.953761335752563
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 1.9554848042316788
629, epoch_train_loss=1.9554848042316788
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 1.9632455413506509
630, epoch_train_loss=1.9632455413506509
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 1.9927949214231857
631, epoch_train_loss=1.9927949214231857
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 2.073644525039189
632, epoch_train_loss=2.073644525039189
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 2.3521924403312746
633, epoch_train_loss=2.3521924403312746
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 2.374828976515759
634, epoch_train_loss=2.374828976515759
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 2.263969559978471
635, epoch_train_loss=2.263969559978471
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 2.053033666643433
636, epoch_train_loss=2.053033666643433
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 2.2667432810097643
637, epoch_train_loss=2.2667432810097643
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 2.0433962599934565
638, epoch_train_loss=2.0433962599934565
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 2.0357855191903713
639, epoch_train_loss=2.0357855191903713
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 2.147199434566951
640, epoch_train_loss=2.147199434566951
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 1.9961299323542794
641, epoch_train_loss=1.9961299323542794
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 2.077494459804952
642, epoch_train_loss=2.077494459804952
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 2.0944592388206247
643, epoch_train_loss=2.0944592388206247
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 1.9733943752770828
644, epoch_train_loss=1.9733943752770828
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 2.0372934497512722
645, epoch_train_loss=2.0372934497512722
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 2.0122036577164377
646, epoch_train_loss=2.0122036577164377
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 2.004618854819549
647, epoch_train_loss=2.004618854819549
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 1.9994932226704207
648, epoch_train_loss=1.9994932226704207
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 1.975432947189107
649, epoch_train_loss=1.975432947189107
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 1.9925846242108125
650, epoch_train_loss=1.9925846242108125
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 1.993782048544387
651, epoch_train_loss=1.993782048544387
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 1.9764258315203393
652, epoch_train_loss=1.9764258315203393
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 1.9810645717966227
653, epoch_train_loss=1.9810645717966227
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 1.9651491438206237
654, epoch_train_loss=1.9651491438206237
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 1.9614184008972961
655, epoch_train_loss=1.9614184008972961
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 1.9718660199421474
656, epoch_train_loss=1.9718660199421474
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 1.9595215712452139
657, epoch_train_loss=1.9595215712452139
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 1.9516640630275455
658, epoch_train_loss=1.9516640630275455
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 1.9509419433952573
659, epoch_train_loss=1.9509419433952573
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 1.947229025469597
660, epoch_train_loss=1.947229025469597
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 1.9501670669269167
661, epoch_train_loss=1.9501670669269167
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 1.9448543696524179
662, epoch_train_loss=1.9448543696524179
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 1.937476059281931
663, epoch_train_loss=1.937476059281931
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 1.9416086739348335
664, epoch_train_loss=1.9416086739348335
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 1.9341176027299436
665, epoch_train_loss=1.9341176027299436
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 1.9316530245368755
666, epoch_train_loss=1.9316530245368755
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 1.934301368485779
667, epoch_train_loss=1.934301368485779
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 1.9250503285240341
668, epoch_train_loss=1.9250503285240341
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 1.9245515083863753
669, epoch_train_loss=1.9245515083863753
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 1.929035854078768
670, epoch_train_loss=1.929035854078768
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 1.9265289869243354
671, epoch_train_loss=1.9265289869243354
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 1.9227426142686395
672, epoch_train_loss=1.9227426142686395
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 1.9161852656834146
673, epoch_train_loss=1.9161852656834146
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 1.915648217646009
674, epoch_train_loss=1.915648217646009
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 1.9196381889011644
675, epoch_train_loss=1.9196381889011644
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 1.9186775971182608
676, epoch_train_loss=1.9186775971182608
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 1.9188627963791054
677, epoch_train_loss=1.9188627963791054
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 1.9140758806688827
678, epoch_train_loss=1.9140758806688827
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 1.907393180230243
679, epoch_train_loss=1.907393180230243
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 1.9049337297846396
680, epoch_train_loss=1.9049337297846396
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 1.9016065595469527
681, epoch_train_loss=1.9016065595469527
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 1.8994262636307806
682, epoch_train_loss=1.8994262636307806
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 1.897857688767095
683, epoch_train_loss=1.897857688767095
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 1.8952165155661438
684, epoch_train_loss=1.8952165155661438
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 1.8947514244416894
685, epoch_train_loss=1.8947514244416894
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 1.8930842730944004
686, epoch_train_loss=1.8930842730944004
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 1.8927688477472115
687, epoch_train_loss=1.8927688477472115
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 1.8966732282725878
688, epoch_train_loss=1.8966732282725878
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 1.9094421230370486
689, epoch_train_loss=1.9094421230370486
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 1.9661440287812826
690, epoch_train_loss=1.9661440287812826
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 2.176281264992146
691, epoch_train_loss=2.176281264992146
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 3.1887456115253214
692, epoch_train_loss=3.1887456115253214
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 2.2441977357009937
693, epoch_train_loss=2.2441977357009937
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 2.3379611360541372
694, epoch_train_loss=2.3379611360541372
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 2.2685157510819183
695, epoch_train_loss=2.2685157510819183
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 2.0197244991442758
696, epoch_train_loss=2.0197244991442758
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 2.399312780072298
697, epoch_train_loss=2.399312780072298
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 3.0109662693408894
698, epoch_train_loss=3.0109662693408894
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 3.0467726941810396
699, epoch_train_loss=3.0467726941810396
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 2.4756228802999245
700, epoch_train_loss=2.4756228802999245
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 2.575734639458667
701, epoch_train_loss=2.575734639458667
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 2.5684046946362784
702, epoch_train_loss=2.5684046946362784
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 2.1608649978664487
703, epoch_train_loss=2.1608649978664487
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 2.375912193789124
704, epoch_train_loss=2.375912193789124
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 2.3145166571753504
705, epoch_train_loss=2.3145166571753504
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 2.1452064063044056
706, epoch_train_loss=2.1452064063044056
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 2.2954243817089677
707, epoch_train_loss=2.2954243817089677
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 2.183003537508616
708, epoch_train_loss=2.183003537508616
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 2.125103481804061
709, epoch_train_loss=2.125103481804061
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 2.1740743735359978
710, epoch_train_loss=2.1740743735359978
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 2.0692373517447122
711, epoch_train_loss=2.0692373517447122
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 2.1223448930395317
712, epoch_train_loss=2.1223448930395317
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 2.092214407432151
713, epoch_train_loss=2.092214407432151
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 2.0996032239297007
714, epoch_train_loss=2.0996032239297007
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 2.0854493763417508
715, epoch_train_loss=2.0854493763417508
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 2.039740601164203
716, epoch_train_loss=2.039740601164203
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 2.081276966026929
717, epoch_train_loss=2.081276966026929
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 2.0394824262515483
718, epoch_train_loss=2.0394824262515483
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 2.0496788931729397
719, epoch_train_loss=2.0496788931729397
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 2.0078867620626055
720, epoch_train_loss=2.0078867620626055
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 2.045681375371196
721, epoch_train_loss=2.045681375371196
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 1.9857614750762822
722, epoch_train_loss=1.9857614750762822
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 2.0229305822784087
723, epoch_train_loss=2.0229305822784087
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 1.988023563609751
724, epoch_train_loss=1.988023563609751
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 2.007865711576034
725, epoch_train_loss=2.007865711576034
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 1.977004210918974
726, epoch_train_loss=1.977004210918974
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 1.9935459252532006
727, epoch_train_loss=1.9935459252532006
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 1.96566589018025
728, epoch_train_loss=1.96566589018025
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 1.9822709820599642
729, epoch_train_loss=1.9822709820599642
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 1.964426779492249
730, epoch_train_loss=1.964426779492249
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 1.9693260871325993
731, epoch_train_loss=1.9693260871325993
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 1.949765830788106
732, epoch_train_loss=1.949765830788106
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 1.961252568374486
733, epoch_train_loss=1.961252568374486
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 1.947897857788182
734, epoch_train_loss=1.947897857788182
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 1.953758230116515
735, epoch_train_loss=1.953758230116515
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 1.9424121007652766
736, epoch_train_loss=1.9424121007652766
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 1.949763983494547
737, epoch_train_loss=1.949763983494547
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 1.937336739694431
738, epoch_train_loss=1.937336739694431
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 1.943589546378901
739, epoch_train_loss=1.943589546378901
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 1.9352122857623029
740, epoch_train_loss=1.9352122857623029
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 1.9363950693279328
741, epoch_train_loss=1.9363950693279328
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 1.9319878682780978
742, epoch_train_loss=1.9319878682780978
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 1.9299380332195468
743, epoch_train_loss=1.9299380332195468
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 1.9290857482121466
744, epoch_train_loss=1.9290857482121466
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 1.924190966314797
745, epoch_train_loss=1.924190966314797
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 1.9262863074974175
746, epoch_train_loss=1.9262863074974175
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 1.92017159563685
747, epoch_train_loss=1.92017159563685
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 1.9215259115348964
748, epoch_train_loss=1.9215259115348964
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 1.919207743948881
749, epoch_train_loss=1.919207743948881
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 1.9170899112891626
750, epoch_train_loss=1.9170899112891626
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 1.9175726690890005
751, epoch_train_loss=1.9175726690890005
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 1.9132934243850164
752, epoch_train_loss=1.9132934243850164
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 1.9132182276667782
753, epoch_train_loss=1.9132182276667782
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 1.9119885756885668
754, epoch_train_loss=1.9119885756885668
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 1.909380211513203
755, epoch_train_loss=1.909380211513203
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 1.909348981110362
756, epoch_train_loss=1.909348981110362
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 1.9065764724679912
757, epoch_train_loss=1.9065764724679912
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 1.9049619011319512
758, epoch_train_loss=1.9049619011319512
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 1.9046396355226816
759, epoch_train_loss=1.9046396355226816
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 1.902175857138079
760, epoch_train_loss=1.902175857138079
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 1.900809843691851
761, epoch_train_loss=1.900809843691851
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 1.9000883772948425
762, epoch_train_loss=1.9000883772948425
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 1.897836035253093
763, epoch_train_loss=1.897836035253093
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 1.8964309431733186
764, epoch_train_loss=1.8964309431733186
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 1.8957770996852856
765, epoch_train_loss=1.8957770996852856
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 1.8939081011280718
766, epoch_train_loss=1.8939081011280718
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 1.892230879858934
767, epoch_train_loss=1.892230879858934
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 1.891355851890885
768, epoch_train_loss=1.891355851890885
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 1.8899685663613695
769, epoch_train_loss=1.8899685663613695
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 1.8882764079501024
770, epoch_train_loss=1.8882764079501024
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 1.8869850981619665
771, epoch_train_loss=1.8869850981619665
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 1.8858846566229421
772, epoch_train_loss=1.8858846566229421
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 1.8844463548450716
773, epoch_train_loss=1.8844463548450716
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 1.8828454497314064
774, epoch_train_loss=1.8828454497314064
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 1.8816643134337596
775, epoch_train_loss=1.8816643134337596
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 1.8805133091150834
776, epoch_train_loss=1.8805133091150834
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 1.8790178441511403
777, epoch_train_loss=1.8790178441511403
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 1.8775531835152703
778, epoch_train_loss=1.8775531835152703
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 1.8762695715375177
779, epoch_train_loss=1.8762695715375177
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 1.8750822762068695
780, epoch_train_loss=1.8750822762068695
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 1.8737946574457351
781, epoch_train_loss=1.8737946574457351
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 1.8723616506048075
782, epoch_train_loss=1.8723616506048075
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 1.8709506134249478
783, epoch_train_loss=1.8709506134249478
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 1.8696315366200544
784, epoch_train_loss=1.8696315366200544
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 1.868376490245846
785, epoch_train_loss=1.868376490245846
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 1.8671474880798153
786, epoch_train_loss=1.8671474880798153
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 1.8658841341917065
787, epoch_train_loss=1.8658841341917065
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 1.864552135636997
788, epoch_train_loss=1.864552135636997
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 1.8632049993475963
789, epoch_train_loss=1.8632049993475963
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 1.861833563998214
790, epoch_train_loss=1.861833563998214
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 1.860485478718949
791, epoch_train_loss=1.860485478718949
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 1.8591492437329757
792, epoch_train_loss=1.8591492437329757
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 1.8578167370667489
793, epoch_train_loss=1.8578167370667489
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 1.8564977163562062
794, epoch_train_loss=1.8564977163562062
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 1.855179840985702
795, epoch_train_loss=1.855179840985702
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 1.8538669475560496
796, epoch_train_loss=1.8538669475560496
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 1.8525634540834437
797, epoch_train_loss=1.8525634540834437
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 1.8512781450285525
798, epoch_train_loss=1.8512781450285525
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 1.8500820832338463
799, epoch_train_loss=1.8500820832338463
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 1.8490987370466012
800, epoch_train_loss=1.8490987370466012
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 1.8488100329455248
801, epoch_train_loss=1.8488100329455248
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 1.8506142662742795
802, epoch_train_loss=1.8506142662742795
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 1.8600861802737192
803, epoch_train_loss=1.8600861802737192
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 1.892794954779393
804, epoch_train_loss=1.892794954779393
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 2.0285143049587244
805, epoch_train_loss=2.0285143049587244
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 2.3390609678967595
806, epoch_train_loss=2.3390609678967595
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 3.4260726005535402
807, epoch_train_loss=3.4260726005535402
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 3.3510782319760843
808, epoch_train_loss=3.3510782319760843
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 2.6016882076441203
809, epoch_train_loss=2.6016882076441203
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 2.895199296960582
810, epoch_train_loss=2.895199296960582
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 3.115232465342947
811, epoch_train_loss=3.115232465342947
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 2.721947091294218
812, epoch_train_loss=2.721947091294218
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 2.7091082735564282
813, epoch_train_loss=2.7091082735564282
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 2.5886575021003413
814, epoch_train_loss=2.5886575021003413
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 3.161212673735729
815, epoch_train_loss=3.161212673735729
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 3.1827961431769034
816, epoch_train_loss=3.1827961431769034
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 3.107155910318165
817, epoch_train_loss=3.107155910318165
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 3.0299428672891433
818, epoch_train_loss=3.0299428672891433
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 2.9896875050945195
819, epoch_train_loss=2.9896875050945195
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 2.8545003082740092
820, epoch_train_loss=2.8545003082740092
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 2.7508643795634806
821, epoch_train_loss=2.7508643795634806
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 2.7552595821350523
822, epoch_train_loss=2.7552595821350523
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 2.747987135770702
823, epoch_train_loss=2.747987135770702
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 2.722506866202357
824, epoch_train_loss=2.722506866202357
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 2.7294144886892364
825, epoch_train_loss=2.7294144886892364
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 2.719869474369582
826, epoch_train_loss=2.719869474369582
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 2.6851814839550268
827, epoch_train_loss=2.6851814839550268
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 2.640735097190422
828, epoch_train_loss=2.640735097190422
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 2.5825296175528822
829, epoch_train_loss=2.5825296175528822
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 2.573414129573833
830, epoch_train_loss=2.573414129573833
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 2.582816430365909
831, epoch_train_loss=2.582816430365909
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 2.5435548161445083
832, epoch_train_loss=2.5435548161445083
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 2.4921392174282726
833, epoch_train_loss=2.4921392174282726
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 2.4637305687068567
834, epoch_train_loss=2.4637305687068567
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 2.4585388058823576
835, epoch_train_loss=2.4585388058823576
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 2.43625838169159
836, epoch_train_loss=2.43625838169159
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 2.39161188381697
837, epoch_train_loss=2.39161188381697
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 2.3727495681841706
838, epoch_train_loss=2.3727495681841706
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 2.373685109171816
839, epoch_train_loss=2.373685109171816
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 2.351475497232173
840, epoch_train_loss=2.351475497232173
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 2.334042607374084
841, epoch_train_loss=2.334042607374084
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 2.3151123720078717
842, epoch_train_loss=2.3151123720078717
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 2.300047665160727
843, epoch_train_loss=2.300047665160727
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 2.277280767699857
844, epoch_train_loss=2.277280767699857
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 2.2604571963068056
845, epoch_train_loss=2.2604571963068056
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 2.2501934371890497
846, epoch_train_loss=2.2501934371890497
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 2.2292065707766313
847, epoch_train_loss=2.2292065707766313
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 2.208370839998774
848, epoch_train_loss=2.208370839998774
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 2.2035793056095665
849, epoch_train_loss=2.2035793056095665
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 2.1907709608266024
850, epoch_train_loss=2.1907709608266024
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 2.1686005987253845
851, epoch_train_loss=2.1686005987253845
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 2.1563234729443916
852, epoch_train_loss=2.1563234729443916
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 2.1481954817034854
853, epoch_train_loss=2.1481954817034854
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 2.138828112032438
854, epoch_train_loss=2.138828112032438
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 2.1338982000116653
855, epoch_train_loss=2.1338982000116653
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 2.1436539172055085
856, epoch_train_loss=2.1436539172055085
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 2.172160073281953
857, epoch_train_loss=2.172160073281953
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 2.1180326128761418
858, epoch_train_loss=2.1180326128761418
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 2.068762281624149
859, epoch_train_loss=2.068762281624149
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 2.096282828727441
860, epoch_train_loss=2.096282828727441
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 2.1139438115493814
861, epoch_train_loss=2.1139438115493814
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 2.1305841983568614
862, epoch_train_loss=2.1305841983568614
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 2.096567302677136
863, epoch_train_loss=2.096567302677136
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 2.0274187207283663
864, epoch_train_loss=2.0274187207283663
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 1.9960716461150332
865, epoch_train_loss=1.9960716461150332
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 2.014543020028013
866, epoch_train_loss=2.014543020028013
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 2.0449823389943034
867, epoch_train_loss=2.0449823389943034
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 2.073298493227937
868, epoch_train_loss=2.073298493227937
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 2.1117293536742188
869, epoch_train_loss=2.1117293536742188
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 2.109719706822939
870, epoch_train_loss=2.109719706822939
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 2.038645212654617
871, epoch_train_loss=2.038645212654617
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 1.9598210774584797
872, epoch_train_loss=1.9598210774584797
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 1.9915536668067089
873, epoch_train_loss=1.9915536668067089
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 2.0677394387916066
874, epoch_train_loss=2.0677394387916066
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 2.064996320774356
875, epoch_train_loss=2.064996320774356
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 1.9948977697782162
876, epoch_train_loss=1.9948977697782162
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 1.9343948470985273
877, epoch_train_loss=1.9343948470985273
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 1.936295211661612
878, epoch_train_loss=1.936295211661612
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 1.9880448990754283
879, epoch_train_loss=1.9880448990754283
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 2.0750552373846594
880, epoch_train_loss=2.0750552373846594
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 2.1416875647414577
881, epoch_train_loss=2.1416875647414577
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 2.1305346478498235
882, epoch_train_loss=2.1305346478498235
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 1.940966700867146
883, epoch_train_loss=1.940966700867146
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 1.9955506880018685
884, epoch_train_loss=1.9955506880018685
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 2.062744638467753
885, epoch_train_loss=2.062744638467753
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 1.922060360433498
886, epoch_train_loss=1.922060360433498
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 2.0055973906729703
887, epoch_train_loss=2.0055973906729703
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 2.0872455148377376
888, epoch_train_loss=2.0872455148377376
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 1.9043792951106966
889, epoch_train_loss=1.9043792951106966
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 2.025531074508035
890, epoch_train_loss=2.025531074508035
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 2.140809417976004
891, epoch_train_loss=2.140809417976004
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 1.9045569128434838
892, epoch_train_loss=1.9045569128434838
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 2.2876518506861174
893, epoch_train_loss=2.2876518506861174
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 2.3110106227288627
894, epoch_train_loss=2.3110106227288627
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 2.3669567154220004
895, epoch_train_loss=2.3669567154220004
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 2.0372523526394164
896, epoch_train_loss=2.0372523526394164
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 2.4172022412317498
897, epoch_train_loss=2.4172022412317498
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 2.035616146525765
898, epoch_train_loss=2.035616146525765
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 2.269983872468426
899, epoch_train_loss=2.269983872468426
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 2.2476560476652687
900, epoch_train_loss=2.2476560476652687
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 1.9547773829722117
901, epoch_train_loss=1.9547773829722117
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 2.258803414378134
902, epoch_train_loss=2.258803414378134
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 1.9652604748269038
903, epoch_train_loss=1.9652604748269038
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 2.1409554510396274
904, epoch_train_loss=2.1409554510396274
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 1.980154849722667
905, epoch_train_loss=1.980154849722667
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 2.242299229582302
906, epoch_train_loss=2.242299229582302
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 1.9909317876994794
907, epoch_train_loss=1.9909317876994794
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 2.1234041007501965
908, epoch_train_loss=2.1234041007501965
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 2.036597466753525
909, epoch_train_loss=2.036597466753525
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 2.0606427713661555
910, epoch_train_loss=2.0606427713661555
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 2.047638917292214
911, epoch_train_loss=2.047638917292214
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 2.0509853492715053
912, epoch_train_loss=2.0509853492715053
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 2.0235427223349642
913, epoch_train_loss=2.0235427223349642
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 1.966357287449612
914, epoch_train_loss=1.966357287449612
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 2.012856879044286
915, epoch_train_loss=2.012856879044286
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 2.0078557083086572
916, epoch_train_loss=2.0078557083086572
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 1.9659250105643622
917, epoch_train_loss=1.9659250105643622
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 2.003453846701411
918, epoch_train_loss=2.003453846701411
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 1.9314698067461171
919, epoch_train_loss=1.9314698067461171
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 1.9566660464009062
920, epoch_train_loss=1.9566660464009062
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 1.9353291354160194
921, epoch_train_loss=1.9353291354160194
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 1.9033768225917012
922, epoch_train_loss=1.9033768225917012
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 1.928304991820095
923, epoch_train_loss=1.928304991820095
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 1.8982821613891145
924, epoch_train_loss=1.8982821613891145
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 1.908519305311101
925, epoch_train_loss=1.908519305311101
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 1.9022919889975918
926, epoch_train_loss=1.9022919889975918
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 1.8712480112268615
927, epoch_train_loss=1.8712480112268615
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 1.877495311571111
928, epoch_train_loss=1.877495311571111
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 1.907127702486427
929, epoch_train_loss=1.907127702486427
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 1.8749203398980632
930, epoch_train_loss=1.8749203398980632
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 1.855793879846768
931, epoch_train_loss=1.855793879846768
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 1.864722058762454
932, epoch_train_loss=1.864722058762454
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 1.8975864445256891
933, epoch_train_loss=1.8975864445256891
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 2.0447831574994266
934, epoch_train_loss=2.0447831574994266
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 1.8556695305868165
935, epoch_train_loss=1.8556695305868165
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 1.8345086920254998
936, epoch_train_loss=1.8345086920254998
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 1.8869594961218485
937, epoch_train_loss=1.8869594961218485
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 1.9262116668160827
938, epoch_train_loss=1.9262116668160827
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 2.1173798285640744
939, epoch_train_loss=2.1173798285640744
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 1.8295602455133344
940, epoch_train_loss=1.8295602455133344
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 2.4738624426506615
941, epoch_train_loss=2.4738624426506615
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 2.744716690378025
942, epoch_train_loss=2.744716690378025
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 3.09392583673859
943, epoch_train_loss=3.09392583673859
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 2.9578180977376514
944, epoch_train_loss=2.9578180977376514
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 2.695920159792325
945, epoch_train_loss=2.695920159792325
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 2.5441588992531856
946, epoch_train_loss=2.5441588992531856
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 2.5178088745867906
947, epoch_train_loss=2.5178088745867906
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 2.5632268285869255
948, epoch_train_loss=2.5632268285869255
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 2.4828262703254347
949, epoch_train_loss=2.4828262703254347
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 2.5736244418764422
950, epoch_train_loss=2.5736244418764422
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 2.3735446870241694
951, epoch_train_loss=2.3735446870241694
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 2.415172842358673
952, epoch_train_loss=2.415172842358673
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 2.2778998327633
953, epoch_train_loss=2.2778998327633
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 2.3483516534294377
954, epoch_train_loss=2.3483516534294377
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 2.288096671021615
955, epoch_train_loss=2.288096671021615
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 2.3069891606053132
956, epoch_train_loss=2.3069891606053132
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 2.290765579892195
957, epoch_train_loss=2.290765579892195
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 2.223383852386002
958, epoch_train_loss=2.223383852386002
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 2.2250043768771777
959, epoch_train_loss=2.2250043768771777
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 2.2171982641641574
960, epoch_train_loss=2.2171982641641574
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 2.180272067450607
961, epoch_train_loss=2.180272067450607
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 2.1503555135227455
962, epoch_train_loss=2.1503555135227455
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 2.13648488185005
963, epoch_train_loss=2.13648488185005
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 2.1332073614425218
964, epoch_train_loss=2.1332073614425218
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 2.125683175150103
965, epoch_train_loss=2.125683175150103
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 2.120356861161797
966, epoch_train_loss=2.120356861161797
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 2.1218181641077645
967, epoch_train_loss=2.1218181641077645
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 2.113092547918077
968, epoch_train_loss=2.113092547918077
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 2.089964632279546
969, epoch_train_loss=2.089964632279546
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 2.068810532837022
970, epoch_train_loss=2.068810532837022
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 2.053963616622162
971, epoch_train_loss=2.053963616622162
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 2.04294801705645
972, epoch_train_loss=2.04294801705645
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 2.0352227314047013
973, epoch_train_loss=2.0352227314047013
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 2.0234004546644906
974, epoch_train_loss=2.0234004546644906
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 2.0123464972802934
975, epoch_train_loss=2.0123464972802934
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 2.002695353318593
976, epoch_train_loss=2.002695353318593
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 1.9898006341536918
977, epoch_train_loss=1.9898006341536918
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 1.9836967055332821
978, epoch_train_loss=1.9836967055332821
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 1.9820675112758661
979, epoch_train_loss=1.9820675112758661
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 1.9773898345037126
980, epoch_train_loss=1.9773898345037126
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 1.9701556510413631
981, epoch_train_loss=1.9701556510413631
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 1.9640060609508092
982, epoch_train_loss=1.9640060609508092
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 1.9607175910327583
983, epoch_train_loss=1.9607175910327583
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 1.9569330014076207
984, epoch_train_loss=1.9569330014076207
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 1.9549196189946305
985, epoch_train_loss=1.9549196189946305
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 1.9516665037504495
986, epoch_train_loss=1.9516665037504495
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 1.946156593284104
987, epoch_train_loss=1.946156593284104
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 1.9382182544427011
988, epoch_train_loss=1.9382182544427011
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 1.9335339773325178
989, epoch_train_loss=1.9335339773325178
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 1.931113740661097
990, epoch_train_loss=1.931113740661097
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 1.928619453658504
991, epoch_train_loss=1.928619453658504
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 1.9238553576274882
992, epoch_train_loss=1.9238553576274882
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 1.9195279519835913
993, epoch_train_loss=1.9195279519835913
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 1.9160631904071022
994, epoch_train_loss=1.9160631904071022
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 1.9135088029440581
995, epoch_train_loss=1.9135088029440581
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 1.9110177988848027
996, epoch_train_loss=1.9110177988848027
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 1.90819358590891
997, epoch_train_loss=1.90819358590891
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 1.9050116160091621
998, epoch_train_loss=1.9050116160091621
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 1.901819552813095
999, epoch_train_loss=1.901819552813095
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 1.8999869591263805
1000, epoch_train_loss=1.8999869591263805
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 1.8989187130601846
1001, epoch_train_loss=1.8989187130601846
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 1.8975662216130134
1002, epoch_train_loss=1.8975662216130134
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 1.8954997169499466
1003, epoch_train_loss=1.8954997169499466
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 1.893186118467906
1004, epoch_train_loss=1.893186118467906
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 1.8915560943162766
1005, epoch_train_loss=1.8915560943162766
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 1.8900460206407688
1006, epoch_train_loss=1.8900460206407688
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 1.888183876322363
1007, epoch_train_loss=1.888183876322363
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 1.8863524169163093
1008, epoch_train_loss=1.8863524169163093
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 1.8848012502011284
1009, epoch_train_loss=1.8848012502011284
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 1.8835411761730638
1010, epoch_train_loss=1.8835411761730638
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 1.8822058458923556
1011, epoch_train_loss=1.8822058458923556
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 1.880474824759924
1012, epoch_train_loss=1.880474824759924
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 1.8787798566802203
1013, epoch_train_loss=1.8787798566802203
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 1.877554397172684
1014, epoch_train_loss=1.877554397172684
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 1.8765050697921157
1015, epoch_train_loss=1.8765050697921157
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 1.8751823497402733
1016, epoch_train_loss=1.8751823497402733
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 1.8736561856360996
1017, epoch_train_loss=1.8736561856360996
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 1.87227036500562
1018, epoch_train_loss=1.87227036500562
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 1.8710639502167654
1019, epoch_train_loss=1.8710639502167654
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 1.8698547347276158
1020, epoch_train_loss=1.8698547347276158
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 1.8685483172282795
1021, epoch_train_loss=1.8685483172282795
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 1.8672040029690073
1022, epoch_train_loss=1.8672040029690073
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 1.865911465827323
1023, epoch_train_loss=1.865911465827323
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 1.864645356803869
1024, epoch_train_loss=1.864645356803869
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 1.8633395244868498
1025, epoch_train_loss=1.8633395244868498
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 1.8620255841481057
1026, epoch_train_loss=1.8620255841481057
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 1.860819153506217
1027, epoch_train_loss=1.860819153506217
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 1.8596920491922015
1028, epoch_train_loss=1.8596920491922015
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 1.858485285860873
1029, epoch_train_loss=1.858485285860873
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 1.8572192074108191
1030, epoch_train_loss=1.8572192074108191
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 1.8560040190218912
1031, epoch_train_loss=1.8560040190218912
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 1.85484927780617
1032, epoch_train_loss=1.85484927780617
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 1.8537019325749475
1033, epoch_train_loss=1.8537019325749475
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 1.8525297109738632
1034, epoch_train_loss=1.8525297109738632
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 1.8513655555545907
1035, epoch_train_loss=1.8513655555545907
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 1.8502300141263714
1036, epoch_train_loss=1.8502300141263714
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 1.849085593027381
1037, epoch_train_loss=1.849085593027381
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 1.8479262274543662
1038, epoch_train_loss=1.8479262274543662
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 1.8467701213697274
1039, epoch_train_loss=1.8467701213697274
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 1.8456316104792536
1040, epoch_train_loss=1.8456316104792536
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 1.844498751122265
1041, epoch_train_loss=1.844498751122265
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 1.8433449436790903
1042, epoch_train_loss=1.8433449436790903
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 1.8422120368181398
1043, epoch_train_loss=1.8422120368181398
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 1.841217811176923
1044, epoch_train_loss=1.841217811176923
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 1.8406609929023516
1045, epoch_train_loss=1.8406609929023516
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 1.8420342415547617
1046, epoch_train_loss=1.8420342415547617
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 1.8506108886020234
1047, epoch_train_loss=1.8506108886020234
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 1.8987571487404775
1048, epoch_train_loss=1.8987571487404775
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 2.013050054840389
1049, epoch_train_loss=2.013050054840389
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 2.5805430708642305
1050, epoch_train_loss=2.5805430708642305
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 2.101345049176006
1051, epoch_train_loss=2.101345049176006
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 2.2438435871666123
1052, epoch_train_loss=2.2438435871666123
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 2.0601318018777706
1053, epoch_train_loss=2.0601318018777706
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 2.1683945922874353
1054, epoch_train_loss=2.1683945922874353
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 1.935483267159682
1055, epoch_train_loss=1.935483267159682
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 2.0643322249222846
1056, epoch_train_loss=2.0643322249222846
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 1.933341638581512
1057, epoch_train_loss=1.933341638581512
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 2.107103755141144
1058, epoch_train_loss=2.107103755141144
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 1.9473734443193071
1059, epoch_train_loss=1.9473734443193071
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 2.009996211627031
1060, epoch_train_loss=2.009996211627031
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 1.9454531843082221
1061, epoch_train_loss=1.9454531843082221
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 1.99483414804624
1062, epoch_train_loss=1.99483414804624
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 1.9121594160906104
1063, epoch_train_loss=1.9121594160906104
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 1.9350560925737983
1064, epoch_train_loss=1.9350560925737983
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 1.9380440650809647
1065, epoch_train_loss=1.9380440650809647
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 1.947446996854015
1066, epoch_train_loss=1.947446996854015
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 1.9379443821965885
1067, epoch_train_loss=1.9379443821965885
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 1.9175318217049553
1068, epoch_train_loss=1.9175318217049553
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 1.9227250085934509
1069, epoch_train_loss=1.9227250085934509
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 1.8964120645450728
1070, epoch_train_loss=1.8964120645450728
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 1.9129301642196348
1071, epoch_train_loss=1.9129301642196348
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 1.8950425261935866
1072, epoch_train_loss=1.8950425261935866
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 1.907447030328844
1073, epoch_train_loss=1.907447030328844
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 1.8836356380486758
1074, epoch_train_loss=1.8836356380486758
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 1.900774523649442
1075, epoch_train_loss=1.900774523649442
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 1.8829839074482715
1076, epoch_train_loss=1.8829839074482715
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 1.890167011018896
1077, epoch_train_loss=1.890167011018896
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 1.8694616153841268
1078, epoch_train_loss=1.8694616153841268
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 1.8782846089762955
1079, epoch_train_loss=1.8782846089762955
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 1.865103681351313
1080, epoch_train_loss=1.865103681351313
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 1.8712783606293697
1081, epoch_train_loss=1.8712783606293697
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 1.861562552083986
1082, epoch_train_loss=1.861562552083986
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 1.8669897727026974
1083, epoch_train_loss=1.8669897727026974
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 1.8516599370406301
1084, epoch_train_loss=1.8516599370406301
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 1.854876564287845
1085, epoch_train_loss=1.854876564287845
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 1.8460905551187226
1086, epoch_train_loss=1.8460905551187226
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 1.849453377103061
1087, epoch_train_loss=1.849453377103061
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 1.8437307204798354
1088, epoch_train_loss=1.8437307204798354
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 1.841600975468358
1089, epoch_train_loss=1.841600975468358
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 1.8406689224640964
1090, epoch_train_loss=1.8406689224640964
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 1.833413242839016
1091, epoch_train_loss=1.833413242839016
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 1.8356911704040382
1092, epoch_train_loss=1.8356911704040382
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 1.8311221278182563
1093, epoch_train_loss=1.8311221278182563
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 1.8303892351041415
1094, epoch_train_loss=1.8303892351041415
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 1.8296894555460874
1095, epoch_train_loss=1.8296894555460874
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 1.8247029737556741
1096, epoch_train_loss=1.8247029737556741
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 1.8249464197287062
1097, epoch_train_loss=1.8249464197287062
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 1.8222571803561654
1098, epoch_train_loss=1.8222571803561654
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 1.8192790575925086
1099, epoch_train_loss=1.8192790575925086
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 1.8202683754018392
1100, epoch_train_loss=1.8202683754018392
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 1.817468491843781
1101, epoch_train_loss=1.817468491843781
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 1.8143541797413756
1102, epoch_train_loss=1.8143541797413756
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 1.8145385613584033
1103, epoch_train_loss=1.8145385613584033
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 1.8126695487241746
1104, epoch_train_loss=1.8126695487241746
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 1.8100990406880157
1105, epoch_train_loss=1.8100990406880157
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 1.8099569897349708
1106, epoch_train_loss=1.8099569897349708
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 1.8091717074966656
1107, epoch_train_loss=1.8091717074966656
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 1.8064449046051845
1108, epoch_train_loss=1.8064449046051845
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 1.805009392102831
1109, epoch_train_loss=1.805009392102831
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 1.8048874240097401
1110, epoch_train_loss=1.8048874240097401
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 1.803648005626882
1111, epoch_train_loss=1.803648005626882
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 1.8015519914050246
1112, epoch_train_loss=1.8015519914050246
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 1.8002446225479583
1113, epoch_train_loss=1.8002446225479583
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 1.799621989226354
1114, epoch_train_loss=1.799621989226354
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 1.7984693076281564
1115, epoch_train_loss=1.7984693076281564
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 1.7967123964731015
1116, epoch_train_loss=1.7967123964731015
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 1.7952236445109857
1117, epoch_train_loss=1.7952236445109857
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 1.7943129935984616
1118, epoch_train_loss=1.7943129935984616
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 1.7934485308198498
1119, epoch_train_loss=1.7934485308198498
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 1.7921082068846068
1120, epoch_train_loss=1.7921082068846068
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 1.7905270625092562
1121, epoch_train_loss=1.7905270625092562
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 1.7892572013087327
1122, epoch_train_loss=1.7892572013087327
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 1.7883504688179666
1123, epoch_train_loss=1.7883504688179666
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 1.7874288522879271
1124, epoch_train_loss=1.7874288522879271
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 1.7862359815405737
1125, epoch_train_loss=1.7862359815405737
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 1.7848717059972388
1126, epoch_train_loss=1.7848717059972388
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 1.783540232286226
1127, epoch_train_loss=1.783540232286226
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 1.7823410879645256
1128, epoch_train_loss=1.7823410879645256
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 1.7812854139970333
1129, epoch_train_loss=1.7812854139970333
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 1.7802723010337298
1130, epoch_train_loss=1.7802723010337298
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 1.7792242156172033
1131, epoch_train_loss=1.7792242156172033
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 1.7781456885132865
1132, epoch_train_loss=1.7781456885132865
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 1.7770368836857784
1133, epoch_train_loss=1.7770368836857784
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 1.7759215658661343
1134, epoch_train_loss=1.7759215658661343
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 1.7747937229143798
1135, epoch_train_loss=1.7747937229143798
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 1.773717766608237
1136, epoch_train_loss=1.773717766608237
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 1.7727364485622648
1137, epoch_train_loss=1.7727364485622648
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 1.771974934704696
1138, epoch_train_loss=1.771974934704696
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 1.7716204790554597
1139, epoch_train_loss=1.7716204790554597
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 1.77229220284374
1140, epoch_train_loss=1.77229220284374
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 1.7750083796585956
1141, epoch_train_loss=1.7750083796585956
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 1.7839905573441097
1142, epoch_train_loss=1.7839905573441097
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 1.805799614494436
1143, epoch_train_loss=1.805799614494436
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 1.8765230368850518
1144, epoch_train_loss=1.8765230368850518
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 2.0053115961846526
1145, epoch_train_loss=2.0053115961846526
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 2.4306832350066236
1146, epoch_train_loss=2.4306832350066236
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 1.8944756384705628
1147, epoch_train_loss=1.8944756384705628
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 1.8717806219631223
1148, epoch_train_loss=1.8717806219631223
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 2.1561181188078336
1149, epoch_train_loss=2.1561181188078336
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 1.8550261889606279
1150, epoch_train_loss=1.8550261889606279
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 1.8378242225923316
1151, epoch_train_loss=1.8378242225923316
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 1.9400630034399386
1152, epoch_train_loss=1.9400630034399386
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 1.8294669406488393
1153, epoch_train_loss=1.8294669406488393
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 1.9019600566691586
1154, epoch_train_loss=1.9019600566691586
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 1.853820907391158
1155, epoch_train_loss=1.853820907391158
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 1.8205043448670637
1156, epoch_train_loss=1.8205043448670637
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 1.9115121629482128
1157, epoch_train_loss=1.9115121629482128
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 1.925509914977216
1158, epoch_train_loss=1.925509914977216
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 1.8291437027775332
1159, epoch_train_loss=1.8291437027775332
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 1.9110408254818414
1160, epoch_train_loss=1.9110408254818414
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 1.8103508892629274
1161, epoch_train_loss=1.8103508892629274
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 1.86536052425414
1162, epoch_train_loss=1.86536052425414
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 1.8916654165105766
1163, epoch_train_loss=1.8916654165105766
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 1.8064098339497965
1164, epoch_train_loss=1.8064098339497965
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 1.8302200408153628
1165, epoch_train_loss=1.8302200408153628
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 1.834765400664894
1166, epoch_train_loss=1.834765400664894
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 1.7943117153299473
1167, epoch_train_loss=1.7943117153299473
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 1.8330560121836728
1168, epoch_train_loss=1.8330560121836728
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 1.812942091846424
1169, epoch_train_loss=1.812942091846424
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 1.7847927630176252
1170, epoch_train_loss=1.7847927630176252
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 1.8010199760951895
1171, epoch_train_loss=1.8010199760951895
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 1.7954795746462213
1172, epoch_train_loss=1.7954795746462213
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 1.7904442559422127
1173, epoch_train_loss=1.7904442559422127
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 1.792704516914022
1174, epoch_train_loss=1.792704516914022
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 1.78597546081395
1175, epoch_train_loss=1.78597546081395
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 1.7860675511650437
1176, epoch_train_loss=1.7860675511650437
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 1.7879595487710669
1177, epoch_train_loss=1.7879595487710669
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 1.7809563490185176
1178, epoch_train_loss=1.7809563490185176
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 1.7784922126591807
1179, epoch_train_loss=1.7784922126591807
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 1.7798661064614718
1180, epoch_train_loss=1.7798661064614718
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 1.7733518366546628
1181, epoch_train_loss=1.7733518366546628
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 1.771017147415846
1182, epoch_train_loss=1.771017147415846
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 1.7725520970811186
1183, epoch_train_loss=1.7725520970811186
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 1.7716700537154655
1184, epoch_train_loss=1.7716700537154655
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 1.7670245999354506
1185, epoch_train_loss=1.7670245999354506
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 1.7636761220997765
1186, epoch_train_loss=1.7636761220997765
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 1.7660942679238443
1187, epoch_train_loss=1.7660942679238443
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 1.7677341599969072
1188, epoch_train_loss=1.7677341599969072
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 1.7619647103377332
1189, epoch_train_loss=1.7619647103377332
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 1.7566995202302382
1190, epoch_train_loss=1.7566995202302382
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 1.7569523186794627
1191, epoch_train_loss=1.7569523186794627
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 1.757407269896104
1192, epoch_train_loss=1.757407269896104
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 1.7555652856174646
1193, epoch_train_loss=1.7555652856174646
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 1.7533041536604814
1194, epoch_train_loss=1.7533041536604814
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 1.7507669286558765
1195, epoch_train_loss=1.7507669286558765
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 1.7487647802895092
1196, epoch_train_loss=1.7487647802895092
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 1.7482175045353265
1197, epoch_train_loss=1.7482175045353265
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 1.7471477883448545
1198, epoch_train_loss=1.7471477883448545
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 1.7456098561058573
1199, epoch_train_loss=1.7456098561058573
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 1.744492626340647
1200, epoch_train_loss=1.744492626340647
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 1.7428024718561166
1201, epoch_train_loss=1.7428024718561166
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 1.7409964461590386
1202, epoch_train_loss=1.7409964461590386
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 1.739568727651137
1203, epoch_train_loss=1.739568727651137
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 1.737911859154509
1204, epoch_train_loss=1.737911859154509
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 1.736441814993535
1205, epoch_train_loss=1.736441814993535
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 1.73517420674663
1206, epoch_train_loss=1.73517420674663
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 1.7336013927724778
1207, epoch_train_loss=1.7336013927724778
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 1.732315952907233
1208, epoch_train_loss=1.732315952907233
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 1.7311969822990452
1209, epoch_train_loss=1.7311969822990452
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 1.7300886819384895
1210, epoch_train_loss=1.7300886819384895
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 1.7309228325861812
1211, epoch_train_loss=1.7309228325861812
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 1.7354296885657374
1212, epoch_train_loss=1.7354296885657374
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 1.7558758135183168
1213, epoch_train_loss=1.7558758135183168
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 1.7983513279361774
1214, epoch_train_loss=1.7983513279361774
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 1.991894817149136
1215, epoch_train_loss=1.991894817149136
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 2.3016015092253066
1216, epoch_train_loss=2.3016015092253066
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 3.7218304600044725
1217, epoch_train_loss=3.7218304600044725
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 3.46487444807418
1218, epoch_train_loss=3.46487444807418
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 3.6246300508191114
1219, epoch_train_loss=3.6246300508191114
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 3.0846215776595587
1220, epoch_train_loss=3.0846215776595587
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 2.833078763677544
1221, epoch_train_loss=2.833078763677544
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 2.703412974572488
1222, epoch_train_loss=2.703412974572488
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 2.555578629663764
1223, epoch_train_loss=2.555578629663764
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 2.6642415049908106
1224, epoch_train_loss=2.6642415049908106
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 2.3192949300970835
1225, epoch_train_loss=2.3192949300970835
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 2.725493911902035
1226, epoch_train_loss=2.725493911902035
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 2.3491182465175404
1227, epoch_train_loss=2.3491182465175404
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 2.5140024661116573
1228, epoch_train_loss=2.5140024661116573
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 2.4481177512385566
1229, epoch_train_loss=2.4481177512385566
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 2.5246125550480563
1230, epoch_train_loss=2.5246125550480563
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 2.47044314467145
1231, epoch_train_loss=2.47044314467145
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 2.427505165465209
1232, epoch_train_loss=2.427505165465209
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 2.314209412129893
1233, epoch_train_loss=2.314209412129893
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 2.2874102960420593
1234, epoch_train_loss=2.2874102960420593
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 2.199907967101413
1235, epoch_train_loss=2.199907967101413
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 2.144785356965126
1236, epoch_train_loss=2.144785356965126
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 2.1077337413338615
1237, epoch_train_loss=2.1077337413338615
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 2.051596528447532
1238, epoch_train_loss=2.051596528447532
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 3.9340896185615275
1239, epoch_train_loss=3.9340896185615275
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 2.14834522499729
1240, epoch_train_loss=2.14834522499729
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 2.264222861553971
1241, epoch_train_loss=2.264222861553971
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 2.3631863089263883
1242, epoch_train_loss=2.3631863089263883
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 2.415082859447623
1243, epoch_train_loss=2.415082859447623
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 2.445786179812129
1244, epoch_train_loss=2.445786179812129
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 2.412071338532293
1245, epoch_train_loss=2.412071338532293
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 2.379553704328893
1246, epoch_train_loss=2.379553704328893
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 2.3821141494952314
1247, epoch_train_loss=2.3821141494952314
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 2.342771299575065
1248, epoch_train_loss=2.342771299575065
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 2.3677159993108563
1249, epoch_train_loss=2.3677159993108563
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 2.3077801415320476
1250, epoch_train_loss=2.3077801415320476
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 2.2947532463661173
1251, epoch_train_loss=2.2947532463661173
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 2.294890633326874
1252, epoch_train_loss=2.294890633326874
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 2.2625165709062705
1253, epoch_train_loss=2.2625165709062705
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 2.2650246852868294
1254, epoch_train_loss=2.2650246852868294
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 2.2318722568427134
1255, epoch_train_loss=2.2318722568427134
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 2.222600439563249
1256, epoch_train_loss=2.222600439563249
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 2.1806936507172296
1257, epoch_train_loss=2.1806936507172296
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 2.1711805465218528
1258, epoch_train_loss=2.1711805465218528
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 2.132614637198811
1259, epoch_train_loss=2.132614637198811
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 2.1104025347151962
1260, epoch_train_loss=2.1104025347151962
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 2.093642693058766
1261, epoch_train_loss=2.093642693058766
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 2.0578282760313145
1262, epoch_train_loss=2.0578282760313145
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 2.0389735079218383
1263, epoch_train_loss=2.0389735079218383
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 2.020389691238899
1264, epoch_train_loss=2.020389691238899
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 1.9867662609145946
1265, epoch_train_loss=1.9867662609145946
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 1.978556049490662
1266, epoch_train_loss=1.978556049490662
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 1.9711726838472616
1267, epoch_train_loss=1.9711726838472616
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 1.9608334210869731
1268, epoch_train_loss=1.9608334210869731
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 1.94299711249461
1269, epoch_train_loss=1.94299711249461
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 1.9230965914310942
1270, epoch_train_loss=1.9230965914310942
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 1.9229270986332723
1271, epoch_train_loss=1.9229270986332723
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 1.9106407528631917
1272, epoch_train_loss=1.9106407528631917
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 1.895532813691562
1273, epoch_train_loss=1.895532813691562
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 1.8936906936582503
1274, epoch_train_loss=1.8936906936582503
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 1.879762535628171
1275, epoch_train_loss=1.879762535628171
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 1.8790102419820276
1276, epoch_train_loss=1.8790102419820276
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 1.8672980474482708
1277, epoch_train_loss=1.8672980474482708
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 1.8681490063546815
1278, epoch_train_loss=1.8681490063546815
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 1.867460630056079
1279, epoch_train_loss=1.867460630056079
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 1.8849902099799107
1280, epoch_train_loss=1.8849902099799107
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 1.901711726723518
1281, epoch_train_loss=1.901711726723518
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 1.9185106860903727
1282, epoch_train_loss=1.9185106860903727
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 1.8636158303312729
1283, epoch_train_loss=1.8636158303312729
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 1.8331119529893336
1284, epoch_train_loss=1.8331119529893336
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 1.8294101548164168
1285, epoch_train_loss=1.8294101548164168
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 1.8434803122848922
1286, epoch_train_loss=1.8434803122848922
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 1.848858097303516
1287, epoch_train_loss=1.848858097303516
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 1.8208452815864065
1288, epoch_train_loss=1.8208452815864065
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 1.8072446235805755
1289, epoch_train_loss=1.8072446235805755
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 1.8060027808996582
1290, epoch_train_loss=1.8060027808996582
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 1.8180087417406245
1291, epoch_train_loss=1.8180087417406245
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 1.8327242722504642
1292, epoch_train_loss=1.8327242722504642
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 1.8297341829129852
1293, epoch_train_loss=1.8297341829129852
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 1.8500060670688003
1294, epoch_train_loss=1.8500060670688003
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 1.9038679304128538
1295, epoch_train_loss=1.9038679304128538
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 1.984950154959495
1296, epoch_train_loss=1.984950154959495
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 1.8406531229298122
1297, epoch_train_loss=1.8406531229298122
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 1.7974349312180564
1298, epoch_train_loss=1.7974349312180564
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 1.9515037069380137
1299, epoch_train_loss=1.9515037069380137
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 2.306978178888774
1300, epoch_train_loss=2.306978178888774
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 2.287326369252699
1301, epoch_train_loss=2.287326369252699
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 2.445187806543273
1302, epoch_train_loss=2.445187806543273
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 3.31770535394059
1303, epoch_train_loss=3.31770535394059
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 3.3020313763793965
1304, epoch_train_loss=3.3020313763793965
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 2.7569951798270798
1305, epoch_train_loss=2.7569951798270798
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 2.7047707839866892
1306, epoch_train_loss=2.7047707839866892
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 2.5106093992745953
1307, epoch_train_loss=2.5106093992745953
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 2.2499737950969747
1308, epoch_train_loss=2.2499737950969747
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 2.377929585085084
1309, epoch_train_loss=2.377929585085084
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 2.5588180300224757
1310, epoch_train_loss=2.5588180300224757
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 2.306583579619122
1311, epoch_train_loss=2.306583579619122
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 2.3452404619924994
1312, epoch_train_loss=2.3452404619924994
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 2.0853890216407023
1313, epoch_train_loss=2.0853890216407023
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 2.21559129160831
1314, epoch_train_loss=2.21559129160831
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 2.3510081281528072
1315, epoch_train_loss=2.3510081281528072
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 2.3086043030709797
1316, epoch_train_loss=2.3086043030709797
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 2.187614928723189
1317, epoch_train_loss=2.187614928723189
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 2.108179783416595
1318, epoch_train_loss=2.108179783416595
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 2.0785376978636703
1319, epoch_train_loss=2.0785376978636703
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 2.188600144450648
1320, epoch_train_loss=2.188600144450648
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 2.126524483068076
1321, epoch_train_loss=2.126524483068076
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 2.0876678722600115
1322, epoch_train_loss=2.0876678722600115
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 2.0495744826415336
1323, epoch_train_loss=2.0495744826415336
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 1.980590642708702
1324, epoch_train_loss=1.980590642708702
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 2.017642459654156
1325, epoch_train_loss=2.017642459654156
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 2.0201003971680396
1326, epoch_train_loss=2.0201003971680396
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 1.9502581845434803
1327, epoch_train_loss=1.9502581845434803
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 1.9557084711202315
1328, epoch_train_loss=1.9557084711202315
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 1.946088787183823
1329, epoch_train_loss=1.946088787183823
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 1.976686912699942
1330, epoch_train_loss=1.976686912699942
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 1.909126915981483
1331, epoch_train_loss=1.909126915981483
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 1.9062752316263192
1332, epoch_train_loss=1.9062752316263192
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 1.8975473754289904
1333, epoch_train_loss=1.8975473754289904
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 1.9186619279323187
1334, epoch_train_loss=1.9186619279323187
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 1.9043804832567814
1335, epoch_train_loss=1.9043804832567814
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 1.8801205633136457
1336, epoch_train_loss=1.8801205633136457
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 1.8804206623034
1337, epoch_train_loss=1.8804206623034
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 1.8772794513770557
1338, epoch_train_loss=1.8772794513770557
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 1.8708137440285135
1339, epoch_train_loss=1.8708137440285135
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 1.852962016547001
1340, epoch_train_loss=1.852962016547001
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 1.8431624262667627
1341, epoch_train_loss=1.8431624262667627
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 1.8494009441738093
1342, epoch_train_loss=1.8494009441738093
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 1.8493089877706046
1343, epoch_train_loss=1.8493089877706046
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 1.8467191496396018
1344, epoch_train_loss=1.8467191496396018
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 1.8350103011743135
1345, epoch_train_loss=1.8350103011743135
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 1.8318919450239555
1346, epoch_train_loss=1.8318919450239555
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 1.8242892813595857
1347, epoch_train_loss=1.8242892813595857
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 1.8254762821798847
1348, epoch_train_loss=1.8254762821798847
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 1.8155386376959117
1349, epoch_train_loss=1.8155386376959117
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 1.8131350316641777
1350, epoch_train_loss=1.8131350316641777
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 1.8076258509989769
1351, epoch_train_loss=1.8076258509989769
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 1.8036737036085773
1352, epoch_train_loss=1.8036737036085773
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 1.7985732617275456
1353, epoch_train_loss=1.7985732617275456
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 1.7913899000696278
1354, epoch_train_loss=1.7913899000696278
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 1.791609700901732
1355, epoch_train_loss=1.791609700901732
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 1.7899328685130047
1356, epoch_train_loss=1.7899328685130047
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 1.7847697293807443
1357, epoch_train_loss=1.7847697293807443
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 1.7826279745019253
1358, epoch_train_loss=1.7826279745019253
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 1.782977957764544
1359, epoch_train_loss=1.782977957764544
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 1.7810602793507175
1360, epoch_train_loss=1.7810602793507175
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 1.7772992556317646
1361, epoch_train_loss=1.7772992556317646
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 1.7748656947454369
1362, epoch_train_loss=1.7748656947454369
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 1.7734027984778853
1363, epoch_train_loss=1.7734027984778853
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 1.770920264148736
1364, epoch_train_loss=1.770920264148736
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 1.7673763828944107
1365, epoch_train_loss=1.7673763828944107
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 1.763671870530637
1366, epoch_train_loss=1.763671870530637
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 1.7610822023964898
1367, epoch_train_loss=1.7610822023964898
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 1.759730556796281
1368, epoch_train_loss=1.759730556796281
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 1.7584484170826138
1369, epoch_train_loss=1.7584484170826138
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 1.7564293756690619
1370, epoch_train_loss=1.7564293756690619
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 1.7540303529349506
1371, epoch_train_loss=1.7540303529349506
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 1.7516256784272741
1372, epoch_train_loss=1.7516256784272741
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 1.749000485395227
1373, epoch_train_loss=1.749000485395227
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 1.7468418541701298
1374, epoch_train_loss=1.7468418541701298
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 1.7452345635015516
1375, epoch_train_loss=1.7452345635015516
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 1.7437957044555032
1376, epoch_train_loss=1.7437957044555032
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 1.7431541882314237
1377, epoch_train_loss=1.7431541882314237
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 1.743905293439914
1378, epoch_train_loss=1.743905293439914
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 1.7495152113732335
1379, epoch_train_loss=1.7495152113732335
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 1.765372484849812
1380, epoch_train_loss=1.765372484849812
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 1.8337810611243006
1381, epoch_train_loss=1.8337810611243006
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 1.9795183850296032
1382, epoch_train_loss=1.9795183850296032
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 2.633830675220041
1383, epoch_train_loss=2.633830675220041
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 2.058820017846266
1384, epoch_train_loss=2.058820017846266
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 1.8058610985715404
1385, epoch_train_loss=1.8058610985715404
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 2.0860524181299
1386, epoch_train_loss=2.0860524181299
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 1.9919304784712006
1387, epoch_train_loss=1.9919304784712006
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 1.928983044960595
1388, epoch_train_loss=1.928983044960595
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 1.8293084820640508
1389, epoch_train_loss=1.8293084820640508
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 1.9293065901891933
1390, epoch_train_loss=1.9293065901891933
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 1.8011177284228763
1391, epoch_train_loss=1.8011177284228763
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 1.8213761205851469
1392, epoch_train_loss=1.8213761205851469
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 1.9785732735857104
1393, epoch_train_loss=1.9785732735857104
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 2.179666803452319
1394, epoch_train_loss=2.179666803452319
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 1.783533018695943
1395, epoch_train_loss=1.783533018695943
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 2.033149594213102
1396, epoch_train_loss=2.033149594213102
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 1.9827726050076138
1397, epoch_train_loss=1.9827726050076138
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 2.0462655347234184
1398, epoch_train_loss=2.0462655347234184
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 1.9255563857889682
1399, epoch_train_loss=1.9255563857889682
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 2.11607437311086
1400, epoch_train_loss=2.11607437311086
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 2.2798778685992827
1401, epoch_train_loss=2.2798778685992827
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 2.042728681276095
1402, epoch_train_loss=2.042728681276095
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 2.098918269771272
1403, epoch_train_loss=2.098918269771272
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 1.8860353481732408
1404, epoch_train_loss=1.8860353481732408
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 1.9762860873629085
1405, epoch_train_loss=1.9762860873629085
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 1.8712723686285793
1406, epoch_train_loss=1.8712723686285793
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 1.9894833819728435
1407, epoch_train_loss=1.9894833819728435
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 1.8144102320920035
1408, epoch_train_loss=1.8144102320920035
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 1.9009752014413968
1409, epoch_train_loss=1.9009752014413968
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 1.8036603521698877
1410, epoch_train_loss=1.8036603521698877
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 1.8978575848950678
1411, epoch_train_loss=1.8978575848950678
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 1.8060159165737515
1412, epoch_train_loss=1.8060159165737515
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 1.8777471211714585
1413, epoch_train_loss=1.8777471211714585
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 1.7874445059740305
1414, epoch_train_loss=1.7874445059740305
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 1.884858917813907
1415, epoch_train_loss=1.884858917813907
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 1.8240915820101766
1416, epoch_train_loss=1.8240915820101766
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 1.8447153817999913
1417, epoch_train_loss=1.8447153817999913
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 1.8082760521550263
1418, epoch_train_loss=1.8082760521550263
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 1.8259338121600768
1419, epoch_train_loss=1.8259338121600768
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 1.818805413497982
1420, epoch_train_loss=1.818805413497982
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 1.786772289489582
1421, epoch_train_loss=1.786772289489582
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 1.8548260723490206
1422, epoch_train_loss=1.8548260723490206
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 1.7840632049230982
1423, epoch_train_loss=1.7840632049230982
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 1.776224975768069
1424, epoch_train_loss=1.776224975768069
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 1.8085203081826333
1425, epoch_train_loss=1.8085203081826333
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 1.737534485137103
1426, epoch_train_loss=1.737534485137103
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 1.783008367576621
1427, epoch_train_loss=1.783008367576621
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 1.7682806736492316
1428, epoch_train_loss=1.7682806736492316
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 1.7318598995122902
1429, epoch_train_loss=1.7318598995122902
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 1.7418605037831616
1430, epoch_train_loss=1.7418605037831616
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 1.7446020326696021
1431, epoch_train_loss=1.7446020326696021
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 1.7264822893427825
1432, epoch_train_loss=1.7264822893427825
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 1.7360299223112472
1433, epoch_train_loss=1.7360299223112472
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 1.7300053068506063
1434, epoch_train_loss=1.7300053068506063
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 1.7175866950453613
1435, epoch_train_loss=1.7175866950453613
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 1.7251217727345105
1436, epoch_train_loss=1.7251217727345105
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 1.7238435907697436
1437, epoch_train_loss=1.7238435907697436
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 1.712757580392945
1438, epoch_train_loss=1.712757580392945
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 1.7115819080299233
1439, epoch_train_loss=1.7115819080299233
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 1.7146286972483735
1440, epoch_train_loss=1.7146286972483735
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 1.707772687977743
1441, epoch_train_loss=1.707772687977743
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 1.7040032532682439
1442, epoch_train_loss=1.7040032532682439
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 1.7075145338381876
1443, epoch_train_loss=1.7075145338381876
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 1.7063398311517164
1444, epoch_train_loss=1.7063398311517164
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 1.698699254548268
1445, epoch_train_loss=1.698699254548268
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 1.6969680212211868
1446, epoch_train_loss=1.6969680212211868
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 1.6990111728682096
1447, epoch_train_loss=1.6990111728682096
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 1.6958958363131735
1448, epoch_train_loss=1.6958958363131735
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 1.6911257121842278
1449, epoch_train_loss=1.6911257121842278
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 1.6889470988799427
1450, epoch_train_loss=1.6889470988799427
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 1.6890218539834942
1451, epoch_train_loss=1.6890218539834942
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 1.6889767148881378
1452, epoch_train_loss=1.6889767148881378
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 1.6861383375056405
1453, epoch_train_loss=1.6861383375056405
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 1.6819915750012548
1454, epoch_train_loss=1.6819915750012548
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 1.6791613901607656
1455, epoch_train_loss=1.6791613901607656
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 1.6787861493265355
1456, epoch_train_loss=1.6787861493265355
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 1.6793157952186653
1457, epoch_train_loss=1.6793157952186653
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 1.6791822381059451
1458, epoch_train_loss=1.6791822381059451
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 1.6795893291995907
1459, epoch_train_loss=1.6795893291995907
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 1.678126765218285
1460, epoch_train_loss=1.678126765218285
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 1.6770129114895869
1461, epoch_train_loss=1.6770129114895869
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 1.6756751538302126
1462, epoch_train_loss=1.6756751538302126
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 1.6792145922531676
1463, epoch_train_loss=1.6792145922531676
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 1.6865543257967526
1464, epoch_train_loss=1.6865543257967526
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 1.7181744964274759
1465, epoch_train_loss=1.7181744964274759
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 1.7624526969276701
1466, epoch_train_loss=1.7624526969276701
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 1.9434437118314851
1467, epoch_train_loss=1.9434437118314851
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 2.0141749902641974
1468, epoch_train_loss=2.0141749902641974
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 2.453375002239015
1469, epoch_train_loss=2.453375002239015
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 1.7837050064528082
1470, epoch_train_loss=1.7837050064528082
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 2.641618218032034
1471, epoch_train_loss=2.641618218032034
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 3.8949241795345895
1472, epoch_train_loss=3.8949241795345895
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 3.8232592136393495
1473, epoch_train_loss=3.8232592136393495
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 3.8652260094814115
1474, epoch_train_loss=3.8652260094814115
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 4.100424759583484
1475, epoch_train_loss=4.100424759583484
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 3.742620507778511
1476, epoch_train_loss=3.742620507778511
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 3.370273804971205
1477, epoch_train_loss=3.370273804971205
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 3.0751741395748073
1478, epoch_train_loss=3.0751741395748073
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 3.039559190586851
1479, epoch_train_loss=3.039559190586851
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 3.087490171966584
1480, epoch_train_loss=3.087490171966584
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 3.049537474031659
1481, epoch_train_loss=3.049537474031659
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 2.9649367411863077
1482, epoch_train_loss=2.9649367411863077
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 2.893256967204218
1483, epoch_train_loss=2.893256967204218
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 2.790418653645794
1484, epoch_train_loss=2.790418653645794
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 2.697633251368299
1485, epoch_train_loss=2.697633251368299
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 2.615314140042348
1486, epoch_train_loss=2.615314140042348
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 2.5412494208805274
1487, epoch_train_loss=2.5412494208805274
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 2.5119186787379877
1488, epoch_train_loss=2.5119186787379877
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 2.4822562422839654
1489, epoch_train_loss=2.4822562422839654
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 2.464680064211637
1490, epoch_train_loss=2.464680064211637
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 2.44411623077959
1491, epoch_train_loss=2.44411623077959
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 2.4090256527488205
1492, epoch_train_loss=2.4090256527488205
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 2.37763910247443
1493, epoch_train_loss=2.37763910247443
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 2.365320625395567
1494, epoch_train_loss=2.365320625395567
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 2.362826505385908
1495, epoch_train_loss=2.362826505385908
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 2.394372523758522
1496, epoch_train_loss=2.394372523758522
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 2.4664965412199007
1497, epoch_train_loss=2.4664965412199007
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 2.3295135824438757
1498, epoch_train_loss=2.3295135824438757
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 2.367951450110128
1499, epoch_train_loss=2.367951450110128
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 2.3159098626827226
1500, epoch_train_loss=2.3159098626827226
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 2.306409070460963
1501, epoch_train_loss=2.306409070460963
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 2.2490835613424474
1502, epoch_train_loss=2.2490835613424474
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 2.26323091422164
1503, epoch_train_loss=2.26323091422164
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 2.229351787873016
1504, epoch_train_loss=2.229351787873016
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 2.229883064619735
1505, epoch_train_loss=2.229883064619735
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 2.1903091682162135
1506, epoch_train_loss=2.1903091682162135
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 2.1891648898293288
1507, epoch_train_loss=2.1891648898293288
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 2.156003344992711
1508, epoch_train_loss=2.156003344992711
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 2.1598039454590436
1509, epoch_train_loss=2.1598039454590436
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 2.146453568409791
1510, epoch_train_loss=2.146453568409791
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 2.1476017522883555
1511, epoch_train_loss=2.1476017522883555
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 2.1297515345806235
1512, epoch_train_loss=2.1297515345806235
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 2.128318370503247
1513, epoch_train_loss=2.128318370503247
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 2.118631329218195
1514, epoch_train_loss=2.118631329218195
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 2.11693149103679
1515, epoch_train_loss=2.11693149103679
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 2.109704905858255
1516, epoch_train_loss=2.109704905858255
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 2.1016833497578005
1517, epoch_train_loss=2.1016833497578005
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 2.0944223085050813
1518, epoch_train_loss=2.0944223085050813
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 2.085109052809017
1519, epoch_train_loss=2.085109052809017
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 2.0779435777709496
1520, epoch_train_loss=2.0779435777709496
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 2.0640313623316398
1521, epoch_train_loss=2.0640313623316398
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 2.0584114038698877
1522, epoch_train_loss=2.0584114038698877
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 2.053149747815972
1523, epoch_train_loss=2.053149747815972
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 2.0499974796439018
1524, epoch_train_loss=2.0499974796439018
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 2.0449224044312704
1525, epoch_train_loss=2.0449224044312704
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 2.0461109587857997
1526, epoch_train_loss=2.0461109587857997
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 2.0412804750429823
1527, epoch_train_loss=2.0412804750429823
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 2.0433369643698676
1528, epoch_train_loss=2.0433369643698676
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 2.0339886963163614
1529, epoch_train_loss=2.0339886963163614
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 2.0222381716858564
1530, epoch_train_loss=2.0222381716858564
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 1.9996025504041717
1531, epoch_train_loss=1.9996025504041717
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 1.992490228873629
1532, epoch_train_loss=1.992490228873629
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 2.0022085793195448
1533, epoch_train_loss=2.0022085793195448
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 2.0046740337448847
1534, epoch_train_loss=2.0046740337448847
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 2.0119000259221953
1535, epoch_train_loss=2.0119000259221953
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 1.9805847818240412
1536, epoch_train_loss=1.9805847818240412
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 1.9579375906403418
1537, epoch_train_loss=1.9579375906403418
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 1.9538870520697438
1538, epoch_train_loss=1.9538870520697438
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 1.963034409316288
1539, epoch_train_loss=1.963034409316288
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 2.0136004939684193
1540, epoch_train_loss=2.0136004939684193
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 2.013638765656989
1541, epoch_train_loss=2.013638765656989
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 1.9980802090127059
1542, epoch_train_loss=1.9980802090127059
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 1.9266916464079842
1543, epoch_train_loss=1.9266916464079842
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 1.9795351063627264
1544, epoch_train_loss=1.9795351063627264
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 2.293204158720708
1545, epoch_train_loss=2.293204158720708
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 1.9899781676551358
1546, epoch_train_loss=1.9899781676551358
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 2.289503433167545
1547, epoch_train_loss=2.289503433167545
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 2.630011382399473
1548, epoch_train_loss=2.630011382399473
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 2.7193681667440255
1549, epoch_train_loss=2.7193681667440255
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 2.347369166488899
1550, epoch_train_loss=2.347369166488899
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 2.4498596337877387
1551, epoch_train_loss=2.4498596337877387
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 2.353272262554447
1552, epoch_train_loss=2.353272262554447
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 2.520753901536679
1553, epoch_train_loss=2.520753901536679
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 2.225106668162388
1554, epoch_train_loss=2.225106668162388
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 2.353401219670085
1555, epoch_train_loss=2.353401219670085
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 2.3536884523355375
1556, epoch_train_loss=2.3536884523355375
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 2.21699988446803
1557, epoch_train_loss=2.21699988446803
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 2.2816298283828296
1558, epoch_train_loss=2.2816298283828296
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 2.2507067077369096
1559, epoch_train_loss=2.2507067077369096
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 2.207159675292853
1560, epoch_train_loss=2.207159675292853
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 2.1620479766699594
1561, epoch_train_loss=2.1620479766699594
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 2.151898097568284
1562, epoch_train_loss=2.151898097568284
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 2.1893320206705216
1563, epoch_train_loss=2.1893320206705216
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 2.08795592909394
1564, epoch_train_loss=2.08795592909394
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 2.1315185195681505
1565, epoch_train_loss=2.1315185195681505
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 2.0802935400173426
1566, epoch_train_loss=2.0802935400173426
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 2.1172473113389048
1567, epoch_train_loss=2.1172473113389048
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 2.04887441162934
1568, epoch_train_loss=2.04887441162934
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 2.102032185746676
1569, epoch_train_loss=2.102032185746676
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 2.0641471881654927
1570, epoch_train_loss=2.0641471881654927
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 2.0945835021183177
1571, epoch_train_loss=2.0945835021183177
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 2.046811382210559
1572, epoch_train_loss=2.046811382210559
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 2.067882524428605
1573, epoch_train_loss=2.067882524428605
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 2.0224427559936333
1574, epoch_train_loss=2.0224427559936333
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 2.043488926132795
1575, epoch_train_loss=2.043488926132795
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 2.016936155972664
1576, epoch_train_loss=2.016936155972664
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 2.0349262668475494
1577, epoch_train_loss=2.0349262668475494
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 2.013011886016958
1578, epoch_train_loss=2.013011886016958
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 2.0268461574014007
1579, epoch_train_loss=2.0268461574014007
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 2.009560215773717
1580, epoch_train_loss=2.009560215773717
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 2.013424548288266
1581, epoch_train_loss=2.013424548288266
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 1.9968144422063372
1582, epoch_train_loss=1.9968144422063372
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 2.0002249538397514
1583, epoch_train_loss=2.0002249538397514
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 1.990264146845771
1584, epoch_train_loss=1.990264146845771
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 1.9913446579766523
1585, epoch_train_loss=1.9913446579766523
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 1.9837589740485477
1586, epoch_train_loss=1.9837589740485477
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 1.9817459560318615
1587, epoch_train_loss=1.9817459560318615
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 1.9778598273813048
1588, epoch_train_loss=1.9778598273813048
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 1.971998748389963
1589, epoch_train_loss=1.971998748389963
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 1.9685252624029188
1590, epoch_train_loss=1.9685252624029188
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 1.9570792357809368
1591, epoch_train_loss=1.9570792357809368
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 1.9499370822203375
1592, epoch_train_loss=1.9499370822203375
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 1.9354537957685505
1593, epoch_train_loss=1.9354537957685505
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 1.9255160912012177
1594, epoch_train_loss=1.9255160912012177
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 1.9206121370807867
1595, epoch_train_loss=1.9206121370807867
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 1.923775025589273
1596, epoch_train_loss=1.923775025589273
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 1.9219544837594422
1597, epoch_train_loss=1.9219544837594422
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 1.9091797456564632
1598, epoch_train_loss=1.9091797456564632
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 1.9014357273983575
1599, epoch_train_loss=1.9014357273983575
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 1.9015347065007395
1600, epoch_train_loss=1.9015347065007395
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 1.897445428133719
1601, epoch_train_loss=1.897445428133719
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 1.8891699870212046
1602, epoch_train_loss=1.8891699870212046
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 1.8819520776607441
1603, epoch_train_loss=1.8819520776607441
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 1.8777749085023285
1604, epoch_train_loss=1.8777749085023285
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 1.8750828153955867
1605, epoch_train_loss=1.8750828153955867
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 1.871253624675624
1606, epoch_train_loss=1.871253624675624
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 1.8652894056806009
1607, epoch_train_loss=1.8652894056806009
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 1.8603057805360392
1608, epoch_train_loss=1.8603057805360392
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 1.8583049025559768
1609, epoch_train_loss=1.8583049025559768
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 1.8571152530147759
1610, epoch_train_loss=1.8571152530147759
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 1.85369582822144
1611, epoch_train_loss=1.85369582822144
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 1.8508120999483553
1612, epoch_train_loss=1.8508120999483553
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 1.85074883028889
1613, epoch_train_loss=1.85074883028889
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 1.8722209676871
1614, epoch_train_loss=1.8722209676871
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 1.9268289673755756
1615, epoch_train_loss=1.9268289673755756
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 2.132564453992892
1616, epoch_train_loss=2.132564453992892
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 1.8976255190466347
1617, epoch_train_loss=1.8976255190466347
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 1.9046579579215397
1618, epoch_train_loss=1.9046579579215397
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 1.987037578897947
1619, epoch_train_loss=1.987037578897947
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 1.8415358060347253
1620, epoch_train_loss=1.8415358060347253
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 2.0243447248932656
1621, epoch_train_loss=2.0243447248932656
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 2.4836951606077693
1622, epoch_train_loss=2.4836951606077693
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 1.8897569256933766
1623, epoch_train_loss=1.8897569256933766
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 2.590811876149275
1624, epoch_train_loss=2.590811876149275
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 2.1311455148321623
1625, epoch_train_loss=2.1311455148321623
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 2.4978451875989265
1626, epoch_train_loss=2.4978451875989265
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 1.9992336752249267
1627, epoch_train_loss=1.9992336752249267
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 2.4175050488528265
1628, epoch_train_loss=2.4175050488528265
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 2.2662712677441292
1629, epoch_train_loss=2.2662712677441292
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 2.317576321555478
1630, epoch_train_loss=2.317576321555478
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 2.1111761878852695
1631, epoch_train_loss=2.1111761878852695
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 2.2687866280318207
1632, epoch_train_loss=2.2687866280318207
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 2.2299798874242884
1633, epoch_train_loss=2.2299798874242884
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 1.9877867926336361
1634, epoch_train_loss=1.9877867926336361
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 2.206761157919461
1635, epoch_train_loss=2.206761157919461
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 2.012359300221776
1636, epoch_train_loss=2.012359300221776
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 2.0229190617409105
1637, epoch_train_loss=2.0229190617409105
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 1.939812155857
1638, epoch_train_loss=1.939812155857
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 2.0397294154279937
1639, epoch_train_loss=2.0397294154279937
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 1.9336430769164312
1640, epoch_train_loss=1.9336430769164312
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 1.9670503736182758
1641, epoch_train_loss=1.9670503736182758
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 1.9843440311484462
1642, epoch_train_loss=1.9843440311484462
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 1.9186827689448538
1643, epoch_train_loss=1.9186827689448538
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 1.9718708138217644
1644, epoch_train_loss=1.9718708138217644
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 1.9886711478054324
1645, epoch_train_loss=1.9886711478054324
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 1.9009969487496912
1646, epoch_train_loss=1.9009969487496912
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 1.9476085292410175
1647, epoch_train_loss=1.9476085292410175
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 1.8949285455005909
1648, epoch_train_loss=1.8949285455005909
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 1.912905166200114
1649, epoch_train_loss=1.912905166200114
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 1.8592006645666042
1650, epoch_train_loss=1.8592006645666042
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 1.8825766637520247
1651, epoch_train_loss=1.8825766637520247
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 1.985342887638318
1652, epoch_train_loss=1.985342887638318
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 1.8815031530520903
1653, epoch_train_loss=1.8815031530520903
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 1.8762475478731941
1654, epoch_train_loss=1.8762475478731941
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 1.9063884987437956
1655, epoch_train_loss=1.9063884987437956
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 1.8665802450532896
1656, epoch_train_loss=1.8665802450532896
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 1.902906550141457
1657, epoch_train_loss=1.902906550141457
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 1.8918892106086174
1658, epoch_train_loss=1.8918892106086174
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 1.8529036994800452
1659, epoch_train_loss=1.8529036994800452
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 1.934029197002334
1660, epoch_train_loss=1.934029197002334
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 2.031273133900861
1661, epoch_train_loss=2.031273133900861
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 1.8402737037004098
1662, epoch_train_loss=1.8402737037004098
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 1.9085536671204055
1663, epoch_train_loss=1.9085536671204055
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 2.036818176092597
1664, epoch_train_loss=2.036818176092597
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 1.8682989631719145
1665, epoch_train_loss=1.8682989631719145
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 2.104498698543376
1666, epoch_train_loss=2.104498698543376
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 1.9571727076109633
1667, epoch_train_loss=1.9571727076109633
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 2.028719673634648
1668, epoch_train_loss=2.028719673634648
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 1.9431653892813858
1669, epoch_train_loss=1.9431653892813858
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 2.0347488049582547
1670, epoch_train_loss=2.0347488049582547
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 1.9553313936392933
1671, epoch_train_loss=1.9553313936392933
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 1.9904901074912764
1672, epoch_train_loss=1.9904901074912764
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 1.9753789404285214
1673, epoch_train_loss=1.9753789404285214
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 1.8376267050205632
1674, epoch_train_loss=1.8376267050205632
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 1.9119082282727464
1675, epoch_train_loss=1.9119082282727464
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 1.8584496988457186
1676, epoch_train_loss=1.8584496988457186
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 1.812598302533472
1677, epoch_train_loss=1.812598302533472
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 1.8242765604101825
1678, epoch_train_loss=1.8242765604101825
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 1.8811153498122257
1679, epoch_train_loss=1.8811153498122257
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 2.0082902161523526
1680, epoch_train_loss=2.0082902161523526
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 1.8973592075879453
1681, epoch_train_loss=1.8973592075879453
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 1.8316472185203405
1682, epoch_train_loss=1.8316472185203405
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 1.842763724807191
1683, epoch_train_loss=1.842763724807191
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 1.853509688620857
1684, epoch_train_loss=1.853509688620857
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 1.8248061743958266
1685, epoch_train_loss=1.8248061743958266
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 1.7941324020066074
1686, epoch_train_loss=1.7941324020066074
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 1.794305804729766
1687, epoch_train_loss=1.794305804729766
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 1.8075473315226565
1688, epoch_train_loss=1.8075473315226565
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 1.8782828151890965
1689, epoch_train_loss=1.8782828151890965
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 2.1882899108646585
1690, epoch_train_loss=2.1882899108646585
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 1.897187516246703
1691, epoch_train_loss=1.897187516246703
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 1.908997113838458
1692, epoch_train_loss=1.908997113838458
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 1.9540987463266377
1693, epoch_train_loss=1.9540987463266377
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 1.9170618761607012
1694, epoch_train_loss=1.9170618761607012
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 1.9104455707776935
1695, epoch_train_loss=1.9104455707776935
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 1.816963627315463
1696, epoch_train_loss=1.816963627315463
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 1.7837294216674218
1697, epoch_train_loss=1.7837294216674218
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 1.9409444085128638
1698, epoch_train_loss=1.9409444085128638
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 2.709979482394542
1699, epoch_train_loss=2.709979482394542
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 1.8320207099205448
1700, epoch_train_loss=1.8320207099205448
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 2.1292370026613288
1701, epoch_train_loss=2.1292370026613288
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 2.0933027502277373
1702, epoch_train_loss=2.0933027502277373
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 2.3139360307624357
1703, epoch_train_loss=2.3139360307624357
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 2.1142403337958546
1704, epoch_train_loss=2.1142403337958546
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 2.2387685420744776
1705, epoch_train_loss=2.2387685420744776
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 2.040943337375453
1706, epoch_train_loss=2.040943337375453
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 2.118103472868713
1707, epoch_train_loss=2.118103472868713
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 2.0752914974160013
1708, epoch_train_loss=2.0752914974160013
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 2.0634101957458864
1709, epoch_train_loss=2.0634101957458864
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 2.0743809335711885
1710, epoch_train_loss=2.0743809335711885
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 1.9881159049805794
1711, epoch_train_loss=1.9881159049805794
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 2.0689545943670162
1712, epoch_train_loss=2.0689545943670162
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 1.9661420409109944
1713, epoch_train_loss=1.9661420409109944
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 2.0214682810430498
1714, epoch_train_loss=2.0214682810430498
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 1.9543226345694846
1715, epoch_train_loss=1.9543226345694846
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 1.9585611820321829
1716, epoch_train_loss=1.9585611820321829
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 1.9617849395926914
1717, epoch_train_loss=1.9617849395926914
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 1.8926254807163663
1718, epoch_train_loss=1.8926254807163663
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 1.9298489757938362
1719, epoch_train_loss=1.9298489757938362
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 1.8899769501700379
1720, epoch_train_loss=1.8899769501700379
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 1.8637214806366251
1721, epoch_train_loss=1.8637214806366251
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 1.8619439155477955
1722, epoch_train_loss=1.8619439155477955
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 1.87235296331459
1723, epoch_train_loss=1.87235296331459
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 1.9211767852928843
1724, epoch_train_loss=1.9211767852928843
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 1.853804642152057
1725, epoch_train_loss=1.853804642152057
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 1.8514380304063958
1726, epoch_train_loss=1.8514380304063958
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 1.868909104816341
1727, epoch_train_loss=1.868909104816341
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 1.817343599997785
1728, epoch_train_loss=1.817343599997785
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 1.8532880453279297
1729, epoch_train_loss=1.8532880453279297
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 1.9529571577275693
1730, epoch_train_loss=1.9529571577275693
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 1.8085771366489587
1731, epoch_train_loss=1.8085771366489587
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 1.8072121269410502
1732, epoch_train_loss=1.8072121269410502
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 1.9105374373800126
1733, epoch_train_loss=1.9105374373800126
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 1.841174596469678
1734, epoch_train_loss=1.841174596469678
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 1.8060903605556107
1735, epoch_train_loss=1.8060903605556107
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 1.7794004983015979
1736, epoch_train_loss=1.7794004983015979
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 1.7975990068014676
1737, epoch_train_loss=1.7975990068014676
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 1.90318406026861
1738, epoch_train_loss=1.90318406026861
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 1.9600386931503084
1739, epoch_train_loss=1.9600386931503084
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 2.2456637351674984
1740, epoch_train_loss=2.2456637351674984
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 1.8185488767373632
1741, epoch_train_loss=1.8185488767373632
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 2.340497548056678
1742, epoch_train_loss=2.340497548056678
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 2.1259964214050253
1743, epoch_train_loss=2.1259964214050253
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 2.304627611513848
1744, epoch_train_loss=2.304627611513848
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 2.1832459171615004
1745, epoch_train_loss=2.1832459171615004
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 2.353501896399192
1746, epoch_train_loss=2.353501896399192
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 2.1889586402792798
1747, epoch_train_loss=2.1889586402792798
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 1.951634177078088
1748, epoch_train_loss=1.951634177078088
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 2.1383564307432774
1749, epoch_train_loss=2.1383564307432774
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 1.8925511202407246
1750, epoch_train_loss=1.8925511202407246
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 2.323717613206787
1751, epoch_train_loss=2.323717613206787
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 2.83320752241188
1752, epoch_train_loss=2.83320752241188
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 2.271301773641829
1753, epoch_train_loss=2.271301773641829
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 2.1341145050773487
1754, epoch_train_loss=2.1341145050773487
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 2.8095942040875936
1755, epoch_train_loss=2.8095942040875936
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 2.380885779857706
1756, epoch_train_loss=2.380885779857706
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 2.141979872806905
1757, epoch_train_loss=2.141979872806905
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 2.649663444024456
1758, epoch_train_loss=2.649663444024456
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 2.187277325904347
1759, epoch_train_loss=2.187277325904347
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 2.362368769897619
1760, epoch_train_loss=2.362368769897619
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 2.4404762084675213
1761, epoch_train_loss=2.4404762084675213
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 2.16298735728456
1762, epoch_train_loss=2.16298735728456
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 2.2402107286942092
1763, epoch_train_loss=2.2402107286942092
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 2.268559191647896
1764, epoch_train_loss=2.268559191647896
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 2.0630337240079903
1765, epoch_train_loss=2.0630337240079903
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 2.2381370826578797
1766, epoch_train_loss=2.2381370826578797
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 2.153954099477835
1767, epoch_train_loss=2.153954099477835
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 2.0665525853210647
1768, epoch_train_loss=2.0665525853210647
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 2.174193787150999
1769, epoch_train_loss=2.174193787150999
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 2.1375159072491883
1770, epoch_train_loss=2.1375159072491883
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 2.0453675147254637
1771, epoch_train_loss=2.0453675147254637
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 2.1026705677764803
1772, epoch_train_loss=2.1026705677764803
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 2.1014478285045404
1773, epoch_train_loss=2.1014478285045404
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 2.0199217972619827
1774, epoch_train_loss=2.0199217972619827
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 2.0449761364842556
1775, epoch_train_loss=2.0449761364842556
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 2.0449556700420537
1776, epoch_train_loss=2.0449556700420537
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 2.000796367105709
1777, epoch_train_loss=2.000796367105709
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 2.003023844728646
1778, epoch_train_loss=2.003023844728646
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 1.9886536865288722
1779, epoch_train_loss=1.9886536865288722
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 1.9865651049442588
1780, epoch_train_loss=1.9865651049442588
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 1.9659761233881898
1781, epoch_train_loss=1.9659761233881898
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 1.9489742882140133
1782, epoch_train_loss=1.9489742882140133
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 1.9681112040684743
1783, epoch_train_loss=1.9681112040684743
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 1.9373232706744086
1784, epoch_train_loss=1.9373232706744086
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 1.9405669430362487
1785, epoch_train_loss=1.9405669430362487
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 1.9357802582212316
1786, epoch_train_loss=1.9357802582212316
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 1.9313651919779735
1787, epoch_train_loss=1.9313651919779735
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 1.9269291380374622
1788, epoch_train_loss=1.9269291380374622
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 1.9080655678613458
1789, epoch_train_loss=1.9080655678613458
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 1.914175849508748
1790, epoch_train_loss=1.914175849508748
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 1.8926956278569622
1791, epoch_train_loss=1.8926956278569622
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 1.8831247179267974
1792, epoch_train_loss=1.8831247179267974
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 1.8633390035938768
1793, epoch_train_loss=1.8633390035938768
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 1.861406940662658
1794, epoch_train_loss=1.861406940662658
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 1.8521664321426083
1795, epoch_train_loss=1.8521664321426083
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 1.8513208806198225
1796, epoch_train_loss=1.8513208806198225
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 1.8490755318890912
1797, epoch_train_loss=1.8490755318890912
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 1.8303184916036785
1798, epoch_train_loss=1.8303184916036785
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 1.8216139886747804
1799, epoch_train_loss=1.8216139886747804
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 1.8213683883273024
1800, epoch_train_loss=1.8213683883273024
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 1.8138054391838445
1801, epoch_train_loss=1.8138054391838445
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 1.8093296897807847
1802, epoch_train_loss=1.8093296897807847
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 1.8087452417667411
1803, epoch_train_loss=1.8087452417667411
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 1.803178086521074
1804, epoch_train_loss=1.803178086521074
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 1.7957111261452234
1805, epoch_train_loss=1.7957111261452234
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 1.7883602564783365
1806, epoch_train_loss=1.7883602564783365
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 1.7832394422431872
1807, epoch_train_loss=1.7832394422431872
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 1.7766883184172502
1808, epoch_train_loss=1.7766883184172502
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 1.7704823550986957
1809, epoch_train_loss=1.7704823550986957
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 1.7681115909992247
1810, epoch_train_loss=1.7681115909992247
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 1.7765549998642078
1811, epoch_train_loss=1.7765549998642078
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 1.794884561200731
1812, epoch_train_loss=1.794884561200731
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 1.8594284494533906
1813, epoch_train_loss=1.8594284494533906
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 1.8018195444817493
1814, epoch_train_loss=1.8018195444817493
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 1.7789918845295707
1815, epoch_train_loss=1.7789918845295707
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 1.7457005859277117
1816, epoch_train_loss=1.7457005859277117
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 1.742192953109186
1817, epoch_train_loss=1.742192953109186
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 1.792909178897372
1818, epoch_train_loss=1.792909178897372
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 1.9776131653745075
1819, epoch_train_loss=1.9776131653745075
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 2.593567063720655
1820, epoch_train_loss=2.593567063720655
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 1.7869084194331146
1821, epoch_train_loss=1.7869084194331146
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 2.835666812958454
1822, epoch_train_loss=2.835666812958454
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 2.156840256601475
1823, epoch_train_loss=2.156840256601475
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 2.851571621314735
1824, epoch_train_loss=2.851571621314735
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 2.1209369124800177
1825, epoch_train_loss=2.1209369124800177
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 2.5810505435618105
1826, epoch_train_loss=2.5810505435618105
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 2.1919002221316206
1827, epoch_train_loss=2.1919002221316206
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 2.466192665744114
1828, epoch_train_loss=2.466192665744114
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 2.3150740097893046
1829, epoch_train_loss=2.3150740097893046
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 2.1771546800582615
1830, epoch_train_loss=2.1771546800582615
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 2.3267029465570537
1831, epoch_train_loss=2.3267029465570537
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 2.1960450576218125
1832, epoch_train_loss=2.1960450576218125
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 2.179914052883093
1833, epoch_train_loss=2.179914052883093
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 2.2658661522487495
1834, epoch_train_loss=2.2658661522487495
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 2.1854400319585454
1835, epoch_train_loss=2.1854400319585454
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 2.1696913180496846
1836, epoch_train_loss=2.1696913180496846
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 2.1992191359805573
1837, epoch_train_loss=2.1992191359805573
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 2.154221270331696
1838, epoch_train_loss=2.154221270331696
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 2.1255366500514574
1839, epoch_train_loss=2.1255366500514574
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 2.1603384602464675
1840, epoch_train_loss=2.1603384602464675
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 2.115214245139821
1841, epoch_train_loss=2.115214245139821
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 2.1000609527007934
1842, epoch_train_loss=2.1000609527007934
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 2.134719733675144
1843, epoch_train_loss=2.134719733675144
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 2.0997892163572334
1844, epoch_train_loss=2.0997892163572334
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 2.0697445284350757
1845, epoch_train_loss=2.0697445284350757
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 2.0779996832709084
1846, epoch_train_loss=2.0779996832709084
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 2.067416462674745
1847, epoch_train_loss=2.067416462674745
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 2.0481760304985386
1848, epoch_train_loss=2.0481760304985386
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 2.0458598737772866
1849, epoch_train_loss=2.0458598737772866
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 2.028605551804732
1850, epoch_train_loss=2.028605551804732
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 2.0191562410686474
1851, epoch_train_loss=2.0191562410686474
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 2.0226846947753443
1852, epoch_train_loss=2.0226846947753443
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 1.9982670728713547
1853, epoch_train_loss=1.9982670728713547
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 1.9994568610096908
1854, epoch_train_loss=1.9994568610096908
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 1.9853068545766286
1855, epoch_train_loss=1.9853068545766286
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 1.980127282945107
1856, epoch_train_loss=1.980127282945107
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 1.977532268403692
1857, epoch_train_loss=1.977532268403692
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 1.9630673148874949
1858, epoch_train_loss=1.9630673148874949
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 1.9630531764130563
1859, epoch_train_loss=1.9630531764130563
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 1.9466348291506528
1860, epoch_train_loss=1.9466348291506528
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 1.948806122961735
1861, epoch_train_loss=1.948806122961735
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 1.9368873281509016
1862, epoch_train_loss=1.9368873281509016
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 1.9345861898948116
1863, epoch_train_loss=1.9345861898948116
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 1.9296671010776958
1864, epoch_train_loss=1.9296671010776958
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 1.9239559241727013
1865, epoch_train_loss=1.9239559241727013
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 1.9268543753053562
1866, epoch_train_loss=1.9268543753053562
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 1.918042394294665
1867, epoch_train_loss=1.918042394294665
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 1.9209432673663218
1868, epoch_train_loss=1.9209432673663218
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 1.9157807096113098
1869, epoch_train_loss=1.9157807096113098
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 1.913661279130383
1870, epoch_train_loss=1.913661279130383
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 1.9139823498457005
1871, epoch_train_loss=1.9139823498457005
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 1.9072331693382876
1872, epoch_train_loss=1.9072331693382876
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 1.9076613379257499
1873, epoch_train_loss=1.9076613379257499
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 1.903842977512991
1874, epoch_train_loss=1.903842977512991
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 1.9001411064133602
1875, epoch_train_loss=1.9001411064133602
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 1.900116913132662
1876, epoch_train_loss=1.900116913132662
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 1.8960568000686686
1877, epoch_train_loss=1.8960568000686686
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 1.8955709559043945
1878, epoch_train_loss=1.8955709559043945
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 1.8931767097693784
1879, epoch_train_loss=1.8931767097693784
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 1.8898698737326611
1880, epoch_train_loss=1.8898698737326611
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 1.889427567445672
1881, epoch_train_loss=1.889427567445672
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 1.8862431788217724
1882, epoch_train_loss=1.8862431788217724
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 1.884473024669262
1883, epoch_train_loss=1.884473024669262
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 1.8832683014331537
1884, epoch_train_loss=1.8832683014331537
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 1.8806064147692358
1885, epoch_train_loss=1.8806064147692358
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 1.8797983850867657
1886, epoch_train_loss=1.8797983850867657
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 1.8782115417039684
1887, epoch_train_loss=1.8782115417039684
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 1.8763453134918675
1888, epoch_train_loss=1.8763453134918675
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 1.8756622914851724
1889, epoch_train_loss=1.8756622914851724
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 1.8738126878486394
1890, epoch_train_loss=1.8738126878486394
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 1.8722408443168508
1891, epoch_train_loss=1.8722408443168508
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 1.8712010171358369
1892, epoch_train_loss=1.8712010171358369
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 1.8693917968096527
1893, epoch_train_loss=1.8693917968096527
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 1.8681888724050644
1894, epoch_train_loss=1.8681888724050644
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 1.8669404065322766
1895, epoch_train_loss=1.8669404065322766
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 1.8652432152306178
1896, epoch_train_loss=1.8652432152306178
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 1.8642649827175142
1897, epoch_train_loss=1.8642649827175142
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 1.8630832365830288
1898, epoch_train_loss=1.8630832365830288
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 1.8617111532174444
1899, epoch_train_loss=1.8617111532174444
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 1.86079502920199
1900, epoch_train_loss=1.86079502920199
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 1.8595531780542955
1901, epoch_train_loss=1.8595531780542955
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 1.8583290286729002
1902, epoch_train_loss=1.8583290286729002
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 1.8573336592212748
1903, epoch_train_loss=1.8573336592212748
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 1.8560638145976822
1904, epoch_train_loss=1.8560638145976822
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 1.85489402230086
1905, epoch_train_loss=1.85489402230086
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 1.8538474765908513
1906, epoch_train_loss=1.8538474765908513
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 1.852585010149655
1907, epoch_train_loss=1.852585010149655
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 1.8514055244229675
1908, epoch_train_loss=1.8514055244229675
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 1.8503447699448543
1909, epoch_train_loss=1.8503447699448543
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 1.8491190629941816
1910, epoch_train_loss=1.8491190629941816
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 1.8479475199250195
1911, epoch_train_loss=1.8479475199250195
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 1.846865688727686
1912, epoch_train_loss=1.846865688727686
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 1.8456750396155432
1913, epoch_train_loss=1.8456750396155432
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 1.8445090786804788
1914, epoch_train_loss=1.8445090786804788
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 1.8434135622799595
1915, epoch_train_loss=1.8434135622799595
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 1.8422483304794588
1916, epoch_train_loss=1.8422483304794588
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 1.8410557183078842
1917, epoch_train_loss=1.8410557183078842
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 1.8399214775401596
1918, epoch_train_loss=1.8399214775401596
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 1.8387513157946334
1919, epoch_train_loss=1.8387513157946334
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 1.837549385053143
1920, epoch_train_loss=1.837549385053143
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 1.8363960292619224
1921, epoch_train_loss=1.8363960292619224
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 1.8352424064731148
1922, epoch_train_loss=1.8352424064731148
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 1.8340495198329163
1923, epoch_train_loss=1.8340495198329163
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 1.832872580576566
1924, epoch_train_loss=1.832872580576566
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 1.8317240890110835
1925, epoch_train_loss=1.8317240890110835
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 1.8305470620529403
1926, epoch_train_loss=1.8305470620529403
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 1.8293500248338448
1927, epoch_train_loss=1.8293500248338448
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 1.8281676420245052
1928, epoch_train_loss=1.8281676420245052
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 1.8269872067727948
1929, epoch_train_loss=1.8269872067727948
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 1.82578251126892
1930, epoch_train_loss=1.82578251126892
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 1.82456927368069
1931, epoch_train_loss=1.82456927368069
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 1.8233658008114748
1932, epoch_train_loss=1.8233658008114748
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 1.822158378861917
1933, epoch_train_loss=1.822158378861917
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 1.8209339811980616
1934, epoch_train_loss=1.8209339811980616
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 1.8197012364326437
1935, epoch_train_loss=1.8197012364326437
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 1.818471461698557
1936, epoch_train_loss=1.818471461698557
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 1.81723716268789
1937, epoch_train_loss=1.81723716268789
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 1.8159897963188016
1938, epoch_train_loss=1.8159897963188016
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 1.8147294741808262
1939, epoch_train_loss=1.8147294741808262
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 1.8134635842875013
1940, epoch_train_loss=1.8134635842875013
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 1.812192861648883
1941, epoch_train_loss=1.812192861648883
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 1.8109133279626362
1942, epoch_train_loss=1.8109133279626362
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 1.8096203933096167
1943, epoch_train_loss=1.8096203933096167
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 1.8083144048768867
1944, epoch_train_loss=1.8083144048768867
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 1.8069981895667033
1945, epoch_train_loss=1.8069981895667033
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 1.8056739540390188
1946, epoch_train_loss=1.8056739540390188
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 1.8043406627077236
1947, epoch_train_loss=1.8043406627077236
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 1.8029961134831571
1948, epoch_train_loss=1.8029961134831571
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 1.8016391155632414
1949, epoch_train_loss=1.8016391155632414
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 1.8002697371459282
1950, epoch_train_loss=1.8002697371459282
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 1.7988885663529075
1951, epoch_train_loss=1.7988885663529075
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 1.7974962689123517
1952, epoch_train_loss=1.7974962689123517
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 1.796093680081508
1953, epoch_train_loss=1.796093680081508
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 1.7946809947970073
1954, epoch_train_loss=1.7946809947970073
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 1.7932582835381299
1955, epoch_train_loss=1.7932582835381299
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 1.7918257219063316
1956, epoch_train_loss=1.7918257219063316
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 1.7903840163973905
1957, epoch_train_loss=1.7903840163973905
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 1.78893370607377
1958, epoch_train_loss=1.78893370607377
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 1.7874758707012208
1959, epoch_train_loss=1.7874758707012208
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 1.786012424670078
1960, epoch_train_loss=1.786012424670078
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 1.784548472288758
1961, epoch_train_loss=1.784548472288758
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 1.7830951337882668
1962, epoch_train_loss=1.7830951337882668
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 1.7816853402818684
1963, epoch_train_loss=1.7816853402818684
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 1.780401950650863
1964, epoch_train_loss=1.780401950650863
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 1.779518106115471
1965, epoch_train_loss=1.779518106115471
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 1.779744539392022
1966, epoch_train_loss=1.779744539392022
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 1.783828310200856
1967, epoch_train_loss=1.783828310200856
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 1.797591139987532
1968, epoch_train_loss=1.797591139987532
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 1.8474687710839663
1969, epoch_train_loss=1.8474687710839663
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 1.9095520512022268
1970, epoch_train_loss=1.9095520512022268
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 2.037228968623111
1971, epoch_train_loss=2.037228968623111
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 1.8125357426701443
1972, epoch_train_loss=1.8125357426701443
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 1.8330017972423627
1973, epoch_train_loss=1.8330017972423627
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 2.079187866406178
1974, epoch_train_loss=2.079187866406178
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 1.8435134403001148
1975, epoch_train_loss=1.8435134403001148
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 1.8121403387742074
1976, epoch_train_loss=1.8121403387742074
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 2.053467534492296
1977, epoch_train_loss=2.053467534492296
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 1.8437344444223065
1978, epoch_train_loss=1.8437344444223065
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 1.8101425698914488
1979, epoch_train_loss=1.8101425698914488
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 1.7960096308590405
1980, epoch_train_loss=1.7960096308590405
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 1.88387907080444
1981, epoch_train_loss=1.88387907080444
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 1.9971488207404324
1982, epoch_train_loss=1.9971488207404324
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 1.853500785349711
1983, epoch_train_loss=1.853500785349711
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 2.0346946469542506
1984, epoch_train_loss=2.0346946469542506
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 2.5457014654787877
1985, epoch_train_loss=2.5457014654787877
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 1.9572381411714392
1986, epoch_train_loss=1.9572381411714392
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 2.446989816437967
1987, epoch_train_loss=2.446989816437967
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 2.0846256197050175
1988, epoch_train_loss=2.0846256197050175
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 2.2889503708136556
1989, epoch_train_loss=2.2889503708136556
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 1.912898090856616
1990, epoch_train_loss=1.912898090856616
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 2.2286065339061234
1991, epoch_train_loss=2.2286065339061234
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 2.434120534883174
1992, epoch_train_loss=2.434120534883174
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 2.0815601777818693
1993, epoch_train_loss=2.0815601777818693
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 2.3014297491935767
1994, epoch_train_loss=2.3014297491935767
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 1.9868337104170302
1995, epoch_train_loss=1.9868337104170302
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 1.9853200130789157
1996, epoch_train_loss=1.9853200130789157
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 2.07996777980709
1997, epoch_train_loss=2.07996777980709
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 1.8235784899882286
1998, epoch_train_loss=1.8235784899882286
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 2.0062268282926894
1999, epoch_train_loss=2.0062268282926894
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 2.071838138858833
2000, epoch_train_loss=2.071838138858833
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 2.0053916944542785
2001, epoch_train_loss=2.0053916944542785
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 2.0947917295124547
2002, epoch_train_loss=2.0947917295124547
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 2.1776739733738957
2003, epoch_train_loss=2.1776739733738957
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 2.045433982108898
2004, epoch_train_loss=2.045433982108898
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 1.8498587449570618
2005, epoch_train_loss=1.8498587449570618
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 2.029339040658247
2006, epoch_train_loss=2.029339040658247
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 2.0689495234890956
2007, epoch_train_loss=2.0689495234890956
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 1.8827918747550831
2008, epoch_train_loss=1.8827918747550831
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 1.9044472483868484
2009, epoch_train_loss=1.9044472483868484
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 1.9930570394084106
2010, epoch_train_loss=1.9930570394084106
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 1.870173096756329
2011, epoch_train_loss=1.870173096756329
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 1.8425012286230145
2012, epoch_train_loss=1.8425012286230145
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 1.908682735415086
2013, epoch_train_loss=1.908682735415086
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 1.8824442776752734
2014, epoch_train_loss=1.8824442776752734
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 1.84412369590332
2015, epoch_train_loss=1.84412369590332
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 1.8608337467839864
2016, epoch_train_loss=1.8608337467839864
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 1.8689637336569063
2017, epoch_train_loss=1.8689637336569063
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 1.8170228100368733
2018, epoch_train_loss=1.8170228100368733
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 1.8088423240523104
2019, epoch_train_loss=1.8088423240523104
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 1.830451042529826
2020, epoch_train_loss=1.830451042529826
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 1.7993983497767998
2021, epoch_train_loss=1.7993983497767998
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 1.7702526620721017
2022, epoch_train_loss=1.7702526620721017
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 1.789647043611657
2023, epoch_train_loss=1.789647043611657
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 1.7932021257030248
2024, epoch_train_loss=1.7932021257030248
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 1.7675447073560782
2025, epoch_train_loss=1.7675447073560782
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 1.7704910346689096
2026, epoch_train_loss=1.7704910346689096
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 1.7850866710691848
2027, epoch_train_loss=1.7850866710691848
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 1.7689866398005483
2028, epoch_train_loss=1.7689866398005483
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 1.7549168927208696
2029, epoch_train_loss=1.7549168927208696
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 1.765570834992101
2030, epoch_train_loss=1.765570834992101
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 1.7648947200954517
2031, epoch_train_loss=1.7648947200954517
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 1.7506392632624572
2032, epoch_train_loss=1.7506392632624572
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 1.7520199086477226
2033, epoch_train_loss=1.7520199086477226
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 1.7574577490368142
2034, epoch_train_loss=1.7574577490368142
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 1.749782976118346
2035, epoch_train_loss=1.749782976118346
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 1.7487015410580655
2036, epoch_train_loss=1.7487015410580655
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 1.7646178195963136
2037, epoch_train_loss=1.7646178195963136
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 1.7855451399502895
2038, epoch_train_loss=1.7855451399502895
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 1.7876736402591595
2039, epoch_train_loss=1.7876736402591595
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 1.8241626835855413
2040, epoch_train_loss=1.8241626835855413
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 1.8381695678565497
2041, epoch_train_loss=1.8381695678565497
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 1.9101882732700455
2042, epoch_train_loss=1.9101882732700455
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 1.8045483178471098
2043, epoch_train_loss=1.8045483178471098
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 1.7494350633260776
2044, epoch_train_loss=1.7494350633260776
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 1.7393468970076704
2045, epoch_train_loss=1.7393468970076704
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 1.7989110512250996
2046, epoch_train_loss=1.7989110512250996
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 1.9888096427086022
2047, epoch_train_loss=1.9888096427086022
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 1.9173944207507838
2048, epoch_train_loss=1.9173944207507838
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 1.9022876803792914
2049, epoch_train_loss=1.9022876803792914
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 1.759259093601196
2050, epoch_train_loss=1.759259093601196
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 1.8481026190962841
2051, epoch_train_loss=1.8481026190962841
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 2.0601154778409363
2052, epoch_train_loss=2.0601154778409363
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 1.749996424470083
2053, epoch_train_loss=1.749996424470083
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 1.8217752241123384
2054, epoch_train_loss=1.8217752241123384
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 2.071174301585573
2055, epoch_train_loss=2.071174301585573
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 1.7831873545174795
2056, epoch_train_loss=1.7831873545174795
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 2.2796154536089808
2057, epoch_train_loss=2.2796154536089808
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 2.137003258962436
2058, epoch_train_loss=2.137003258962436
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 2.080555272730731
2059, epoch_train_loss=2.080555272730731
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 1.977917599368673
2060, epoch_train_loss=1.977917599368673
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 1.9013505846472591
2061, epoch_train_loss=1.9013505846472591
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 2.0301062851928524
2062, epoch_train_loss=2.0301062851928524
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 2.0063048606474907
2063, epoch_train_loss=2.0063048606474907
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 1.8961256818168646
2064, epoch_train_loss=1.8961256818168646
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 1.8222988967558855
2065, epoch_train_loss=1.8222988967558855
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 1.8648385939306373
2066, epoch_train_loss=1.8648385939306373
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 1.82404608363546
2067, epoch_train_loss=1.82404608363546
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 1.835656102995928
2068, epoch_train_loss=1.835656102995928
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 1.776493687072282
2069, epoch_train_loss=1.776493687072282
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 1.7755640450321937
2070, epoch_train_loss=1.7755640450321937
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 1.8128950558474133
2071, epoch_train_loss=1.8128950558474133
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 1.799076383119384
2072, epoch_train_loss=1.799076383119384
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 1.7458755846115181
2073, epoch_train_loss=1.7458755846115181
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 1.816598382240391
2074, epoch_train_loss=1.816598382240391
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 1.9528277404409253
2075, epoch_train_loss=1.9528277404409253
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 1.7757287633405554
2076, epoch_train_loss=1.7757287633405554
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 1.7359682082894035
2077, epoch_train_loss=1.7359682082894035
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 1.7896824070951987
2078, epoch_train_loss=1.7896824070951987
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 1.7497636409120865
2079, epoch_train_loss=1.7497636409120865
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 1.7176668610608272
2080, epoch_train_loss=1.7176668610608272
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 1.7302577782304438
2081, epoch_train_loss=1.7302577782304438
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 1.768814893453412
2082, epoch_train_loss=1.768814893453412
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 1.8743721628802048
2083, epoch_train_loss=1.8743721628802048
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 1.8536018204836073
2084, epoch_train_loss=1.8536018204836073
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 1.8082533315037876
2085, epoch_train_loss=1.8082533315037876
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 1.7084383276577326
2086, epoch_train_loss=1.7084383276577326
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 1.785527887841483
2087, epoch_train_loss=1.785527887841483
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 2.018744680793751
2088, epoch_train_loss=2.018744680793751
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 1.9327885546051529
2089, epoch_train_loss=1.9327885546051529
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 1.814414451366231
2090, epoch_train_loss=1.814414451366231
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 1.8103732564577968
2091, epoch_train_loss=1.8103732564577968
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 1.9159995747875007
2092, epoch_train_loss=1.9159995747875007
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 1.9702362637667212
2093, epoch_train_loss=1.9702362637667212
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 1.7045405989198368
2094, epoch_train_loss=1.7045405989198368
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 1.9171787567474234
2095, epoch_train_loss=1.9171787567474234
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 2.2509571445817893
2096, epoch_train_loss=2.2509571445817893
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 2.5226496995785834
2097, epoch_train_loss=2.5226496995785834
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 2.000851387932833
2098, epoch_train_loss=2.000851387932833
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 2.171518575942267
2099, epoch_train_loss=2.171518575942267
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 2.1925663151813883
2100, epoch_train_loss=2.1925663151813883
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 2.3036134077577235
2101, epoch_train_loss=2.3036134077577235
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 1.8953185883465185
2102, epoch_train_loss=1.8953185883465185
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 2.006162660469885
2103, epoch_train_loss=2.006162660469885
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 1.9184240346729324
2104, epoch_train_loss=1.9184240346729324
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 1.7454924789842758
2105, epoch_train_loss=1.7454924789842758
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 1.9148573716828008
2106, epoch_train_loss=1.9148573716828008
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 2.2381333231742775
2107, epoch_train_loss=2.2381333231742775
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 3.0677104373292408
2108, epoch_train_loss=3.0677104373292408
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 3.766116491500019
2109, epoch_train_loss=3.766116491500019
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 3.3109444328751465
2110, epoch_train_loss=3.3109444328751465
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 2.6696686656824675
2111, epoch_train_loss=2.6696686656824675
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 3.183344108957676
2112, epoch_train_loss=3.183344108957676
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 3.5939570373158167
2113, epoch_train_loss=3.5939570373158167
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 3.1469790543271605
2114, epoch_train_loss=3.1469790543271605
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 2.476752262056997
2115, epoch_train_loss=2.476752262056997
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 2.5501022064667866
2116, epoch_train_loss=2.5501022064667866
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 2.7303053271779225
2117, epoch_train_loss=2.7303053271779225
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 2.8578308401487362
2118, epoch_train_loss=2.8578308401487362
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 2.883142759229238
2119, epoch_train_loss=2.883142759229238
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 2.8717868093662102
2120, epoch_train_loss=2.8717868093662102
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 2.818619628562163
2121, epoch_train_loss=2.818619628562163
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 2.7348580623867886
2122, epoch_train_loss=2.7348580623867886
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 2.671946047503314
2123, epoch_train_loss=2.671946047503314
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 2.591917662980845
2124, epoch_train_loss=2.591917662980845
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 2.499265182815002
2125, epoch_train_loss=2.499265182815002
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 2.483671817695659
2126, epoch_train_loss=2.483671817695659
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 2.5585620629025683
2127, epoch_train_loss=2.5585620629025683
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 2.6366888428138555
2128, epoch_train_loss=2.6366888428138555
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 2.61067109996246
2129, epoch_train_loss=2.61067109996246
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 2.447556060717605
2130, epoch_train_loss=2.447556060717605
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 2.444572918598133
2131, epoch_train_loss=2.444572918598133
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 2.594247847219706
2132, epoch_train_loss=2.594247847219706
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 2.4875017541806774
2133, epoch_train_loss=2.4875017541806774
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 2.8430101302247692
2134, epoch_train_loss=2.8430101302247692
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 2.691804524062139
2135, epoch_train_loss=2.691804524062139
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 2.5858117244357723
2136, epoch_train_loss=2.5858117244357723
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 2.561357608220018
2137, epoch_train_loss=2.561357608220018
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 2.5289805066220463
2138, epoch_train_loss=2.5289805066220463
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 2.5143185200803924
2139, epoch_train_loss=2.5143185200803924
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 2.510690934152991
2140, epoch_train_loss=2.510690934152991
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 2.5053921824694965
2141, epoch_train_loss=2.5053921824694965
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 2.5134316502237115
2142, epoch_train_loss=2.5134316502237115
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 2.5120774096523832
2143, epoch_train_loss=2.5120774096523832
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 2.5097067160842585
2144, epoch_train_loss=2.5097067160842585
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 2.510958021254543
2145, epoch_train_loss=2.510958021254543
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 2.508933896683239
2146, epoch_train_loss=2.508933896683239
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 2.506276210250341
2147, epoch_train_loss=2.506276210250341
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 2.4962167297143787
2148, epoch_train_loss=2.4962167297143787
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 2.490965226597976
2149, epoch_train_loss=2.490965226597976
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 2.4911326009824393
2150, epoch_train_loss=2.4911326009824393
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 2.494131854114153
2151, epoch_train_loss=2.494131854114153
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 2.4951700779120403
2152, epoch_train_loss=2.4951700779120403
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 2.4951312884556054
2153, epoch_train_loss=2.4951312884556054
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 2.491389121424704
2154, epoch_train_loss=2.491389121424704
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 2.4880883305705206
2155, epoch_train_loss=2.4880883305705206
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 2.4803804690439217
2156, epoch_train_loss=2.4803804690439217
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 2.474741045741555
2157, epoch_train_loss=2.474741045741555
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 2.468269412917471
2158, epoch_train_loss=2.468269412917471
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 2.4646298829744016
2159, epoch_train_loss=2.4646298829744016
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 2.463075161941195
2160, epoch_train_loss=2.463075161941195
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 2.4598636798195694
2161, epoch_train_loss=2.4598636798195694
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 2.4579223397874097
2162, epoch_train_loss=2.4579223397874097
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 2.4518757990997804
2163, epoch_train_loss=2.4518757990997804
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 2.4457255288088033
2164, epoch_train_loss=2.4457255288088033
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 2.439391591361679
2165, epoch_train_loss=2.439391591361679
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 2.432755432261973
2166, epoch_train_loss=2.432755432261973
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 2.428019892120911
2167, epoch_train_loss=2.428019892120911
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 2.4216406550405902
2168, epoch_train_loss=2.4216406550405902
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 2.41485642823503
2169, epoch_train_loss=2.41485642823503
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 2.406283765281732
2170, epoch_train_loss=2.406283765281732
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 2.396299574052714
2171, epoch_train_loss=2.396299574052714
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 2.387461343706955
2172, epoch_train_loss=2.387461343706955
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 2.378828230687515
2173, epoch_train_loss=2.378828230687515
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 2.3708132790617573
2174, epoch_train_loss=2.3708132790617573
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 2.363332909070949
2175, epoch_train_loss=2.363332909070949
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 2.355973704580885
2176, epoch_train_loss=2.355973704580885
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 2.349136779207935
2177, epoch_train_loss=2.349136779207935
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 2.3434470011006874
2178, epoch_train_loss=2.3434470011006874
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 2.3391690192282386
2179, epoch_train_loss=2.3391690192282386
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 2.335406555461769
2180, epoch_train_loss=2.335406555461769
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 2.330759570131096
2181, epoch_train_loss=2.330759570131096
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 2.3248997706014083
2182, epoch_train_loss=2.3248997706014083
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 2.319360928621818
2183, epoch_train_loss=2.319360928621818
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 2.3142455676593108
2184, epoch_train_loss=2.3142455676593108
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 2.3090600385503945
2185, epoch_train_loss=2.3090600385503945
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 2.3036888257250316
2186, epoch_train_loss=2.3036888257250316
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 2.298149218443111
2187, epoch_train_loss=2.298149218443111
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 2.293046387046199
2188, epoch_train_loss=2.293046387046199
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 2.2892220492825612
2189, epoch_train_loss=2.2892220492825612
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 2.286749552712228
2190, epoch_train_loss=2.286749552712228
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 2.2858816061067597
2191, epoch_train_loss=2.2858816061067597
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 2.29093229821917
2192, epoch_train_loss=2.29093229821917
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 2.3030575423845696
2193, epoch_train_loss=2.3030575423845696
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 2.3288675336204077
2194, epoch_train_loss=2.3288675336204077
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 2.3050085511016998
2195, epoch_train_loss=2.3050085511016998
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 2.265386803417236
2196, epoch_train_loss=2.265386803417236
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 2.255177137044834
2197, epoch_train_loss=2.255177137044834
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 2.276983214911073
2198, epoch_train_loss=2.276983214911073
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 2.2786370446458952
2199, epoch_train_loss=2.2786370446458952
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 2.2419003362985817
2200, epoch_train_loss=2.2419003362985817
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 2.237203822962105
2201, epoch_train_loss=2.237203822962105
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 2.258329057614918
2202, epoch_train_loss=2.258329057614918
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 2.249597011710594
2203, epoch_train_loss=2.249597011710594
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 2.22514747391657
2204, epoch_train_loss=2.22514747391657
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 2.216888288871652
2205, epoch_train_loss=2.216888288871652
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 2.2286803868123837
2206, epoch_train_loss=2.2286803868123837
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 2.2328159599324446
2207, epoch_train_loss=2.2328159599324446
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 2.2120269925094176
2208, epoch_train_loss=2.2120269925094176
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 2.199366074675937
2209, epoch_train_loss=2.199366074675937
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 2.205507751935354
2210, epoch_train_loss=2.205507751935354
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 2.2087925207480428
2211, epoch_train_loss=2.2087925207480428
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 2.2002367553910105
2212, epoch_train_loss=2.2002367553910105
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 2.186420520466296
2213, epoch_train_loss=2.186420520466296
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 2.183917535182622
2214, epoch_train_loss=2.183917535182622
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 2.189189674685623
2215, epoch_train_loss=2.189189674685623
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 2.188774061271482
2216, epoch_train_loss=2.188774061271482
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 2.1822524366654985
2217, epoch_train_loss=2.1822524366654985
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 2.171521436167304
2218, epoch_train_loss=2.171521436167304
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 2.1657176290687015
2219, epoch_train_loss=2.1657176290687015
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 2.165914924359721
2220, epoch_train_loss=2.165914924359721
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 2.168424132153366
2221, epoch_train_loss=2.168424132153366
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 2.171704648267875
2222, epoch_train_loss=2.171704648267875
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 2.170076283992172
2223, epoch_train_loss=2.170076283992172
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 2.167527475475015
2224, epoch_train_loss=2.167527475475015
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 2.1587021738386296
2225, epoch_train_loss=2.1587021738386296
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 2.150819418793578
2226, epoch_train_loss=2.150819418793578
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 2.143692333679821
2227, epoch_train_loss=2.143692333679821
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 2.139106521926074
2228, epoch_train_loss=2.139106521926074
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 2.1367921462099635
2229, epoch_train_loss=2.1367921462099635
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 2.1362028199548435
2230, epoch_train_loss=2.1362028199548435
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 2.137675239353356
2231, epoch_train_loss=2.137675239353356
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 2.1414402712903953
2232, epoch_train_loss=2.1414402712903953
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 2.153005784176071
2233, epoch_train_loss=2.153005784176071
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 2.163641330623399
2234, epoch_train_loss=2.163641330623399
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 2.1794478267616855
2235, epoch_train_loss=2.1794478267616855
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 2.153053033603005
2236, epoch_train_loss=2.153053033603005
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 2.1232450771617426
2237, epoch_train_loss=2.1232450771617426
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 2.117734084460379
2238, epoch_train_loss=2.117734084460379
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 2.135823792271087
2239, epoch_train_loss=2.135823792271087
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 2.1544850338811057
2240, epoch_train_loss=2.1544850338811057
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 2.1329570701839025
2241, epoch_train_loss=2.1329570701839025
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 2.1068711545720102
2242, epoch_train_loss=2.1068711545720102
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 2.108152518224727
2243, epoch_train_loss=2.108152518224727
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 2.126880715235047
2244, epoch_train_loss=2.126880715235047
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 2.138108255245011
2245, epoch_train_loss=2.138108255245011
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 2.1127478684503243
2246, epoch_train_loss=2.1127478684503243
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 2.096021308419204
2247, epoch_train_loss=2.096021308419204
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 2.115036242072987
2248, epoch_train_loss=2.115036242072987
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 2.1195933224894374
2249, epoch_train_loss=2.1195933224894374
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 2.1045739915893007
2250, epoch_train_loss=2.1045739915893007
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 2.0904482597821987
2251, epoch_train_loss=2.0904482597821987
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 2.0934989111161126
2252, epoch_train_loss=2.0934989111161126
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 2.1048733491362195
2253, epoch_train_loss=2.1048733491362195
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 2.0924875402384355
2254, epoch_train_loss=2.0924875402384355
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 2.0773066539203158
2255, epoch_train_loss=2.0773066539203158
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 2.0807754431582617
2256, epoch_train_loss=2.0807754431582617
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 2.079010182224265
2257, epoch_train_loss=2.079010182224265
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 2.0746722964258155
2258, epoch_train_loss=2.0746722964258155
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 2.070007938214354
2259, epoch_train_loss=2.070007938214354
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 2.067070858528697
2260, epoch_train_loss=2.067070858528697
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 2.069613556250225
2261, epoch_train_loss=2.069613556250225
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 2.063298541860733
2262, epoch_train_loss=2.063298541860733
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 2.0598893276830834
2263, epoch_train_loss=2.0598893276830834
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 2.060443706458808
2264, epoch_train_loss=2.060443706458808
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 2.058213999662004
2265, epoch_train_loss=2.058213999662004
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 2.056851116462096
2266, epoch_train_loss=2.056851116462096
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 2.0513853478480617
2267, epoch_train_loss=2.0513853478480617
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 2.0502926362263842
2268, epoch_train_loss=2.0502926362263842
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 2.0510967506670523
2269, epoch_train_loss=2.0510967506670523
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 2.0486837075365107
2270, epoch_train_loss=2.0486837075365107
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 2.046181401685982
2271, epoch_train_loss=2.046181401685982
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 2.0409341559745826
2272, epoch_train_loss=2.0409341559745826
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 2.040011639543878
2273, epoch_train_loss=2.040011639543878
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 2.0401964102907093
2274, epoch_train_loss=2.0401964102907093
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 2.039481143206917
2275, epoch_train_loss=2.039481143206917
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 2.037168659109727
2276, epoch_train_loss=2.037168659109727
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 2.031822025325722
2277, epoch_train_loss=2.031822025325722
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 2.0294068939281624
2278, epoch_train_loss=2.0294068939281624
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 2.0280775222735086
2279, epoch_train_loss=2.0280775222735086
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 2.028329326373564
2280, epoch_train_loss=2.028329326373564
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 2.027571004757937
2281, epoch_train_loss=2.027571004757937
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 2.0247181098030467
2282, epoch_train_loss=2.0247181098030467
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 2.0217923079553075
2283, epoch_train_loss=2.0217923079553075
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 2.0184130947737486
2284, epoch_train_loss=2.0184130947737486
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 2.015853588736549
2285, epoch_train_loss=2.015853588736549
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 2.0137028624772526
2286, epoch_train_loss=2.0137028624772526
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 2.0125348931493305
2287, epoch_train_loss=2.0125348931493305
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 2.01155365631176
2288, epoch_train_loss=2.01155365631176
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 2.010874206984714
2289, epoch_train_loss=2.010874206984714
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 2.0100477770975713
2290, epoch_train_loss=2.0100477770975713
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 2.0088371688146704
2291, epoch_train_loss=2.0088371688146704
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 2.0081441627859076
2292, epoch_train_loss=2.0081441627859076
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 2.007001044006045
2293, epoch_train_loss=2.007001044006045
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 2.0061981706497214
2294, epoch_train_loss=2.0061981706497214
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 2.004505361689881
2295, epoch_train_loss=2.004505361689881
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 2.0041698299869046
2296, epoch_train_loss=2.0041698299869046
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 2.003135220873576
2297, epoch_train_loss=2.003135220873576
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 2.003662410281058
2298, epoch_train_loss=2.003662410281058
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 2.0024531969419246
2299, epoch_train_loss=2.0024531969419246
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 2.003408293921507
2300, epoch_train_loss=2.003408293921507
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 2.0011487049808117
2301, epoch_train_loss=2.0011487049808117
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 2.0000090834381807
2302, epoch_train_loss=2.0000090834381807
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 1.9946799126606238
2303, epoch_train_loss=1.9946799126606238
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 1.9904746471275974
2304, epoch_train_loss=1.9904746471275974
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 1.9847493991131773
2305, epoch_train_loss=1.9847493991131773
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 1.9803965241302859
2306, epoch_train_loss=1.9803965241302859
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 1.9768453132644241
2307, epoch_train_loss=1.9768453132644241
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 1.9743912642271397
2308, epoch_train_loss=1.9743912642271397
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 1.9727402688480828
2309, epoch_train_loss=1.9727402688480828
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 1.9716929066349107
2310, epoch_train_loss=1.9716929066349107
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 1.9712759981825392
2311, epoch_train_loss=1.9712759981825392
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 1.9714006102836306
2312, epoch_train_loss=1.9714006102836306
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 1.973282314030433
2313, epoch_train_loss=1.973282314030433
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 1.9758562273030604
2314, epoch_train_loss=1.9758562273030604
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 1.984109214455388
2315, epoch_train_loss=1.984109214455388
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 1.9898967236176832
2316, epoch_train_loss=1.9898967236176832
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 2.0045844591796906
2317, epoch_train_loss=2.0045844591796906
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 1.9972089899962482
2318, epoch_train_loss=1.9972089899962482
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 1.9870152083349806
2319, epoch_train_loss=1.9870152083349806
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 1.9639766000936596
2320, epoch_train_loss=1.9639766000936596
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 1.952867576001298
2321, epoch_train_loss=1.952867576001298
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 1.9550705399700943
2322, epoch_train_loss=1.9550705399700943
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 1.9647901413127193
2323, epoch_train_loss=1.9647901413127193
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 1.9801872624532317
2324, epoch_train_loss=1.9801872624532317
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 1.9690260310930086
2325, epoch_train_loss=1.9690260310930086
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 1.9544816970988401
2326, epoch_train_loss=1.9544816970988401
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 1.9441526201311963
2327, epoch_train_loss=1.9441526201311963
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 1.9452205700416383
2328, epoch_train_loss=1.9452205700416383
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 1.948338344499075
2329, epoch_train_loss=1.948338344499075
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 1.9520790228936566
2330, epoch_train_loss=1.9520790228936566
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 1.9590709435208313
2331, epoch_train_loss=1.9590709435208313
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 1.9464110668521644
2332, epoch_train_loss=1.9464110668521644
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 1.939534742656601
2333, epoch_train_loss=1.939534742656601
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 1.9340587976313772
2334, epoch_train_loss=1.9340587976313772
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 1.9466796357053966
2335, epoch_train_loss=1.9466796357053966
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 1.9467708522167773
2336, epoch_train_loss=1.9467708522167773
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 1.9469932756062056
2337, epoch_train_loss=1.9469932756062056
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 1.9656953948552673
2338, epoch_train_loss=1.9656953948552673
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 1.9283255869213307
2339, epoch_train_loss=1.9283255869213307
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 1.9655319839836793
2340, epoch_train_loss=1.9655319839836793
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 2.0341251102106574
2341, epoch_train_loss=2.0341251102106574
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 2.0627528165922127
2342, epoch_train_loss=2.0627528165922127
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 2.326899601642896
2343, epoch_train_loss=2.326899601642896
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 2.776789849226003
2344, epoch_train_loss=2.776789849226003
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 4.552988391790029
2345, epoch_train_loss=4.552988391790029
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 3.595183056580457
2346, epoch_train_loss=3.595183056580457
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 3.0656541817522887
2347, epoch_train_loss=3.0656541817522887
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 2.62028365796525
2348, epoch_train_loss=2.62028365796525
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 2.3481015118163646
2349, epoch_train_loss=2.3481015118163646
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 2.468138289235842
2350, epoch_train_loss=2.468138289235842
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 2.2555880262677905
2351, epoch_train_loss=2.2555880262677905
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 2.1436124640703746
2352, epoch_train_loss=2.1436124640703746
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 2.3852632692735667
2353, epoch_train_loss=2.3852632692735667
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 2.1819887858248284
2354, epoch_train_loss=2.1819887858248284
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 2.659655067882834
2355, epoch_train_loss=2.659655067882834
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 2.838175867709452
2356, epoch_train_loss=2.838175867709452
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 2.929927808849037
2357, epoch_train_loss=2.929927808849037
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 2.8956134781939906
2358, epoch_train_loss=2.8956134781939906
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 3.009155809193612
2359, epoch_train_loss=3.009155809193612
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 2.8211699756898003
2360, epoch_train_loss=2.8211699756898003
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 2.805219308598133
2361, epoch_train_loss=2.805219308598133
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 2.63964959894479
2362, epoch_train_loss=2.63964959894479
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 2.3696817147798472
2363, epoch_train_loss=2.3696817147798472
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 2.3803687172572534
2364, epoch_train_loss=2.3803687172572534
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 2.3693319103189086
2365, epoch_train_loss=2.3693319103189086
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 2.275484017431695
2366, epoch_train_loss=2.275484017431695
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 2.356460523974042
2367, epoch_train_loss=2.356460523974042
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 2.4014533390192527
2368, epoch_train_loss=2.4014533390192527
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 2.3033169405482985
2369, epoch_train_loss=2.3033169405482985
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 2.2927429545611453
2370, epoch_train_loss=2.2927429545611453
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 2.279423165131345
2371, epoch_train_loss=2.279423165131345
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 2.2800609857558336
2372, epoch_train_loss=2.2800609857558336
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 2.300763411690112
2373, epoch_train_loss=2.300763411690112
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 2.2604971369398643
2374, epoch_train_loss=2.2604971369398643
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 2.274590975589888
2375, epoch_train_loss=2.274590975589888
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 2.2145888721597955
2376, epoch_train_loss=2.2145888721597955
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 2.206609336861222
2377, epoch_train_loss=2.206609336861222
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 2.179940272890741
2378, epoch_train_loss=2.179940272890741
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 2.1615264958698286
2379, epoch_train_loss=2.1615264958698286
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 2.170724078561001
2380, epoch_train_loss=2.170724078561001
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 2.170337968178275
2381, epoch_train_loss=2.170337968178275
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 2.1661938183754006
2382, epoch_train_loss=2.1661938183754006
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 2.1654672731760534
2383, epoch_train_loss=2.1654672731760534
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 2.157779005095053
2384, epoch_train_loss=2.157779005095053
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 2.150619067580521
2385, epoch_train_loss=2.150619067580521
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 2.151785024605075
2386, epoch_train_loss=2.151785024605075
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 2.149852915565092
2387, epoch_train_loss=2.149852915565092
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 2.140214816009748
2388, epoch_train_loss=2.140214816009748
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 2.1314697839757253
2389, epoch_train_loss=2.1314697839757253
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 2.1248429470954022
2390, epoch_train_loss=2.1248429470954022
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 2.1187657235626665
2391, epoch_train_loss=2.1187657235626665
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 2.1161204327848564
2392, epoch_train_loss=2.1161204327848564
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 2.1168745023254045
2393, epoch_train_loss=2.1168745023254045
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 2.113617181019764
2394, epoch_train_loss=2.113617181019764
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 2.105979432393026
2395, epoch_train_loss=2.105979432393026
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 2.09840860261174
2396, epoch_train_loss=2.09840860261174
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 2.090263299816097
2397, epoch_train_loss=2.090263299816097
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 2.0830748283551483
2398, epoch_train_loss=2.0830748283551483
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 2.080655278788903
2399, epoch_train_loss=2.080655278788903
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 2.0805430243880414
2400, epoch_train_loss=2.0805430243880414
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 2.0769362783152303
2401, epoch_train_loss=2.0769362783152303
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 2.0716030659188656
2402, epoch_train_loss=2.0716030659188656
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 2.0671387704598105
2403, epoch_train_loss=2.0671387704598105
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 2.0633181445978424
2404, epoch_train_loss=2.0633181445978424
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 2.0615215293606837
2405, epoch_train_loss=2.0615215293606837
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 2.060879335055574
2406, epoch_train_loss=2.060879335055574
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 2.0577069102669068
2407, epoch_train_loss=2.0577069102669068
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 2.0530808425511635
2408, epoch_train_loss=2.0530808425511635
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 2.0483843164739617
2409, epoch_train_loss=2.0483843164739617
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 2.043072098280318
2410, epoch_train_loss=2.043072098280318
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 2.038751837546713
2411, epoch_train_loss=2.038751837546713
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 2.0359450923504987
2412, epoch_train_loss=2.0359450923504987
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 2.0321056348817805
2413, epoch_train_loss=2.0321056348817805
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 2.0272879984113072
2414, epoch_train_loss=2.0272879984113072
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 2.0228451520546766
2415, epoch_train_loss=2.0228451520546766
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 2.0185867608464543
2416, epoch_train_loss=2.0185867608464543
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 2.01517719599861
2417, epoch_train_loss=2.01517719599861
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 2.0120301311869224
2418, epoch_train_loss=2.0120301311869224
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 2.007808191444354
2419, epoch_train_loss=2.007808191444354
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 2.0035204213171927
2420, epoch_train_loss=2.0035204213171927
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 1.9989911472613267
2421, epoch_train_loss=1.9989911472613267
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 1.9941722651809946
2422, epoch_train_loss=1.9941722651809946
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 1.9897817284879948
2423, epoch_train_loss=1.9897817284879948
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 1.9852339451281507
2424, epoch_train_loss=1.9852339451281507
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 1.9808349861218686
2425, epoch_train_loss=1.9808349861218686
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 1.9764664166849208
2426, epoch_train_loss=1.9764664166849208
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 1.9715754938965602
2427, epoch_train_loss=1.9715754938965602
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 1.9668566974904123
2428, epoch_train_loss=1.9668566974904123
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 1.9621419277011578
2429, epoch_train_loss=1.9621419277011578
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 1.9576849590909757
2430, epoch_train_loss=1.9576849590909757
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 1.953391146506828
2431, epoch_train_loss=1.953391146506828
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 1.9489260733478377
2432, epoch_train_loss=1.9489260733478377
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 1.9446569015784554
2433, epoch_train_loss=1.9446569015784554
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 1.940350669514863
2434, epoch_train_loss=1.940350669514863
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 1.9362894859733428
2435, epoch_train_loss=1.9362894859733428
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 1.9323297005237756
2436, epoch_train_loss=1.9323297005237756
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 1.928566142844118
2437, epoch_train_loss=1.928566142844118
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 1.9249906463971116
2438, epoch_train_loss=1.9249906463971116
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 1.9214488489014647
2439, epoch_train_loss=1.9214488489014647
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 1.9180844834921296
2440, epoch_train_loss=1.9180844834921296
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 1.914828403948324
2441, epoch_train_loss=1.914828403948324
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 1.9118411971283578
2442, epoch_train_loss=1.9118411971283578
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 1.9088916288539846
2443, epoch_train_loss=1.9088916288539846
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 1.9060617721193678
2444, epoch_train_loss=1.9060617721193678
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 1.9032365423660382
2445, epoch_train_loss=1.9032365423660382
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 1.9004725466563892
2446, epoch_train_loss=1.9004725466563892
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 1.897707440043188
2447, epoch_train_loss=1.897707440043188
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 1.895045480992742
2448, epoch_train_loss=1.895045480992742
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 1.8924358609417555
2449, epoch_train_loss=1.8924358609417555
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 1.889869768092693
2450, epoch_train_loss=1.889869768092693
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 1.8873185270806057
2451, epoch_train_loss=1.8873185270806057
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 1.8848233801596577
2452, epoch_train_loss=1.8848233801596577
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 1.8823481835070055
2453, epoch_train_loss=1.8823481835070055
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 1.8799538658806891
2454, epoch_train_loss=1.8799538658806891
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 1.8776233525564958
2455, epoch_train_loss=1.8776233525564958
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 1.8753638066071667
2456, epoch_train_loss=1.8753638066071667
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 1.8731379852707797
2457, epoch_train_loss=1.8731379852707797
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 1.8709892228842122
2458, epoch_train_loss=1.8709892228842122
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 1.8688772338302417
2459, epoch_train_loss=1.8688772338302417
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 1.8668398936360846
2460, epoch_train_loss=1.8668398936360846
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 1.864863804809375
2461, epoch_train_loss=1.864863804809375
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 1.8629451913420962
2462, epoch_train_loss=1.8629451913420962
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 1.8610692352652307
2463, epoch_train_loss=1.8610692352652307
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 1.8592344899462587
2464, epoch_train_loss=1.8592344899462587
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 1.8574377187835174
2465, epoch_train_loss=1.8574377187835174
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 1.8556699004784571
2466, epoch_train_loss=1.8556699004784571
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 1.853945398111628
2467, epoch_train_loss=1.853945398111628
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 1.852239189268741
2468, epoch_train_loss=1.852239189268741
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 1.850557403288082
2469, epoch_train_loss=1.850557403288082
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 1.8488963197529331
2470, epoch_train_loss=1.8488963197529331
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 1.847244823781543
2471, epoch_train_loss=1.847244823781543
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 1.845616397919031
2472, epoch_train_loss=1.845616397919031
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 1.844001570247251
2473, epoch_train_loss=1.844001570247251
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 1.84239989617397
2474, epoch_train_loss=1.84239989617397
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 1.8408153902123536
2475, epoch_train_loss=1.8408153902123536
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 1.839238503952728
2476, epoch_train_loss=1.839238503952728
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 1.8376748832194971
2477, epoch_train_loss=1.8376748832194971
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 1.8361266372796814
2478, epoch_train_loss=1.8361266372796814
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 1.834588990143143
2479, epoch_train_loss=1.834588990143143
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 1.833067174054438
2480, epoch_train_loss=1.833067174054438
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 1.8315582509961248
2481, epoch_train_loss=1.8315582509961248
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 1.8300579259550906
2482, epoch_train_loss=1.8300579259550906
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 1.8285693465691182
2483, epoch_train_loss=1.8285693465691182
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 1.8270907428955385
2484, epoch_train_loss=1.8270907428955385
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 1.8256212016015227
2485, epoch_train_loss=1.8256212016015227
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 1.8241609983286535
2486, epoch_train_loss=1.8241609983286535
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 1.8227091571257321
2487, epoch_train_loss=1.8227091571257321
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 1.821264640309372
2488, epoch_train_loss=1.821264640309372
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 1.8198252601405414
2489, epoch_train_loss=1.8198252601405414
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 1.8183922950258091
2490, epoch_train_loss=1.8183922950258091
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 1.8169657279682134
2491, epoch_train_loss=1.8169657279682134
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 1.8155437754633177
2492, epoch_train_loss=1.8155437754633177
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 1.8141262882942772
2493, epoch_train_loss=1.8141262882942772
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 1.812712528294153
2494, epoch_train_loss=1.812712528294153
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 1.811303132091139
2495, epoch_train_loss=1.811303132091139
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 1.809897705603057
2496, epoch_train_loss=1.809897705603057
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 1.808495554793435
2497, epoch_train_loss=1.808495554793435
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 1.8070966206322616
2498, epoch_train_loss=1.8070966206322616
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 1.8057002003836007
2499, epoch_train_loss=1.8057002003836007
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002f520> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002f520> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeb002f520> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002e710> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002cb50> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002eef0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002fe50> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002e6b0> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002e7a0> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002ece0> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeb002dd80> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002e2f0> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb002c8b0> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb002da80> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002d450> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002cdc0> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002fdf0> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb002ddb0> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002cc40> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002d810> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002c310> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002e800> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb002f880> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeb002e0e0> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeb002d960> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeb002ef20> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeb002df30> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002e710> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002e710> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-3.47389956e-03 -8.82676818e-04 -2.08411238e-03 ... -1.11301603e+01
 -1.11301603e+01 -1.11301603e+01] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046674  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002cb50> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002cb50> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.07670570e-03 -5.92340671e-04 -6.66573372e-05 ... -5.03679786e+00
 -5.03679786e+00 -5.03679786e+00] = SCAN,
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 4)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002eef0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002eef0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.59173730e-03 -7.67300285e-04 -6.09330303e-05 ... -7.27736608e-01
 -7.27736608e-01 -7.27736608e-01] = SCAN,
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 4)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002fe50> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002fe50> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-6.71503005e-03 -1.44519923e-03 -1.44519923e-03 ... -1.46899070e-02
 -2.03947707e+00 -2.03947707e+00] = SCAN,
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 4)
mol:  [['O', array([0., 0., 0.])]]
SCF not converged.
SCF energy = -75.0033802934089 after 50 cycles  <S^2> = 2.002744  2S+1 = 3.0018288
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002e6b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002e6b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.71055561e-04 -1.41123831e-04 -6.97425026e-06 ... -5.78449347e+00
 -5.78449347e+00 -5.78449347e+00] = SCAN,
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 4)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121376  <S^2> = 0.7516194  2S+1 = 2.0016187
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002e7a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002e7a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.06046800e-03 -9.79646678e-04 -3.40075764e-04 ... -1.26648275e+01
 -1.26648275e+01 -1.26648275e+01] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 4)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560991313  <S^2> = 0.75226415  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002ece0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002ece0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-9.65126555e-03 -6.07434158e-03 -3.02991964e-03 ... -3.80436776e-05
 -1.63249621e-03 -1.18193555e-04] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 4)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786832695  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002dd80> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002dd80> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-9.90398567e-04 -9.35751335e-04 -9.79751388e-04 ... -1.18986567e+01
 -1.18986567e+01 -1.18986567e+01] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 0  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002e2f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002e2f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.04987770e-03 -6.68954111e-04 -8.57556562e-04 ... -1.07485605e-03
 -8.01425702e-01 -8.01425702e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 4)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.337792446513  <S^2> = 4.0073189e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002c8b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002c8b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.97917639e-04 -2.54437615e-05 -3.15202008e-05 ... -6.37386388e-01
 -6.37386388e-01 -6.37386388e-01] = SCAN,
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 4)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322843  <S^2> = 1.5987212e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002da80> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002da80> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.50217343e-04 -2.07520331e-04 -9.23619961e-04 ... -2.76182455e-06
 -4.27559894e+00 -4.27559894e+00] = SCAN,
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 4)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.00560888896  <S^2> = 4.938272e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002d450> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002d450> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-0.00155834 -0.00091688 -0.00215831 ... -0.00091688 -0.41618506
 -0.41618506] = SCAN,
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 4)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.1901591e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002cdc0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002cdc0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.92948752e-04 -1.95215890e-05 -1.16699780e-03 ... -4.89378326e-01
 -4.89378326e-01 -4.89378326e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 4)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894556081  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002fdf0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002fdf0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-6.54902370e-04 -1.16029846e-04 -5.96623414e-06 ... -6.59150586e-01
 -6.59150586e-01 -6.59150586e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 4)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346376  <S^2> = 1.4210855e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002ddb0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002ddb0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.83278186e-05 -8.83278186e-05 -9.75839793e-04 ... -3.46740731e-05
 -3.31729009e-05 -3.31729009e-05] = SCAN,
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 4)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5369932e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002cc40> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002cc40> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-5.37000596e-04 -8.55494373e-04 -2.46853248e-03 ... -7.34251993e-01
 -7.34251993e-01 -7.34251993e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 4)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374077  <S^2> = 7.6383344e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002d810> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002d810> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.38161478e-04 -1.81223966e-05 -2.37327566e-05 ... -2.83738108e+00
 -2.83738108e+00 -2.83738108e+00] = SCAN,
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 4)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.6605389e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002c310> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002c310> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-0.00113445 -0.00118624 -0.00118624 ... -0.48434639 -0.48434639
 -0.48434639] = SCAN,
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 4)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5862867e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002e800> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002e800> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-0.00297936 -0.00297936 -0.00407091 ... -0.00297936 -0.00297936
 -0.00407091] = SCAN,
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 4)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.31335e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002f880> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002f880> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.61401455e-04 -4.90485117e-04 -2.56451688e-03 ... -9.59296114e+00
 -9.59296114e+00 -9.59296114e+00] = SCAN,
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 4)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469576  <S^2> = 2.5389468e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002e0e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002e0e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.28637187e-03 -4.32380890e-04 -3.74072638e-05 ... -1.91722763e+00
 -1.91722763e+00 -1.91722763e+00] = SCAN,
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 4)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336185587  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002d960> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002d960> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.60123232e-04 -2.60157929e-04 -2.60140327e-04 ... -3.86943966e-01
 -3.86943966e-01 -3.86943966e-01] = SCAN,
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 4)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864076  <S^2> = 3.170797e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002ef20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002ef20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.68439856e-04 -2.42462783e-04 -1.69965237e-05 ... -2.55256081e-05
 -2.55256081e-05 -2.55256081e-05] = SCAN,
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 4)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.2003735e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeb002df30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeb002df30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-7.67691257e-04 -4.57409182e-05 -2.02835243e-04 ... -1.14928928e+00
 -1.14928928e+00 -1.14928928e+00] = SCAN,
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 4)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3157475e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.33847724e-04 -2.34902391e-04 -1.75660753e-05 ... -1.92925750e-05
 -1.92925750e-05 -1.92925750e-05] = SCAN,
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 4)
PRE NAN FILT: tFxc.shape=(224159,), tdrho.shape=(224159, 4)
nan_filt_rho.shape=(224159,)
nan_filt_fxc.shape=(224159,)
tFxc.shape=(224159,), tdrho.shape=(224159, 4)
inp[0].shape = (224159, 4)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 5.4782685979268075
0, epoch_train_loss=5.4782685979268075
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 4.917195571802378
1, epoch_train_loss=4.917195571802378
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 4.133242876462766
2, epoch_train_loss=4.133242876462766
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 2.742313385323606
3, epoch_train_loss=2.742313385323606
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 1.2991437096331835
4, epoch_train_loss=1.2991437096331835
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 2.028394144858969
5, epoch_train_loss=2.028394144858969
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 1.4030275521998923
6, epoch_train_loss=1.4030275521998923
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.6408564024934175
7, epoch_train_loss=0.6408564024934175
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.7981546856642326
8, epoch_train_loss=0.7981546856642326
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.8949330345979918
9, epoch_train_loss=0.8949330345979918
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.7003345963670001
10, epoch_train_loss=0.7003345963670001
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.4232809341374281
11, epoch_train_loss=0.4232809341374281
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.321821522860073
12, epoch_train_loss=0.321821522860073
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.47195048668991235
13, epoch_train_loss=0.47195048668991235
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.5021063039914845
14, epoch_train_loss=0.5021063039914845
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.31153612632782746
15, epoch_train_loss=0.31153612632782746
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.24020579574479048
16, epoch_train_loss=0.24020579574479048
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.3292426400440358
17, epoch_train_loss=0.3292426400440358
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.35175480076492044
18, epoch_train_loss=0.35175480076492044
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.25354334176855675
19, epoch_train_loss=0.25354334176855675
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.1695491114856266
20, epoch_train_loss=0.1695491114856266
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.20473197294730688
21, epoch_train_loss=0.20473197294730688
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.25046829136924276
22, epoch_train_loss=0.25046829136924276
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.1863834240557321
23, epoch_train_loss=0.1863834240557321
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.12867405400128915
24, epoch_train_loss=0.12867405400128915
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.15225315428482045
25, epoch_train_loss=0.15225315428482045
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.17600149846251043
26, epoch_train_loss=0.17600149846251043
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.13741486598689145
27, epoch_train_loss=0.13741486598689145
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.08918269322371304
28, epoch_train_loss=0.08918269322371304
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.11949970790357733
29, epoch_train_loss=0.11949970790357733
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.11952112128580351
30, epoch_train_loss=0.11952112128580351
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.06851921929835861
31, epoch_train_loss=0.06851921929835861
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.06962400947781014
32, epoch_train_loss=0.06962400947781014
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.08436931175560405
33, epoch_train_loss=0.08436931175560405
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.06512434091113678
34, epoch_train_loss=0.06512434091113678
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.04468809908585046
35, epoch_train_loss=0.04468809908585046
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.05687739270020786
36, epoch_train_loss=0.05687739270020786
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.05443501056191844
37, epoch_train_loss=0.05443501056191844
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.033077427464395036
38, epoch_train_loss=0.033077427464395036
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.03549705602924803
39, epoch_train_loss=0.03549705602924803
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.039701958653454
40, epoch_train_loss=0.039701958653454
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.025176472416397904
41, epoch_train_loss=0.025176472416397904
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.021827407534613607
42, epoch_train_loss=0.021827407534613607
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.03000808085043962
43, epoch_train_loss=0.03000808085043962
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.02015829879257913
44, epoch_train_loss=0.02015829879257913
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.015270185381908188
45, epoch_train_loss=0.015270185381908188
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.021918146887804035
46, epoch_train_loss=0.021918146887804035
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.016422085330020233
47, epoch_train_loss=0.016422085330020233
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.009627452818058727
48, epoch_train_loss=0.009627452818058727
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.014766747677067404
49, epoch_train_loss=0.014766747677067404
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.012132397309295556
50, epoch_train_loss=0.012132397309295556
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.008205565409143004
51, epoch_train_loss=0.008205565409143004
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.011478514542849745
52, epoch_train_loss=0.011478514542849745
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.00851007988913441
53, epoch_train_loss=0.00851007988913441
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.006935428494654538
54, epoch_train_loss=0.006935428494654538
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.009505113727722463
55, epoch_train_loss=0.009505113727722463
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.00554638421539508
56, epoch_train_loss=0.00554638421539508
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.005523192846592589
57, epoch_train_loss=0.005523192846592589
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0069331148080596875
58, epoch_train_loss=0.0069331148080596875
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.004024551532604687
59, epoch_train_loss=0.004024551532604687
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.005225864984642795
60, epoch_train_loss=0.005225864984642795
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.00514157529103767
61, epoch_train_loss=0.00514157529103767
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.003247646467355342
62, epoch_train_loss=0.003247646467355342
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.004547132208015114
63, epoch_train_loss=0.004547132208015114
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.003448896146576056
64, epoch_train_loss=0.003448896146576056
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0034639240576786116
65, epoch_train_loss=0.0034639240576786116
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.0036927431785755607
66, epoch_train_loss=0.0036927431785755607
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0024968183868610376
67, epoch_train_loss=0.0024968183868610376
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.003555218781750569
68, epoch_train_loss=0.003555218781750569
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0029240170789572657
69, epoch_train_loss=0.0029240170789572657
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0023798849019155102
70, epoch_train_loss=0.0023798849019155102
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.002959624154770215
71, epoch_train_loss=0.002959624154770215
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0022146519715447576
72, epoch_train_loss=0.0022146519715447576
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0026321289995355156
73, epoch_train_loss=0.0026321289995355156
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0023381259023270186
74, epoch_train_loss=0.0023381259023270186
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.002183159626523854
75, epoch_train_loss=0.002183159626523854
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.002392674362284334
76, epoch_train_loss=0.002392674362284334
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0019479621045829564
77, epoch_train_loss=0.0019479621045829564
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.002272150046375647
78, epoch_train_loss=0.002272150046375647
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0018692340692254392
79, epoch_train_loss=0.0018692340692254392
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0019413794883656314
80, epoch_train_loss=0.0019413794883656314
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.002001182397303478
81, epoch_train_loss=0.002001182397303478
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0016823074360481384
82, epoch_train_loss=0.0016823074360481384
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.00183174876520693
83, epoch_train_loss=0.00183174876520693
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0015883464452423478
84, epoch_train_loss=0.0015883464452423478
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0016858675259745924
85, epoch_train_loss=0.0016858675259745924
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.001510425958597229
86, epoch_train_loss=0.001510425958597229
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.0015238283362368685
87, epoch_train_loss=0.0015238283362368685
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0015008911771931947
88, epoch_train_loss=0.0015008911771931947
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.001394270805981191
89, epoch_train_loss=0.001394270805981191
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.001466205152912023
90, epoch_train_loss=0.001466205152912023
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0013065463419715748
91, epoch_train_loss=0.0013065463419715748
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0014029329438354202
92, epoch_train_loss=0.0014029329438354202
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0013019995286790227
93, epoch_train_loss=0.0013019995286790227
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.0013190710371709389
94, epoch_train_loss=0.0013190710371709389
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0012600847570956057
95, epoch_train_loss=0.0012600847570956057
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0012601486893243524
96, epoch_train_loss=0.0012601486893243524
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.00122009221389254
97, epoch_train_loss=0.00122009221389254
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0011745977001839485
98, epoch_train_loss=0.0011745977001839485
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0011834984389008795
99, epoch_train_loss=0.0011834984389008795
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0011163677992414244
100, epoch_train_loss=0.0011163677992414244
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.001129105663410444
101, epoch_train_loss=0.001129105663410444
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0010634294615129798
102, epoch_train_loss=0.0010634294615129798
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.001074284662628532
103, epoch_train_loss=0.001074284662628532
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0010243022384078693
104, epoch_train_loss=0.0010243022384078693
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0010250783082489119
105, epoch_train_loss=0.0010250783082489119
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0009822367726588137
106, epoch_train_loss=0.0009822367726588137
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0009861908187384421
107, epoch_train_loss=0.0009861908187384421
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0009445580238268784
108, epoch_train_loss=0.0009445580238268784
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0009375854823038748
109, epoch_train_loss=0.0009375854823038748
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0009122077763315335
110, epoch_train_loss=0.0009122077763315335
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0008968268960214739
111, epoch_train_loss=0.0008968268960214739
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0008754905125275811
112, epoch_train_loss=0.0008754905125275811
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0008604324411363527
113, epoch_train_loss=0.0008604324411363527
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0008414694760895747
114, epoch_train_loss=0.0008414694760895747
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0008259117893825947
115, epoch_train_loss=0.0008259117893825947
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0008089644358088844
116, epoch_train_loss=0.0008089644358088844
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007949657460229655
117, epoch_train_loss=0.0007949657460229655
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0007808987993886405
118, epoch_train_loss=0.0007808987993886405
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007641303403817782
119, epoch_train_loss=0.0007641303403817782
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.0007524793885001714
120, epoch_train_loss=0.0007524793885001714
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007367639791052399
121, epoch_train_loss=0.0007367639791052399
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007230907694430475
122, epoch_train_loss=0.0007230907694430475
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0007102932273792471
123, epoch_train_loss=0.0007102932273792471
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0006965654897277873
124, epoch_train_loss=0.0006965654897277873
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0006839331304432663
125, epoch_train_loss=0.0006839331304432663
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0006708239884197176
126, epoch_train_loss=0.0006708239884197176
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0006593356370888419
127, epoch_train_loss=0.0006593356370888419
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0006468176604751975
128, epoch_train_loss=0.0006468176604751975
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0006360850868069687
129, epoch_train_loss=0.0006360850868069687
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0006245209472956907
130, epoch_train_loss=0.0006245209472956907
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0006145737680418839
131, epoch_train_loss=0.0006145737680418839
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0006026635096177268
132, epoch_train_loss=0.0006026635096177268
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.000594182015062762
133, epoch_train_loss=0.000594182015062762
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0005823421634885919
134, epoch_train_loss=0.0005823421634885919
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0005742167685368892
135, epoch_train_loss=0.0005742167685368892
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0005632792045039342
136, epoch_train_loss=0.0005632792045039342
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.000555077036854852
137, epoch_train_loss=0.000555077036854852
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0005448813589912835
138, epoch_train_loss=0.0005448813589912835
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0005368442169864025
139, epoch_train_loss=0.0005368442169864025
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0005276119102059282
140, epoch_train_loss=0.0005276119102059282
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0005194585311361302
141, epoch_train_loss=0.0005194585311361302
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0005111516172539878
142, epoch_train_loss=0.0005111516172539878
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0005030528401160503
143, epoch_train_loss=0.0005030528401160503
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0004952737320867747
144, epoch_train_loss=0.0004952737320867747
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.00048744969445583245
145, epoch_train_loss=0.00048744969445583245
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.00048021068763923116
146, epoch_train_loss=0.00048021068763923116
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.00047252840120241705
147, epoch_train_loss=0.00047252840120241705
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0004657319411794136
148, epoch_train_loss=0.0004657319411794136
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.00045836225912800006
149, epoch_train_loss=0.00045836225912800006
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.00045175776629132104
150, epoch_train_loss=0.00045175776629132104
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.00044491778494403807
151, epoch_train_loss=0.00044491778494403807
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.00043843696965220966
152, epoch_train_loss=0.00043843696965220966
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.00043205528622407746
153, epoch_train_loss=0.00043205528622407746
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.00042573959322770325
154, epoch_train_loss=0.00042573959322770325
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.00041974186110314246
155, epoch_train_loss=0.00041974186110314246
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0004136314822682133
156, epoch_train_loss=0.0004136314822682133
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.00040795410071968463
157, epoch_train_loss=0.00040795410071968463
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0004021360988883388
158, epoch_train_loss=0.0004021360988883388
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0003966171253154003
159, epoch_train_loss=0.0003966171253154003
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.000391178862927426
160, epoch_train_loss=0.000391178862927426
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.00038578781194331213
161, epoch_train_loss=0.00038578781194331213
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.00038066268813546607
162, epoch_train_loss=0.00038066268813546607
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0003754948682181291
163, epoch_train_loss=0.0003754948682181291
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.00037055761206872273
164, epoch_train_loss=0.00037055761206872273
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.00036566767993689695
165, epoch_train_loss=0.00036566767993689695
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0003608773949253809
166, epoch_train_loss=0.0003608773949253809
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0003562527937192279
167, epoch_train_loss=0.0003562527937192279
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.00035164242404122725
168, epoch_train_loss=0.00035164242404122725
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0003472229682266361
169, epoch_train_loss=0.0003472229682266361
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.00034283260438129094
170, epoch_train_loss=0.00034283260438129094
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0003385688654519289
171, epoch_train_loss=0.0003385688654519289
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.00033441316045720475
172, epoch_train_loss=0.00033441316045720475
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0003303003388279533
173, epoch_train_loss=0.0003303003388279533
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.00032634297359235737
174, epoch_train_loss=0.00032634297359235737
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0003224121174585306
175, epoch_train_loss=0.0003224121174585306
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.00031859765097061275
176, epoch_train_loss=0.00031859765097061275
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.00031486729932087395
177, epoch_train_loss=0.00031486729932087395
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0003111921139172031
178, epoch_train_loss=0.0003111921139172031
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.0003076281745051322
179, epoch_train_loss=0.0003076281745051322
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0003041206162681997
180, epoch_train_loss=0.0003041206162681997
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0003006874266113831
181, epoch_train_loss=0.0003006874266113831
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.00029734673504740644
182, epoch_train_loss=0.00029734673504740644
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0002940515775452654
183, epoch_train_loss=0.0002940515775452654
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0002908457421147866
184, epoch_train_loss=0.0002908457421147866
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0002877029856114226
185, epoch_train_loss=0.0002877029856114226
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0002846155245445241
186, epoch_train_loss=0.0002846155245445241
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.00028160984653637317
187, epoch_train_loss=0.00028160984653637317
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0002786533145237444
188, epoch_train_loss=0.0002786533145237444
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.00027576171354682706
189, epoch_train_loss=0.00027576171354682706
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0002729365378185727
190, epoch_train_loss=0.0002729365378185727
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0002701598208384676
191, epoch_train_loss=0.0002701598208384676
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.00026744579106355597
192, epoch_train_loss=0.00026744579106355597
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0002647894406164931
193, epoch_train_loss=0.0002647894406164931
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.00026217944949511325
194, epoch_train_loss=0.00026217944949511325
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0002596299876207319
195, epoch_train_loss=0.0002596299876207319
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.00025712823387797305
196, epoch_train_loss=0.00025712823387797305
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.00025467454250597925
197, epoch_train_loss=0.00025467454250597925
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.00025227327060863306
198, epoch_train_loss=0.00025227327060863306
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.00024991748560678634
199, epoch_train_loss=0.00024991748560678634
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0002476063258233114
200, epoch_train_loss=0.0002476063258233114
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.0002453438927235659
201, epoch_train_loss=0.0002453438927235659
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0002431225032782039
202, epoch_train_loss=0.0002431225032782039
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0002409442089632919
203, epoch_train_loss=0.0002409442089632919
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.00023880919219553112
204, epoch_train_loss=0.00023880919219553112
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.00023671360786650233
205, epoch_train_loss=0.00023671360786650233
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.00023465685398752186
206, epoch_train_loss=0.00023465685398752186
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.00023264064598409894
207, epoch_train_loss=0.00023264064598409894
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.00023066028091345977
208, epoch_train_loss=0.00023066028091345977
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.000228716585111584
209, epoch_train_loss=0.000228716585111584
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.00022680968495081378
210, epoch_train_loss=0.00022680968495081378
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.0002249367257161637
211, epoch_train_loss=0.0002249367257161637
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.0002230972604642857
212, epoch_train_loss=0.0002230972604642857
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.0002212920754075708
213, epoch_train_loss=0.0002212920754075708
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.00021951824049144068
214, epoch_train_loss=0.00021951824049144068
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0002177757363156232
215, epoch_train_loss=0.0002177757363156232
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.00021606440006206908
216, epoch_train_loss=0.00021606440006206908
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.00021438273625207376
217, epoch_train_loss=0.00021438273625207376
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0002127297065809702
218, epoch_train_loss=0.0002127297065809702
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.00021110557588521062
219, epoch_train_loss=0.00021110557588521062
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.00020950915008853449
220, epoch_train_loss=0.00020950915008853449
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.00020793932335470974
221, epoch_train_loss=0.00020793932335470974
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.00020639607143781602
222, epoch_train_loss=0.00020639607143781602
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.00020487875840221904
223, epoch_train_loss=0.00020487875840221904
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0002033861690263074
224, epoch_train_loss=0.0002033861690263074
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0002019181322382729
225, epoch_train_loss=0.0002019181322382729
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.00020047421318488052
226, epoch_train_loss=0.00020047421318488052
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.00019905345099651767
227, epoch_train_loss=0.00019905345099651767
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.0001976553812909711
228, epoch_train_loss=0.0001976553812909711
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0001962796658240347
229, epoch_train_loss=0.0001962796658240347
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.00019492573840100436
230, epoch_train_loss=0.00019492573840100436
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.00019359283825445427
231, epoch_train_loss=0.00019359283825445427
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.00019228072317191818
232, epoch_train_loss=0.00019228072317191818
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.00019098892892837447
233, epoch_train_loss=0.00019098892892837447
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.00018971686673054962
234, epoch_train_loss=0.00018971686673054962
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0001884640580365911
235, epoch_train_loss=0.0001884640580365911
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.00018723022084565316
236, epoch_train_loss=0.00018723022084565316
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.00018601487659017477
237, epoch_train_loss=0.00018601487659017477
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.00018481752512944518
238, epoch_train_loss=0.00018481752512944518
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.00018363781637529557
239, epoch_train_loss=0.00018363781637529557
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.00018247544250016195
240, epoch_train_loss=0.00018247544250016195
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.00018132995249796016
241, epoch_train_loss=0.00018132995249796016
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0001802009521709608
242, epoch_train_loss=0.0001802009521709608
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.00017908813191128947
243, epoch_train_loss=0.00017908813191128947
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.00017799116850939221
244, epoch_train_loss=0.00017799116850939221
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.00017690970092482962
245, epoch_train_loss=0.00017690970092482962
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.00017584335970689694
246, epoch_train_loss=0.00017584335970689694
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.00017479188719591012
247, epoch_train_loss=0.00017479188719591012
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.0001737549706729835
248, epoch_train_loss=0.0001737549706729835
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.00017273229771483988
249, epoch_train_loss=0.00017273229771483988
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.00017172355916719056
250, epoch_train_loss=0.00017172355916719056
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.00017072849272802243
251, epoch_train_loss=0.00017072849272802243
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0001697468385514808
252, epoch_train_loss=0.0001697468385514808
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.00016877830940380603
253, epoch_train_loss=0.00016877830940380603
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.00016782263946657955
254, epoch_train_loss=0.00016782263946657955
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.00016687957862531567
255, epoch_train_loss=0.00016687957862531567
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.00016594889846268198
256, epoch_train_loss=0.00016594889846268198
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.00016503034795819192
257, epoch_train_loss=0.00016503034795819192
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.00016412368777668314
258, epoch_train_loss=0.00016412368777668314
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.00016322868969791208
259, epoch_train_loss=0.00016322868969791208
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.00016234514140510547
260, epoch_train_loss=0.00016234514140510547
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.00016147283028507893
261, epoch_train_loss=0.00016147283028507893
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.00016061153571823674
262, epoch_train_loss=0.00016061153571823674
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.000159761053601031
263, epoch_train_loss=0.000159761053601031
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.00015892118415226418
264, epoch_train_loss=0.00015892118415226418
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.00015809173864011916
265, epoch_train_loss=0.00015809173864011916
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0001572725247580449
266, epoch_train_loss=0.0001572725247580449
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.00015646335339426518
267, epoch_train_loss=0.00015646335339426518
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.00015566404377206404
268, epoch_train_loss=0.00015566404377206404
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.00015487441917253516
269, epoch_train_loss=0.00015487441917253516
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.00015409431120363122
270, epoch_train_loss=0.00015409431120363122
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.00015332354980177322
271, epoch_train_loss=0.00015332354980177322
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0001525619691862478
272, epoch_train_loss=0.0001525619691862478
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.00015180940733311693
273, epoch_train_loss=0.00015180940733311693
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.00015106570810497936
274, epoch_train_loss=0.00015106570810497936
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0001503307198784737
275, epoch_train_loss=0.0001503307198784737
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.00014960429198405037
276, epoch_train_loss=0.00014960429198405037
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.00014888627785120316
277, epoch_train_loss=0.00014888627785120316
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0001481765328741067
278, epoch_train_loss=0.0001481765328741067
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.00014747491698371184
279, epoch_train_loss=0.00014747491698371184
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.00014678129345032333
280, epoch_train_loss=0.00014678129345032333
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.00014609552862501892
281, epoch_train_loss=0.00014609552862501892
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.00014541749150650648
282, epoch_train_loss=0.00014541749150650648
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.00014474705270625793
283, epoch_train_loss=0.00014474705270625793
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.00014408408648719536
284, epoch_train_loss=0.00014408408648719536
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0001434284694467338
285, epoch_train_loss=0.0001434284694467338
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.00014278008117780266
286, epoch_train_loss=0.00014278008117780266
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.00014213880375021562
287, epoch_train_loss=0.00014213880375021562
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.00014150452168372953
288, epoch_train_loss=0.00014150452168372953
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0001408771217157147
289, epoch_train_loss=0.0001408771217157147
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.0001402564925517487
290, epoch_train_loss=0.0001402564925517487
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.00013964252539449724
291, epoch_train_loss=0.00013964252539449724
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.0001390351136375814
292, epoch_train_loss=0.0001390351136375814
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.00013843415266178417
293, epoch_train_loss=0.00013843415266178417
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.00013783954023018023
294, epoch_train_loss=0.00013783954023018023
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.00013725117596272707
295, epoch_train_loss=0.00013725117596272707
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.00013666896142207322
296, epoch_train_loss=0.00013666896142207322
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.000136092800106189
297, epoch_train_loss=0.000136092800106189
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.00013552259730229685
298, epoch_train_loss=0.00013552259730229685
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.00013495826015552377
299, epoch_train_loss=0.00013495826015552377
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.00013439969749677816
300, epoch_train_loss=0.00013439969749677816
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.00013384682015029955
301, epoch_train_loss=0.00013384682015029955
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.0001332995404174221
302, epoch_train_loss=0.0001332995404174221
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.00013275777224829754
303, epoch_train_loss=0.00013275777224829754
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.0001322214313712296
304, epoch_train_loss=0.0001322214313712296
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.00013169043505970377
305, epoch_train_loss=0.00013169043505970377
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.00013116470199182772
306, epoch_train_loss=0.00013116470199182772
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.00013064415250194607
307, epoch_train_loss=0.00013064415250194607
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.00013012870837574679
308, epoch_train_loss=0.00013012870837574679
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.00012961829282647083
309, epoch_train_loss=0.00012961829282647083
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0001291128304436102
310, epoch_train_loss=0.0001291128304436102
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0001286122472360762
311, epoch_train_loss=0.0001286122472360762
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.00012811647063340882
312, epoch_train_loss=0.00012811647063340882
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.00012762542921716623
313, epoch_train_loss=0.00012762542921716623
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.00012713905299705552
314, epoch_train_loss=0.00012713905299705552
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.0001266572733124056
315, epoch_train_loss=0.0001266572733124056
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0001261800225668184
316, epoch_train_loss=0.0001261800225668184
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.00012570723451385356
317, epoch_train_loss=0.00012570723451385356
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.00012523884414559087
318, epoch_train_loss=0.00012523884414559087
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.00012477478747852702
319, epoch_train_loss=0.00012477478747852702
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.00012431500175007627
320, epoch_train_loss=0.00012431500175007627
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.00012385942537320645
321, epoch_train_loss=0.00012385942537320645
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.0001234079978010677
322, epoch_train_loss=0.0001234079978010677
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0001229606595434021
323, epoch_train_loss=0.0001229606595434021
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.0001225173522505869
324, epoch_train_loss=0.0001225173522505869
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.0001220780185416291
325, epoch_train_loss=0.0001220780185416291
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.00012164260211483135
326, epoch_train_loss=0.00012164260211483135
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.00012121104765184696
327, epoch_train_loss=0.00012121104765184696
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.00012078330086496471
328, epoch_train_loss=0.00012078330086496471
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.00012035930855901146
329, epoch_train_loss=0.00012035930855901146
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.00011993901864589554
330, epoch_train_loss=0.00011993901864589554
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.00011952238053613415
331, epoch_train_loss=0.00011952238053613415
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0001191093457768784
332, epoch_train_loss=0.0001191093457768784
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.00011869986996906621
333, epoch_train_loss=0.00011869986996906621
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.00011829391705929295
334, epoch_train_loss=0.00011829391705929295
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.00011789147095650894
335, epoch_train_loss=0.00011789147095650894
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.0001174925647222155
336, epoch_train_loss=0.0001174925647222155
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.00011709735735913769
337, epoch_train_loss=0.00011709735735913769
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.00011670633668098092
338, epoch_train_loss=0.00011670633668098092
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.00011632086467940312
339, epoch_train_loss=0.00011632086467940312
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.00011594466750507324
340, epoch_train_loss=0.00011594466750507324
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0001155879441222872
341, epoch_train_loss=0.0001155879441222872
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.00011527895553615486
342, epoch_train_loss=0.00011527895553615486
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.00011509673999453637
343, epoch_train_loss=0.00011509673999453637
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.00011526667699225217
344, epoch_train_loss=0.00011526667699225217
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.00011643463787378948
345, epoch_train_loss=0.00011643463787378948
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.00012050437408795594
346, epoch_train_loss=0.00012050437408795594
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0001330327296665189
347, epoch_train_loss=0.0001330327296665189
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0001710765253337269
348, epoch_train_loss=0.0001710765253337269
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.00028433594841469106
349, epoch_train_loss=0.00028433594841469106
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.0006340208646958963
350, epoch_train_loss=0.0006340208646958963
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0016514943885047254
351, epoch_train_loss=0.0016514943885047254
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.004800142914237599
352, epoch_train_loss=0.004800142914237599
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.01202689823170154
353, epoch_train_loss=0.01202689823170154
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.028676837598918474
354, epoch_train_loss=0.028676837598918474
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.03163983702415378
355, epoch_train_loss=0.03163983702415378
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.022752692624260596
356, epoch_train_loss=0.022752692624260596
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0011191024845690184
357, epoch_train_loss=0.0011191024845690184
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.009770720213431661
358, epoch_train_loss=0.009770720213431661
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.023069723009995928
359, epoch_train_loss=0.023069723009995928
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.004582023419994684
360, epoch_train_loss=0.004582023419994684
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.004334447012677865
361, epoch_train_loss=0.004334447012677865
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.015598165802219994
362, epoch_train_loss=0.015598165802219994
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0028251045479219493
363, epoch_train_loss=0.0028251045479219493
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.004227018248871037
364, epoch_train_loss=0.004227018248871037
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.010987422480315215
365, epoch_train_loss=0.010987422480315215
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007648001817963658
366, epoch_train_loss=0.0007648001817963658
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0059258294285636035
367, epoch_train_loss=0.0059258294285636035
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.007500144769395876
368, epoch_train_loss=0.007500144769395876
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0003296166657507338
369, epoch_train_loss=0.0003296166657507338
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.007168307186296458
370, epoch_train_loss=0.007168307186296458
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.003984691616479055
371, epoch_train_loss=0.003984691616479055
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.0013842651923450307
372, epoch_train_loss=0.0013842651923450307
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.006383428188670579
373, epoch_train_loss=0.006383428188670579
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0011916162593946303
374, epoch_train_loss=0.0011916162593946303
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0027713571955410065
375, epoch_train_loss=0.0027713571955410065
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.003692643714751381
376, epoch_train_loss=0.003692643714751381
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.00033524093707981115
377, epoch_train_loss=0.00033524093707981115
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0031979079638490516
378, epoch_train_loss=0.0031979079638490516
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0011705338548932812
379, epoch_train_loss=0.0011705338548932812
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.0011671545503727106
380, epoch_train_loss=0.0011671545503727106
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.0023707262723690566
381, epoch_train_loss=0.0023707262723690566
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0003191173146950894
382, epoch_train_loss=0.0003191173146950894
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0019553607818752414
383, epoch_train_loss=0.0019553607818752414
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0011140767685846543
384, epoch_train_loss=0.0011140767685846543
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0006573680049302971
385, epoch_train_loss=0.0006573680049302971
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.0017155766598843547
386, epoch_train_loss=0.0017155766598843547
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0003656055077296515
387, epoch_train_loss=0.0003656055077296515
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.0010914257078530449
388, epoch_train_loss=0.0010914257078530449
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0009243626740122238
389, epoch_train_loss=0.0009243626740122238
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.000354583464203131
390, epoch_train_loss=0.000354583464203131
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0010730900494363737
391, epoch_train_loss=0.0010730900494363737
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.0003758780100746871
392, epoch_train_loss=0.0003758780100746871
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.0006148459462766207
393, epoch_train_loss=0.0006148459462766207
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007456852967408158
394, epoch_train_loss=0.0007456852967408158
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0002616342675069553
395, epoch_train_loss=0.0002616342675069553
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.000717274758440032
396, epoch_train_loss=0.000717274758440032
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.00041915127864169905
397, epoch_train_loss=0.00041915127864169905
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.000349795848738251
398, epoch_train_loss=0.000349795848738251
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0006036882199679962
399, epoch_train_loss=0.0006036882199679962
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0002512085454517876
400, epoch_train_loss=0.0002512085454517876
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0004248484395206741
401, epoch_train_loss=0.0004248484395206741
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0004188906048251843
402, epoch_train_loss=0.0004188906048251843
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.00022454704693040058
403, epoch_train_loss=0.00022454704693040058
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.00041900265843527025
404, epoch_train_loss=0.00041900265843527025
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.00028063894845072317
405, epoch_train_loss=0.00028063894845072317
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.00025032989601094234
406, epoch_train_loss=0.00025032989601094234
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.00036044798890333293
407, epoch_train_loss=0.00036044798890333293
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.00021133170888414977
408, epoch_train_loss=0.00021133170888414977
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0002708406560972846
409, epoch_train_loss=0.0002708406560972846
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0002909197149341887
410, epoch_train_loss=0.0002909197149341887
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.00018964559962260177
411, epoch_train_loss=0.00018964559962260177
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.0002679313693943108
412, epoch_train_loss=0.0002679313693943108
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0002358238916217949
413, epoch_train_loss=0.0002358238916217949
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.00018604347957429151
414, epoch_train_loss=0.00018604347957429151
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0002494429429435682
415, epoch_train_loss=0.0002494429429435682
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0001990016502120086
416, epoch_train_loss=0.0001990016502120086
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.00018576229035626837
417, epoch_train_loss=0.00018576229035626837
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.0002251613412437939
418, epoch_train_loss=0.0002251613412437939
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.00017716555359464727
419, epoch_train_loss=0.00017716555359464727
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.00018246288650625018
420, epoch_train_loss=0.00018246288650625018
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.00020261361491858605
421, epoch_train_loss=0.00020261361491858605
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.00016429173883096286
422, epoch_train_loss=0.00016429173883096286
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0001766037033335523
423, epoch_train_loss=0.0001766037033335523
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.00018424373527649844
424, epoch_train_loss=0.00018424373527649844
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.00015646905412636085
425, epoch_train_loss=0.00015646905412636085
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.00016910226490666696
426, epoch_train_loss=0.00016910226490666696
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.00017041338260921323
427, epoch_train_loss=0.00017041338260921323
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.00015073272015785847
428, epoch_train_loss=0.00015073272015785847
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.00016143711021605038
429, epoch_train_loss=0.00016143711021605038
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.00016004596167730213
430, epoch_train_loss=0.00016004596167730213
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.00014617447397017802
431, epoch_train_loss=0.00014617447397017802
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.00015422232286797403
432, epoch_train_loss=0.00015422232286797403
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.00015231525956433146
433, epoch_train_loss=0.00015231525956433146
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.00014206669813609003
434, epoch_train_loss=0.00014206669813609003
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.00014784524292115334
435, epoch_train_loss=0.00014784524292115334
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.0001461863000166121
436, epoch_train_loss=0.0001461863000166121
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.00013843178217805223
437, epoch_train_loss=0.00013843178217805223
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0001422350832580864
438, epoch_train_loss=0.0001422350832580864
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0001412596964984947
439, epoch_train_loss=0.0001412596964984947
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0001351543480553868
440, epoch_train_loss=0.0001351543480553868
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.00013741570091564274
441, epoch_train_loss=0.00013741570091564274
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.00013707768151716355
442, epoch_train_loss=0.00013707768151716355
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0001322528892473699
443, epoch_train_loss=0.0001322528892473699
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.00013322807351133034
444, epoch_train_loss=0.00013322807351133034
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.00013344352903473143
445, epoch_train_loss=0.00013344352903473143
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.00012963891539735498
446, epoch_train_loss=0.00012963891539735498
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.0001296413021928426
447, epoch_train_loss=0.0001296413021928426
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.00013014514635437645
448, epoch_train_loss=0.00013014514635437645
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.00012729695192269298
449, epoch_train_loss=0.00012729695192269298
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.000126557006794749
450, epoch_train_loss=0.000126557006794749
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.00012712201881410999
451, epoch_train_loss=0.00012712201881410999
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.00012514822370033972
452, epoch_train_loss=0.00012514822370033972
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.00012392341383801568
453, epoch_train_loss=0.00012392341383801568
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.00012432843609467677
454, epoch_train_loss=0.00012432843609467677
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.00012310861415861703
455, epoch_train_loss=0.00012310861415861703
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.00012167806673728598
456, epoch_train_loss=0.00012167806673728598
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0001217583389421528
457, epoch_train_loss=0.0001217583389421528
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.00012112086803595103
458, epoch_train_loss=0.00012112086803595103
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.00011974333747186157
459, epoch_train_loss=0.00011974333747186157
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.00011944157487831165
460, epoch_train_loss=0.00011944157487831165
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.00011914879880916461
461, epoch_train_loss=0.00011914879880916461
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.00011802474914157269
462, epoch_train_loss=0.00011802474914157269
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.00011739235199924882
463, epoch_train_loss=0.00011739235199924882
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.00011720816174354473
464, epoch_train_loss=0.00011720816174354473
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.00011641535517972492
465, epoch_train_loss=0.00011641535517972492
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.00011561531827505855
466, epoch_train_loss=0.00011561531827505855
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.00011533999175177092
467, epoch_train_loss=0.00011533999175177092
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.00011484208938895575
468, epoch_train_loss=0.00011484208938895575
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.00011405459070159803
469, epoch_train_loss=0.00011405459070159803
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.00011360924618310828
470, epoch_train_loss=0.00011360924618310828
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.00011326934110773338
471, epoch_train_loss=0.00011326934110773338
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.00011262872216185743
472, epoch_train_loss=0.00011262872216185743
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.00011205721977302052
473, epoch_train_loss=0.00011205721977302052
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.00011172114957610835
474, epoch_train_loss=0.00011172114957610835
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.00011125669478029203
475, epoch_train_loss=0.00011125669478029203
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.00011067095153745146
476, epoch_train_loss=0.00011067095153745146
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.00011025530825952738
477, epoch_train_loss=0.00011025530825952738
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.00010989379728320635
478, epoch_train_loss=0.00010989379728320635
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.00010939358915820376
479, epoch_train_loss=0.00010939358915820376
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.00010891347777323411
480, epoch_train_loss=0.00010891347777323411
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.00010855539035075964
481, epoch_train_loss=0.00010855539035075964
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.00010815849513947553
482, epoch_train_loss=0.00010815849513947553
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.00010768968395035404
483, epoch_train_loss=0.00010768968395035404
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.00010728707205176613
484, epoch_train_loss=0.00010728707205176613
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.00010693855398891416
485, epoch_train_loss=0.00010693855398891416
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.00010653582857687463
486, epoch_train_loss=0.00010653582857687463
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.00010611541337207332
487, epoch_train_loss=0.00010611541337207332
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.00010575533830604772
488, epoch_train_loss=0.00010575533830604772
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.00010540802837699645
489, epoch_train_loss=0.00010540802837699645
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.00010502096503906932
490, epoch_train_loss=0.00010502096503906932
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.00010464201136294957
491, epoch_train_loss=0.00010464201136294957
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.00010430459156852559
492, epoch_train_loss=0.00010430459156852559
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.00010396378976118052
493, epoch_train_loss=0.00010396378976118052
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0001036000137974191
494, epoch_train_loss=0.0001036000137974191
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.00010325151008977625
495, epoch_train_loss=0.00010325151008977625
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0001029289029609379
496, epoch_train_loss=0.0001029289029609379
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.00010259998019829036
497, epoch_train_loss=0.00010259998019829036
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.00010225928292232818
498, epoch_train_loss=0.00010225928292232818
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.00010193305603670338
499, epoch_train_loss=0.00010193305603670338
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.00010162322819709826
500, epoch_train_loss=0.00010162322819709826
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.000101308698724155
501, epoch_train_loss=0.000101308698724155
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.00010098850668699899
502, epoch_train_loss=0.00010098850668699899
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.00010067962461248026
503, epoch_train_loss=0.00010067962461248026
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0001003820932554906
504, epoch_train_loss=0.0001003820932554906
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.00010008227760237988
505, epoch_train_loss=0.00010008227760237988
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 9.977985434572326e-05
506, epoch_train_loss=9.977985434572326e-05
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 9.948555203540433e-05
507, epoch_train_loss=9.948555203540433e-05
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 9.919990534335069e-05
508, epoch_train_loss=9.919990534335069e-05
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 9.891413039578099e-05
509, epoch_train_loss=9.891413039578099e-05
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 9.862721740158484e-05
510, epoch_train_loss=9.862721740158484e-05
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 9.834588953069137e-05
511, epoch_train_loss=9.834588953069137e-05
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 9.807150968454162e-05
512, epoch_train_loss=9.807150968454162e-05
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 9.77986660641402e-05
513, epoch_train_loss=9.77986660641402e-05
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 9.75255596644792e-05
514, epoch_train_loss=9.75255596644792e-05
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 9.72561426789547e-05
515, epoch_train_loss=9.72561426789547e-05
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 9.699232103938301e-05
516, epoch_train_loss=9.699232103938301e-05
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 9.673116427765609e-05
517, epoch_train_loss=9.673116427765609e-05
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 9.64705135116299e-05
518, epoch_train_loss=9.64705135116299e-05
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 9.621223794978025e-05
519, epoch_train_loss=9.621223794978025e-05
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 9.59583201813376e-05
520, epoch_train_loss=9.59583201813376e-05
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 9.570763158750472e-05
521, epoch_train_loss=9.570763158750472e-05
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 9.545824159266652e-05
522, epoch_train_loss=9.545824159266652e-05
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 9.521049287766657e-05
523, epoch_train_loss=9.521049287766657e-05
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 9.496594358077468e-05
524, epoch_train_loss=9.496594358077468e-05
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 9.47246663873941e-05
525, epoch_train_loss=9.47246663873941e-05
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 9.448537565721965e-05
526, epoch_train_loss=9.448537565721965e-05
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 9.424755628049309e-05
527, epoch_train_loss=9.424755628049309e-05
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 9.401199465940422e-05
528, epoch_train_loss=9.401199465940422e-05
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 9.377930849544124e-05
529, epoch_train_loss=9.377930849544124e-05
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 9.354901533802635e-05
530, epoch_train_loss=9.354901533802635e-05
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 9.332040066879114e-05
531, epoch_train_loss=9.332040066879114e-05
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 9.309351712099088e-05
532, epoch_train_loss=9.309351712099088e-05
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 9.2868900750077e-05
533, epoch_train_loss=9.2868900750077e-05
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 9.264667517952703e-05
534, epoch_train_loss=9.264667517952703e-05
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 9.242641346856556e-05
535, epoch_train_loss=9.242641346856556e-05
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 9.220778877413418e-05
536, epoch_train_loss=9.220778877413418e-05
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 9.199093944896525e-05
537, epoch_train_loss=9.199093944896525e-05
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 9.177615148824936e-05
538, epoch_train_loss=9.177615148824936e-05
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 9.156340081725141e-05
539, epoch_train_loss=9.156340081725141e-05
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 9.135241481031521e-05
540, epoch_train_loss=9.135241481031521e-05
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 9.114302757053066e-05
541, epoch_train_loss=9.114302757053066e-05
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 9.093533324631376e-05
542, epoch_train_loss=9.093533324631376e-05
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 9.072947500829174e-05
543, epoch_train_loss=9.072947500829174e-05
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 9.052541997414847e-05
544, epoch_train_loss=9.052541997414847e-05
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 9.032300565571636e-05
545, epoch_train_loss=9.032300565571636e-05
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 9.01221246517445e-05
546, epoch_train_loss=9.01221246517445e-05
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 8.992281412365542e-05
547, epoch_train_loss=8.992281412365542e-05
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 8.97251462880722e-05
548, epoch_train_loss=8.97251462880722e-05
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 8.952910982253653e-05
549, epoch_train_loss=8.952910982253653e-05
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 8.933461103141341e-05
550, epoch_train_loss=8.933461103141341e-05
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 8.914156861077425e-05
551, epoch_train_loss=8.914156861077425e-05
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 8.894997653474813e-05
552, epoch_train_loss=8.894997653474813e-05
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 8.875986723736521e-05
553, epoch_train_loss=8.875986723736521e-05
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 8.857124432286058e-05
554, epoch_train_loss=8.857124432286058e-05
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 8.838406113610555e-05
555, epoch_train_loss=8.838406113610555e-05
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 8.819825643455051e-05
556, epoch_train_loss=8.819825643455051e-05
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 8.801380056523967e-05
557, epoch_train_loss=8.801380056523967e-05
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 8.783069576616262e-05
558, epoch_train_loss=8.783069576616262e-05
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 8.764894777487921e-05
559, epoch_train_loss=8.764894777487921e-05
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 8.746853901861225e-05
560, epoch_train_loss=8.746853901861225e-05
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 8.728943130076634e-05
561, epoch_train_loss=8.728943130076634e-05
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 8.711158975213238e-05
562, epoch_train_loss=8.711158975213238e-05
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 8.693499563752795e-05
563, epoch_train_loss=8.693499563752795e-05
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 8.67596447826935e-05
564, epoch_train_loss=8.67596447826935e-05
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 8.658553055412964e-05
565, epoch_train_loss=8.658553055412964e-05
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 8.641263532968289e-05
566, epoch_train_loss=8.641263532968289e-05
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 8.624093313112264e-05
567, epoch_train_loss=8.624093313112264e-05
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 8.607039899911763e-05
568, epoch_train_loss=8.607039899911763e-05
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 8.590101651587206e-05
569, epoch_train_loss=8.590101651587206e-05
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 8.573277547364051e-05
570, epoch_train_loss=8.573277547364051e-05
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 8.55656663303926e-05
571, epoch_train_loss=8.55656663303926e-05
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 8.539967509849834e-05
572, epoch_train_loss=8.539967509849834e-05
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 8.523478328610434e-05
573, epoch_train_loss=8.523478328610434e-05
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 8.507097198465448e-05
574, epoch_train_loss=8.507097198465448e-05
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 8.490822472950862e-05
575, epoch_train_loss=8.490822472950862e-05
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 8.474652899379291e-05
576, epoch_train_loss=8.474652899379291e-05
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 8.458587378342393e-05
577, epoch_train_loss=8.458587378342393e-05
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 8.44262475862853e-05
578, epoch_train_loss=8.44262475862853e-05
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 8.426763708658777e-05
579, epoch_train_loss=8.426763708658777e-05
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 8.411002751118614e-05
580, epoch_train_loss=8.411002751118614e-05
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 8.395340436317279e-05
581, epoch_train_loss=8.395340436317279e-05
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 8.379775419997676e-05
582, epoch_train_loss=8.379775419997676e-05
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 8.364306529866364e-05
583, epoch_train_loss=8.364306529866364e-05
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 8.348932657673228e-05
584, epoch_train_loss=8.348932657673228e-05
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 8.333652719467545e-05
585, epoch_train_loss=8.333652719467545e-05
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 8.318465571726465e-05
586, epoch_train_loss=8.318465571726465e-05
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 8.303370032083527e-05
587, epoch_train_loss=8.303370032083527e-05
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 8.288364908900248e-05
588, epoch_train_loss=8.288364908900248e-05
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 8.273449038728048e-05
589, epoch_train_loss=8.273449038728048e-05
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 8.258621327336481e-05
590, epoch_train_loss=8.258621327336481e-05
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 8.243880722266015e-05
591, epoch_train_loss=8.243880722266015e-05
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 8.229226223787714e-05
592, epoch_train_loss=8.229226223787714e-05
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 8.214656833624628e-05
593, epoch_train_loss=8.214656833624628e-05
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 8.200171561990921e-05
594, epoch_train_loss=8.200171561990921e-05
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 8.185769412072224e-05
595, epoch_train_loss=8.185769412072224e-05
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 8.17144939241609e-05
596, epoch_train_loss=8.17144939241609e-05
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 8.157210529335361e-05
597, epoch_train_loss=8.157210529335361e-05
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 8.143051863018266e-05
598, epoch_train_loss=8.143051863018266e-05
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 8.128972467845356e-05
599, epoch_train_loss=8.128972467845356e-05
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 8.114971434839502e-05
600, epoch_train_loss=8.114971434839502e-05
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 8.101047883364203e-05
601, epoch_train_loss=8.101047883364203e-05
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 8.087200939833788e-05
602, epoch_train_loss=8.087200939833788e-05
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 8.073429752128158e-05
603, epoch_train_loss=8.073429752128158e-05
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 8.059733472558468e-05
604, epoch_train_loss=8.059733472558468e-05
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 8.046111266740924e-05
605, epoch_train_loss=8.046111266740924e-05
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 8.03256231204142e-05
606, epoch_train_loss=8.03256231204142e-05
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 8.019085796649336e-05
607, epoch_train_loss=8.019085796649336e-05
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 8.005680923401799e-05
608, epoch_train_loss=8.005680923401799e-05
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 7.992346907060027e-05
609, epoch_train_loss=7.992346907060027e-05
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 7.979082978835197e-05
610, epoch_train_loss=7.979082978835197e-05
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 7.965888379521742e-05
611, epoch_train_loss=7.965888379521742e-05
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 7.952762367044782e-05
612, epoch_train_loss=7.952762367044782e-05
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 7.939704206216122e-05
613, epoch_train_loss=7.939704206216122e-05
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 7.926713180658751e-05
614, epoch_train_loss=7.926713180658751e-05
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 7.913788578362689e-05
615, epoch_train_loss=7.913788578362689e-05
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 7.900929703254502e-05
616, epoch_train_loss=7.900929703254502e-05
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 7.88813586505822e-05
617, epoch_train_loss=7.88813586505822e-05
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 7.875406389720344e-05
618, epoch_train_loss=7.875406389720344e-05
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 7.862740608079375e-05
619, epoch_train_loss=7.862740608079375e-05
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 7.850137867175991e-05
620, epoch_train_loss=7.850137867175991e-05
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 7.837597517271445e-05
621, epoch_train_loss=7.837597517271445e-05
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 7.825118924236082e-05
622, epoch_train_loss=7.825118924236082e-05
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 7.812701458801888e-05
623, epoch_train_loss=7.812701458801888e-05
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 7.800344506307312e-05
624, epoch_train_loss=7.800344506307312e-05
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 7.788047457485689e-05
625, epoch_train_loss=7.788047457485689e-05
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 7.775809716214643e-05
626, epoch_train_loss=7.775809716214643e-05
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 7.76363069101537e-05
627, epoch_train_loss=7.76363069101537e-05
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 7.751509807236644e-05
628, epoch_train_loss=7.751509807236644e-05
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 7.739446493415873e-05
629, epoch_train_loss=7.739446493415873e-05
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 7.727440198825427e-05
630, epoch_train_loss=7.727440198825427e-05
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 7.715490377098065e-05
631, epoch_train_loss=7.715490377098065e-05
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 7.703596512628088e-05
632, epoch_train_loss=7.703596512628088e-05
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 7.691758101391966e-05
633, epoch_train_loss=7.691758101391966e-05
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 7.679974696702111e-05
634, epoch_train_loss=7.679974696702111e-05
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 7.668245893606912e-05
635, epoch_train_loss=7.668245893606912e-05
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 7.656571420552202e-05
636, epoch_train_loss=7.656571420552202e-05
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 7.644951161914036e-05
637, epoch_train_loss=7.644951161914036e-05
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 7.633385376922879e-05
638, epoch_train_loss=7.633385376922879e-05
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 7.621874886031075e-05
639, epoch_train_loss=7.621874886031075e-05
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 7.610421718815647e-05
640, epoch_train_loss=7.610421718815647e-05
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 7.599029963574129e-05
641, epoch_train_loss=7.599029963574129e-05
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 7.587707926945002e-05
642, epoch_train_loss=7.587707926945002e-05
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 7.576471703691957e-05
643, epoch_train_loss=7.576471703691957e-05
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 7.56535308536651e-05
644, epoch_train_loss=7.56535308536651e-05
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 7.554414357664747e-05
645, epoch_train_loss=7.554414357664747e-05
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 7.543779417989049e-05
646, epoch_train_loss=7.543779417989049e-05
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 7.533696430487274e-05
647, epoch_train_loss=7.533696430487274e-05
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 7.524667075838757e-05
648, epoch_train_loss=7.524667075838757e-05
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 7.517721238243988e-05
649, epoch_train_loss=7.517721238243988e-05
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 7.514978196558108e-05
650, epoch_train_loss=7.514978196558108e-05
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 7.520902778662408e-05
651, epoch_train_loss=7.520902778662408e-05
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 7.544831145306454e-05
652, epoch_train_loss=7.544831145306454e-05
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 7.607001620370572e-05
653, epoch_train_loss=7.607001620370572e-05
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 7.750213003253638e-05
654, epoch_train_loss=7.750213003253638e-05
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 8.07049090266408e-05
655, epoch_train_loss=8.07049090266408e-05
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 8.771160623182108e-05
656, epoch_train_loss=8.771160623182108e-05
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.00010330393679890506
657, epoch_train_loss=0.00010330393679890506
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.00013740620178199662
658, epoch_train_loss=0.00013740620178199662
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.00021513490947504694
659, epoch_train_loss=0.00021513490947504694
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.00038516897929233426
660, epoch_train_loss=0.00038516897929233426
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0007874193131062118
661, epoch_train_loss=0.0007874193131062118
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.001644628732873782
662, epoch_train_loss=0.001644628732873782
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0037706645701773927
663, epoch_train_loss=0.0037706645701773927
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.007791648591555923
664, epoch_train_loss=0.007791648591555923
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.018005759703581502
665, epoch_train_loss=0.018005759703581502
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.029595235874979135
666, epoch_train_loss=0.029595235874979135
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.05479124637612584
667, epoch_train_loss=0.05479124637612584
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.041721779593233636
668, epoch_train_loss=0.041721779593233636
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.026008595086824886
669, epoch_train_loss=0.026008595086824886
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.0016094007084830274
670, epoch_train_loss=0.0016094007084830274
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.008827599124640135
671, epoch_train_loss=0.008827599124640135
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.027835118001541637
672, epoch_train_loss=0.027835118001541637
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.011910120237365157
673, epoch_train_loss=0.011910120237365157
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.00024828956210979286
674, epoch_train_loss=0.00024828956210979286
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.00940904143800384
675, epoch_train_loss=0.00940904143800384
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.010794436421194755
676, epoch_train_loss=0.010794436421194755
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.002091462534794985
677, epoch_train_loss=0.002091462534794985
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.002312800238955937
678, epoch_train_loss=0.002312800238955937
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.007682276963163183
679, epoch_train_loss=0.007682276963163183
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0037680981360940875
680, epoch_train_loss=0.0037680981360940875
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0006707957068152271
681, epoch_train_loss=0.0006707957068152271
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.005637406749696963
682, epoch_train_loss=0.005637406749696963
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.0042146104144587145
683, epoch_train_loss=0.0042146104144587145
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0004057187362914718
684, epoch_train_loss=0.0004057187362914718
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.004361758002777497
685, epoch_train_loss=0.004361758002777497
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.003976381925648798
686, epoch_train_loss=0.003976381925648798
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.00036808555677733077
687, epoch_train_loss=0.00036808555677733077
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.003600016781938301
688, epoch_train_loss=0.003600016781938301
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.00345773281618541
689, epoch_train_loss=0.00345773281618541
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0003622850714935667
690, epoch_train_loss=0.0003622850714935667
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0030454956205394996
691, epoch_train_loss=0.0030454956205394996
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.002931106125435343
692, epoch_train_loss=0.002931106125435343
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.00034858542920789383
693, epoch_train_loss=0.00034858542920789383
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.002602422736007342
694, epoch_train_loss=0.002602422736007342
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0024509384980449917
695, epoch_train_loss=0.0024509384980449917
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.00033804291547834655
696, epoch_train_loss=0.00033804291547834655
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.002194933766037629
697, epoch_train_loss=0.002194933766037629
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.002045531015198664
698, epoch_train_loss=0.002045531015198664
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0003128594494116116
699, epoch_train_loss=0.0003128594494116116
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0018243751733507767
700, epoch_train_loss=0.0018243751733507767
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.001715383050600948
701, epoch_train_loss=0.001715383050600948
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.0002885852140782303
702, epoch_train_loss=0.0002885852140782303
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0014808563084035742
703, epoch_train_loss=0.0014808563084035742
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.0014590721100306383
704, epoch_train_loss=0.0014590721100306383
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.00026545777131977235
705, epoch_train_loss=0.00026545777131977235
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0011679027085501914
706, epoch_train_loss=0.0011679027085501914
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0012526183185729677
707, epoch_train_loss=0.0012526183185729677
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0002507753489102155
708, epoch_train_loss=0.0002507753489102155
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0008852204135199392
709, epoch_train_loss=0.0008852204135199392
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.0010798705866856024
710, epoch_train_loss=0.0010798705866856024
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.00024950109291536264
711, epoch_train_loss=0.00024950109291536264
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0006438948421832838
712, epoch_train_loss=0.0006438948421832838
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.0009191725493178488
713, epoch_train_loss=0.0009191725493178488
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.0002647477805927199
714, epoch_train_loss=0.0002647477805927199
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.0004447729595775344
715, epoch_train_loss=0.0004447729595775344
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.000761528377994635
716, epoch_train_loss=0.000761528377994635
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0002881026353473702
717, epoch_train_loss=0.0002881026353473702
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.00029605861234839685
718, epoch_train_loss=0.00029605861234839685
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0006029829263888296
719, epoch_train_loss=0.0006029829263888296
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.00031206221484058716
720, epoch_train_loss=0.00031206221484058716
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0001999138289373429
721, epoch_train_loss=0.0001999138289373429
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.0004511776843285086
722, epoch_train_loss=0.0004511776843285086
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.00032417061645252643
723, epoch_train_loss=0.00032417061645252643
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.00015666800823739031
724, epoch_train_loss=0.00015666800823739031
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.000316137956117914
725, epoch_train_loss=0.000316137956117914
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0003166077313883456
726, epoch_train_loss=0.0003166077313883456
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.00015466435344447057
727, epoch_train_loss=0.00015466435344447057
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0002130749473370871
728, epoch_train_loss=0.0002130749473370871
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0002839206488241488
729, epoch_train_loss=0.0002839206488241488
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.00017561325497279136
730, epoch_train_loss=0.00017561325497279136
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.00015091042006298367
731, epoch_train_loss=0.00015091042006298367
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.00023248659923596105
732, epoch_train_loss=0.00023248659923596105
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.00019521149820581825
733, epoch_train_loss=0.00019521149820581825
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.00012946158796905936
734, epoch_train_loss=0.00012946158796905936
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.00017692965390058175
735, epoch_train_loss=0.00017692965390058175
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.00019565479431020932
736, epoch_train_loss=0.00019565479431020932
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0001353046401694313
737, epoch_train_loss=0.0001353046401694313
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.00013517834842030925
738, epoch_train_loss=0.00013517834842030925
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.00017366810815194926
739, epoch_train_loss=0.00017366810815194926
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.00014766679884731313
740, epoch_train_loss=0.00014766679884731313
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.00011790240776532882
741, epoch_train_loss=0.00011790240776532882
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.00014163917315683833
742, epoch_train_loss=0.00014163917315683833
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.0001493854505376776
743, epoch_train_loss=0.0001493854505376776
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.00012056653600230208
744, epoch_train_loss=0.00012056653600230208
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.00011747619549644364
745, epoch_train_loss=0.00011747619549644364
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.00013608400621739324
746, epoch_train_loss=0.00013608400621739324
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.00012760932380469252
747, epoch_train_loss=0.00012760932380469252
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.00010989858566615121
748, epoch_train_loss=0.00010989858566615121
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0001174726942851259
749, epoch_train_loss=0.0001174726942851259
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0001255856970458824
750, epoch_train_loss=0.0001255856970458824
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0001132343898130173
751, epoch_train_loss=0.0001132343898130173
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.00010615558507951853
752, epoch_train_loss=0.00010615558507951853
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.00011441660696158731
753, epoch_train_loss=0.00011441660696158731
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.00011509515280764247
754, epoch_train_loss=0.00011509515280764247
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.00010531545724519664
755, epoch_train_loss=0.00010531545724519664
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.00010394894781666755
756, epoch_train_loss=0.00010394894781666755
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.00010958723544601798
757, epoch_train_loss=0.00010958723544601798
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.00010737092210506986
758, epoch_train_loss=0.00010737092210506986
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.0001008690240014078
759, epoch_train_loss=0.0001008690240014078
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.00010159404621010314
760, epoch_train_loss=0.00010159404621010314
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.00010479991850259165
761, epoch_train_loss=0.00010479991850259165
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.00010192444675398605
762, epoch_train_loss=0.00010192444675398605
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 9.790925298526533e-05
763, epoch_train_loss=9.790925298526533e-05
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 9.898410016112742e-05
764, epoch_train_loss=9.898410016112742e-05
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.00010058403722391767
765, epoch_train_loss=0.00010058403722391767
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 9.811175650629173e-05
766, epoch_train_loss=9.811175650629173e-05
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 9.557383595878944e-05
767, epoch_train_loss=9.557383595878944e-05
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 9.639541913859143e-05
768, epoch_train_loss=9.639541913859143e-05
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 9.717304299055347e-05
769, epoch_train_loss=9.717304299055347e-05
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 9.52729709965624e-05
770, epoch_train_loss=9.52729709965624e-05
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 9.354592003136476e-05
771, epoch_train_loss=9.354592003136476e-05
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 9.400832265177521e-05
772, epoch_train_loss=9.400832265177521e-05
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 9.437424403302034e-05
773, epoch_train_loss=9.437424403302034e-05
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 9.301836500515201e-05
774, epoch_train_loss=9.301836500515201e-05
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 9.17289029827284e-05
775, epoch_train_loss=9.17289029827284e-05
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 9.187383038768158e-05
776, epoch_train_loss=9.187383038768158e-05
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 9.205723538399004e-05
777, epoch_train_loss=9.205723538399004e-05
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 9.11165061259701e-05
778, epoch_train_loss=9.11165061259701e-05
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 9.009350922119878e-05
779, epoch_train_loss=9.009350922119878e-05
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 8.999645854873388e-05
780, epoch_train_loss=8.999645854873388e-05
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 9.007406539631124e-05
781, epoch_train_loss=9.007406539631124e-05
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 8.944903895598016e-05
782, epoch_train_loss=8.944903895598016e-05
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 8.861989394651997e-05
783, epoch_train_loss=8.861989394651997e-05
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 8.835138867556025e-05
784, epoch_train_loss=8.835138867556025e-05
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 8.834498264967092e-05
785, epoch_train_loss=8.834498264967092e-05
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 8.794096632071194e-05
786, epoch_train_loss=8.794096632071194e-05
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 8.727985877175906e-05
787, epoch_train_loss=8.727985877175906e-05
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 8.690673711445102e-05
788, epoch_train_loss=8.690673711445102e-05
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 8.681052543942838e-05
789, epoch_train_loss=8.681052543942838e-05
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 8.655023899061112e-05
790, epoch_train_loss=8.655023899061112e-05
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 8.604483767943278e-05
791, epoch_train_loss=8.604483767943278e-05
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 8.562996908383704e-05
792, epoch_train_loss=8.562996908383704e-05
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 8.544397127887805e-05
793, epoch_train_loss=8.544397127887805e-05
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 8.525279253822312e-05
794, epoch_train_loss=8.525279253822312e-05
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 8.488557289798013e-05
795, epoch_train_loss=8.488557289798013e-05
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 8.448538186607967e-05
796, epoch_train_loss=8.448538186607967e-05
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 8.42265238547625e-05
797, epoch_train_loss=8.42265238547625e-05
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 8.404442405518583e-05
798, epoch_train_loss=8.404442405518583e-05
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 8.378004086238482e-05
799, epoch_train_loss=8.378004086238482e-05
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 8.343582839149797e-05
800, epoch_train_loss=8.343582839149797e-05
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 8.313940715437257e-05
801, epoch_train_loss=8.313940715437257e-05
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 8.293018317911133e-05
802, epoch_train_loss=8.293018317911133e-05
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 8.272035974119264e-05
803, epoch_train_loss=8.272035974119264e-05
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 8.244622567350242e-05
804, epoch_train_loss=8.244622567350242e-05
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 8.215506148246563e-05
805, epoch_train_loss=8.215506148246563e-05
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 8.191479154684601e-05
806, epoch_train_loss=8.191479154684601e-05
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 8.171413846933924e-05
807, epoch_train_loss=8.171413846933924e-05
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 8.149432413980728e-05
808, epoch_train_loss=8.149432413980728e-05
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 8.123961007016625e-05
809, epoch_train_loss=8.123961007016625e-05
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 8.099041058892162e-05
810, epoch_train_loss=8.099041058892162e-05
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 8.077627682741237e-05
811, epoch_train_loss=8.077627682741237e-05
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 8.057843917378413e-05
812, epoch_train_loss=8.057843917378413e-05
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 8.03643761900222e-05
813, epoch_train_loss=8.03643761900222e-05
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 8.013366427971076e-05
814, epoch_train_loss=8.013366427971076e-05
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 7.991190099596755e-05
815, epoch_train_loss=7.991190099596755e-05
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 7.97118127171703e-05
816, epoch_train_loss=7.97118127171703e-05
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 7.95195261223215e-05
817, epoch_train_loss=7.95195261223215e-05
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 7.931746321976712e-05
818, epoch_train_loss=7.931746321976712e-05
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 7.910739415387665e-05
819, epoch_train_loss=7.910739415387665e-05
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 7.890406396898013e-05
820, epoch_train_loss=7.890406396898013e-05
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 7.871413882680906e-05
821, epoch_train_loss=7.871413882680906e-05
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 7.852963089341991e-05
822, epoch_train_loss=7.852963089341991e-05
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 7.834046190282466e-05
823, epoch_train_loss=7.834046190282466e-05
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 7.814708749932934e-05
824, epoch_train_loss=7.814708749932934e-05
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 7.795759727789179e-05
825, epoch_train_loss=7.795759727789179e-05
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 7.777658548229394e-05
826, epoch_train_loss=7.777658548229394e-05
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 7.760039039020595e-05
827, epoch_train_loss=7.760039039020595e-05
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 7.742297256050426e-05
828, epoch_train_loss=7.742297256050426e-05
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 7.724330944511559e-05
829, epoch_train_loss=7.724330944511559e-05
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 7.706539522067411e-05
830, epoch_train_loss=7.706539522067411e-05
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 7.689272583762332e-05
831, epoch_train_loss=7.689272583762332e-05
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 7.672442129014351e-05
832, epoch_train_loss=7.672442129014351e-05
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 7.655707323709084e-05
833, epoch_train_loss=7.655707323709084e-05
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 7.638893186160791e-05
834, epoch_train_loss=7.638893186160791e-05
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 7.622136698505504e-05
835, epoch_train_loss=7.622136698505504e-05
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 7.605675371238846e-05
836, epoch_train_loss=7.605675371238846e-05
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 7.589569249262831e-05
837, epoch_train_loss=7.589569249262831e-05
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 7.573674269837332e-05
838, epoch_train_loss=7.573674269837332e-05
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 7.557828304019015e-05
839, epoch_train_loss=7.557828304019015e-05
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 7.542014557281416e-05
840, epoch_train_loss=7.542014557281416e-05
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 7.52634645974658e-05
841, epoch_train_loss=7.52634645974658e-05
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 7.510922247956869e-05
842, epoch_train_loss=7.510922247956869e-05
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 7.495731273768938e-05
843, epoch_train_loss=7.495731273768938e-05
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 7.480682890507193e-05
844, epoch_train_loss=7.480682890507193e-05
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 7.465707092865394e-05
845, epoch_train_loss=7.465707092865394e-05
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 7.450813892193316e-05
846, epoch_train_loss=7.450813892193316e-05
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 7.436063018239313e-05
847, epoch_train_loss=7.436063018239313e-05
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 7.421497582367645e-05
848, epoch_train_loss=7.421497582367645e-05
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 7.40710512491867e-05
849, epoch_train_loss=7.40710512491867e-05
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 7.392838781889141e-05
850, epoch_train_loss=7.392838781889141e-05
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 7.378663836924545e-05
851, epoch_train_loss=7.378663836924545e-05
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 7.36458221791492e-05
852, epoch_train_loss=7.36458221791492e-05
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 7.350622073182814e-05
853, epoch_train_loss=7.350622073182814e-05
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 7.336805370483684e-05
854, epoch_train_loss=7.336805370483684e-05
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 7.323129955274436e-05
855, epoch_train_loss=7.323129955274436e-05
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 7.309574412188426e-05
856, epoch_train_loss=7.309574412188426e-05
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 7.29611756581711e-05
857, epoch_train_loss=7.29611756581711e-05
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 7.282754149511891e-05
858, epoch_train_loss=7.282754149511891e-05
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 7.2694930970994e-05
859, epoch_train_loss=7.2694930970994e-05
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 7.256346807353931e-05
860, epoch_train_loss=7.256346807353931e-05
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 7.243319068217018e-05
861, epoch_train_loss=7.243319068217018e-05
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 7.23040295537365e-05
862, epoch_train_loss=7.23040295537365e-05
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 7.217587063528062e-05
863, epoch_train_loss=7.217587063528062e-05
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 7.20486300783335e-05
864, epoch_train_loss=7.20486300783335e-05
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 7.192229977815208e-05
865, epoch_train_loss=7.192229977815208e-05
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 7.179691948256209e-05
866, epoch_train_loss=7.179691948256209e-05
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 7.167253186053752e-05
867, epoch_train_loss=7.167253186053752e-05
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 7.15491405275245e-05
868, epoch_train_loss=7.15491405275245e-05
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 7.142670655626174e-05
869, epoch_train_loss=7.142670655626174e-05
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 7.13051746593744e-05
870, epoch_train_loss=7.13051746593744e-05
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 7.11845000379663e-05
871, epoch_train_loss=7.11845000379663e-05
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 7.106466742871961e-05
872, epoch_train_loss=7.106466742871961e-05
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 7.09456825446666e-05
873, epoch_train_loss=7.09456825446666e-05
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 7.082755786473965e-05
874, epoch_train_loss=7.082755786473965e-05
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 7.071029455536943e-05
875, epoch_train_loss=7.071029455536943e-05
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 7.059387773589622e-05
876, epoch_train_loss=7.059387773589622e-05
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 7.047828126333077e-05
877, epoch_train_loss=7.047828126333077e-05
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 7.036347721631772e-05
878, epoch_train_loss=7.036347721631772e-05
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 7.02494456689163e-05
879, epoch_train_loss=7.02494456689163e-05
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 7.013617542716267e-05
880, epoch_train_loss=7.013617542716267e-05
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 7.002366350970774e-05
881, epoch_train_loss=7.002366350970774e-05
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 6.991190721139463e-05
882, epoch_train_loss=6.991190721139463e-05
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 6.980090159166636e-05
883, epoch_train_loss=6.980090159166636e-05
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 6.969063602978923e-05
884, epoch_train_loss=6.969063602978923e-05
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 6.958109613435227e-05
885, epoch_train_loss=6.958109613435227e-05
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 6.947226652137387e-05
886, epoch_train_loss=6.947226652137387e-05
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 6.936413253455356e-05
887, epoch_train_loss=6.936413253455356e-05
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 6.925668319141768e-05
888, epoch_train_loss=6.925668319141768e-05
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 6.914990931314862e-05
889, epoch_train_loss=6.914990931314862e-05
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 6.904380439603548e-05
890, epoch_train_loss=6.904380439603548e-05
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 6.893836150776293e-05
891, epoch_train_loss=6.893836150776293e-05
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 6.883357360473876e-05
892, epoch_train_loss=6.883357360473876e-05
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 6.872943219590455e-05
893, epoch_train_loss=6.872943219590455e-05
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 6.86259279224812e-05
894, epoch_train_loss=6.86259279224812e-05
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 6.85230510333521e-05
895, epoch_train_loss=6.85230510333521e-05
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 6.842079163418718e-05
896, epoch_train_loss=6.842079163418718e-05
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 6.831914071106546e-05
897, epoch_train_loss=6.831914071106546e-05
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 6.821808950398586e-05
898, epoch_train_loss=6.821808950398586e-05
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 6.811763046594823e-05
899, epoch_train_loss=6.811763046594823e-05
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 6.801775598622917e-05
900, epoch_train_loss=6.801775598622917e-05
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 6.791845928378004e-05
901, epoch_train_loss=6.791845928378004e-05
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 6.781973319308449e-05
902, epoch_train_loss=6.781973319308449e-05
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 6.772157093181487e-05
903, epoch_train_loss=6.772157093181487e-05
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 6.76239653647026e-05
904, epoch_train_loss=6.76239653647026e-05
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 6.752690949661766e-05
905, epoch_train_loss=6.752690949661766e-05
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 6.74303962666468e-05
906, epoch_train_loss=6.74303962666468e-05
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 6.733441867551684e-05
907, epoch_train_loss=6.733441867551684e-05
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 6.723896993096036e-05
908, epoch_train_loss=6.723896993096036e-05
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 6.714404323457451e-05
909, epoch_train_loss=6.714404323457451e-05
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 6.704963216310097e-05
910, epoch_train_loss=6.704963216310097e-05
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 6.695573021523227e-05
911, epoch_train_loss=6.695573021523227e-05
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 6.686233131738791e-05
912, epoch_train_loss=6.686233131738791e-05
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 6.676942923076849e-05
913, epoch_train_loss=6.676942923076849e-05
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 6.667701818350098e-05
914, epoch_train_loss=6.667701818350098e-05
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 6.658509215663741e-05
915, epoch_train_loss=6.658509215663741e-05
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 6.649364559137512e-05
916, epoch_train_loss=6.649364559137512e-05
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 6.640267268290998e-05
917, epoch_train_loss=6.640267268290998e-05
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 6.631216805771459e-05
918, epoch_train_loss=6.631216805771459e-05
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 6.622212610168467e-05
919, epoch_train_loss=6.622212610168467e-05
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 6.613254162670412e-05
920, epoch_train_loss=6.613254162670412e-05
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 6.604340920118867e-05
921, epoch_train_loss=6.604340920118867e-05
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 6.59547238313172e-05
922, epoch_train_loss=6.59547238313172e-05
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 6.586648027174685e-05
923, epoch_train_loss=6.586648027174685e-05
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 6.577867373924021e-05
924, epoch_train_loss=6.577867373924021e-05
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 6.569129918606845e-05
925, epoch_train_loss=6.569129918606845e-05
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 6.560435208681702e-05
926, epoch_train_loss=6.560435208681702e-05
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 6.551782762527492e-05
927, epoch_train_loss=6.551782762527492e-05
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 6.543172163259583e-05
928, epoch_train_loss=6.543172163259583e-05
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 6.534602962721783e-05
929, epoch_train_loss=6.534602962721783e-05
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 6.526074803830976e-05
930, epoch_train_loss=6.526074803830976e-05
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 6.517587303332155e-05
931, epoch_train_loss=6.517587303332155e-05
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 6.509140219909422e-05
932, epoch_train_loss=6.509140219909422e-05
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 6.500733318883879e-05
933, epoch_train_loss=6.500733318883879e-05
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 6.492366627265337e-05
934, epoch_train_loss=6.492366627265337e-05
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 6.484040289361719e-05
935, epoch_train_loss=6.484040289361719e-05
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 6.47575501130059e-05
936, epoch_train_loss=6.47575501130059e-05
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 6.467511983334819e-05
937, epoch_train_loss=6.467511983334819e-05
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 6.459313757433937e-05
938, epoch_train_loss=6.459313757433937e-05
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 6.451164533520637e-05
939, epoch_train_loss=6.451164533520637e-05
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 6.443072175907477e-05
940, epoch_train_loss=6.443072175907477e-05
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 6.435049904569945e-05
941, epoch_train_loss=6.435049904569945e-05
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 6.427121598512023e-05
942, epoch_train_loss=6.427121598512023e-05
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 6.419328552180619e-05
943, epoch_train_loss=6.419328552180619e-05
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 6.411745018479772e-05
944, epoch_train_loss=6.411745018479772e-05
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 6.404503030846449e-05
945, epoch_train_loss=6.404503030846449e-05
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 6.39784172013247e-05
946, epoch_train_loss=6.39784172013247e-05
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 6.392197660641691e-05
947, epoch_train_loss=6.392197660641691e-05
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 6.38837045960285e-05
948, epoch_train_loss=6.38837045960285e-05
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 6.387858276531761e-05
949, epoch_train_loss=6.387858276531761e-05
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 6.393435973667952e-05
950, epoch_train_loss=6.393435973667952e-05
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 6.41044642610373e-05
951, epoch_train_loss=6.41044642610373e-05
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 6.448866814009621e-05
952, epoch_train_loss=6.448866814009621e-05
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 6.528519748067154e-05
953, epoch_train_loss=6.528519748067154e-05
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 6.686471688451557e-05
954, epoch_train_loss=6.686471688451557e-05
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 6.999363399487405e-05
955, epoch_train_loss=6.999363399487405e-05
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 7.608816523791539e-05
956, epoch_train_loss=7.608816523791539e-05
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 8.824636213079408e-05
957, epoch_train_loss=8.824636213079408e-05
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.00011198294268020656
958, epoch_train_loss=0.00011198294268020656
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.00016046629756681505
959, epoch_train_loss=0.00016046629756681505
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0002551403272448543
960, epoch_train_loss=0.0002551403272448543
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0004553294843643249
961, epoch_train_loss=0.0004553294843643249
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.0008397056930061551
962, epoch_train_loss=0.0008397056930061551
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0016925465761007412
963, epoch_train_loss=0.0016925465761007412
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.003229396051718342
964, epoch_train_loss=0.003229396051718342
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.006855919701412879
965, epoch_train_loss=0.006855919701412879
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.012190844839916228
966, epoch_train_loss=0.012190844839916228
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.02540437091182976
967, epoch_train_loss=0.02540437091182976
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.034365030399369584
968, epoch_train_loss=0.034365030399369584
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0566813571719763
969, epoch_train_loss=0.0566813571719763
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.037520900768411504
970, epoch_train_loss=0.037520900768411504
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.02186655832401892
971, epoch_train_loss=0.02186655832401892
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.0019738554469139174
972, epoch_train_loss=0.0019738554469139174
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.005005525261322359
973, epoch_train_loss=0.005005525261322359
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.020389536071019253
974, epoch_train_loss=0.020389536071019253
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.015810456964021075
975, epoch_train_loss=0.015810456964021075
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.004840141333672349
976, epoch_train_loss=0.004840141333672349
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0006834118721778209
977, epoch_train_loss=0.0006834118721778209
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.00860569125811392
978, epoch_train_loss=0.00860569125811392
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.012577570667604765
979, epoch_train_loss=0.012577570667604765
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.002771019908197364
980, epoch_train_loss=0.002771019908197364
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0014904791500522348
981, epoch_train_loss=0.0014904791500522348
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.008184255926454671
982, epoch_train_loss=0.008184255926454671
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.005342608110861673
983, epoch_train_loss=0.005342608110861673
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0005045789212665394
984, epoch_train_loss=0.0005045789212665394
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.0025604593477036616
985, epoch_train_loss=0.0025604593477036616
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.004822833951344555
986, epoch_train_loss=0.004822833951344555
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.002232160406987953
987, epoch_train_loss=0.002232160406987953
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.00045903706923008334
988, epoch_train_loss=0.00045903706923008334
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.0030331814964066717
989, epoch_train_loss=0.0030331814964066717
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.0033459519012819243
990, epoch_train_loss=0.0033459519012819243
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0005910780209692625
991, epoch_train_loss=0.0005910780209692625
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0013213471562359134
992, epoch_train_loss=0.0013213471562359134
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0030280144644521147
993, epoch_train_loss=0.0030280144644521147
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.0011865070530857754
994, epoch_train_loss=0.0011865070530857754
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0004588628405501521
995, epoch_train_loss=0.0004588628405501521
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0018639932551197816
996, epoch_train_loss=0.0018639932551197816
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.001529179375473751
997, epoch_train_loss=0.001529179375473751
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.0003312630687444268
998, epoch_train_loss=0.0003312630687444268
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.0008236565491480509
999, epoch_train_loss=0.0008236565491480509
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.001358480261893946
1000, epoch_train_loss=0.001358480261893946
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.0006667832763805307
1001, epoch_train_loss=0.0006667832763805307
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.00029093341782751743
1002, epoch_train_loss=0.00029093341782751743
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0009067411679615253
1003, epoch_train_loss=0.0009067411679615253
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0009045399740526553
1004, epoch_train_loss=0.0009045399740526553
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.0002890498676141321
1005, epoch_train_loss=0.0002890498676141321
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.0004126773260888464
1006, epoch_train_loss=0.0004126773260888464
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0008017547133408763
1007, epoch_train_loss=0.0008017547133408763
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.00047751946031321857
1008, epoch_train_loss=0.00047751946031321857
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.00019786474858749946
1009, epoch_train_loss=0.00019786474858749946
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.000449319075647445
1010, epoch_train_loss=0.000449319075647445
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.0005458457190232278
1011, epoch_train_loss=0.0005458457190232278
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.00027191785871365714
1012, epoch_train_loss=0.00027191785871365714
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.0001920994785924347
1013, epoch_train_loss=0.0001920994785924347
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.00038951798017237944
1014, epoch_train_loss=0.00038951798017237944
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0003845712685988879
1015, epoch_train_loss=0.0003845712685988879
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.00018374941917848975
1016, epoch_train_loss=0.00018374941917848975
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.00018775781240525612
1017, epoch_train_loss=0.00018775781240525612
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0003219265980748344
1018, epoch_train_loss=0.0003219265980748344
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.00026798640188565844
1019, epoch_train_loss=0.00026798640188565844
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0001450070434702305
1020, epoch_train_loss=0.0001450070434702305
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0001708767549573138
1021, epoch_train_loss=0.0001708767549573138
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0002504874527225707
1022, epoch_train_loss=0.0002504874527225707
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.00020697772460930716
1023, epoch_train_loss=0.00020697772460930716
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.00012702262446919602
1024, epoch_train_loss=0.00012702262446919602
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.0001490569809083247
1025, epoch_train_loss=0.0001490569809083247
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.00020152065685811262
1026, epoch_train_loss=0.00020152065685811262
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0001693788141145502
1027, epoch_train_loss=0.0001693788141145502
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.00011576111165833653
1028, epoch_train_loss=0.00011576111165833653
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.00012810930765768278
1029, epoch_train_loss=0.00012810930765768278
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.00016240375175015636
1030, epoch_train_loss=0.00016240375175015636
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.00014763546686198269
1031, epoch_train_loss=0.00014763546686198269
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.00010945665937272079
1032, epoch_train_loss=0.00010945665937272079
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.00011162778282375934
1033, epoch_train_loss=0.00011162778282375934
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0001358021098212135
1034, epoch_train_loss=0.0001358021098212135
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.00013152571511436826
1035, epoch_train_loss=0.00013152571511436826
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.00010572407948908107
1036, epoch_train_loss=0.00010572407948908107
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.00010010932147026864
1037, epoch_train_loss=0.00010010932147026864
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.00011535520155900403
1038, epoch_train_loss=0.00011535520155900403
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.00011899008063317216
1039, epoch_train_loss=0.00011899008063317216
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.00010339900693012427
1040, epoch_train_loss=0.00010339900693012427
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 9.354742930839209e-05
1041, epoch_train_loss=9.354742930839209e-05
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.00010085316018505762
1042, epoch_train_loss=0.00010085316018505762
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.00010736427517811942
1043, epoch_train_loss=0.00010736427517811942
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.00010077894784458025
1044, epoch_train_loss=0.00010077894784458025
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 9.086899900189594e-05
1045, epoch_train_loss=9.086899900189594e-05
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 9.133058660049677e-05
1046, epoch_train_loss=9.133058660049677e-05
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 9.725711221962237e-05
1047, epoch_train_loss=9.725711221962237e-05
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 9.675983095398376e-05
1048, epoch_train_loss=9.675983095398376e-05
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 9.003503859798089e-05
1049, epoch_train_loss=9.003503859798089e-05
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 8.635355387178804e-05
1050, epoch_train_loss=8.635355387178804e-05
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 8.905779018091718e-05
1051, epoch_train_loss=8.905779018091718e-05
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 9.146258964015933e-05
1052, epoch_train_loss=9.146258964015933e-05
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 8.889407745262045e-05
1053, epoch_train_loss=8.889407745262045e-05
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 8.459859953785566e-05
1054, epoch_train_loss=8.459859953785566e-05
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 8.381757175788206e-05
1055, epoch_train_loss=8.381757175788206e-05
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 8.581410651277889e-05
1056, epoch_train_loss=8.581410651277889e-05
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 8.627930672156997e-05
1057, epoch_train_loss=8.627930672156997e-05
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 8.388608236344749e-05
1058, epoch_train_loss=8.388608236344749e-05
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 8.148390567992828e-05
1059, epoch_train_loss=8.148390567992828e-05
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 8.148702375621093e-05
1060, epoch_train_loss=8.148702375621093e-05
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 8.256683040574447e-05
1061, epoch_train_loss=8.256683040574447e-05
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 8.236944943255703e-05
1062, epoch_train_loss=8.236944943255703e-05
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 8.062563168038359e-05
1063, epoch_train_loss=8.062563168038359e-05
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 7.923067186344336e-05
1064, epoch_train_loss=7.923067186344336e-05
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 7.925560820571448e-05
1065, epoch_train_loss=7.925560820571448e-05
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 7.97703914823186e-05
1066, epoch_train_loss=7.97703914823186e-05
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 7.946740807457721e-05
1067, epoch_train_loss=7.946740807457721e-05
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 7.829660940311504e-05
1068, epoch_train_loss=7.829660940311504e-05
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 7.736926050792056e-05
1069, epoch_train_loss=7.736926050792056e-05
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 7.725484552320418e-05
1070, epoch_train_loss=7.725484552320418e-05
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 7.746693053610234e-05
1071, epoch_train_loss=7.746693053610234e-05
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 7.72281704246214e-05
1072, epoch_train_loss=7.72281704246214e-05
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 7.646572734800883e-05
1073, epoch_train_loss=7.646572734800883e-05
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 7.577290017768367e-05
1074, epoch_train_loss=7.577290017768367e-05
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 7.553407994049701e-05
1075, epoch_train_loss=7.553407994049701e-05
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 7.556829814637787e-05
1076, epoch_train_loss=7.556829814637787e-05
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 7.540779367279874e-05
1077, epoch_train_loss=7.540779367279874e-05
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 7.492417605885774e-05
1078, epoch_train_loss=7.492417605885774e-05
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 7.438262007886211e-05
1079, epoch_train_loss=7.438262007886211e-05
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 7.406889417084773e-05
1080, epoch_train_loss=7.406889417084773e-05
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 7.397638869680335e-05
1081, epoch_train_loss=7.397638869680335e-05
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 7.38569396311588e-05
1082, epoch_train_loss=7.38569396311588e-05
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 7.355961725910925e-05
1083, epoch_train_loss=7.355961725910925e-05
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 7.315237307807347e-05
1084, epoch_train_loss=7.315237307807347e-05
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 7.281824317553207e-05
1085, epoch_train_loss=7.281824317553207e-05
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 7.263239890661566e-05
1086, epoch_train_loss=7.263239890661566e-05
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 7.250560285472989e-05
1087, epoch_train_loss=7.250560285472989e-05
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 7.23165521088858e-05
1088, epoch_train_loss=7.23165521088858e-05
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 7.203083053842128e-05
1089, epoch_train_loss=7.203083053842128e-05
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 7.172821028164938e-05
1090, epoch_train_loss=7.172821028164938e-05
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 7.14900034521931e-05
1091, epoch_train_loss=7.14900034521931e-05
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 7.132478250498177e-05
1092, epoch_train_loss=7.132478250498177e-05
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 7.117354376917708e-05
1093, epoch_train_loss=7.117354376917708e-05
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 7.09777844056579e-05
1094, epoch_train_loss=7.09777844056579e-05
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 7.073962630416603e-05
1095, epoch_train_loss=7.073962630416603e-05
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 7.050102556219972e-05
1096, epoch_train_loss=7.050102556219972e-05
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 7.030155881325e-05
1097, epoch_train_loss=7.030155881325e-05
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 7.01394044860847e-05
1098, epoch_train_loss=7.01394044860847e-05
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 6.998254842048724e-05
1099, epoch_train_loss=6.998254842048724e-05
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 6.980489091491325e-05
1100, epoch_train_loss=6.980489091491325e-05
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 6.960491091023313e-05
1101, epoch_train_loss=6.960491091023313e-05
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 6.940504310332582e-05
1102, epoch_train_loss=6.940504310332582e-05
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 6.922438560521116e-05
1103, epoch_train_loss=6.922438560521116e-05
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 6.906492275616143e-05
1104, epoch_train_loss=6.906492275616143e-05
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 6.891308445522678e-05
1105, epoch_train_loss=6.891308445522678e-05
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 6.875327753053208e-05
1106, epoch_train_loss=6.875327753053208e-05
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 6.858258126353316e-05
1107, epoch_train_loss=6.858258126353316e-05
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 6.840840466303356e-05
1108, epoch_train_loss=6.840840466303356e-05
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 6.824185145841861e-05
1109, epoch_train_loss=6.824185145841861e-05
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 6.808748878894554e-05
1110, epoch_train_loss=6.808748878894554e-05
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 6.794113647533325e-05
1111, epoch_train_loss=6.794113647533325e-05
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 6.77955732101521e-05
1112, epoch_train_loss=6.77955732101521e-05
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 6.764547188836605e-05
1113, epoch_train_loss=6.764547188836605e-05
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 6.749186314752132e-05
1114, epoch_train_loss=6.749186314752132e-05
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 6.733926398981105e-05
1115, epoch_train_loss=6.733926398981105e-05
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 6.71918936635154e-05
1116, epoch_train_loss=6.71918936635154e-05
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 6.705098564554133e-05
1117, epoch_train_loss=6.705098564554133e-05
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 6.691403243044162e-05
1118, epoch_train_loss=6.691403243044162e-05
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 6.677787121739273e-05
1119, epoch_train_loss=6.677787121739273e-05
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 6.664041501225947e-05
1120, epoch_train_loss=6.664041501225947e-05
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 6.650198852612351e-05
1121, epoch_train_loss=6.650198852612351e-05
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 6.636460004537423e-05
1122, epoch_train_loss=6.636460004537423e-05
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 6.623001534004855e-05
1123, epoch_train_loss=6.623001534004855e-05
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 6.609903481651934e-05
1124, epoch_train_loss=6.609903481651934e-05
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 6.597089689142419e-05
1125, epoch_train_loss=6.597089689142419e-05
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 6.584423111432599e-05
1126, epoch_train_loss=6.584423111432599e-05
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 6.571796648537041e-05
1127, epoch_train_loss=6.571796648537041e-05
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 6.559174138710506e-05
1128, epoch_train_loss=6.559174138710506e-05
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 6.54661108693251e-05
1129, epoch_train_loss=6.54661108693251e-05
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 6.534184679784881e-05
1130, epoch_train_loss=6.534184679784881e-05
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 6.521954081926813e-05
1131, epoch_train_loss=6.521954081926813e-05
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 6.509932925319378e-05
1132, epoch_train_loss=6.509932925319378e-05
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 6.498082182726576e-05
1133, epoch_train_loss=6.498082182726576e-05
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 6.486353051780725e-05
1134, epoch_train_loss=6.486353051780725e-05
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 6.474701314344005e-05
1135, epoch_train_loss=6.474701314344005e-05
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 6.463112043400904e-05
1136, epoch_train_loss=6.463112043400904e-05
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 6.451599715053445e-05
1137, epoch_train_loss=6.451599715053445e-05
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 6.440187119235866e-05
1138, epoch_train_loss=6.440187119235866e-05
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 6.428900567338474e-05
1139, epoch_train_loss=6.428900567338474e-05
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 6.417749190441642e-05
1140, epoch_train_loss=6.417749190441642e-05
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 6.406727784190432e-05
1141, epoch_train_loss=6.406727784190432e-05
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 6.395822168880775e-05
1142, epoch_train_loss=6.395822168880775e-05
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 6.385012327783955e-05
1143, epoch_train_loss=6.385012327783955e-05
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 6.374286475889336e-05
1144, epoch_train_loss=6.374286475889336e-05
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 6.363638025179025e-05
1145, epoch_train_loss=6.363638025179025e-05
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 6.353068716265484e-05
1146, epoch_train_loss=6.353068716265484e-05
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 6.342584974552082e-05
1147, epoch_train_loss=6.342584974552082e-05
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 6.33219252272774e-05
1148, epoch_train_loss=6.33219252272774e-05
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 6.321895806850957e-05
1149, epoch_train_loss=6.321895806850957e-05
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 6.311695133488378e-05
1150, epoch_train_loss=6.311695133488378e-05
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 6.301587058195924e-05
1151, epoch_train_loss=6.301587058195924e-05
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 6.291567117870272e-05
1152, epoch_train_loss=6.291567117870272e-05
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 6.281629314697827e-05
1153, epoch_train_loss=6.281629314697827e-05
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 6.271769117561958e-05
1154, epoch_train_loss=6.271769117561958e-05
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 6.261983606134294e-05
1155, epoch_train_loss=6.261983606134294e-05
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 6.252270697840698e-05
1156, epoch_train_loss=6.252270697840698e-05
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 6.242630592490706e-05
1157, epoch_train_loss=6.242630592490706e-05
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 6.23306305982852e-05
1158, epoch_train_loss=6.23306305982852e-05
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 6.223568683396366e-05
1159, epoch_train_loss=6.223568683396366e-05
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 6.214147501643863e-05
1160, epoch_train_loss=6.214147501643863e-05
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 6.204798945281646e-05
1161, epoch_train_loss=6.204798945281646e-05
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 6.19552220552876e-05
1162, epoch_train_loss=6.19552220552876e-05
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 6.186315883652908e-05
1163, epoch_train_loss=6.186315883652908e-05
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 6.177178361433431e-05
1164, epoch_train_loss=6.177178361433431e-05
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 6.168108111441113e-05
1165, epoch_train_loss=6.168108111441113e-05
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 6.159103443789237e-05
1166, epoch_train_loss=6.159103443789237e-05
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 6.150162919243915e-05
1167, epoch_train_loss=6.150162919243915e-05
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 6.141285313779767e-05
1168, epoch_train_loss=6.141285313779767e-05
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 6.132469301697071e-05
1169, epoch_train_loss=6.132469301697071e-05
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 6.123714070465823e-05
1170, epoch_train_loss=6.123714070465823e-05
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 6.115018514852646e-05
1171, epoch_train_loss=6.115018514852646e-05
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 6.106381913713348e-05
1172, epoch_train_loss=6.106381913713348e-05
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 6.097803369749203e-05
1173, epoch_train_loss=6.097803369749203e-05
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 6.0892821463637685e-05
1174, epoch_train_loss=6.0892821463637685e-05
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 6.0808173942305375e-05
1175, epoch_train_loss=6.0808173942305375e-05
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 6.072408436755384e-05
1176, epoch_train_loss=6.072408436755384e-05
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 6.064054370667543e-05
1177, epoch_train_loss=6.064054370667543e-05
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 6.055754590641561e-05
1178, epoch_train_loss=6.055754590641561e-05
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 6.047508203543546e-05
1179, epoch_train_loss=6.047508203543546e-05
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 6.0393146194737586e-05
1180, epoch_train_loss=6.0393146194737586e-05
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 6.031173043660971e-05
1181, epoch_train_loss=6.031173043660971e-05
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 6.0230829274719767e-05
1182, epoch_train_loss=6.0230829274719767e-05
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 6.0150435845167295e-05
1183, epoch_train_loss=6.0150435845167295e-05
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 6.007054631033292e-05
1184, epoch_train_loss=6.007054631033292e-05
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 5.999115525318175e-05
1185, epoch_train_loss=5.999115525318175e-05
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 5.9912262014618794e-05
1186, epoch_train_loss=5.9912262014618794e-05
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 5.983386469048776e-05
1187, epoch_train_loss=5.983386469048776e-05
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 5.975596850005432e-05
1188, epoch_train_loss=5.975596850005432e-05
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 5.967857974913152e-05
1189, epoch_train_loss=5.967857974913152e-05
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 5.960171674492547e-05
1190, epoch_train_loss=5.960171674492547e-05
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 5.9525404835734214e-05
1191, epoch_train_loss=5.9525404835734214e-05
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 5.9449693518809607e-05
1192, epoch_train_loss=5.9449693518809607e-05
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 5.9374654876726216e-05
1193, epoch_train_loss=5.9374654876726216e-05
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 5.9300415268913784e-05
1194, epoch_train_loss=5.9300415268913784e-05
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 5.922716721966247e-05
1195, epoch_train_loss=5.922716721966247e-05
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 5.915523489048287e-05
1196, epoch_train_loss=5.915523489048287e-05
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 5.908513192445681e-05
1197, epoch_train_loss=5.908513192445681e-05
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 5.9017713229577247e-05
1198, epoch_train_loss=5.9017713229577247e-05
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 5.895437919004784e-05
1199, epoch_train_loss=5.895437919004784e-05
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 5.8897464172859e-05
1200, epoch_train_loss=5.8897464172859e-05
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 5.8850907661054106e-05
1201, epoch_train_loss=5.8850907661054106e-05
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 5.882131841778187e-05
1202, epoch_train_loss=5.882131841778187e-05
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 5.882017563029347e-05
1203, epoch_train_loss=5.882017563029347e-05
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 5.8866868213611555e-05
1204, epoch_train_loss=5.8866868213611555e-05
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 5.899610255248057e-05
1205, epoch_train_loss=5.899610255248057e-05
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 5.926673474174112e-05
1206, epoch_train_loss=5.926673474174112e-05
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 5.978777475453233e-05
1207, epoch_train_loss=5.978777475453233e-05
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 6.074360906700213e-05
1208, epoch_train_loss=6.074360906700213e-05
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 6.249049061117235e-05
1209, epoch_train_loss=6.249049061117235e-05
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 6.562219549804846e-05
1210, epoch_train_loss=6.562219549804846e-05
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 7.1353273690879e-05
1211, epoch_train_loss=7.1353273690879e-05
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 8.16356006807969e-05
1212, epoch_train_loss=8.16356006807969e-05
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.00010080741311375158
1213, epoch_train_loss=0.00010080741311375158
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.00013532941195198905
1214, epoch_train_loss=0.00013532941195198905
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.00020154283575561286
1215, epoch_train_loss=0.00020154283575561286
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.00032031680862553124
1216, epoch_train_loss=0.00032031680862553124
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.0005570561474455109
1217, epoch_train_loss=0.0005570561474455109
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.0009717791417981227
1218, epoch_train_loss=0.0009717791417981227
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0018431397708980964
1219, epoch_train_loss=0.0018431397708980964
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.003264966708350485
1220, epoch_train_loss=0.003264966708350485
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.006467894896407466
1221, epoch_train_loss=0.006467894896407466
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.010751960064464154
1222, epoch_train_loss=0.010751960064464154
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.021170102886437437
1223, epoch_train_loss=0.021170102886437437
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.028327817836735752
1224, epoch_train_loss=0.028327817836735752
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.04757783943645082
1225, epoch_train_loss=0.04757783943645082
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.03724396735620307
1226, epoch_train_loss=0.03724396735620307
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.03217845457403001
1227, epoch_train_loss=0.03217845457403001
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.008501487487803711
1228, epoch_train_loss=0.008501487487803711
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.00020646347507408507
1229, epoch_train_loss=0.00020646347507408507
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.007725584628154704
1230, epoch_train_loss=0.007725584628154704
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.015604943617195126
1231, epoch_train_loss=0.015604943617195126
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.016940862762009727
1232, epoch_train_loss=0.016940862762009727
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.004060388082942697
1233, epoch_train_loss=0.004060388082942697
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007501932573959068
1234, epoch_train_loss=0.0007501932573959068
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.007802737872592358
1235, epoch_train_loss=0.007802737872592358
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.009318936560682108
1236, epoch_train_loss=0.009318936560682108
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.004404464499539231
1237, epoch_train_loss=0.004404464499539231
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0002774622388854643
1238, epoch_train_loss=0.0002774622388854643
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0038364844272456827
1239, epoch_train_loss=0.0038364844272456827
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.007347097039871407
1240, epoch_train_loss=0.007347097039871407
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0028098293645454206
1241, epoch_train_loss=0.0028098293645454206
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.00033555809296982944
1242, epoch_train_loss=0.00033555809296982944
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.003057399954040378
1243, epoch_train_loss=0.003057399954040378
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.004010211015368829
1244, epoch_train_loss=0.004010211015368829
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0016142819797147184
1245, epoch_train_loss=0.0016142819797147184
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0003615293113445221
1246, epoch_train_loss=0.0003615293113445221
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0022019322138961987
1247, epoch_train_loss=0.0022019322138961987
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0029841346797116358
1248, epoch_train_loss=0.0029841346797116358
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.0008874850778096652
1249, epoch_train_loss=0.0008874850778096652
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0004717977084522261
1250, epoch_train_loss=0.0004717977084522261
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0019011851401654334
1251, epoch_train_loss=0.0019011851401654334
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.0017282249915048823
1252, epoch_train_loss=0.0017282249915048823
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.00047883148029086354
1253, epoch_train_loss=0.00047883148029086354
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0004641653258897575
1254, epoch_train_loss=0.0004641653258897575
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0013253269003068887
1255, epoch_train_loss=0.0013253269003068887
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.0012018386918918526
1256, epoch_train_loss=0.0012018386918918526
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0003291212300787811
1257, epoch_train_loss=0.0003291212300787811
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.00041673322593381226
1258, epoch_train_loss=0.00041673322593381226
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.0010252011507077762
1259, epoch_train_loss=0.0010252011507077762
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007839891012032572
1260, epoch_train_loss=0.0007839891012032572
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0002458034402851741
1261, epoch_train_loss=0.0002458034402851741
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0003233506245097773
1262, epoch_train_loss=0.0003233506245097773
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0006919272919052487
1263, epoch_train_loss=0.0006919272919052487
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0005923870535171962
1264, epoch_train_loss=0.0005923870535171962
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0002142345237467934
1265, epoch_train_loss=0.0002142345237467934
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.00023297699981850753
1266, epoch_train_loss=0.00023297699981850753
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0004959153489643428
1267, epoch_train_loss=0.0004959153489643428
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0004439774304924729
1268, epoch_train_loss=0.0004439774304924729
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.00019747472362771783
1269, epoch_train_loss=0.00019747472362771783
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.00016129278587627063
1270, epoch_train_loss=0.00016129278587627063
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.00032532916625514476
1271, epoch_train_loss=0.00032532916625514476
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.0003577828922310822
1272, epoch_train_loss=0.0003577828922310822
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.00019650559063903844
1273, epoch_train_loss=0.00019650559063903844
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.00012291250557915044
1274, epoch_train_loss=0.00012291250557915044
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.00021395757586931664
1275, epoch_train_loss=0.00021395757586931664
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0002723505487010747
1276, epoch_train_loss=0.0002723505487010747
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.00019738136797985544
1277, epoch_train_loss=0.00019738136797985544
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.00011259682973800074
1278, epoch_train_loss=0.00011259682973800074
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.00013759608178055244
1279, epoch_train_loss=0.00013759608178055244
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.00020167131826847532
1280, epoch_train_loss=0.00020167131826847532
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.00018666663984130745
1281, epoch_train_loss=0.00018666663984130745
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.00012110825003558026
1282, epoch_train_loss=0.00012110825003558026
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.00010088702729288301
1283, epoch_train_loss=0.00010088702729288301
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.00013820872934494462
1284, epoch_train_loss=0.00013820872934494462
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.00016173076686733673
1285, epoch_train_loss=0.00016173076686733673
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.00013125576559842324
1286, epoch_train_loss=0.00013125576559842324
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 9.567292246092865e-05
1287, epoch_train_loss=9.567292246092865e-05
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 9.868312517027195e-05
1288, epoch_train_loss=9.868312517027195e-05
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.00012409536604387567
1289, epoch_train_loss=0.00012409536604387567
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0001278667097353507
1290, epoch_train_loss=0.0001278667097353507
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.00010429408134385638
1291, epoch_train_loss=0.00010429408134385638
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 8.666139484933245e-05
1292, epoch_train_loss=8.666139484933245e-05
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 9.350518184346884e-05
1293, epoch_train_loss=9.350518184346884e-05
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.00010784646669038009
1294, epoch_train_loss=0.00010784646669038009
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.00010658564091745332
1295, epoch_train_loss=0.00010658564091745332
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 9.146725741137882e-05
1296, epoch_train_loss=9.146725741137882e-05
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 8.199001355851724e-05
1297, epoch_train_loss=8.199001355851724e-05
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 8.685187498993532e-05
1298, epoch_train_loss=8.685187498993532e-05
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 9.500043136474333e-05
1299, epoch_train_loss=9.500043136474333e-05
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 9.391194657899579e-05
1300, epoch_train_loss=9.391194657899579e-05
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 8.479147305157958e-05
1301, epoch_train_loss=8.479147305157958e-05
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 7.866938901369871e-05
1302, epoch_train_loss=7.866938901369871e-05
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 8.086690274880698e-05
1303, epoch_train_loss=8.086690274880698e-05
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 8.572118575927839e-05
1304, epoch_train_loss=8.572118575927839e-05
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 8.583339084719085e-05
1305, epoch_train_loss=8.583339084719085e-05
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 8.072744232506271e-05
1306, epoch_train_loss=8.072744232506271e-05
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 7.622359454798095e-05
1307, epoch_train_loss=7.622359454798095e-05
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 7.638016004454586e-05
1308, epoch_train_loss=7.638016004454586e-05
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 7.912350790733495e-05
1309, epoch_train_loss=7.912350790733495e-05
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 8.012896672181854e-05
1310, epoch_train_loss=8.012896672181854e-05
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 7.770330457034605e-05
1311, epoch_train_loss=7.770330457034605e-05
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 7.449743971389271e-05
1312, epoch_train_loss=7.449743971389271e-05
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 7.337047214369442e-05
1313, epoch_train_loss=7.337047214369442e-05
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 7.450553602366128e-05
1314, epoch_train_loss=7.450553602366128e-05
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 7.566236642439774e-05
1315, epoch_train_loss=7.566236642439774e-05
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 7.503827109235989e-05
1316, epoch_train_loss=7.503827109235989e-05
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 7.311001830129059e-05
1317, epoch_train_loss=7.311001830129059e-05
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 7.158690292963734e-05
1318, epoch_train_loss=7.158690292963734e-05
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 7.146890533425213e-05
1319, epoch_train_loss=7.146890533425213e-05
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 7.217325588239096e-05
1320, epoch_train_loss=7.217325588239096e-05
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 7.240857174171055e-05
1321, epoch_train_loss=7.240857174171055e-05
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 7.167100898095862e-05
1322, epoch_train_loss=7.167100898095862e-05
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 7.046114753687414e-05
1323, epoch_train_loss=7.046114753687414e-05
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 6.970232863396022e-05
1324, epoch_train_loss=6.970232863396022e-05
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 6.967791401760159e-05
1325, epoch_train_loss=6.967791401760159e-05
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 6.996622288515224e-05
1326, epoch_train_loss=6.996622288515224e-05
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 6.994089610851766e-05
1327, epoch_train_loss=6.994089610851766e-05
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 6.939895444875369e-05
1328, epoch_train_loss=6.939895444875369e-05
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 6.866415498003891e-05
1329, epoch_train_loss=6.866415498003891e-05
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 6.816769664406203e-05
1330, epoch_train_loss=6.816769664406203e-05
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 6.805676383298377e-05
1331, epoch_train_loss=6.805676383298377e-05
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 6.812349176001799e-05
1332, epoch_train_loss=6.812349176001799e-05
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 6.804830258083135e-05
1333, epoch_train_loss=6.804830258083135e-05
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 6.771715301549513e-05
1334, epoch_train_loss=6.771715301549513e-05
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 6.724438329548098e-05
1335, epoch_train_loss=6.724438329548098e-05
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 6.685948050362892e-05
1336, epoch_train_loss=6.685948050362892e-05
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 6.666766073307709e-05
1337, epoch_train_loss=6.666766073307709e-05
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 6.660906105719546e-05
1338, epoch_train_loss=6.660906105719546e-05
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 6.653220666086902e-05
1339, epoch_train_loss=6.653220666086902e-05
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 6.633461660676985e-05
1340, epoch_train_loss=6.633461660676985e-05
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 6.603441603557911e-05
1341, epoch_train_loss=6.603441603557911e-05
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 6.57265050595143e-05
1342, epoch_train_loss=6.57265050595143e-05
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 6.549587459336963e-05
1343, epoch_train_loss=6.549587459336963e-05
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 6.535824319356496e-05
1344, epoch_train_loss=6.535824319356496e-05
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 6.52574754628791e-05
1345, epoch_train_loss=6.52574754628791e-05
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 6.512987506474073e-05
1346, epoch_train_loss=6.512987506474073e-05
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 6.494225960194045e-05
1347, epoch_train_loss=6.494225960194045e-05
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 6.471620811320094e-05
1348, epoch_train_loss=6.471620811320094e-05
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 6.449575474739479e-05
1349, epoch_train_loss=6.449575474739479e-05
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 6.431490354284148e-05
1350, epoch_train_loss=6.431490354284148e-05
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 6.417678079303246e-05
1351, epoch_train_loss=6.417678079303246e-05
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 6.405714001397345e-05
1352, epoch_train_loss=6.405714001397345e-05
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 6.392709364806737e-05
1353, epoch_train_loss=6.392709364806737e-05
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 6.377237208433638e-05
1354, epoch_train_loss=6.377237208433638e-05
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 6.359791699654354e-05
1355, epoch_train_loss=6.359791699654354e-05
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 6.342258477249933e-05
1356, epoch_train_loss=6.342258477249933e-05
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 6.326207894723688e-05
1357, epoch_train_loss=6.326207894723688e-05
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 6.31224442230656e-05
1358, epoch_train_loss=6.31224442230656e-05
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 6.299712324556612e-05
1359, epoch_train_loss=6.299712324556612e-05
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 6.287400085083712e-05
1360, epoch_train_loss=6.287400085083712e-05
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 6.274383957338708e-05
1361, epoch_train_loss=6.274383957338708e-05
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 6.260390522655665e-05
1362, epoch_train_loss=6.260390522655665e-05
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 6.245871367456539e-05
1363, epoch_train_loss=6.245871367456539e-05
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 6.231555374404191e-05
1364, epoch_train_loss=6.231555374404191e-05
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 6.217992949948475e-05
1365, epoch_train_loss=6.217992949948475e-05
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 6.205354108387929e-05
1366, epoch_train_loss=6.205354108387929e-05
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 6.193371139380388e-05
1367, epoch_train_loss=6.193371139380388e-05
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 6.181612230490783e-05
1368, epoch_train_loss=6.181612230490783e-05
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 6.169711181098243e-05
1369, epoch_train_loss=6.169711181098243e-05
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 6.15750079761832e-05
1370, epoch_train_loss=6.15750079761832e-05
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 6.145088806223738e-05
1371, epoch_train_loss=6.145088806223738e-05
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 6.132690890278324e-05
1372, epoch_train_loss=6.132690890278324e-05
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 6.120549740395946e-05
1373, epoch_train_loss=6.120549740395946e-05
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 6.108800192740311e-05
1374, epoch_train_loss=6.108800192740311e-05
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 6.0974396448672125e-05
1375, epoch_train_loss=6.0974396448672125e-05
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 6.086368015555704e-05
1376, epoch_train_loss=6.086368015555704e-05
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 6.0754431833087424e-05
1377, epoch_train_loss=6.0754431833087424e-05
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 6.064540725333904e-05
1378, epoch_train_loss=6.064540725333904e-05
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 6.0536136301047845e-05
1379, epoch_train_loss=6.0536136301047845e-05
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 6.042662000496953e-05
1380, epoch_train_loss=6.042662000496953e-05
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 6.0317504949637766e-05
1381, epoch_train_loss=6.0317504949637766e-05
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 6.020943851153638e-05
1382, epoch_train_loss=6.020943851153638e-05
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 6.010299585012056e-05
1383, epoch_train_loss=6.010299585012056e-05
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 5.999844031797192e-05
1384, epoch_train_loss=5.999844031797192e-05
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 5.989570355679591e-05
1385, epoch_train_loss=5.989570355679591e-05
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 5.979450806419778e-05
1386, epoch_train_loss=5.979450806419778e-05
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 5.969449657153364e-05
1387, epoch_train_loss=5.969449657153364e-05
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 5.959531068359297e-05
1388, epoch_train_loss=5.959531068359297e-05
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 5.949674774079897e-05
1389, epoch_train_loss=5.949674774079897e-05
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 5.939870990416485e-05
1390, epoch_train_loss=5.939870990416485e-05
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 5.9301225563825315e-05
1391, epoch_train_loss=5.9301225563825315e-05
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 5.920441672155802e-05
1392, epoch_train_loss=5.920441672155802e-05
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 5.910839131927028e-05
1393, epoch_train_loss=5.910839131927028e-05
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 5.9013280273756324e-05
1394, epoch_train_loss=5.9013280273756324e-05
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 5.8919142739172325e-05
1395, epoch_train_loss=5.8919142739172325e-05
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 5.882600339414677e-05
1396, epoch_train_loss=5.882600339414677e-05
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 5.873384465073933e-05
1397, epoch_train_loss=5.873384465073933e-05
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 5.864261443062557e-05
1398, epoch_train_loss=5.864261443062557e-05
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 5.8552248291564674e-05
1399, epoch_train_loss=5.8552248291564674e-05
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 5.846268645496855e-05
1400, epoch_train_loss=5.846268645496855e-05
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 5.8373864853708145e-05
1401, epoch_train_loss=5.8373864853708145e-05
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 5.828574572813575e-05
1402, epoch_train_loss=5.828574572813575e-05
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 5.8198296022499455e-05
1403, epoch_train_loss=5.8198296022499455e-05
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 5.811149485553306e-05
1404, epoch_train_loss=5.811149485553306e-05
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 5.802533681887976e-05
1405, epoch_train_loss=5.802533681887976e-05
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 5.793981206859419e-05
1406, epoch_train_loss=5.793981206859419e-05
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 5.785492321969677e-05
1407, epoch_train_loss=5.785492321969677e-05
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 5.7770666616184545e-05
1408, epoch_train_loss=5.7770666616184545e-05
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 5.768704084229625e-05
1409, epoch_train_loss=5.768704084229625e-05
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 5.7604041179031206e-05
1410, epoch_train_loss=5.7604041179031206e-05
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 5.7521664614574706e-05
1411, epoch_train_loss=5.7521664614574706e-05
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 5.743990024610127e-05
1412, epoch_train_loss=5.743990024610127e-05
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 5.7358745200078025e-05
1413, epoch_train_loss=5.7358745200078025e-05
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 5.72781857062629e-05
1414, epoch_train_loss=5.72781857062629e-05
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 5.7198217115574864e-05
1415, epoch_train_loss=5.7198217115574864e-05
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 5.7118827395743774e-05
1416, epoch_train_loss=5.7118827395743774e-05
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 5.704001101211432e-05
1417, epoch_train_loss=5.704001101211432e-05
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 5.696175833285364e-05
1418, epoch_train_loss=5.696175833285364e-05
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 5.6884066603481105e-05
1419, epoch_train_loss=5.6884066603481105e-05
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 5.6806928148250305e-05
1420, epoch_train_loss=5.6806928148250305e-05
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 5.6730346068120796e-05
1421, epoch_train_loss=5.6730346068120796e-05
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 5.665431882623083e-05
1422, epoch_train_loss=5.665431882623083e-05
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 5.657885831307976e-05
1423, epoch_train_loss=5.657885831307976e-05
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 5.650397665999644e-05
1424, epoch_train_loss=5.650397665999644e-05
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 5.6429704847821986e-05
1425, epoch_train_loss=5.6429704847821986e-05
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 5.635608303309439e-05
1426, epoch_train_loss=5.635608303309439e-05
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 5.628318634019877e-05
1427, epoch_train_loss=5.628318634019877e-05
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 5.6211118803485896e-05
1428, epoch_train_loss=5.6211118803485896e-05
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 5.614005726875285e-05
1429, epoch_train_loss=5.614005726875285e-05
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 5.607026052271421e-05
1430, epoch_train_loss=5.607026052271421e-05
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 5.6002149616230765e-05
1431, epoch_train_loss=5.6002149616230765e-05
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 5.5936369416071336e-05
1432, epoch_train_loss=5.5936369416071336e-05
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 5.587395364276396e-05
1433, epoch_train_loss=5.587395364276396e-05
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 5.5816542269343885e-05
1434, epoch_train_loss=5.5816542269343885e-05
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 5.576676096102312e-05
1435, epoch_train_loss=5.576676096102312e-05
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 5.572890805079828e-05
1436, epoch_train_loss=5.572890805079828e-05
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 5.570988611787279e-05
1437, epoch_train_loss=5.570988611787279e-05
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 5.5721347597303755e-05
1438, epoch_train_loss=5.5721347597303755e-05
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 5.578206569439902e-05
1439, epoch_train_loss=5.578206569439902e-05
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 5.5924770156043684e-05
1440, epoch_train_loss=5.5924770156043684e-05
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 5.6202196737917436e-05
1441, epoch_train_loss=5.6202196737917436e-05
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 5.670972730598452e-05
1442, epoch_train_loss=5.670972730598452e-05
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 5.75999690915431e-05
1443, epoch_train_loss=5.75999690915431e-05
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 5.916180551838299e-05
1444, epoch_train_loss=5.916180551838299e-05
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 6.18483537600154e-05
1445, epoch_train_loss=6.18483537600154e-05
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 6.657121873698284e-05
1446, epoch_train_loss=6.657121873698284e-05
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 7.470148816734655e-05
1447, epoch_train_loss=7.470148816734655e-05
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 8.924848766562725e-05
1448, epoch_train_loss=8.924848766562725e-05
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0001143863673708282
1449, epoch_train_loss=0.0001143863673708282
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.00016056914510642593
1450, epoch_train_loss=0.00016056914510642593
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.00024023028159040634
1451, epoch_train_loss=0.00024023028159040634
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0003918639692274814
1452, epoch_train_loss=0.0003918639692274814
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0006490609368097534
1453, epoch_train_loss=0.0006490609368097534
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.0011627785469085045
1454, epoch_train_loss=0.0011627785469085045
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.0019917214231740844
1455, epoch_train_loss=0.0019917214231740844
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.0037599400898485637
1456, epoch_train_loss=0.0037599400898485637
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.006266820860297393
1457, epoch_train_loss=0.006266820860297393
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.012083521919775991
1458, epoch_train_loss=0.012083521919775991
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.01782044360820722
1459, epoch_train_loss=0.01782044360820722
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.032533140192931034
1460, epoch_train_loss=0.032533140192931034
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.034564409278615704
1461, epoch_train_loss=0.034564409278615704
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.04664158275367508
1462, epoch_train_loss=0.04664158275367508
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.025452121536626324
1463, epoch_train_loss=0.025452121536626324
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.010850674552469441
1464, epoch_train_loss=0.010850674552469441
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0004850435714277768
1465, epoch_train_loss=0.0004850435714277768
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.0042880973649496255
1466, epoch_train_loss=0.0042880973649496255
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.01515144146962324
1467, epoch_train_loss=0.01515144146962324
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.013736555110041043
1468, epoch_train_loss=0.013736555110041043
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0073564549410579366
1469, epoch_train_loss=0.0073564549410579366
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.00043276264035202705
1470, epoch_train_loss=0.00043276264035202705
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0030123340766896717
1471, epoch_train_loss=0.0030123340766896717
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.009171624365142803
1472, epoch_train_loss=0.009171624365142803
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.006418826370624666
1473, epoch_train_loss=0.006418826370624666
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0014247373329125458
1474, epoch_train_loss=0.0014247373329125458
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007256353866052849
1475, epoch_train_loss=0.0007256353866052849
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.004145021276915199
1476, epoch_train_loss=0.004145021276915199
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.005438963020513998
1477, epoch_train_loss=0.005438963020513998
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.001666301343580799
1478, epoch_train_loss=0.001666301343580799
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.00038088657364643275
1479, epoch_train_loss=0.00038088657364643275
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0026729090319566958
1480, epoch_train_loss=0.0026729090319566958
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.0032697580508307066
1481, epoch_train_loss=0.0032697580508307066
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.0014406814737561568
1482, epoch_train_loss=0.0014406814737561568
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0002569083224310029
1483, epoch_train_loss=0.0002569083224310029
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0015254809802833216
1484, epoch_train_loss=0.0015254809802833216
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0025138741827290855
1485, epoch_train_loss=0.0025138741827290855
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0011578426105149431
1486, epoch_train_loss=0.0011578426105149431
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.00022784519980647376
1487, epoch_train_loss=0.00022784519980647376
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.0009787551860270857
1488, epoch_train_loss=0.0009787551860270857
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.0015800383199154498
1489, epoch_train_loss=0.0015800383199154498
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.000985545138088851
1490, epoch_train_loss=0.000985545138088851
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.00022009028511237228
1491, epoch_train_loss=0.00022009028511237228
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.000552737581501723
1492, epoch_train_loss=0.000552737581501723
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0011396875719180426
1493, epoch_train_loss=0.0011396875719180426
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0008046766960853946
1494, epoch_train_loss=0.0008046766960853946
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0002352311292674102
1495, epoch_train_loss=0.0002352311292674102
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.00029037597980129093
1496, epoch_train_loss=0.00029037597980129093
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0006896934520486029
1497, epoch_train_loss=0.0006896934520486029
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0006923561557130992
1498, epoch_train_loss=0.0006923561557130992
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0002850254772485313
1499, epoch_train_loss=0.0002850254772485313
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.00015693392562646805
1500, epoch_train_loss=0.00015693392562646805
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.00040448106164074713
1501, epoch_train_loss=0.00040448106164074713
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.0005170529757167981
1502, epoch_train_loss=0.0005170529757167981
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.00032742075772178346
1503, epoch_train_loss=0.00032742075772178346
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.00012869270064375958
1504, epoch_train_loss=0.00012869270064375958
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0002000780081251684
1505, epoch_train_loss=0.0002000780081251684
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0003580267154449078
1506, epoch_train_loss=0.0003580267154449078
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.00032293289113461164
1507, epoch_train_loss=0.00032293289113461164
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.0001660792091588088
1508, epoch_train_loss=0.0001660792091588088
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.00010955609186964521
1509, epoch_train_loss=0.00010955609186964521
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.00019730376673871366
1510, epoch_train_loss=0.00019730376673871366
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.00026521272027753794
1511, epoch_train_loss=0.00026521272027753794
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.0002033905268509473
1512, epoch_train_loss=0.0002033905268509473
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.00011146169922591418
1513, epoch_train_loss=0.00011146169922591418
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.00010530026076368952
1514, epoch_train_loss=0.00010530026076368952
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0001654790033262892
1515, epoch_train_loss=0.0001654790033262892
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.00019214677637575828
1516, epoch_train_loss=0.00019214677637575828
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.00014500439549987418
1517, epoch_train_loss=0.00014500439549987418
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 9.349613394119907e-05
1518, epoch_train_loss=9.349613394119907e-05
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 9.561045426338193e-05
1519, epoch_train_loss=9.561045426338193e-05
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0001322059339998611
1520, epoch_train_loss=0.0001322059339998611
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.00014571351489071338
1521, epoch_train_loss=0.00014571351489071338
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.00011756512723964334
1522, epoch_train_loss=0.00011756512723964334
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 8.604132526897308e-05
1523, epoch_train_loss=8.604132526897308e-05
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 8.518099599085044e-05
1524, epoch_train_loss=8.518099599085044e-05
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.00010590963472544423
1525, epoch_train_loss=0.00010590963472544423
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.00011676289249501696
1526, epoch_train_loss=0.00011676289249501696
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.00010284191264089949
1527, epoch_train_loss=0.00010284191264089949
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 8.27665636513888e-05
1528, epoch_train_loss=8.27665636513888e-05
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 7.739901209483118e-05
1529, epoch_train_loss=7.739901209483118e-05
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 8.782590103367559e-05
1530, epoch_train_loss=8.782590103367559e-05
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 9.713613437840832e-05
1531, epoch_train_loss=9.713613437840832e-05
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 9.315293879350794e-05
1532, epoch_train_loss=9.315293879350794e-05
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 8.106033613778186e-05
1533, epoch_train_loss=8.106033613778186e-05
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 7.367289314087447e-05
1534, epoch_train_loss=7.367289314087447e-05
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 7.639916687614522e-05
1535, epoch_train_loss=7.639916687614522e-05
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 8.313537630194868e-05
1536, epoch_train_loss=8.313537630194868e-05
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 8.461977676173933e-05
1537, epoch_train_loss=8.461977676173933e-05
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 7.936740601818573e-05
1538, epoch_train_loss=7.936740601818573e-05
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 7.272451921660988e-05
1539, epoch_train_loss=7.272451921660988e-05
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 7.079599716726741e-05
1540, epoch_train_loss=7.079599716726741e-05
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 7.359253137305567e-05
1541, epoch_train_loss=7.359253137305567e-05
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 7.665920564004399e-05
1542, epoch_train_loss=7.665920564004399e-05
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 7.617579491999088e-05
1543, epoch_train_loss=7.617579491999088e-05
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 7.254812555465485e-05
1544, epoch_train_loss=7.254812555465485e-05
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 6.916723836022878e-05
1545, epoch_train_loss=6.916723836022878e-05
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 6.855587132482296e-05
1546, epoch_train_loss=6.855587132482296e-05
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 7.01535901943696e-05
1547, epoch_train_loss=7.01535901943696e-05
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 7.157942308037319e-05
1548, epoch_train_loss=7.157942308037319e-05
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 7.102894350504854e-05
1549, epoch_train_loss=7.102894350504854e-05
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 6.897172027074078e-05
1550, epoch_train_loss=6.897172027074078e-05
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 6.703976892894896e-05
1551, epoch_train_loss=6.703976892894896e-05
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 6.652896753919065e-05
1552, epoch_train_loss=6.652896753919065e-05
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 6.721235641249052e-05
1553, epoch_train_loss=6.721235641249052e-05
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 6.793821690022106e-05
1554, epoch_train_loss=6.793821690022106e-05
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 6.775524264026166e-05
1555, epoch_train_loss=6.775524264026166e-05
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 6.667995228292595e-05
1556, epoch_train_loss=6.667995228292595e-05
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 6.547437801792129e-05
1557, epoch_train_loss=6.547437801792129e-05
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 6.487027757712262e-05
1558, epoch_train_loss=6.487027757712262e-05
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 6.496730460227644e-05
1559, epoch_train_loss=6.496730460227644e-05
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 6.53201686173898e-05
1560, epoch_train_loss=6.53201686173898e-05
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 6.536295169238942e-05
1561, epoch_train_loss=6.536295169238942e-05
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 6.49144819010157e-05
1562, epoch_train_loss=6.49144819010157e-05
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 6.419357155824207e-05
1563, epoch_train_loss=6.419357155824207e-05
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 6.359941155685972e-05
1564, epoch_train_loss=6.359941155685972e-05
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 6.335692604447071e-05
1565, epoch_train_loss=6.335692604447071e-05
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 6.339748894131622e-05
1566, epoch_train_loss=6.339748894131622e-05
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 6.346793430148615e-05
1567, epoch_train_loss=6.346793430148615e-05
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 6.335165609807806e-05
1568, epoch_train_loss=6.335165609807806e-05
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 6.30117145315414e-05
1569, epoch_train_loss=6.30117145315414e-05
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 6.257760256186421e-05
1570, epoch_train_loss=6.257760256186421e-05
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 6.2220175265327e-05
1571, epoch_train_loss=6.2220175265327e-05
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 6.202783787799697e-05
1572, epoch_train_loss=6.202783787799697e-05
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 6.196668484631564e-05
1573, epoch_train_loss=6.196668484631564e-05
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 6.192637526858852e-05
1574, epoch_train_loss=6.192637526858852e-05
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 6.181163098175642e-05
1575, epoch_train_loss=6.181163098175642e-05
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 6.159439151399564e-05
1576, epoch_train_loss=6.159439151399564e-05
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 6.13198099932396e-05
1577, epoch_train_loss=6.13198099932396e-05
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 6.106011253024002e-05
1578, epoch_train_loss=6.106011253024002e-05
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 6.086701742894206e-05
1579, epoch_train_loss=6.086701742894206e-05
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 6.07433328914931e-05
1580, epoch_train_loss=6.07433328914931e-05
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 6.065486319828302e-05
1581, epoch_train_loss=6.065486319828302e-05
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 6.055441806306458e-05
1582, epoch_train_loss=6.055441806306458e-05
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 6.041555050817376e-05
1583, epoch_train_loss=6.041555050817376e-05
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 6.023758519056287e-05
1584, epoch_train_loss=6.023758519056287e-05
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 6.00447852837386e-05
1585, epoch_train_loss=6.00447852837386e-05
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 5.986390959444007e-05
1586, epoch_train_loss=5.986390959444007e-05
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 5.9712429291549405e-05
1587, epoch_train_loss=5.9712429291549405e-05
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 5.958968211203863e-05
1588, epoch_train_loss=5.958968211203863e-05
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 5.948279486412988e-05
1589, epoch_train_loss=5.948279486412988e-05
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 5.9374241999373324e-05
1590, epoch_train_loss=5.9374241999373324e-05
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 5.9252872204371425e-05
1591, epoch_train_loss=5.9252872204371425e-05
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 5.911617416487859e-05
1592, epoch_train_loss=5.911617416487859e-05
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 5.897070847647326e-05
1593, epoch_train_loss=5.897070847647326e-05
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 5.8826111461740325e-05
1594, epoch_train_loss=5.8826111461740325e-05
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 5.8690530516763104e-05
1595, epoch_train_loss=5.8690530516763104e-05
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 5.8567287864043966e-05
1596, epoch_train_loss=5.8567287864043966e-05
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 5.8454479793248805e-05
1597, epoch_train_loss=5.8454479793248805e-05
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 5.834714840766153e-05
1598, epoch_train_loss=5.834714840766153e-05
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 5.823981659819819e-05
1599, epoch_train_loss=5.823981659819819e-05
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 5.8128873570338154e-05
1600, epoch_train_loss=5.8128873570338154e-05
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 5.801335231115977e-05
1601, epoch_train_loss=5.801335231115977e-05
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 5.789490945122673e-05
1602, epoch_train_loss=5.789490945122673e-05
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 5.7776166038281835e-05
1603, epoch_train_loss=5.7776166038281835e-05
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 5.766003162115408e-05
1604, epoch_train_loss=5.766003162115408e-05
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 5.7548074989641475e-05
1605, epoch_train_loss=5.7548074989641475e-05
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 5.744077976092953e-05
1606, epoch_train_loss=5.744077976092953e-05
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 5.733728270412696e-05
1607, epoch_train_loss=5.733728270412696e-05
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 5.723623210753596e-05
1608, epoch_train_loss=5.723623210753596e-05
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 5.7136115644717337e-05
1609, epoch_train_loss=5.7136115644717337e-05
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 5.703592069349089e-05
1610, epoch_train_loss=5.703592069349089e-05
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 5.693511879758116e-05
1611, epoch_train_loss=5.693511879758116e-05
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 5.683385283273133e-05
1612, epoch_train_loss=5.683385283273133e-05
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 5.673258293991845e-05
1613, epoch_train_loss=5.673258293991845e-05
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 5.6631938489458964e-05
1614, epoch_train_loss=5.6631938489458964e-05
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 5.653251400944808e-05
1615, epoch_train_loss=5.653251400944808e-05
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 5.6434678353018494e-05
1616, epoch_train_loss=5.6434678353018494e-05
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 5.633860370448477e-05
1617, epoch_train_loss=5.633860370448477e-05
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 5.624421938812092e-05
1618, epoch_train_loss=5.624421938812092e-05
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 5.615133031837854e-05
1619, epoch_train_loss=5.615133031837854e-05
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 5.60596533536791e-05
1620, epoch_train_loss=5.60596533536791e-05
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 5.5968937917209024e-05
1621, epoch_train_loss=5.5968937917209024e-05
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 5.587894814478895e-05
1622, epoch_train_loss=5.587894814478895e-05
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 5.578955775813762e-05
1623, epoch_train_loss=5.578955775813762e-05
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 5.570068361328962e-05
1624, epoch_train_loss=5.570068361328962e-05
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 5.5612321085878475e-05
1625, epoch_train_loss=5.5612321085878475e-05
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 5.5524501107934945e-05
1626, epoch_train_loss=5.5524501107934945e-05
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 5.543727496500225e-05
1627, epoch_train_loss=5.543727496500225e-05
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 5.53506992293524e-05
1628, epoch_train_loss=5.53506992293524e-05
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 5.5264820943544824e-05
1629, epoch_train_loss=5.5264820943544824e-05
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 5.517967587001231e-05
1630, epoch_train_loss=5.517967587001231e-05
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 5.50952789487079e-05
1631, epoch_train_loss=5.50952789487079e-05
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 5.5011641438363754e-05
1632, epoch_train_loss=5.5011641438363754e-05
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 5.492874624903399e-05
1633, epoch_train_loss=5.492874624903399e-05
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 5.484658651270631e-05
1634, epoch_train_loss=5.484658651270631e-05
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 5.476513454711426e-05
1635, epoch_train_loss=5.476513454711426e-05
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 5.468437335044511e-05
1636, epoch_train_loss=5.468437335044511e-05
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 5.4604275297225555e-05
1637, epoch_train_loss=5.4604275297225555e-05
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 5.452482331358342e-05
1638, epoch_train_loss=5.452482331358342e-05
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 5.4445993316268754e-05
1639, epoch_train_loss=5.4445993316268754e-05
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 5.43677718514755e-05
1640, epoch_train_loss=5.43677718514755e-05
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 5.429014100232956e-05
1641, epoch_train_loss=5.429014100232956e-05
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 5.421308848118752e-05
1642, epoch_train_loss=5.421308848118752e-05
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 5.4136603359099416e-05
1643, epoch_train_loss=5.4136603359099416e-05
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 5.4060674468342214e-05
1644, epoch_train_loss=5.4060674468342214e-05
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 5.398529576121325e-05
1645, epoch_train_loss=5.398529576121325e-05
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 5.391045915107501e-05
1646, epoch_train_loss=5.391045915107501e-05
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 5.383616301630599e-05
1647, epoch_train_loss=5.383616301630599e-05
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 5.376240293939459e-05
1648, epoch_train_loss=5.376240293939459e-05
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 5.368918523258497e-05
1649, epoch_train_loss=5.368918523258497e-05
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 5.361651328028348e-05
1650, epoch_train_loss=5.361651328028348e-05
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 5.354440690790779e-05
1651, epoch_train_loss=5.354440690790779e-05
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 5.3472887827356235e-05
1652, epoch_train_loss=5.3472887827356235e-05
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 5.3402004131034126e-05
1653, epoch_train_loss=5.3402004131034126e-05
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 5.333181944810891e-05
1654, epoch_train_loss=5.333181944810891e-05
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 5.3262447503560113e-05
1655, epoch_train_loss=5.3262447503560113e-05
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 5.319405031269013e-05
1656, epoch_train_loss=5.319405031269013e-05
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 5.3126897810057147e-05
1657, epoch_train_loss=5.3126897810057147e-05
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 5.3061394630732286e-05
1658, epoch_train_loss=5.3061394630732286e-05
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 5.299819569773217e-05
1659, epoch_train_loss=5.299819569773217e-05
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 5.293832230582169e-05
1660, epoch_train_loss=5.293832230582169e-05
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 5.288341354664153e-05
1661, epoch_train_loss=5.288341354664153e-05
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 5.283610963295938e-05
1662, epoch_train_loss=5.283610963295938e-05
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 5.280064809473182e-05
1663, epoch_train_loss=5.280064809473182e-05
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 5.27840639174549e-05
1664, epoch_train_loss=5.27840639174549e-05
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 5.2797671614062734e-05
1665, epoch_train_loss=5.2797671614062734e-05
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 5.286083834185941e-05
1666, epoch_train_loss=5.286083834185941e-05
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 5.300473219711113e-05
1667, epoch_train_loss=5.300473219711113e-05
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 5.328453004755205e-05
1668, epoch_train_loss=5.328453004755205e-05
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 5.378862416062195e-05
1669, epoch_train_loss=5.378862416062195e-05
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 5.467993779830136e-05
1670, epoch_train_loss=5.467993779830136e-05
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 5.621571481782486e-05
1671, epoch_train_loss=5.621571481782486e-05
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 5.8895628206314704e-05
1672, epoch_train_loss=5.8895628206314704e-05
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 6.348393086971408e-05
1673, epoch_train_loss=6.348393086971408e-05
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 7.157767136506496e-05
1674, epoch_train_loss=7.157767136506496e-05
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 8.547322239334776e-05
1675, epoch_train_loss=8.547322239334776e-05
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.00011051753579302758
1676, epoch_train_loss=0.00011051753579302758
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.00015355915915068156
1677, epoch_train_loss=0.00015355915915068156
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.00023348201278616294
1678, epoch_train_loss=0.00023348201278616294
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.0003696678865952329
1679, epoch_train_loss=0.0003696678865952329
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0006329797884778241
1680, epoch_train_loss=0.0006329797884778241
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.0010683807999548958
1681, epoch_train_loss=0.0010683807999548958
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.001958673327646763
1682, epoch_train_loss=0.001958673327646763
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.003320447727975265
1683, epoch_train_loss=0.003320447727975265
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.006326114944387671
1684, epoch_train_loss=0.006326114944387671
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.010089604560985555
1685, epoch_train_loss=0.010089604560985555
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0192366545214298
1686, epoch_train_loss=0.0192366545214298
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.02537727302923472
1687, epoch_train_loss=0.02537727302923472
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.04286857971263761
1688, epoch_train_loss=0.04286857971263761
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.03590880843363731
1689, epoch_train_loss=0.03590880843363731
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.03621018774870286
1690, epoch_train_loss=0.03621018774870286
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.013010580038571652
1691, epoch_train_loss=0.013010580038571652
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.0011545395969358326
1692, epoch_train_loss=0.0011545395969358326
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0024658922139651532
1693, epoch_train_loss=0.0024658922139651532
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.011246007201613745
1694, epoch_train_loss=0.011246007201613745
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.0186903969450701
1695, epoch_train_loss=0.0186903969450701
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.008768465702239664
1696, epoch_train_loss=0.008768465702239664
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.0009638819988859917
1697, epoch_train_loss=0.0009638819988859917
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0019632538029146288
1698, epoch_train_loss=0.0019632538029146288
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.007360421632277707
1699, epoch_train_loss=0.007360421632277707
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.009122446257857027
1700, epoch_train_loss=0.009122446257857027
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.0025948286761378046
1701, epoch_train_loss=0.0025948286761378046
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.00046200549448446643
1702, epoch_train_loss=0.00046200549448446643
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.004077332738601909
1703, epoch_train_loss=0.004077332738601909
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.005310646330902592
1704, epoch_train_loss=0.005310646330902592
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0027567985367491117
1705, epoch_train_loss=0.0027567985367491117
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.00027196733596196167
1706, epoch_train_loss=0.00027196733596196167
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.002003868957378914
1707, epoch_train_loss=0.002003868957378914
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.004121591667152551
1708, epoch_train_loss=0.004121591667152551
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.002228840050399108
1709, epoch_train_loss=0.002228840050399108
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.00029681505866081354
1710, epoch_train_loss=0.00029681505866081354
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.0011568239682034477
1711, epoch_train_loss=0.0011568239682034477
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.002409982524652676
1712, epoch_train_loss=0.002409982524652676
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0018921596529391897
1713, epoch_train_loss=0.0018921596529391897
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.00037783008266915544
1714, epoch_train_loss=0.00037783008266915544
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.0006357648403451726
1715, epoch_train_loss=0.0006357648403451726
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.0017388284184004937
1716, epoch_train_loss=0.0017388284184004937
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.0014105041193492407
1717, epoch_train_loss=0.0014105041193492407
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.00042340737717186703
1718, epoch_train_loss=0.00042340737717186703
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.00030369009889751736
1719, epoch_train_loss=0.00030369009889751736
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.000999297910275728
1720, epoch_train_loss=0.000999297910275728
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.0011583710584014359
1721, epoch_train_loss=0.0011583710584014359
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0004923905264510211
1722, epoch_train_loss=0.0004923905264510211
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.00016347749174623442
1723, epoch_train_loss=0.00016347749174623442
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.000560429944110214
1724, epoch_train_loss=0.000560429944110214
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.0007965591429589661
1725, epoch_train_loss=0.0007965591429589661
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0005308151470703952
1726, epoch_train_loss=0.0005308151470703952
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.00015518870911581837
1727, epoch_train_loss=0.00015518870911581837
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.00025349227671750646
1728, epoch_train_loss=0.00025349227671750646
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0005323925478955116
1729, epoch_train_loss=0.0005323925478955116
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0004910904515138004
1730, epoch_train_loss=0.0004910904515138004
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.00022204774388203815
1731, epoch_train_loss=0.00022204774388203815
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.00011877190350700926
1732, epoch_train_loss=0.00011877190350700926
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.00027058238180566505
1733, epoch_train_loss=0.00027058238180566505
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.000391751025796434
1734, epoch_train_loss=0.000391751025796434
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.00028026703939352984
1735, epoch_train_loss=0.00028026703939352984
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.0001227399414008551
1736, epoch_train_loss=0.0001227399414008551
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.00012183199194152028
1737, epoch_train_loss=0.00012183199194152028
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.0002289298948763589
1738, epoch_train_loss=0.0002289298948763589
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.00026795367599415765
1739, epoch_train_loss=0.00026795367599415765
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.000176070631375036
1740, epoch_train_loss=0.000176070631375036
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 9.492033749754329e-05
1741, epoch_train_loss=9.492033749754329e-05
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.00011091140737690106
1742, epoch_train_loss=0.00011091140737690106
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.00017731874582502572
1743, epoch_train_loss=0.00017731874582502572
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.000188200518699897
1744, epoch_train_loss=0.000188200518699897
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0001326645023069503
1745, epoch_train_loss=0.0001326645023069503
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 8.391008341053046e-05
1746, epoch_train_loss=8.391008341053046e-05
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 9.611853979875468e-05
1747, epoch_train_loss=9.611853979875468e-05
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0001332626827094719
1748, epoch_train_loss=0.0001332626827094719
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.00014314521630407867
1749, epoch_train_loss=0.00014314521630407867
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.00011048486978976953
1750, epoch_train_loss=0.00011048486978976953
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 8.03648811660528e-05
1751, epoch_train_loss=8.03648811660528e-05
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 8.135710655060925e-05
1752, epoch_train_loss=8.135710655060925e-05
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.00010405458575469776
1753, epoch_train_loss=0.00010405458575469776
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.00011364860498899192
1754, epoch_train_loss=0.00011364860498899192
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 9.937181543152576e-05
1755, epoch_train_loss=9.937181543152576e-05
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 7.813137565620355e-05
1756, epoch_train_loss=7.813137565620355e-05
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 7.336131144759367e-05
1757, epoch_train_loss=7.336131144759367e-05
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 8.372661627111948e-05
1758, epoch_train_loss=8.372661627111948e-05
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 9.390512158323698e-05
1759, epoch_train_loss=9.390512158323698e-05
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 8.984249221203132e-05
1760, epoch_train_loss=8.984249221203132e-05
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 7.78110561116799e-05
1761, epoch_train_loss=7.78110561116799e-05
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 6.965083574617051e-05
1762, epoch_train_loss=6.965083574617051e-05
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 7.227683375123469e-05
1763, epoch_train_loss=7.227683375123469e-05
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 7.9077705242228e-05
1764, epoch_train_loss=7.9077705242228e-05
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 8.138506606963721e-05
1765, epoch_train_loss=8.138506606963721e-05
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 7.627492709075831e-05
1766, epoch_train_loss=7.627492709075831e-05
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 6.949700157915703e-05
1767, epoch_train_loss=6.949700157915703e-05
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 6.689958079742986e-05
1768, epoch_train_loss=6.689958079742986e-05
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 6.95772867683686e-05
1769, epoch_train_loss=6.95772867683686e-05
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 7.289625849859303e-05
1770, epoch_train_loss=7.289625849859303e-05
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 7.294112488240276e-05
1771, epoch_train_loss=7.294112488240276e-05
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 6.943804098880677e-05
1772, epoch_train_loss=6.943804098880677e-05
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 6.585603434463983e-05
1773, epoch_train_loss=6.585603434463983e-05
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 6.485566265638127e-05
1774, epoch_train_loss=6.485566265638127e-05
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 6.637681634046326e-05
1775, epoch_train_loss=6.637681634046326e-05
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 6.798778456074032e-05
1776, epoch_train_loss=6.798778456074032e-05
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 6.774291680738747e-05
1777, epoch_train_loss=6.774291680738747e-05
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 6.578841740456133e-05
1778, epoch_train_loss=6.578841740456133e-05
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 6.372320411576938e-05
1779, epoch_train_loss=6.372320411576938e-05
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 6.302221531402423e-05
1780, epoch_train_loss=6.302221531402423e-05
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 6.361933169924987e-05
1781, epoch_train_loss=6.361933169924987e-05
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 6.445339655940859e-05
1782, epoch_train_loss=6.445339655940859e-05
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 6.441595299583784e-05
1783, epoch_train_loss=6.441595299583784e-05
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 6.343224806391653e-05
1784, epoch_train_loss=6.343224806391653e-05
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 6.217700942888333e-05
1785, epoch_train_loss=6.217700942888333e-05
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 6.14986423566017e-05
1786, epoch_train_loss=6.14986423566017e-05
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 6.152945193597105e-05
1787, epoch_train_loss=6.152945193597105e-05
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 6.19230734276641e-05
1788, epoch_train_loss=6.19230734276641e-05
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 6.201724090792048e-05
1789, epoch_train_loss=6.201724090792048e-05
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 6.163435319759402e-05
1790, epoch_train_loss=6.163435319759402e-05
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 6.0908374678492856e-05
1791, epoch_train_loss=6.0908374678492856e-05
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 6.0302747855453495e-05
1792, epoch_train_loss=6.0302747855453495e-05
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 6.00282386569913e-05
1793, epoch_train_loss=6.00282386569913e-05
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 6.008030865511838e-05
1794, epoch_train_loss=6.008030865511838e-05
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 6.016058549628514e-05
1795, epoch_train_loss=6.016058549628514e-05
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 6.0073786993247526e-05
1796, epoch_train_loss=6.0073786993247526e-05
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 5.9736843185844454e-05
1797, epoch_train_loss=5.9736843185844454e-05
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 5.930883419148279e-05
1798, epoch_train_loss=5.930883419148279e-05
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 5.894756029360852e-05
1799, epoch_train_loss=5.894756029360852e-05
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 5.8765426068539205e-05
1800, epoch_train_loss=5.8765426068539205e-05
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 5.871330748971888e-05
1801, epoch_train_loss=5.871330748971888e-05
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 5.868486421231847e-05
1802, epoch_train_loss=5.868486421231847e-05
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 5.8570211345629884e-05
1803, epoch_train_loss=5.8570211345629884e-05
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 5.835141877511223e-05
1804, epoch_train_loss=5.835141877511223e-05
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 5.807611683711033e-05
1805, epoch_train_loss=5.807611683711033e-05
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 5.782348916162607e-05
1806, epoch_train_loss=5.782348916162607e-05
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 5.7645888563406286e-05
1807, epoch_train_loss=5.7645888563406286e-05
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 5.753659791600041e-05
1808, epoch_train_loss=5.753659791600041e-05
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 5.7458342208852595e-05
1809, epoch_train_loss=5.7458342208852595e-05
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 5.735707565376634e-05
1810, epoch_train_loss=5.735707565376634e-05
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 5.7213367956238825e-05
1811, epoch_train_loss=5.7213367956238825e-05
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 5.702969159129763e-05
1812, epoch_train_loss=5.702969159129763e-05
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 5.684034774214679e-05
1813, epoch_train_loss=5.684034774214679e-05
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 5.666890139931484e-05
1814, epoch_train_loss=5.666890139931484e-05
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 5.653403466049518e-05
1815, epoch_train_loss=5.653403466049518e-05
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 5.6424035317217846e-05
1816, epoch_train_loss=5.6424035317217846e-05
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 5.632522426541125e-05
1817, epoch_train_loss=5.632522426541125e-05
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 5.6215946506369744e-05
1818, epoch_train_loss=5.6215946506369744e-05
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 5.609039194655019e-05
1819, epoch_train_loss=5.609039194655019e-05
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 5.5949343972383836e-05
1820, epoch_train_loss=5.5949343972383836e-05
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 5.5805037670236497e-05
1821, epoch_train_loss=5.5805037670236497e-05
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 5.5667152228101e-05
1822, epoch_train_loss=5.5667152228101e-05
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 5.554307477735178e-05
1823, epoch_train_loss=5.554307477735178e-05
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 5.5431898810727335e-05
1824, epoch_train_loss=5.5431898810727335e-05
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 5.5328157019576347e-05
1825, epoch_train_loss=5.5328157019576347e-05
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 5.522541524227756e-05
1826, epoch_train_loss=5.522541524227756e-05
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 5.5117962607612484e-05
1827, epoch_train_loss=5.5117962607612484e-05
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 5.5005133207875034e-05
1828, epoch_train_loss=5.5005133207875034e-05
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 5.4888026714514946e-05
1829, epoch_train_loss=5.4888026714514946e-05
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 5.477112100652036e-05
1830, epoch_train_loss=5.477112100652036e-05
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 5.4657083148659726e-05
1831, epoch_train_loss=5.4657083148659726e-05
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 5.454883471643282e-05
1832, epoch_train_loss=5.454883471643282e-05
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 5.444552780490102e-05
1833, epoch_train_loss=5.444552780490102e-05
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 5.434646665434029e-05
1834, epoch_train_loss=5.434646665434029e-05
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 5.4248937391199046e-05
1835, epoch_train_loss=5.4248937391199046e-05
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 5.4151529770606246e-05
1836, epoch_train_loss=5.4151529770606246e-05
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 5.405290806421775e-05
1837, epoch_train_loss=5.405290806421775e-05
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 5.39532618743988e-05
1838, epoch_train_loss=5.39532618743988e-05
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 5.385311837366119e-05
1839, epoch_train_loss=5.385311837366119e-05
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 5.375357348955062e-05
1840, epoch_train_loss=5.375357348955062e-05
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 5.365558666577634e-05
1841, epoch_train_loss=5.365558666577634e-05
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 5.355962394471828e-05
1842, epoch_train_loss=5.355962394471828e-05
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 5.346598710767153e-05
1843, epoch_train_loss=5.346598710767153e-05
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 5.337423722293495e-05
1844, epoch_train_loss=5.337423722293495e-05
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 5.328408748663738e-05
1845, epoch_train_loss=5.328408748663738e-05
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 5.319485329113061e-05
1846, epoch_train_loss=5.319485329113061e-05
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 5.310627810106474e-05
1847, epoch_train_loss=5.310627810106474e-05
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 5.3017954301692624e-05
1848, epoch_train_loss=5.3017954301692624e-05
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 5.29299701478618e-05
1849, epoch_train_loss=5.29299701478618e-05
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 5.284228837062878e-05
1850, epoch_train_loss=5.284228837062878e-05
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 5.2755152281675285e-05
1851, epoch_train_loss=5.2755152281675285e-05
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 5.266870429178502e-05
1852, epoch_train_loss=5.266870429178502e-05
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 5.258311935051602e-05
1853, epoch_train_loss=5.258311935051602e-05
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 5.2498498152435024e-05
1854, epoch_train_loss=5.2498498152435024e-05
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 5.241486463801644e-05
1855, epoch_train_loss=5.241486463801644e-05
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 5.2332225660067665e-05
1856, epoch_train_loss=5.2332225660067665e-05
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 5.225048374773282e-05
1857, epoch_train_loss=5.225048374773282e-05
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 5.216961150176642e-05
1858, epoch_train_loss=5.216961150176642e-05
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 5.2089475598334324e-05
1859, epoch_train_loss=5.2089475598334324e-05
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 5.2010048786476525e-05
1860, epoch_train_loss=5.2010048786476525e-05
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 5.193123691931093e-05
1861, epoch_train_loss=5.193123691931093e-05
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 5.185302797611209e-05
1862, epoch_train_loss=5.185302797611209e-05
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 5.177537373120159e-05
1863, epoch_train_loss=5.177537373120159e-05
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 5.1698279318247905e-05
1864, epoch_train_loss=5.1698279318247905e-05
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 5.162173134967075e-05
1865, epoch_train_loss=5.162173134967075e-05
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 5.1545729932012696e-05
1866, epoch_train_loss=5.1545729932012696e-05
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 5.1470286692987276e-05
1867, epoch_train_loss=5.1470286692987276e-05
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 5.13953901548831e-05
1868, epoch_train_loss=5.13953901548831e-05
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 5.132105696389196e-05
1869, epoch_train_loss=5.132105696389196e-05
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 5.1247268648249736e-05
1870, epoch_train_loss=5.1247268648249736e-05
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 5.117403915214044e-05
1871, epoch_train_loss=5.117403915214044e-05
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 5.1101345423534933e-05
1872, epoch_train_loss=5.1101345423534933e-05
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 5.102919783994721e-05
1873, epoch_train_loss=5.102919783994721e-05
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 5.095757419159011e-05
1874, epoch_train_loss=5.095757419159011e-05
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 5.088647809699436e-05
1875, epoch_train_loss=5.088647809699436e-05
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 5.081589442626555e-05
1876, epoch_train_loss=5.081589442626555e-05
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 5.0745821770824894e-05
1877, epoch_train_loss=5.0745821770824894e-05
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 5.0676250702224945e-05
1878, epoch_train_loss=5.0676250702224945e-05
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 5.0607179712941616e-05
1879, epoch_train_loss=5.0607179712941616e-05
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 5.053860647748948e-05
1880, epoch_train_loss=5.053860647748948e-05
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 5.047053217955288e-05
1881, epoch_train_loss=5.047053217955288e-05
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 5.0402963615163916e-05
1882, epoch_train_loss=5.0402963615163916e-05
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 5.033591313385591e-05
1883, epoch_train_loss=5.033591313385591e-05
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 5.0269400632712914e-05
1884, epoch_train_loss=5.0269400632712914e-05
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 5.020346232323752e-05
1885, epoch_train_loss=5.020346232323752e-05
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 5.013814741655831e-05
1886, epoch_train_loss=5.013814741655831e-05
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 5.00735405815689e-05
1887, epoch_train_loss=5.00735405815689e-05
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 5.0009756678355955e-05
1888, epoch_train_loss=5.0009756678355955e-05
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 4.99469859422735e-05
1889, epoch_train_loss=4.99469859422735e-05
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 4.988549621926307e-05
1890, epoch_train_loss=4.988549621926307e-05
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 4.9825715932547775e-05
1891, epoch_train_loss=4.9825715932547775e-05
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 4.976827762978139e-05
1892, epoch_train_loss=4.976827762978139e-05
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 4.971417169863967e-05
1893, epoch_train_loss=4.971417169863967e-05
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 4.966492249769306e-05
1894, epoch_train_loss=4.966492249769306e-05
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 4.962289644137366e-05
1895, epoch_train_loss=4.962289644137366e-05
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 4.9591864555980016e-05
1896, epoch_train_loss=4.9591864555980016e-05
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 4.957766829164908e-05
1897, epoch_train_loss=4.957766829164908e-05
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 4.958992395538693e-05
1898, epoch_train_loss=4.958992395538693e-05
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 4.964351641079886e-05
1899, epoch_train_loss=4.964351641079886e-05
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 4.976377836702493e-05
1900, epoch_train_loss=4.976377836702493e-05
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 4.9989781069275486e-05
1901, epoch_train_loss=4.9989781069275486e-05
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 5.0390573298072024e-05
1902, epoch_train_loss=5.0390573298072024e-05
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 5.107153536352306e-05
1903, epoch_train_loss=5.107153536352306e-05
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 5.222773719021742e-05
1904, epoch_train_loss=5.222773719021742e-05
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 5.4150130054265834e-05
1905, epoch_train_loss=5.4150130054265834e-05
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 5.741124545346857e-05
1906, epoch_train_loss=5.741124545346857e-05
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 6.282838159722352e-05
1907, epoch_train_loss=6.282838159722352e-05
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 7.21535776130106e-05
1908, epoch_train_loss=7.21535776130106e-05
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 8.769699526225661e-05
1909, epoch_train_loss=8.769699526225661e-05
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.00011507766730048966
1910, epoch_train_loss=0.00011507766730048966
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.00016071876264501888
1911, epoch_train_loss=0.00016071876264501888
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.00024363233743365185
1912, epoch_train_loss=0.00024363233743365185
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.00038042742702015206
1913, epoch_train_loss=0.00038042742702015206
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0006393835982223923
1914, epoch_train_loss=0.0006393835982223923
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0010531676507444865
1915, epoch_train_loss=0.0010531676507444865
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.001881884150051972
1916, epoch_train_loss=0.001881884150051972
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.003105660408822322
1917, epoch_train_loss=0.003105660408822322
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.005751295742451437
1918, epoch_train_loss=0.005751295742451437
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.008968472682161504
1919, epoch_train_loss=0.008968472682161504
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.01663982627215765
1920, epoch_train_loss=0.01663982627215765
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.021902154047640673
1921, epoch_train_loss=0.021902154047640673
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.03664177254989334
1922, epoch_train_loss=0.03664177254989334
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.03243774847775713
1923, epoch_train_loss=0.03243774847775713
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.03531240718626711
1924, epoch_train_loss=0.03531240718626711
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.015133809026360674
1925, epoch_train_loss=0.015133809026360674
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.003176913009468852
1926, epoch_train_loss=0.003176913009468852
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.000522276044508915
1927, epoch_train_loss=0.000522276044508915
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.007065641625598789
1928, epoch_train_loss=0.007065641625598789
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.015600639681061242
1929, epoch_train_loss=0.015600639681061242
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.01062579200201043
1930, epoch_train_loss=0.01062579200201043
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.003719636378535607
1931, epoch_train_loss=0.003719636378535607
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.00022627639107320184
1932, epoch_train_loss=0.00022627639107320184
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.0037173272856097705
1933, epoch_train_loss=0.0037173272856097705
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.00830195954217768
1934, epoch_train_loss=0.00830195954217768
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.005101479564616406
1935, epoch_train_loss=0.005101479564616406
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0010359631633214178
1936, epoch_train_loss=0.0010359631633214178
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0006797685738828062
1937, epoch_train_loss=0.0006797685738828062
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0034888676153927373
1938, epoch_train_loss=0.0034888676153927373
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.004762636471970845
1939, epoch_train_loss=0.004762636471970845
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.001848641932663057
1940, epoch_train_loss=0.001848641932663057
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0002281964206770888
1941, epoch_train_loss=0.0002281964206770888
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.001571964794756995
1942, epoch_train_loss=0.001571964794756995
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0028288872995902788
1943, epoch_train_loss=0.0028288872995902788
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.002089286997735644
1944, epoch_train_loss=0.002089286997735644
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.00041522943367414405
1945, epoch_train_loss=0.00041522943367414405
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.0005375113359262489
1946, epoch_train_loss=0.0005375113359262489
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0017693979646704705
1947, epoch_train_loss=0.0017693979646704705
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0016848632799297016
1948, epoch_train_loss=0.0016848632799297016
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0006692487614532232
1949, epoch_train_loss=0.0006692487614532232
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.00018397391158965463
1950, epoch_train_loss=0.00018397391158965463
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007795584765059304
1951, epoch_train_loss=0.0007795584765059304
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.0013077087864622082
1952, epoch_train_loss=0.0013077087864622082
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0008132466370097259
1953, epoch_train_loss=0.0008132466370097259
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0002093486111292915
1954, epoch_train_loss=0.0002093486111292915
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.000272301274332723
1955, epoch_train_loss=0.000272301274332723
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007119322269762867
1956, epoch_train_loss=0.0007119322269762867
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007965277822804259
1957, epoch_train_loss=0.0007965277822804259
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.0003737968203098337
1958, epoch_train_loss=0.0003737968203098337
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.0001195415719097856
1959, epoch_train_loss=0.0001195415719097856
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.0002947629836760777
1960, epoch_train_loss=0.0002947629836760777
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0005248642383071431
1961, epoch_train_loss=0.0005248642383071431
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0004683931297155755
1962, epoch_train_loss=0.0004683931297155755
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.00020034075143216348
1963, epoch_train_loss=0.00020034075143216348
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.00010463188943591413
1964, epoch_train_loss=0.00010463188943591413
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.00024221314302730145
1965, epoch_train_loss=0.00024221314302730145
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.00036019978745527374
1966, epoch_train_loss=0.00036019978745527374
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0002982628756320012
1967, epoch_train_loss=0.0002982628756320012
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.00013928979384321508
1968, epoch_train_loss=0.00013928979384321508
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 9.140039534462391e-05
1969, epoch_train_loss=9.140039534462391e-05
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.00017572889388315773
1970, epoch_train_loss=0.00017572889388315773
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0002467705808001376
1971, epoch_train_loss=0.0002467705808001376
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.00021318954770029389
1972, epoch_train_loss=0.00021318954770029389
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.00011812614950437157
1973, epoch_train_loss=0.00011812614950437157
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 7.996939902985147e-05
1974, epoch_train_loss=7.996939902985147e-05
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.00012192797602616916
1975, epoch_train_loss=0.00012192797602616916
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.00017131182294041655
1976, epoch_train_loss=0.00017131182294041655
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0001645915157003275
1977, epoch_train_loss=0.0001645915157003275
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.00011081778327551035
1978, epoch_train_loss=0.00011081778327551035
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 7.504110559788226e-05
1979, epoch_train_loss=7.504110559788226e-05
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 8.717988812727219e-05
1980, epoch_train_loss=8.717988812727219e-05
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.00011960766781918616
1981, epoch_train_loss=0.00011960766781918616
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.00012979471380282116
1982, epoch_train_loss=0.00012979471380282116
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.00010562151207523323
1983, epoch_train_loss=0.00010562151207523323
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 7.683744405978507e-05
1984, epoch_train_loss=7.683744405978507e-05
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 7.046542976601359e-05
1985, epoch_train_loss=7.046542976601359e-05
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 8.603461718369161e-05
1986, epoch_train_loss=8.603461718369161e-05
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.00010086285185075807
1987, epoch_train_loss=0.00010086285185075807
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 9.708235264762874e-05
1988, epoch_train_loss=9.708235264762874e-05
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 8.039889284744405e-05
1989, epoch_train_loss=8.039889284744405e-05
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 6.738305116292949e-05
1990, epoch_train_loss=6.738305116292949e-05
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 6.835792979629105e-05
1991, epoch_train_loss=6.835792979629105e-05
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 7.808511274104967e-05
1992, epoch_train_loss=7.808511274104967e-05
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 8.380841647497309e-05
1993, epoch_train_loss=8.380841647497309e-05
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 7.972387171446948e-05
1994, epoch_train_loss=7.972387171446948e-05
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 7.00057891953402e-05
1995, epoch_train_loss=7.00057891953402e-05
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 6.369321620029965e-05
1996, epoch_train_loss=6.369321620029965e-05
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 6.48411708446098e-05
1997, epoch_train_loss=6.48411708446098e-05
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 6.994576767105385e-05
1998, epoch_train_loss=6.994576767105385e-05
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 7.281612337204701e-05
1999, epoch_train_loss=7.281612337204701e-05
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 7.041187023527161e-05
2000, epoch_train_loss=7.041187023527161e-05
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 6.516672412076486e-05
2001, epoch_train_loss=6.516672412076486e-05
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 6.141591416376396e-05
2002, epoch_train_loss=6.141591416376396e-05
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 6.14751661254959e-05
2003, epoch_train_loss=6.14751661254959e-05
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 6.393017532501462e-05
2004, epoch_train_loss=6.393017532501462e-05
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 6.571333500859733e-05
2005, epoch_train_loss=6.571333500859733e-05
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 6.497498420630031e-05
2006, epoch_train_loss=6.497498420630031e-05
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 6.228690849837227e-05
2007, epoch_train_loss=6.228690849837227e-05
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 5.9788159343789564e-05
2008, epoch_train_loss=5.9788159343789564e-05
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 5.901211317749257e-05
2009, epoch_train_loss=5.901211317749257e-05
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 5.9852414552371904e-05
2010, epoch_train_loss=5.9852414552371904e-05
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 6.0998465835500946e-05
2011, epoch_train_loss=6.0998465835500946e-05
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 6.114073588215937e-05
2012, epoch_train_loss=6.114073588215937e-05
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 6.007731278823927e-05
2013, epoch_train_loss=6.007731278823927e-05
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 5.852947463111293e-05
2014, epoch_train_loss=5.852947463111293e-05
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 5.747357957620756e-05
2015, epoch_train_loss=5.747357957620756e-05
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 5.733528456383843e-05
2016, epoch_train_loss=5.733528456383843e-05
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 5.779292202057105e-05
2017, epoch_train_loss=5.779292202057105e-05
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 5.817432486683625e-05
2018, epoch_train_loss=5.817432486683625e-05
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 5.8008146583295995e-05
2019, epoch_train_loss=5.8008146583295995e-05
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 5.7315908953660924e-05
2020, epoch_train_loss=5.7315908953660924e-05
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 5.647832164923446e-05
2021, epoch_train_loss=5.647832164923446e-05
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 5.5917350899170784e-05
2022, epoch_train_loss=5.5917350899170784e-05
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 5.577997619708419e-05
2023, epoch_train_loss=5.577997619708419e-05
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 5.591371488030748e-05
2024, epoch_train_loss=5.591371488030748e-05
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 5.6023831237530165e-05
2025, epoch_train_loss=5.6023831237530165e-05
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 5.5894683561290806e-05
2026, epoch_train_loss=5.5894683561290806e-05
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 5.551551392323103e-05
2027, epoch_train_loss=5.551551392323103e-05
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 5.503912693279445e-05
2028, epoch_train_loss=5.503912693279445e-05
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 5.464918783989165e-05
2029, epoch_train_loss=5.464918783989165e-05
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 5.444606710442321e-05
2030, epoch_train_loss=5.444606710442321e-05
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 5.439927345716768e-05
2031, epoch_train_loss=5.439927345716768e-05
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 5.439502292765965e-05
2032, epoch_train_loss=5.439502292765965e-05
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 5.4321887706782794e-05
2033, epoch_train_loss=5.4321887706782794e-05
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 5.413479123498958e-05
2034, epoch_train_loss=5.413479123498958e-05
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 5.3862596027585584e-05
2035, epoch_train_loss=5.3862596027585584e-05
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 5.3581175356013036e-05
2036, epoch_train_loss=5.3581175356013036e-05
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 5.3356342866374786e-05
2037, epoch_train_loss=5.3356342866374786e-05
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 5.3211579973022986e-05
2038, epoch_train_loss=5.3211579973022986e-05
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 5.3126522941877714e-05
2039, epoch_train_loss=5.3126522941877714e-05
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 5.305460034115439e-05
2040, epoch_train_loss=5.305460034115439e-05
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 5.295456476200097e-05
2041, epoch_train_loss=5.295456476200097e-05
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 5.2809227261570635e-05
2042, epoch_train_loss=5.2809227261570635e-05
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 5.262957421633384e-05
2043, epoch_train_loss=5.262957421633384e-05
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 5.244131622916057e-05
2044, epoch_train_loss=5.244131622916057e-05
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 5.227133897232703e-05
2045, epoch_train_loss=5.227133897232703e-05
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 5.213285468494999e-05
2046, epoch_train_loss=5.213285468494999e-05
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 5.202309180943879e-05
2047, epoch_train_loss=5.202309180943879e-05
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 5.1928313979658735e-05
2048, epoch_train_loss=5.1928313979658735e-05
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 5.183200659445978e-05
2049, epoch_train_loss=5.183200659445978e-05
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 5.1722584188588445e-05
2050, epoch_train_loss=5.1722584188588445e-05
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 5.159766590766657e-05
2051, epoch_train_loss=5.159766590766657e-05
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 5.146259026234473e-05
2052, epoch_train_loss=5.146259026234473e-05
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 5.132626164439473e-05
2053, epoch_train_loss=5.132626164439473e-05
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 5.119726489310773e-05
2054, epoch_train_loss=5.119726489310773e-05
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 5.107994239344485e-05
2055, epoch_train_loss=5.107994239344485e-05
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 5.097403476922798e-05
2056, epoch_train_loss=5.097403476922798e-05
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 5.087571680654642e-05
2057, epoch_train_loss=5.087571680654642e-05
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 5.0779968990853806e-05
2058, epoch_train_loss=5.0779968990853806e-05
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 5.068227696042025e-05
2059, epoch_train_loss=5.068227696042025e-05
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 5.058051085781334e-05
2060, epoch_train_loss=5.058051085781334e-05
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 5.047481229780868e-05
2061, epoch_train_loss=5.047481229780868e-05
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 5.0366972920201894e-05
2062, epoch_train_loss=5.0366972920201894e-05
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 5.025957058277111e-05
2063, epoch_train_loss=5.025957058277111e-05
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 5.0154886268923526e-05
2064, epoch_train_loss=5.0154886268923526e-05
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 5.005421410421756e-05
2065, epoch_train_loss=5.005421410421756e-05
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 4.995777288242286e-05
2066, epoch_train_loss=4.995777288242286e-05
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 4.986492532905667e-05
2067, epoch_train_loss=4.986492532905667e-05
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 4.977443374539694e-05
2068, epoch_train_loss=4.977443374539694e-05
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 4.9685077549870466e-05
2069, epoch_train_loss=4.9685077549870466e-05
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 4.9595887977918255e-05
2070, epoch_train_loss=4.9595887977918255e-05
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 4.9506360450797394e-05
2071, epoch_train_loss=4.9506360450797394e-05
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 4.941638908151208e-05
2072, epoch_train_loss=4.941638908151208e-05
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 4.932629621375258e-05
2073, epoch_train_loss=4.932629621375258e-05
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 4.923652464769065e-05
2074, epoch_train_loss=4.923652464769065e-05
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 4.914755737271726e-05
2075, epoch_train_loss=4.914755737271726e-05
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 4.9059794479496554e-05
2076, epoch_train_loss=4.9059794479496554e-05
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 4.897347874860473e-05
2077, epoch_train_loss=4.897347874860473e-05
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 4.888867714911244e-05
2078, epoch_train_loss=4.888867714911244e-05
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 4.8805319417327445e-05
2079, epoch_train_loss=4.8805319417327445e-05
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 4.872326445730119e-05
2080, epoch_train_loss=4.872326445730119e-05
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 4.864229846567176e-05
2081, epoch_train_loss=4.864229846567176e-05
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 4.8562234357593736e-05
2082, epoch_train_loss=4.8562234357593736e-05
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 4.8482906253469384e-05
2083, epoch_train_loss=4.8482906253469384e-05
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 4.8404197258058154e-05
2084, epoch_train_loss=4.8404197258058154e-05
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 4.8326024994502085e-05
2085, epoch_train_loss=4.8326024994502085e-05
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 4.824836755899458e-05
2086, epoch_train_loss=4.824836755899458e-05
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 4.817121852260089e-05
2087, epoch_train_loss=4.817121852260089e-05
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 4.80945952918845e-05
2088, epoch_train_loss=4.80945952918845e-05
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 4.80185204151769e-05
2089, epoch_train_loss=4.80185204151769e-05
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 4.794302832032883e-05
2090, epoch_train_loss=4.794302832032883e-05
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 4.786813333026236e-05
2091, epoch_train_loss=4.786813333026236e-05
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 4.779385514367324e-05
2092, epoch_train_loss=4.779385514367324e-05
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 4.772019771401885e-05
2093, epoch_train_loss=4.772019771401885e-05
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 4.764716588364173e-05
2094, epoch_train_loss=4.764716588364173e-05
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 4.757474771228455e-05
2095, epoch_train_loss=4.757474771228455e-05
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 4.7502939592348025e-05
2096, epoch_train_loss=4.7502939592348025e-05
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 4.7431724247726936e-05
2097, epoch_train_loss=4.7431724247726936e-05
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 4.7361091224750535e-05
2098, epoch_train_loss=4.7361091224750535e-05
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 4.729102130295461e-05
2099, epoch_train_loss=4.729102130295461e-05
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 4.7221505921140404e-05
2100, epoch_train_loss=4.7221505921140404e-05
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 4.715252659468788e-05
2101, epoch_train_loss=4.715252659468788e-05
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 4.708407449092815e-05
2102, epoch_train_loss=4.708407449092815e-05
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 4.701613564921129e-05
2103, epoch_train_loss=4.701613564921129e-05
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 4.694870449954382e-05
2104, epoch_train_loss=4.694870449954382e-05
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 4.688176980457786e-05
2105, epoch_train_loss=4.688176980457786e-05
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 4.681532970425281e-05
2106, epoch_train_loss=4.681532970425281e-05
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 4.674937928850621e-05
2107, epoch_train_loss=4.674937928850621e-05
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 4.66839226771686e-05
2108, epoch_train_loss=4.66839226771686e-05
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 4.661896276890106e-05
2109, epoch_train_loss=4.661896276890106e-05
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 4.655451684354064e-05
2110, epoch_train_loss=4.655451684354064e-05
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 4.64906041730671e-05
2111, epoch_train_loss=4.64906041730671e-05
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 4.642726678952481e-05
2112, epoch_train_loss=4.642726678952481e-05
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 4.636455840760638e-05
2113, epoch_train_loss=4.636455840760638e-05
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 4.6302576253138846e-05
2114, epoch_train_loss=4.6302576253138846e-05
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 4.624145239123658e-05
2115, epoch_train_loss=4.624145239123658e-05
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 4.618140564040905e-05
2116, epoch_train_loss=4.618140564040905e-05
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 4.612275184481903e-05
2117, epoch_train_loss=4.612275184481903e-05
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 4.606599491393832e-05
2118, epoch_train_loss=4.606599491393832e-05
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 4.601189315311959e-05
2119, epoch_train_loss=4.601189315311959e-05
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 4.596163719841346e-05
2120, epoch_train_loss=4.596163719841346e-05
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 4.591708524970536e-05
2121, epoch_train_loss=4.591708524970536e-05
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 4.5881139056049956e-05
2122, epoch_train_loss=4.5881139056049956e-05
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 4.585847403448705e-05
2123, epoch_train_loss=4.585847403448705e-05
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 4.5856381381114294e-05
2124, epoch_train_loss=4.5856381381114294e-05
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 4.588698083126887e-05
2125, epoch_train_loss=4.588698083126887e-05
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 4.596914105834228e-05
2126, epoch_train_loss=4.596914105834228e-05
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 4.613528956563797e-05
2127, epoch_train_loss=4.613528956563797e-05
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 4.6435624562384976e-05
2128, epoch_train_loss=4.6435624562384976e-05
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 4.69598393599029e-05
2129, epoch_train_loss=4.69598393599029e-05
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 4.7844845035163525e-05
2130, epoch_train_loss=4.7844845035163525e-05
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 4.9347594936606504e-05
2131, epoch_train_loss=4.9347594936606504e-05
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 5.184928956006331e-05
2132, epoch_train_loss=5.184928956006331e-05
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 5.611442734408068e-05
2133, epoch_train_loss=5.611442734408068e-05
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 6.321873347632738e-05
2134, epoch_train_loss=6.321873347632738e-05
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 7.553426792015617e-05
2135, epoch_train_loss=7.553426792015617e-05
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 9.609656768838229e-05
2136, epoch_train_loss=9.609656768838229e-05
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.00013262565971831875
2137, epoch_train_loss=0.00013262565971831875
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.00019344297077373334
2138, epoch_train_loss=0.00019344297077373334
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0003050873688417596
2139, epoch_train_loss=0.0003050873688417596
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0004880689705985827
2140, epoch_train_loss=0.0004880689705985827
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0008392663719956662
2141, epoch_train_loss=0.0008392663719956662
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0013909353429429128
2142, epoch_train_loss=0.0013909353429429128
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.002516874190672798
2143, epoch_train_loss=0.002516874190672798
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0041143947798598455
2144, epoch_train_loss=0.0041143947798598455
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0076567231071048006
2145, epoch_train_loss=0.0076567231071048006
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.011548766034359519
2146, epoch_train_loss=0.011548766034359519
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.02115224982780097
2147, epoch_train_loss=0.02115224982780097
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.0256369278460863
2148, epoch_train_loss=0.0256369278460863
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.040035296473514656
2149, epoch_train_loss=0.040035296473514656
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.03019969698410386
2150, epoch_train_loss=0.03019969698410386
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.026109073555959653
2151, epoch_train_loss=0.026109073555959653
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.008133756353086533
2152, epoch_train_loss=0.008133756353086533
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.00032171386075765894
2153, epoch_train_loss=0.00032171386075765894
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0031522134297283758
2154, epoch_train_loss=0.0031522134297283758
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.010221927790285076
2155, epoch_train_loss=0.010221927790285076
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.015659027087031877
2156, epoch_train_loss=0.015659027087031877
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.007567154253008333
2157, epoch_train_loss=0.007567154253008333
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0010868065363253195
2158, epoch_train_loss=0.0010868065363253195
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0011608079981948384
2159, epoch_train_loss=0.0011608079981948384
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.005597387233459138
2160, epoch_train_loss=0.005597387233459138
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.008269597320620284
2161, epoch_train_loss=0.008269597320620284
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0034936120569336124
2162, epoch_train_loss=0.0034936120569336124
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.0002967523952701748
2163, epoch_train_loss=0.0002967523952701748
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.0017129921754334896
2164, epoch_train_loss=0.0017129921754334896
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.0042065603085975935
2165, epoch_train_loss=0.0042065603085975935
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.004144398684360111
2166, epoch_train_loss=0.004144398684360111
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.001079224410143962
2167, epoch_train_loss=0.001079224410143962
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0003796067907113813
2168, epoch_train_loss=0.0003796067907113813
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0022021606189635908
2169, epoch_train_loss=0.0022021606189635908
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.002858915331545108
2170, epoch_train_loss=0.002858915331545108
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.0016279557069848259
2171, epoch_train_loss=0.0016279557069848259
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.00023851659570874216
2172, epoch_train_loss=0.00023851659570874216
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.0007635376319345205
2173, epoch_train_loss=0.0007635376319345205
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0019253413777135637
2174, epoch_train_loss=0.0019253413777135637
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.0015732251524815802
2175, epoch_train_loss=0.0015732251524815802
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0005100698727229092
2176, epoch_train_loss=0.0005100698727229092
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.00020032719630692946
2177, epoch_train_loss=0.00020032719630692946
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.0008546142106257131
2178, epoch_train_loss=0.0008546142106257131
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.0013082639650881106
2179, epoch_train_loss=0.0013082639650881106
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.0007562714990819419
2180, epoch_train_loss=0.0007562714990819419
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.00017870676828867258
2181, epoch_train_loss=0.00017870676828867258
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.00027472760055841094
2182, epoch_train_loss=0.00027472760055841094
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007108308005562747
2183, epoch_train_loss=0.0007108308005562747
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007902975902240677
2184, epoch_train_loss=0.0007902975902240677
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.00036716693798576164
2185, epoch_train_loss=0.00036716693798576164
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.00010916843190940618
2186, epoch_train_loss=0.00010916843190940618
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.00026475819871557956
2187, epoch_train_loss=0.00026475819871557956
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0005084800228498256
2188, epoch_train_loss=0.0005084800228498256
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0004780365571363779
2189, epoch_train_loss=0.0004780365571363779
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.00021445876337441804
2190, epoch_train_loss=0.00021445876337441804
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 8.950916486983484e-05
2191, epoch_train_loss=8.950916486983484e-05
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.0002045284267420931
2192, epoch_train_loss=0.0002045284267420931
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.0003405595303746863
2193, epoch_train_loss=0.0003405595303746863
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.00031266556586512445
2194, epoch_train_loss=0.00031266556586512445
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.00015640117604548198
2195, epoch_train_loss=0.00015640117604548198
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 7.851203098874846e-05
2196, epoch_train_loss=7.851203098874846e-05
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0001410092474906711
2197, epoch_train_loss=0.0001410092474906711
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.00022543430489778228
2198, epoch_train_loss=0.00022543430489778228
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.00022277744537029429
2199, epoch_train_loss=0.00022277744537029429
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.00013378876462074045
2200, epoch_train_loss=0.00013378876462074045
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 7.399314742291381e-05
2201, epoch_train_loss=7.399314742291381e-05
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 9.499975286905906e-05
2202, epoch_train_loss=9.499975286905906e-05
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.00014918195035477162
2203, epoch_train_loss=0.00014918195035477162
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0001645190289787177
2204, epoch_train_loss=0.0001645190289787177
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.0001220860234795631
2205, epoch_train_loss=0.0001220860234795631
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 7.566882895971113e-05
2206, epoch_train_loss=7.566882895971113e-05
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 7.037890556451451e-05
2207, epoch_train_loss=7.037890556451451e-05
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 9.93974495458399e-05
2208, epoch_train_loss=9.93974495458399e-05
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.00012111268070574503
2209, epoch_train_loss=0.00012111268070574503
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.00010971831704213217
2210, epoch_train_loss=0.00010971831704213217
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 8.026618624063684e-05
2211, epoch_train_loss=8.026618624063684e-05
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 6.336981749387425e-05
2212, epoch_train_loss=6.336981749387425e-05
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 7.090458647759934e-05
2213, epoch_train_loss=7.090458647759934e-05
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 8.820607684071358e-05
2214, epoch_train_loss=8.820607684071358e-05
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 9.315297929838473e-05
2215, epoch_train_loss=9.315297929838473e-05
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 8.175924016663716e-05
2216, epoch_train_loss=8.175924016663716e-05
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 6.563886290789851e-05
2217, epoch_train_loss=6.563886290789851e-05
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 6.008123419150268e-05
2218, epoch_train_loss=6.008123419150268e-05
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 6.665042586052614e-05
2219, epoch_train_loss=6.665042586052614e-05
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 7.508889501723937e-05
2220, epoch_train_loss=7.508889501723937e-05
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 7.605503556464554e-05
2221, epoch_train_loss=7.605503556464554e-05
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 6.840884672110488e-05
2222, epoch_train_loss=6.840884672110488e-05
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 6.0048009876875405e-05
2223, epoch_train_loss=6.0048009876875405e-05
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 5.759560846223275e-05
2224, epoch_train_loss=5.759560846223275e-05
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 6.12724962517324e-05
2225, epoch_train_loss=6.12724962517324e-05
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 6.563656840108785e-05
2226, epoch_train_loss=6.563656840108785e-05
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 6.59546918949742e-05
2227, epoch_train_loss=6.59546918949742e-05
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 6.19167682884682e-05
2228, epoch_train_loss=6.19167682884682e-05
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 5.722541452795062e-05
2229, epoch_train_loss=5.722541452795062e-05
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 5.542660788032816e-05
2230, epoch_train_loss=5.542660788032816e-05
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 5.6915496376854137e-05
2231, epoch_train_loss=5.6915496376854137e-05
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 5.925535424867145e-05
2232, epoch_train_loss=5.925535424867145e-05
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 5.987442125274346e-05
2233, epoch_train_loss=5.987442125274346e-05
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 5.8067892180282186e-05
2234, epoch_train_loss=5.8067892180282186e-05
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 5.539585169701074e-05
2235, epoch_train_loss=5.539585169701074e-05
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 5.3803843220835813e-05
2236, epoch_train_loss=5.3803843220835813e-05
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 5.394995493736976e-05
2237, epoch_train_loss=5.394995493736976e-05
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 5.5095283112732565e-05
2238, epoch_train_loss=5.5095283112732565e-05
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 5.5790783744449595e-05
2239, epoch_train_loss=5.5790783744449595e-05
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 5.5317767535917214e-05
2240, epoch_train_loss=5.5317767535917214e-05
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 5.395602103358679e-05
2241, epoch_train_loss=5.395602103358679e-05
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 5.268420438800263e-05
2242, epoch_train_loss=5.268420438800263e-05
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 5.216084171767058e-05
2243, epoch_train_loss=5.216084171767058e-05
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 5.2430122846960575e-05
2244, epoch_train_loss=5.2430122846960575e-05
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 5.291350467048814e-05
2245, epoch_train_loss=5.291350467048814e-05
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 5.301619716297617e-05
2246, epoch_train_loss=5.301619716297617e-05
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 5.2557149085130477e-05
2247, epoch_train_loss=5.2557149085130477e-05
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 5.1782923995404576e-05
2248, epoch_train_loss=5.1782923995404576e-05
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 5.112610729375199e-05
2249, epoch_train_loss=5.112610729375199e-05
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 5.085825207781389e-05
2250, epoch_train_loss=5.085825207781389e-05
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 5.093906937993712e-05
2251, epoch_train_loss=5.093906937993712e-05
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 5.1094002446394374e-05
2252, epoch_train_loss=5.1094002446394374e-05
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 5.1079414768553335e-05
2253, epoch_train_loss=5.1079414768553335e-05
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 5.0801605538253204e-05
2254, epoch_train_loss=5.0801605538253204e-05
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 5.0370293568565115e-05
2255, epoch_train_loss=5.0370293568565115e-05
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 4.997156366253878e-05
2256, epoch_train_loss=4.997156366253878e-05
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 4.974273505588431e-05
2257, epoch_train_loss=4.974273505588431e-05
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 4.967986474672335e-05
2258, epoch_train_loss=4.967986474672335e-05
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 4.969353917642958e-05
2259, epoch_train_loss=4.969353917642958e-05
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 4.965939557641986e-05
2260, epoch_train_loss=4.965939557641986e-05
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 4.9514734477141244e-05
2261, epoch_train_loss=4.9514734477141244e-05
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 4.927600954870359e-05
2262, epoch_train_loss=4.927600954870359e-05
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 4.9015227281622624e-05
2263, epoch_train_loss=4.9015227281622624e-05
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 4.880166810658286e-05
2264, epoch_train_loss=4.880166810658286e-05
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 4.866821823207336e-05
2265, epoch_train_loss=4.866821823207336e-05
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 4.85982378157806e-05
2266, epoch_train_loss=4.85982378157806e-05
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 4.854279128612704e-05
2267, epoch_train_loss=4.854279128612704e-05
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 4.846064376675279e-05
2268, epoch_train_loss=4.846064376675279e-05
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 4.8331950885848294e-05
2269, epoch_train_loss=4.8331950885848294e-05
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 4.816849091592142e-05
2270, epoch_train_loss=4.816849091592142e-05
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 4.799735653646573e-05
2271, epoch_train_loss=4.799735653646573e-05
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 4.7847519897305075e-05
2272, epoch_train_loss=4.7847519897305075e-05
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 4.772955574734731e-05
2273, epoch_train_loss=4.772955574734731e-05
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 4.7639836284751975e-05
2274, epoch_train_loss=4.7639836284751975e-05
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 4.756152907021862e-05
2275, epoch_train_loss=4.756152907021862e-05
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 4.7477488424382644e-05
2276, epoch_train_loss=4.7477488424382644e-05
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 4.737713067311309e-05
2277, epoch_train_loss=4.737713067311309e-05
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 4.726146327661869e-05
2278, epoch_train_loss=4.726146327661869e-05
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 4.7137832196529976e-05
2279, epoch_train_loss=4.7137832196529976e-05
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 4.701688891599873e-05
2280, epoch_train_loss=4.701688891599873e-05
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 4.6906598189685456e-05
2281, epoch_train_loss=4.6906598189685456e-05
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 4.680927817029446e-05
2282, epoch_train_loss=4.680927817029446e-05
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 4.672186739666979e-05
2283, epoch_train_loss=4.672186739666979e-05
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 4.663884740830047e-05
2284, epoch_train_loss=4.663884740830047e-05
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 4.655454196597212e-05
2285, epoch_train_loss=4.655454196597212e-05
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 4.646532428159903e-05
2286, epoch_train_loss=4.646532428159903e-05
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 4.637107871159168e-05
2287, epoch_train_loss=4.637107871159168e-05
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 4.627382493746561e-05
2288, epoch_train_loss=4.627382493746561e-05
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 4.617675032116375e-05
2289, epoch_train_loss=4.617675032116375e-05
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 4.608263261431488e-05
2290, epoch_train_loss=4.608263261431488e-05
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 4.599327620709326e-05
2291, epoch_train_loss=4.599327620709326e-05
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 4.590846704249132e-05
2292, epoch_train_loss=4.590846704249132e-05
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 4.5827201834927156e-05
2293, epoch_train_loss=4.5827201834927156e-05
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 4.5747712832103275e-05
2294, epoch_train_loss=4.5747712832103275e-05
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 4.566850238835938e-05
2295, epoch_train_loss=4.566850238835938e-05
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 4.558841794931677e-05
2296, epoch_train_loss=4.558841794931677e-05
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 4.550736573758269e-05
2297, epoch_train_loss=4.550736573758269e-05
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 4.542560215616147e-05
2298, epoch_train_loss=4.542560215616147e-05
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 4.534388997918775e-05
2299, epoch_train_loss=4.534388997918775e-05
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 4.5262981289129125e-05
2300, epoch_train_loss=4.5262981289129125e-05
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 4.5183550459314196e-05
2301, epoch_train_loss=4.5183550459314196e-05
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 4.510583950058584e-05
2302, epoch_train_loss=4.510583950058584e-05
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 4.50298856753381e-05
2303, epoch_train_loss=4.50298856753381e-05
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 4.495545850511663e-05
2304, epoch_train_loss=4.495545850511663e-05
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 4.488218685677076e-05
2305, epoch_train_loss=4.488218685677076e-05
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 4.4809690320751047e-05
2306, epoch_train_loss=4.4809690320751047e-05
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 4.473768770731793e-05
2307, epoch_train_loss=4.473768770731793e-05
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 4.466599236442096e-05
2308, epoch_train_loss=4.466599236442096e-05
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 4.459451704870738e-05
2309, epoch_train_loss=4.459451704870738e-05
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 4.452331512136314e-05
2310, epoch_train_loss=4.452331512136314e-05
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 4.4452477505916915e-05
2311, epoch_train_loss=4.4452477505916915e-05
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 4.438211967465935e-05
2312, epoch_train_loss=4.438211967465935e-05
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 4.431234546155276e-05
2313, epoch_train_loss=4.431234546155276e-05
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 4.4243258237095996e-05
2314, epoch_train_loss=4.4243258237095996e-05
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 4.417489294750093e-05
2315, epoch_train_loss=4.417489294750093e-05
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 4.4107266151973944e-05
2316, epoch_train_loss=4.4107266151973944e-05
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 4.404035998962487e-05
2317, epoch_train_loss=4.404035998962487e-05
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 4.397414872439903e-05
2318, epoch_train_loss=4.397414872439903e-05
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 4.390857254234454e-05
2319, epoch_train_loss=4.390857254234454e-05
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 4.3843594394276054e-05
2320, epoch_train_loss=4.3843594394276054e-05
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 4.377916423788625e-05
2321, epoch_train_loss=4.377916423788625e-05
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 4.3715251088872984e-05
2322, epoch_train_loss=4.3715251088872984e-05
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 4.365181594992729e-05
2323, epoch_train_loss=4.365181594992729e-05
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 4.358884959189394e-05
2324, epoch_train_loss=4.358884959189394e-05
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 4.3526329149648736e-05
2325, epoch_train_loss=4.3526329149648736e-05
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 4.346425126098131e-05
2326, epoch_train_loss=4.346425126098131e-05
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 4.340260492676719e-05
2327, epoch_train_loss=4.340260492676719e-05
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 4.334139538311226e-05
2328, epoch_train_loss=4.334139538311226e-05
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 4.328061337140775e-05
2329, epoch_train_loss=4.328061337140775e-05
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 4.322026270344377e-05
2330, epoch_train_loss=4.322026270344377e-05
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 4.316033965503813e-05
2331, epoch_train_loss=4.316033965503813e-05
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 4.310084786415735e-05
2332, epoch_train_loss=4.310084786415735e-05
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 4.304178150781079e-05
2333, epoch_train_loss=4.304178150781079e-05
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 4.2983145153393243e-05
2334, epoch_train_loss=4.2983145153393243e-05
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 4.292493768425368e-05
2335, epoch_train_loss=4.292493768425368e-05
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 4.286716516967667e-05
2336, epoch_train_loss=4.286716516967667e-05
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 4.2809829568912346e-05
2337, epoch_train_loss=4.2809829568912346e-05
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 4.27529450700594e-05
2338, epoch_train_loss=4.27529450700594e-05
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 4.2696524151401385e-05
2339, epoch_train_loss=4.2696524151401385e-05
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 4.264059360809303e-05
2340, epoch_train_loss=4.264059360809303e-05
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 4.258518472924814e-05
2341, epoch_train_loss=4.258518472924814e-05
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 4.253035322547745e-05
2342, epoch_train_loss=4.253035322547745e-05
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 4.247616991168295e-05
2343, epoch_train_loss=4.247616991168295e-05
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 4.242274657979985e-05
2344, epoch_train_loss=4.242274657979985e-05
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 4.237023683982642e-05
2345, epoch_train_loss=4.237023683982642e-05
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 4.231887259191441e-05
2346, epoch_train_loss=4.231887259191441e-05
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 4.2268985650889306e-05
2347, epoch_train_loss=4.2268985650889306e-05
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 4.2221067335206734e-05
2348, epoch_train_loss=4.2221067335206734e-05
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 4.217584746650254e-05
2349, epoch_train_loss=4.217584746650254e-05
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 4.213439864221465e-05
2350, epoch_train_loss=4.213439864221465e-05
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 4.209836473875901e-05
2351, epoch_train_loss=4.209836473875901e-05
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 4.2070158420996524e-05
2352, epoch_train_loss=4.2070158420996524e-05
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 4.205359069468845e-05
2353, epoch_train_loss=4.205359069468845e-05
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 4.205425298234564e-05
2354, epoch_train_loss=4.205425298234564e-05
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 4.2081254571634923e-05
2355, epoch_train_loss=4.2081254571634923e-05
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 4.214793519805132e-05
2356, epoch_train_loss=4.214793519805132e-05
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 4.227678023493887e-05
2357, epoch_train_loss=4.227678023493887e-05
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 4.2500496914026816e-05
2358, epoch_train_loss=4.2500496914026816e-05
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 4.287646866610669e-05
2359, epoch_train_loss=4.287646866610669e-05
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 4.3486917438640584e-05
2360, epoch_train_loss=4.3486917438640584e-05
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 4.448347737234066e-05
2361, epoch_train_loss=4.448347737234066e-05
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 4.607727852345065e-05
2362, epoch_train_loss=4.607727852345065e-05
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 4.868413677803292e-05
2363, epoch_train_loss=4.868413677803292e-05
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 5.2854490767878816e-05
2364, epoch_train_loss=5.2854490767878816e-05
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 5.977546502605606e-05
2365, epoch_train_loss=5.977546502605606e-05
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 7.088841770583765e-05
2366, epoch_train_loss=7.088841770583765e-05
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 8.973782768996516e-05
2367, epoch_train_loss=8.973782768996516e-05
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.00012003396701809529
2368, epoch_train_loss=0.00012003396701809529
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.000172908045219528
2369, epoch_train_loss=0.000172908045219528
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.00025727991895752993
2370, epoch_train_loss=0.00025727991895752993
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.000410124759039397
2371, epoch_train_loss=0.000410124759039397
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0006483156203493594
2372, epoch_train_loss=0.0006483156203493594
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.0011019741921681815
2373, epoch_train_loss=0.0011019741921681815
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0017700005678105567
2374, epoch_train_loss=0.0017700005678105567
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0031318676511999416
2375, epoch_train_loss=0.0031318676511999416
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.004893967576503282
2376, epoch_train_loss=0.004893967576503282
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.008825533094362905
2377, epoch_train_loss=0.008825533094362905
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.012514867653580147
2378, epoch_train_loss=0.012514867653580147
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.02182349632454607
2379, epoch_train_loss=0.02182349632454607
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.024399303221162322
2380, epoch_train_loss=0.024399303221162322
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.03503186999045146
2381, epoch_train_loss=0.03503186999045146
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.02452899828083458
2382, epoch_train_loss=0.02452899828083458
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.01860834238910509
2383, epoch_train_loss=0.01860834238910509
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.005210493010105572
2384, epoch_train_loss=0.005210493010105572
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.00011344328613938877
2385, epoch_train_loss=0.00011344328613938877
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.003181259498528182
2386, epoch_train_loss=0.003181259498528182
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.008734878374757938
2387, epoch_train_loss=0.008734878374757938
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.012781937636835992
2388, epoch_train_loss=0.012781937636835992
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0066775132493182
2389, epoch_train_loss=0.0066775132493182
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0013569301429784417
2390, epoch_train_loss=0.0013569301429784417
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0004832591881120145
2391, epoch_train_loss=0.0004832591881120145
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.003752208616110807
2392, epoch_train_loss=0.003752208616110807
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.006743074661176276
2393, epoch_train_loss=0.006743074661176276
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.00404496433074366
2394, epoch_train_loss=0.00404496433074366
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0008967777415054027
2395, epoch_train_loss=0.0008967777415054027
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0003880032201303294
2396, epoch_train_loss=0.0003880032201303294
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.002419578311250355
2397, epoch_train_loss=0.002419578311250355
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.003898407794008922
2398, epoch_train_loss=0.003898407794008922
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0021660950042221433
2399, epoch_train_loss=0.0021660950042221433
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.00038901501891205675
2400, epoch_train_loss=0.00038901501891205675
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.0004672461867817093
2401, epoch_train_loss=0.0004672461867817093
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0017515414723043886
2402, epoch_train_loss=0.0017515414723043886
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.002299982051403807
2403, epoch_train_loss=0.002299982051403807
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.0011201933258267994
2404, epoch_train_loss=0.0011201933258267994
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0001826524273939961
2405, epoch_train_loss=0.0001826524273939961
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.00046087557379326065
2406, epoch_train_loss=0.00046087557379326065
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0012191952376431347
2407, epoch_train_loss=0.0012191952376431347
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.001359597911133432
2408, epoch_train_loss=0.001359597911133432
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.000607255977204151
2409, epoch_train_loss=0.000607255977204151
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.00012010664518834179
2410, epoch_train_loss=0.00012010664518834179
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.00036337105542550346
2411, epoch_train_loss=0.00036337105542550346
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.0008006679217517906
2412, epoch_train_loss=0.0008006679217517906
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.0008304821127422907
2413, epoch_train_loss=0.0008304821127422907
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.000381131169921398
2414, epoch_train_loss=0.000381131169921398
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 9.791589893967693e-05
2415, epoch_train_loss=9.791589893967693e-05
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0002372658201919168
2416, epoch_train_loss=0.0002372658201919168
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.0005034453599163463
2417, epoch_train_loss=0.0005034453599163463
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0005395566150221523
2418, epoch_train_loss=0.0005395566150221523
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.00028551201444052335
2419, epoch_train_loss=0.00028551201444052335
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 9.076215769810453e-05
2420, epoch_train_loss=9.076215769810453e-05
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0001366811582882078
2421, epoch_train_loss=0.0001366811582882078
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0002997498846200627
2422, epoch_train_loss=0.0002997498846200627
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.00036138760095065525
2423, epoch_train_loss=0.00036138760095065525
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.00023946774068223613
2424, epoch_train_loss=0.00023946774068223613
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.00010029134032428009
2425, epoch_train_loss=0.00010029134032428009
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 7.917347093673898e-05
2426, epoch_train_loss=7.917347093673898e-05
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.00016415143137542236
2427, epoch_train_loss=0.00016415143137542236
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.00023489160102131544
2428, epoch_train_loss=0.00023489160102131544
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.00020250215941381496
2429, epoch_train_loss=0.00020250215941381496
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.00011747297637490427
2430, epoch_train_loss=0.00011747297637490427
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 6.548427890373977e-05
2431, epoch_train_loss=6.548427890373977e-05
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 8.697637669927749e-05
2432, epoch_train_loss=8.697637669927749e-05
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.00013984477512243897
2433, epoch_train_loss=0.00013984477512243897
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0001568052649620537
2434, epoch_train_loss=0.0001568052649620537
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.000125064277151715
2435, epoch_train_loss=0.000125064277151715
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 7.745040550196481e-05
2436, epoch_train_loss=7.745040550196481e-05
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 6.0149265497386604e-05
2437, epoch_train_loss=6.0149265497386604e-05
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 7.946875694965154e-05
2438, epoch_train_loss=7.946875694965154e-05
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.00010602739974726663
2439, epoch_train_loss=0.00010602739974726663
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.00011104357426579059
2440, epoch_train_loss=0.00011104357426579059
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 8.965722263462443e-05
2441, epoch_train_loss=8.965722263462443e-05
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 6.490099364633763e-05
2442, epoch_train_loss=6.490099364633763e-05
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 5.7014806253284953e-05
2443, epoch_train_loss=5.7014806253284953e-05
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 6.772668840237174e-05
2444, epoch_train_loss=6.772668840237174e-05
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 8.197236443684876e-05
2445, epoch_train_loss=8.197236443684876e-05
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 8.435010052773428e-05
2446, epoch_train_loss=8.435010052773428e-05
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 7.387772325579432e-05
2447, epoch_train_loss=7.387772325579432e-05
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 6.0090451929826185e-05
2448, epoch_train_loss=6.0090451929826185e-05
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 5.418527288799162e-05
2449, epoch_train_loss=5.418527288799162e-05
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 5.836751122116081e-05
2450, epoch_train_loss=5.836751122116081e-05
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 6.59781759984809e-05
2451, epoch_train_loss=6.59781759984809e-05
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 6.915270687419909e-05
2452, epoch_train_loss=6.915270687419909e-05
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 6.498386788861656e-05
2453, epoch_train_loss=6.498386788861656e-05
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 5.757260886300988e-05
2454, epoch_train_loss=5.757260886300988e-05
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 5.252635110442582e-05
2455, epoch_train_loss=5.252635110442582e-05
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 5.268792598015885e-05
2456, epoch_train_loss=5.268792598015885e-05
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 5.626136464807017e-05
2457, epoch_train_loss=5.626136464807017e-05
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 5.917354945846142e-05
2458, epoch_train_loss=5.917354945846142e-05
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 5.8829981705670005e-05
2459, epoch_train_loss=5.8829981705670005e-05
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 5.551921631619354e-05
2460, epoch_train_loss=5.551921631619354e-05
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 5.185540927636774e-05
2461, epoch_train_loss=5.185540927636774e-05
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 5.0137948736790746e-05
2462, epoch_train_loss=5.0137948736790746e-05
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 5.084243608363212e-05
2463, epoch_train_loss=5.084243608363212e-05
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 5.2628863861033845e-05
2464, epoch_train_loss=5.2628863861033845e-05
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 5.364471878604147e-05
2465, epoch_train_loss=5.364471878604147e-05
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 5.30390793146935e-05
2466, epoch_train_loss=5.30390793146935e-05
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 5.121154617628716e-05
2467, epoch_train_loss=5.121154617628716e-05
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 4.9397733430752805e-05
2468, epoch_train_loss=4.9397733430752805e-05
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 4.85514778816708e-05
2469, epoch_train_loss=4.85514778816708e-05
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 4.882151447693173e-05
2470, epoch_train_loss=4.882151447693173e-05
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 4.958824758944012e-05
2471, epoch_train_loss=4.958824758944012e-05
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 5.004388674484368e-05
2472, epoch_train_loss=5.004388674484368e-05
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 4.977072635451886e-05
2473, epoch_train_loss=4.977072635451886e-05
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 4.889203353472778e-05
2474, epoch_train_loss=4.889203353472778e-05
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 4.79115104324432e-05
2475, epoch_train_loss=4.79115104324432e-05
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 4.7291771333656165e-05
2476, epoch_train_loss=4.7291771333656165e-05
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 4.719337620942339e-05
2477, epoch_train_loss=4.719337620942339e-05
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 4.7433891036859535e-05
2478, epoch_train_loss=4.7433891036859535e-05
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 4.7670451706399115e-05
2479, epoch_train_loss=4.7670451706399115e-05
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 4.764461329104455e-05
2480, epoch_train_loss=4.764461329104455e-05
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 4.730009043049169e-05
2481, epoch_train_loss=4.730009043049169e-05
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 4.678669026358502e-05
2482, epoch_train_loss=4.678669026358502e-05
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 4.631583377155195e-05
2483, epoch_train_loss=4.631583377155195e-05
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 4.60414510915715e-05
2484, epoch_train_loss=4.60414510915715e-05
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 4.597841458739449e-05
2485, epoch_train_loss=4.597841458739449e-05
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 4.6029960843832066e-05
2486, epoch_train_loss=4.6029960843832066e-05
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 4.606167833600998e-05
2487, epoch_train_loss=4.606167833600998e-05
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 4.597976335038905e-05
2488, epoch_train_loss=4.597976335038905e-05
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 4.5771469188896623e-05
2489, epoch_train_loss=4.5771469188896623e-05
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 4.5491151753330146e-05
2490, epoch_train_loss=4.5491151753330146e-05
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 4.5221868461194946e-05
2491, epoch_train_loss=4.5221868461194946e-05
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 4.5024553711459965e-05
2492, epoch_train_loss=4.5024553711459965e-05
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 4.491524413044192e-05
2493, epoch_train_loss=4.491524413044192e-05
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 4.48670280268593e-05
2494, epoch_train_loss=4.48670280268593e-05
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 4.4832089982911646e-05
2495, epoch_train_loss=4.4832089982911646e-05
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 4.4767998060720014e-05
2496, epoch_train_loss=4.4767998060720014e-05
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 4.46551672684189e-05
2497, epoch_train_loss=4.46551672684189e-05
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 4.450176343317608e-05
2498, epoch_train_loss=4.450176343317608e-05
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 4.4331854279525456e-05
2499, epoch_train_loss=4.4331854279525456e-05
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02f340> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02f340> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffecc02f340> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02e230> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02ece0> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02e2f0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02e020> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02eb60> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02e500> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02e200> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffecc02e740> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02dbd0> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffecc02ddb0> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffecc02caf0> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02cb50> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02c040> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02c970> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffecc02fa00> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02d870> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02f070> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02c160> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02c730> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffecc02e5f0> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffecc02e620> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffecc02e0b0> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffecc02e680> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffecc02dfc0> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e230> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e230> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-3.47389956e-03 -8.82676818e-04 -2.08411238e-03 ... -1.11301603e+01
 -1.11301603e+01 -1.11301603e+01] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046675  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02ece0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02ece0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.07670570e-03 -5.92340671e-04 -6.66573372e-05 ... -5.03679786e+00
 -5.03679786e+00 -5.03679786e+00] = SCAN,
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 4)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e2f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e2f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.59173730e-03 -7.67300285e-04 -6.09330303e-05 ... -7.27736608e-01
 -7.27736608e-01 -7.27736608e-01] = SCAN,
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 4)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e020> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e020> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-6.71503005e-03 -1.44519923e-03 -1.44519923e-03 ... -1.46899070e-02
 -2.03947707e+00 -2.03947707e+00] = SCAN,
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 4)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033802925921  <S^2> = 2.0027445  2S+1 = 3.0018291
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02eb60> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02eb60> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.69846342e-04 -1.40969146e-04 -6.96757357e-06 ... -5.78449353e+00
 -5.78449353e+00 -5.78449353e+00] = SCAN,
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 4)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121988  <S^2> = 0.75161941  2S+1 = 2.0016188
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e500> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e500> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-9.56008936e-04 -9.56438235e-04 -3.30460807e-04 ... -1.26648275e+01
 -1.26648275e+01 -1.26648275e+01] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 4)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560989243  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e200> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e200> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.33118550e-02 -8.49068703e-03 -4.25301188e-03 ... -1.37659916e-04
 -1.02991814e-03 -7.41975204e-05] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 4)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786821845  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e740> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e740> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.34144045e-03 -8.33231739e-04 -9.25523355e-04 ... -1.18986567e+01
 -1.18986567e+01 -1.18986567e+01] = SCAN,
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 4)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 1.7763568e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02dbd0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02dbd0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.04987770e-03 -6.68954111e-04 -8.57556562e-04 ... -1.07485605e-03
 -8.01425702e-01 -8.01425702e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 4)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.337792446513  <S^2> = 4.0073012e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02ddb0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02ddb0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.97917639e-04 -2.54437615e-05 -3.15202008e-05 ... -6.37386388e-01
 -6.37386388e-01 -6.37386388e-01] = SCAN,
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 4)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322844  <S^2> = 2.1316282e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02caf0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02caf0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.50217343e-04 -2.07520331e-04 -9.23619961e-04 ... -2.76182455e-06
 -4.27559894e+00 -4.27559894e+00] = SCAN,
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 4)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.00560888896  <S^2> = 4.9737992e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02cb50> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02cb50> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-0.00155834 -0.00091688 -0.00215831 ... -0.00091688 -0.41618506
 -0.41618506] = SCAN,
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 4)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.1368684e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02c040> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02c040> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.92948752e-04 -1.95215890e-05 -1.16699780e-03 ... -4.89378326e-01
 -4.89378326e-01 -4.89378326e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 4)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.214894499889  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02c970> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02c970> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-7.33205749e-04 -1.30905131e-04 -6.76514201e-06 ... -6.59150630e-01
 -6.59150630e-01 -6.59150630e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 4)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346375  <S^2> = 8.8817842e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02fa00> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02fa00> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.83278187e-05 -8.83278187e-05 -9.75839793e-04 ... -3.46740731e-05
 -3.31729009e-05 -3.31729009e-05] = SCAN,
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 4)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5991657e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02d870> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02d870> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-5.37000596e-04 -8.55494373e-04 -2.46853248e-03 ... -7.34251993e-01
 -7.34251993e-01 -7.34251993e-01] = SCAN,
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 4)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374078  <S^2> = 6.5725203e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02f070> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02f070> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-2.38161478e-04 -1.81223966e-05 -2.37327566e-05 ... -2.83738108e+00
 -2.83738108e+00 -2.83738108e+00] = SCAN,
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 4)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.3940853e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02c160> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02c160> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-0.00113445 -0.00118624 -0.00118624 ... -0.48434639 -0.48434639
 -0.48434639] = SCAN,
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 4)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506579  <S^2> = 1.5859314e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02c730> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02c730> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-0.00297936 -0.00297936 -0.00407091 ... -0.00297936 -0.00297936
 -0.00407091] = SCAN,
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 4)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845815  <S^2> = 8.31335e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e5f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e5f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.61401455e-04 -4.90485117e-04 -2.56451688e-03 ... -9.59296114e+00
 -9.59296114e+00 -9.59296114e+00] = SCAN,
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 4)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5391245e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e620> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e620> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.28637187e-03 -4.32380890e-04 -3.74072638e-05 ... -1.91722763e+00
 -1.91722763e+00 -1.91722763e+00] = SCAN,
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 4)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336456676  <S^2> = 1.0034705  2S+1 = 2.23917
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e0b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e0b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-1.60119969e-04 -2.60142457e-04 -2.60155553e-04 ... -3.86943881e-01
 -3.86943881e-01 -3.86943881e-01] = SCAN,
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 4)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864077  <S^2> = 3.2418512e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02e680> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02e680> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.68439856e-04 -2.42462783e-04 -1.69965237e-05 ... -2.55256081e-05
 -2.55256081e-05 -2.55256081e-05] = SCAN,
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 4)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.1972649e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffecc02dfc0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffecc02dfc0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-7.67691257e-04 -4.57409182e-05 -2.02835243e-04 ... -1.14928928e+00
 -1.14928928e+00 -1.14928928e+00] = SCAN,
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 4)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437818  <S^2> = 1.3148593e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Exchange contribution only
SCAN,
no spin scaling
exc with xc_func = [-8.33847724e-04 -2.34902391e-04 -1.75660753e-05 ... -1.92925750e-05
 -1.92925750e-05 -1.92925750e-05] = SCAN,
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 4)
PRE NAN FILT: tFxc.shape=(224161,), tdrho.shape=(224161, 4)
nan_filt_rho.shape=(224161,)
nan_filt_fxc.shape=(224161,)
tFxc.shape=(224161,), tdrho.shape=(224161, 4)
inp[0].shape = (224161, 4)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 4.906772746816812
0, epoch_train_loss=4.906772746816812
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 4.578915095722851
1, epoch_train_loss=4.578915095722851
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 4.319930135858155
2, epoch_train_loss=4.319930135858155
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 4.1793878914973455
3, epoch_train_loss=4.1793878914973455
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 3.803109732645415
4, epoch_train_loss=3.803109732645415
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 3.4216864749185683
5, epoch_train_loss=3.4216864749185683
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 2.85631921934903
6, epoch_train_loss=2.85631921934903
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 2.051485808624327
7, epoch_train_loss=2.051485808624327
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 1.2914885665924711
8, epoch_train_loss=1.2914885665924711
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.7249997668326018
9, epoch_train_loss=0.7249997668326018
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.734475707350384
10, epoch_train_loss=0.734475707350384
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 1.5964077483951042
11, epoch_train_loss=1.5964077483951042
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.7750734281844142
12, epoch_train_loss=0.7750734281844142
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.8523512690074713
13, epoch_train_loss=0.8523512690074713
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.3438888356983797
14, epoch_train_loss=0.3438888356983797
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.6973615995782522
15, epoch_train_loss=0.6973615995782522
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.2214211358039089
16, epoch_train_loss=0.2214211358039089
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.2716590924782514
17, epoch_train_loss=0.2716590924782514
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.32691596666040856
18, epoch_train_loss=0.32691596666040856
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.16586863303527286
19, epoch_train_loss=0.16586863303527286
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.17335253151970878
20, epoch_train_loss=0.17335253151970878
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.24025347970763464
21, epoch_train_loss=0.24025347970763464
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.19601029197623915
22, epoch_train_loss=0.19601029197623915
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.11342882630674363
23, epoch_train_loss=0.11342882630674363
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.11300607210325532
24, epoch_train_loss=0.11300607210325532
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.1577239676804959
25, epoch_train_loss=0.1577239676804959
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.12833170312948794
26, epoch_train_loss=0.12833170312948794
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0838607841674857
27, epoch_train_loss=0.0838607841674857
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.10053574108410802
28, epoch_train_loss=0.10053574108410802
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.1100486270666006
29, epoch_train_loss=0.1100486270666006
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0737475259375484
30, epoch_train_loss=0.0737475259375484
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.05213240457198943
31, epoch_train_loss=0.05213240457198943
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.07091599299347023
32, epoch_train_loss=0.07091599299347023
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.0687946853836061
33, epoch_train_loss=0.0687946853836061
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.04485745368491976
34, epoch_train_loss=0.04485745368491976
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.046887775358070836
35, epoch_train_loss=0.046887775358070836
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.05440138755354373
36, epoch_train_loss=0.05440138755354373
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.041682409119793186
37, epoch_train_loss=0.041682409119793186
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.028032451809358743
38, epoch_train_loss=0.028032451809358743
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.034457800123963184
39, epoch_train_loss=0.034457800123963184
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.0350252627765184
40, epoch_train_loss=0.0350252627765184
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.024115910834763353
41, epoch_train_loss=0.024115910834763353
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.026589267746823696
42, epoch_train_loss=0.026589267746823696
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.029005198218903357
43, epoch_train_loss=0.029005198218903357
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.019473009616717187
44, epoch_train_loss=0.019473009616717187
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.017594782145720862
45, epoch_train_loss=0.017594782145720862
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.021456995079852673
46, epoch_train_loss=0.021456995079852673
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.01413974889711131
47, epoch_train_loss=0.01413974889711131
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.01327285855987394
48, epoch_train_loss=0.01327285855987394
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.01797628410449884
49, epoch_train_loss=0.01797628410449884
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.012040339364995946
50, epoch_train_loss=0.012040339364995946
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.009561555100803929
51, epoch_train_loss=0.009561555100803929
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.013525268434447736
52, epoch_train_loss=0.013525268434447736
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.008536918997578358
53, epoch_train_loss=0.008536918997578358
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.006507057541264431
54, epoch_train_loss=0.006507057541264431
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.01077857062454622
55, epoch_train_loss=0.01077857062454622
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.007518807377356529
56, epoch_train_loss=0.007518807377356529
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.005934986977994098
57, epoch_train_loss=0.005934986977994098
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.008724661340714061
58, epoch_train_loss=0.008724661340714061
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.005997816203463202
59, epoch_train_loss=0.005997816203463202
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.005178782767656149
60, epoch_train_loss=0.005178782767656149
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.006417853941771286
61, epoch_train_loss=0.006417853941771286
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.004790780403206783
62, epoch_train_loss=0.004790780403206783
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.005241913312813967
63, epoch_train_loss=0.005241913312813967
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.005165497852881084
64, epoch_train_loss=0.005165497852881084
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.004105537696889754
65, epoch_train_loss=0.004105537696889754
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.004997903954031138
66, epoch_train_loss=0.004997903954031138
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.003837837666998567
67, epoch_train_loss=0.003837837666998567
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.003430705367467554
68, epoch_train_loss=0.003430705367467554
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0042899483660254565
69, epoch_train_loss=0.0042899483660254565
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.003062273051945062
70, epoch_train_loss=0.003062273051945062
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0033261639391081064
71, epoch_train_loss=0.0033261639391081064
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.003529640982205005
72, epoch_train_loss=0.003529640982205005
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.002807874231583305
73, epoch_train_loss=0.002807874231583305
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0031220646515099345
74, epoch_train_loss=0.0031220646515099345
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0026867493065667217
75, epoch_train_loss=0.0026867493065667217
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0026863766933754567
76, epoch_train_loss=0.0026863766933754567
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0026947970080219872
77, epoch_train_loss=0.0026947970080219872
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.0022498157872699103
78, epoch_train_loss=0.0022498157872699103
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0026242960114437525
79, epoch_train_loss=0.0026242960114437525
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0022802980644813613
80, epoch_train_loss=0.0022802980644813613
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.002168163594259221
81, epoch_train_loss=0.002168163594259221
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0023129724734579425
82, epoch_train_loss=0.0023129724734579425
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.001980229860919873
83, epoch_train_loss=0.001980229860919873
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0020791494422628246
84, epoch_train_loss=0.0020791494422628246
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0019196791489655928
85, epoch_train_loss=0.0019196791489655928
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.0019264045586787298
86, epoch_train_loss=0.0019264045586787298
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.001897535844170622
87, epoch_train_loss=0.001897535844170622
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0017463245663785604
88, epoch_train_loss=0.0017463245663785604
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0018627532429587332
89, epoch_train_loss=0.0018627532429587332
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0016630743202927724
90, epoch_train_loss=0.0016630743202927724
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0016822860969971589
91, epoch_train_loss=0.0016822860969971589
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.001654999932121225
92, epoch_train_loss=0.001654999932121225
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.00157281342989717
93, epoch_train_loss=0.00157281342989717
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.001595923133433084
94, epoch_train_loss=0.001595923133433084
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0015092530073951922
95, epoch_train_loss=0.0015092530073951922
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0015365273447252256
96, epoch_train_loss=0.0015365273447252256
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.00143593119142646
97, epoch_train_loss=0.00143593119142646
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0014414093263094652
98, epoch_train_loss=0.0014414093263094652
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0014065559250458284
99, epoch_train_loss=0.0014065559250458284
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.001349299397780754
100, epoch_train_loss=0.001349299397780754
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.0013594587994699824
101, epoch_train_loss=0.0013594587994699824
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.001299176647085954
102, epoch_train_loss=0.001299176647085954
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.0012973552503448241
103, epoch_train_loss=0.0012973552503448241
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0012438115619718526
104, epoch_train_loss=0.0012438115619718526
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0012438231915615637
105, epoch_train_loss=0.0012438231915615637
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0011987508865753086
106, epoch_train_loss=0.0011987508865753086
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0011818290187010617
107, epoch_train_loss=0.0011818290187010617
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0011664102857451215
108, epoch_train_loss=0.0011664102857451215
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0011324594181755566
109, epoch_train_loss=0.0011324594181755566
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0011246060979423628
110, epoch_train_loss=0.0011246060979423628
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.001094129927351422
111, epoch_train_loss=0.001094129927351422
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0010848994129120256
112, epoch_train_loss=0.0010848994129120256
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0010520985774373282
113, epoch_train_loss=0.0010520985774373282
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0010478741446745593
114, epoch_train_loss=0.0010478741446745593
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0010190262172549232
115, epoch_train_loss=0.0010190262172549232
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0010096188572872487
116, epoch_train_loss=0.0010096188572872487
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.000990642118409252
117, epoch_train_loss=0.000990642118409252
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0009762632285400225
118, epoch_train_loss=0.0009762632285400225
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0009586347879986276
119, epoch_train_loss=0.0009586347879986276
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.0009449582122086481
120, epoch_train_loss=0.0009449582122086481
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0009304815869777496
121, epoch_train_loss=0.0009304815869777496
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0009143945970364267
122, epoch_train_loss=0.0009143945970364267
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0009044349441514206
123, epoch_train_loss=0.0009044349441514206
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0008876462659820911
124, epoch_train_loss=0.0008876462659820911
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0008770419974718393
125, epoch_train_loss=0.0008770419974718393
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0008620876678407164
126, epoch_train_loss=0.0008620876678407164
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0008517427026995755
127, epoch_train_loss=0.0008517427026995755
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0008365672822742139
128, epoch_train_loss=0.0008365672822742139
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0008278025134697106
129, epoch_train_loss=0.0008278025134697106
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.000813403824634382
130, epoch_train_loss=0.000813403824634382
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0008041350127215062
131, epoch_train_loss=0.0008041350127215062
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007914964341966351
132, epoch_train_loss=0.0007914964341966351
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007819927688690851
133, epoch_train_loss=0.0007819927688690851
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007695906614054856
134, epoch_train_loss=0.0007695906614054856
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.000760919940988367
135, epoch_train_loss=0.000760919940988367
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007491762244609883
136, epoch_train_loss=0.0007491762244609883
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007405336458477738
137, epoch_train_loss=0.0007405336458477738
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0007299785593048755
138, epoch_train_loss=0.0007299785593048755
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007212050750687716
139, epoch_train_loss=0.0007212050750687716
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007110128575993473
140, epoch_train_loss=0.0007110128575993473
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007027965128377884
141, epoch_train_loss=0.0007027965128377884
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0006929640902999635
142, epoch_train_loss=0.0006929640902999635
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0006849656415507762
143, epoch_train_loss=0.0006849656415507762
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0006758688552635552
144, epoch_train_loss=0.0006758688552635552
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.0006678548976879388
145, epoch_train_loss=0.0006678548976879388
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0006592005157820035
146, epoch_train_loss=0.0006592005157820035
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0006515076507547739
147, epoch_train_loss=0.0006515076507547739
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0006430905870969547
148, epoch_train_loss=0.0006430905870969547
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0006356458019052882
149, epoch_train_loss=0.0006356458019052882
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0006277177840025503
150, epoch_train_loss=0.0006277177840025503
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.0006203530468358464
151, epoch_train_loss=0.0006203530468358464
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0006128809977062897
152, epoch_train_loss=0.0006128809977062897
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0006056885943384027
153, epoch_train_loss=0.0006056885943384027
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0005984586480643113
154, epoch_train_loss=0.0005984586480643113
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.000591507451487074
155, epoch_train_loss=0.000591507451487074
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0005846012499151172
156, epoch_train_loss=0.0005846012499151172
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.0005777997785870689
157, epoch_train_loss=0.0005777997785870689
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0005712420421481316
158, epoch_train_loss=0.0005712420421481316
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0005645866909332379
159, epoch_train_loss=0.0005645866909332379
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.000558257527775132
160, epoch_train_loss=0.000558257527775132
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0005518435044152752
161, epoch_train_loss=0.0005518435044152752
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.0005456974742736912
162, epoch_train_loss=0.0005456974742736912
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0005395115539413382
163, epoch_train_loss=0.0005395115539413382
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.0005335737647699277
164, epoch_train_loss=0.0005335737647699277
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0005275888893558034
165, epoch_train_loss=0.0005275888893558034
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0005218268521357974
166, epoch_train_loss=0.0005218268521357974
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0005160680465693701
167, epoch_train_loss=0.0005160680465693701
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0005104333516411604
168, epoch_train_loss=0.0005104333516411604
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0005049084077090178
169, epoch_train_loss=0.0005049084077090178
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0004994225479210315
170, epoch_train_loss=0.0004994225479210315
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0004940866279070755
171, epoch_train_loss=0.0004940866279070755
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.0004887705982195675
172, epoch_train_loss=0.0004887705982195675
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0004835893565911305
173, epoch_train_loss=0.0004835893565911305
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.00047844278023762146
174, epoch_train_loss=0.00047844278023762146
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.00047341758586085826
175, epoch_train_loss=0.00047341758586085826
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0004684379424633848
176, epoch_train_loss=0.0004684379424633848
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.00046355590290593377
177, epoch_train_loss=0.00046355590290593377
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.00045874643242548214
178, epoch_train_loss=0.00045874643242548214
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.00045399533275101566
179, epoch_train_loss=0.00045399533275101566
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.00044934582919797686
180, epoch_train_loss=0.00044934582919797686
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.000444732786487306
181, epoch_train_loss=0.000444732786487306
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.00044022107810539934
182, epoch_train_loss=0.00044022107810539934
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.00043575921985694344
183, epoch_train_loss=0.00043575921985694344
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0004313718718687921
184, epoch_train_loss=0.0004313718718687921
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0004270554893423276
185, epoch_train_loss=0.0004270554893423276
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0004227920955409768
186, epoch_train_loss=0.0004227920955409768
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0004186071928009293
187, epoch_train_loss=0.0004186071928009293
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0004144734832832672
188, epoch_train_loss=0.0004144734832832672
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.0004104113085273922
189, epoch_train_loss=0.0004104113085273922
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0004064058028757555
190, epoch_train_loss=0.0004064058028757555
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.00040246108844018915
191, epoch_train_loss=0.00040246108844018915
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.0003985787796359613
192, epoch_train_loss=0.0003985787796359613
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.00039474953025518016
193, epoch_train_loss=0.00039474953025518016
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.00039098410670798705
194, epoch_train_loss=0.00039098410670798705
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.00038727001639066416
195, epoch_train_loss=0.00038727001639066416
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.00038361517395084864
196, epoch_train_loss=0.00038361517395084864
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.0003800147107667931
197, epoch_train_loss=0.0003800147107667931
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.00037646572454312524
198, epoch_train_loss=0.00037646572454312524
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.00037297382195098196
199, epoch_train_loss=0.00037297382195098196
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.00036953019481432555
200, epoch_train_loss=0.00036953019481432555
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.00036614100972734263
201, epoch_train_loss=0.00036614100972734263
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.00036280216202484364
202, epoch_train_loss=0.00036280216202484364
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0003595117293793567
203, epoch_train_loss=0.0003595117293793567
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.00035627330712646147
204, epoch_train_loss=0.00035627330712646147
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0003530808263750512
205, epoch_train_loss=0.0003530808263750512
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0003499375592043497
206, epoch_train_loss=0.0003499375592043497
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0003468414569524787
207, epoch_train_loss=0.0003468414569524787
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.000343790317518369
208, epoch_train_loss=0.000343790317518369
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0003407866115018691
209, epoch_train_loss=0.0003407866115018691
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0003378264167217277
210, epoch_train_loss=0.0003378264167217277
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.00033491074511744903
211, epoch_train_loss=0.00033491074511744903
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.00033203919832533197
212, epoch_train_loss=0.00033203919832533197
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.00032920941788135545
213, epoch_train_loss=0.00032920941788135545
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0003264228410473881
214, epoch_train_loss=0.0003264228410473881
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0003236774501001438
215, epoch_train_loss=0.0003236774501001438
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.00032097267522652345
216, epoch_train_loss=0.00032097267522652345
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.0003183088267878328
217, epoch_train_loss=0.0003183088267878328
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0003156840278979411
218, epoch_train_loss=0.0003156840278979411
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0003130984904704581
219, epoch_train_loss=0.0003130984904704581
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.000310551566334817
220, epoch_train_loss=0.000310551566334817
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0003080420677906231
221, epoch_train_loss=0.0003080420677906231
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.00030557008030769253
222, epoch_train_loss=0.00030557008030769253
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.0003031346208663109
223, epoch_train_loss=0.0003031346208663109
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0003007350195919971
224, epoch_train_loss=0.0003007350195919971
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0002983711429274805
225, epoch_train_loss=0.0002983711429274805
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.00029604206580971054
226, epoch_train_loss=0.00029604206580971054
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.00029374726674146926
227, epoch_train_loss=0.00029374726674146926
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.00029148643602935214
228, epoch_train_loss=0.00029148643602935214
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.00028925873035769585
229, epoch_train_loss=0.00028925873035769585
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.00028706373850488544
230, epoch_train_loss=0.00028706373850488544
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.00028490107813892404
231, epoch_train_loss=0.00028490107813892404
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.0002827699337309949
232, epoch_train_loss=0.0002827699337309949
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0002806699751807533
233, epoch_train_loss=0.0002806699751807533
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0002786007376040893
234, epoch_train_loss=0.0002786007376040893
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.00027656150446804414
235, epoch_train_loss=0.00027656150446804414
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.00027455199508493616
236, epoch_train_loss=0.00027455199508493616
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0002725716669601856
237, epoch_train_loss=0.0002725716669601856
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.00027061992846444356
238, epoch_train_loss=0.00027061992846444356
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.0002686964671595717
239, epoch_train_loss=0.0002686964671595717
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.00026680074258814135
240, epoch_train_loss=0.00026680074258814135
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.00026493225650255406
241, epoch_train_loss=0.00026493225650255406
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.00026309063732686224
242, epoch_train_loss=0.00026309063732686224
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.0002612753969338773
243, epoch_train_loss=0.0002612753969338773
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0002594860673592216
244, epoch_train_loss=0.0002594860673592216
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.0002577222687184474
245, epoch_train_loss=0.0002577222687184474
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.0002559835616981567
246, epoch_train_loss=0.0002559835616981567
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0002542694778885248
247, epoch_train_loss=0.0002542694778885248
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.00025257965822910063
248, epoch_train_loss=0.00025257965822910063
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.00025091369272089406
249, epoch_train_loss=0.00025091369272089406
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0002492711435454412
250, epoch_train_loss=0.0002492711435454412
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0002476516590273342
251, epoch_train_loss=0.0002476516590273342
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.00024605483907853473
252, epoch_train_loss=0.00024605483907853473
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.0002444802811316929
253, epoch_train_loss=0.0002444802811316929
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.00024292763369127934
254, epoch_train_loss=0.00024292763369127934
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0002413965296348739
255, epoch_train_loss=0.0002413965296348739
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.00023988658851290518
256, epoch_train_loss=0.00023988658851290518
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0002383974564618901
257, epoch_train_loss=0.0002383974564618901
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.00023692879732914598
258, epoch_train_loss=0.00023692879732914598
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0002354802522616732
259, epoch_train_loss=0.0002354802522616732
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.00023405148449428542
260, epoch_train_loss=0.00023405148449428542
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.00023264217290852596
261, epoch_train_loss=0.00023264217290852596
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.00023125197913385735
262, epoch_train_loss=0.00023125197913385735
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.00022988058166390719
263, epoch_train_loss=0.00022988058166390719
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.0002285276724713046
264, epoch_train_loss=0.0002285276724713046
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.00022719294148747243
265, epoch_train_loss=0.00022719294148747243
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.00022587607677050444
266, epoch_train_loss=0.00022587607677050444
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.00022457678137886709
267, epoch_train_loss=0.00022457678137886709
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0002232947672198619
268, epoch_train_loss=0.0002232947672198619
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.00022202974035328042
269, epoch_train_loss=0.00022202974035328042
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.00022078141806528836
270, epoch_train_loss=0.00022078141806528836
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.00021954952524442085
271, epoch_train_loss=0.00021954952524442085
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.00021833378836919837
272, epoch_train_loss=0.00021833378836919837
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.00021713393818617282
273, epoch_train_loss=0.00021713393818617282
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0002159497138922749
274, epoch_train_loss=0.0002159497138922749
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.00021478085916487222
275, epoch_train_loss=0.00021478085916487222
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.0002136271174399355
276, epoch_train_loss=0.0002136271174399355
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.00021248824062137443
277, epoch_train_loss=0.00021248824062137443
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.00021136398687656251
278, epoch_train_loss=0.00021136398687656251
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.00021025411662889854
279, epoch_train_loss=0.00021025411662889854
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.000209158393399393
280, epoch_train_loss=0.000209158393399393
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.00020807658637694203
281, epoch_train_loss=0.00020807658637694203
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.00020700847146446882
282, epoch_train_loss=0.00020700847146446882
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.00020595382621122323
283, epoch_train_loss=0.00020595382621122323
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0002049124321134491
284, epoch_train_loss=0.0002049124321134491
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.00020388407551688245
285, epoch_train_loss=0.00020388407551688245
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.00020286854700650404
286, epoch_train_loss=0.00020286854700650404
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.00020186564042069612
287, epoch_train_loss=0.00020186564042069612
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.00020087515310153605
288, epoch_train_loss=0.00020087515310153605
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0001998968867176695
289, epoch_train_loss=0.0001998968867176695
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.00019893064612937634
290, epoch_train_loss=0.00019893064612937634
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.00019797623970443638
291, epoch_train_loss=0.00019797623970443638
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.00019703347950558958
292, epoch_train_loss=0.00019703347950558958
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.0001961021812080564
293, epoch_train_loss=0.0001961021812080564
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.00019518216348742232
294, epoch_train_loss=0.00019518216348742232
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.0001942732478916838
295, epoch_train_loss=0.0001942732478916838
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.0001933752596230579
296, epoch_train_loss=0.0001933752596230579
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.00019248802703610636
297, epoch_train_loss=0.00019248802703610636
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.00019161138121231443
298, epoch_train_loss=0.00019161138121231443
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.00019074515569074486
299, epoch_train_loss=0.00019074515569074486
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.00018988918724719317
300, epoch_train_loss=0.00018988918724719317
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0001890433157482453
301, epoch_train_loss=0.0001890433157482453
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.00018820738352722002
302, epoch_train_loss=0.00018820738352722002
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.00018738123534210556
303, epoch_train_loss=0.00018738123534210556
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.00018656471860314182
304, epoch_train_loss=0.00018656471860314182
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.00018575768355998142
305, epoch_train_loss=0.00018575768355998142
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.000184959982749401
306, epoch_train_loss=0.000184959982749401
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.0001841714711352764
307, epoch_train_loss=0.0001841714711352764
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.00018339200577895836
308, epoch_train_loss=0.00018339200577895836
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.00018262144616386898
309, epoch_train_loss=0.00018262144616386898
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.00018185965413917534
310, epoch_train_loss=0.00018185965413917534
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.00018110649361685184
311, epoch_train_loss=0.00018110649361685184
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.00018036183070050917
312, epoch_train_loss=0.00018036183070050917
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.00017962553333715676
313, epoch_train_loss=0.00017962553333715676
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.00017889747180296892
314, epoch_train_loss=0.00017889747180296892
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.00017817751849775895
315, epoch_train_loss=0.00017817751849775895
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0001774655475064184
316, epoch_train_loss=0.0001774655475064184
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.0001767614348688911
317, epoch_train_loss=0.0001767614348688911
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.00017606505866686836
318, epoch_train_loss=0.00017606505866686836
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.00017537629867405712
319, epoch_train_loss=0.00017537629867405712
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.00017469503654679862
320, epoch_train_loss=0.00017469503654679862
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.00017402115573079494
321, epoch_train_loss=0.00017402115573079494
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.00017335454137049237
322, epoch_train_loss=0.00017335454137049237
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.00017269508034907982
323, epoch_train_loss=0.00017269508034907982
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.00017204266134401822
324, epoch_train_loss=0.00017204266134401822
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.00017139717457824053
325, epoch_train_loss=0.00017139717457824053
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.00017075851200191338
326, epoch_train_loss=0.00017075851200191338
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.00017012656712706345
327, epoch_train_loss=0.00017012656712706345
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.00016950123512420135
328, epoch_train_loss=0.00016950123512420135
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.00016888241275113297
329, epoch_train_loss=0.00016888241275113297
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.00016826999819726356
330, epoch_train_loss=0.00016826999819726356
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0001676638912444164
331, epoch_train_loss=0.0001676638912444164
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.00016706399322003878
332, epoch_train_loss=0.00016706399322003878
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0001664702069779897
333, epoch_train_loss=0.0001664702069779897
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.00016588243673507837
334, epoch_train_loss=0.00016588243673507837
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.00016530058820822546
335, epoch_train_loss=0.00016530058820822546
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.00016472456858209337
336, epoch_train_loss=0.00016472456858209337
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0001641542864713031
337, epoch_train_loss=0.0001641542864713031
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.00016358965192059054
338, epoch_train_loss=0.00016358965192059054
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0001630305762230588
339, epoch_train_loss=0.0001630305762230588
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.00016247697222455896
340, epoch_train_loss=0.00016247697222455896
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.00016192875401389197
341, epoch_train_loss=0.00016192875401389197
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.00016138583705663104
342, epoch_train_loss=0.00016138583705663104
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.000160848138135219
343, epoch_train_loss=0.000160848138135219
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.00016031557535123287
344, epoch_train_loss=0.00016031557535123287
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.00015978806807996144
345, epoch_train_loss=0.00015978806807996144
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.00015926553710065626
346, epoch_train_loss=0.00015926553710065626
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.00015874790429404282
347, epoch_train_loss=0.00015874790429404282
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0001582350929504755
348, epoch_train_loss=0.0001582350929504755
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.00015772702745488483
349, epoch_train_loss=0.00015772702745488483
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.00015722363353713872
350, epoch_train_loss=0.00015722363353713872
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0001567248380944861
351, epoch_train_loss=0.0001567248380944861
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.00015623056921693524
352, epoch_train_loss=0.00015623056921693524
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.0001557407561853667
353, epoch_train_loss=0.0001557407561853667
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.00015525532941996584
354, epoch_train_loss=0.00015525532941996584
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.00015477422056983347
355, epoch_train_loss=0.00015477422056983347
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.00015429736234932984
356, epoch_train_loss=0.00015429736234932984
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.00015382468867602443
357, epoch_train_loss=0.00015382468867602443
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.00015335613455021434
358, epoch_train_loss=0.00015335613455021434
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.00015289163603626182
359, epoch_train_loss=0.00015289163603626182
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.00015243113035119765
360, epoch_train_loss=0.00015243113035119765
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.00015197455571325024
361, epoch_train_loss=0.00015197455571325024
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.00015152185147242683
362, epoch_train_loss=0.00015152185147242683
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0001510729579882823
363, epoch_train_loss=0.0001510729579882823
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.00015062781661546776
364, epoch_train_loss=0.00015062781661546776
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.00015018636979044137
365, epoch_train_loss=0.00015018636979044137
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.00014974856088844287
366, epoch_train_loss=0.00014974856088844287
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0001493143343071396
367, epoch_train_loss=0.0001493143343071396
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0001488836354503272
368, epoch_train_loss=0.0001488836354503272
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.00014845641061373788
369, epoch_train_loss=0.00014845641061373788
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.00014803260710627338
370, epoch_train_loss=0.00014803260710627338
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.00014761217310457455
371, epoch_train_loss=0.00014761217310457455
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.00014719505773671407
372, epoch_train_loss=0.00014719505773671407
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.0001467812110321981
373, epoch_train_loss=0.0001467812110321981
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.00014637058394528175
374, epoch_train_loss=0.00014637058394528175
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0001459631282443144
375, epoch_train_loss=0.0001459631282443144
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.00014555879659611335
376, epoch_train_loss=0.00014555879659611335
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.000145157542543522
377, epoch_train_loss=0.000145157542543522
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.00014475932041109964
378, epoch_train_loss=0.00014475932041109964
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.00014436408534441718
379, epoch_train_loss=0.00014436408534441718
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.00014397179340117105
380, epoch_train_loss=0.00014397179340117105
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.00014358240134429613
381, epoch_train_loss=0.00014358240134429613
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.00014319586678281364
382, epoch_train_loss=0.00014319586678281364
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.00014281214811768435
383, epoch_train_loss=0.00014281214811768435
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.00014243120461293114
384, epoch_train_loss=0.00014243120461293114
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.00014205299641208916
385, epoch_train_loss=0.00014205299641208916
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.00014167748479493796
386, epoch_train_loss=0.00014167748479493796
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.00014130463244177232
387, epoch_train_loss=0.00014130463244177232
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.00014093440460517426
388, epoch_train_loss=0.00014093440460517426
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.00014056677077589933
389, epoch_train_loss=0.00014056677077589933
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0001402017098006003
390, epoch_train_loss=0.0001402017098006003
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.00013983922025900364
391, epoch_train_loss=0.00013983922025900364
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.00013947934672523142
392, epoch_train_loss=0.00013947934672523142
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.00013912223940104566
393, epoch_train_loss=0.00013912223940104566
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.00013876830200205967
394, epoch_train_loss=0.00013876830200205967
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.00013841854641039402
395, epoch_train_loss=0.00013841854641039402
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.0001380754824247019
396, epoch_train_loss=0.0001380754824247019
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.00013774532272560106
397, epoch_train_loss=0.00013774532272560106
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.0001374436540442258
398, epoch_train_loss=0.0001374436540442258
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0001372098090342195
399, epoch_train_loss=0.0001372098090342195
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.00013714508891861374
400, epoch_train_loss=0.00013714508891861374
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.00013751072183152018
401, epoch_train_loss=0.00013751072183152018
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0001390008589070154
402, epoch_train_loss=0.0001390008589070154
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.0001434351376780974
403, epoch_train_loss=0.0001434351376780974
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.00015584134872332616
404, epoch_train_loss=0.00015584134872332616
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.00018942283471662591
405, epoch_train_loss=0.00018942283471662591
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0002828313679632512
406, epoch_train_loss=0.0002828313679632512
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.0005336537164773312
407, epoch_train_loss=0.0005336537164773312
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0012576465499665847
408, epoch_train_loss=0.0012576465499665847
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0031176341974542975
409, epoch_train_loss=0.0031176341974542975
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.008673393136904526
410, epoch_train_loss=0.008673393136904526
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.019408061133917548
411, epoch_train_loss=0.019408061133917548
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.047121036942799385
412, epoch_train_loss=0.047121036942799385
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.04693557225074917
413, epoch_train_loss=0.04693557225074917
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0400363935516149
414, epoch_train_loss=0.0400363935516149
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0028764125642599834
415, epoch_train_loss=0.0028764125642599834
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.016862089755368036
416, epoch_train_loss=0.016862089755368036
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.03990805033228717
417, epoch_train_loss=0.03990805033228717
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.004704146479531944
418, epoch_train_loss=0.004704146479531944
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.014609269959038511
419, epoch_train_loss=0.014609269959038511
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.031981341318108744
420, epoch_train_loss=0.031981341318108744
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.00158744777565748
421, epoch_train_loss=0.00158744777565748
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.021663784037278738
422, epoch_train_loss=0.021663784037278738
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.024436811907006778
423, epoch_train_loss=0.024436811907006778
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.001978427955185796
424, epoch_train_loss=0.001978427955185796
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.028892051413376134
425, epoch_train_loss=0.028892051413376134
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0146503456795753
426, epoch_train_loss=0.0146503456795753
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.006841920796612131
427, epoch_train_loss=0.006841920796612131
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.02516288764706622
428, epoch_train_loss=0.02516288764706622
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.003582503981289532
429, epoch_train_loss=0.003582503981289532
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.011979936337083375
430, epoch_train_loss=0.011979936337083375
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.010647029283846638
431, epoch_train_loss=0.010647029283846638
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.0017897909148002038
432, epoch_train_loss=0.0017897909148002038
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.01162317478290391
433, epoch_train_loss=0.01162317478290391
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0010821473701861006
434, epoch_train_loss=0.0010821473701861006
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.008106472915215516
435, epoch_train_loss=0.008106472915215516
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.005207232662153729
436, epoch_train_loss=0.005207232662153729
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.002664119804447101
437, epoch_train_loss=0.002664119804447101
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.007546056654495147
438, epoch_train_loss=0.007546056654495147
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0006136081607843642
439, epoch_train_loss=0.0006136081607843642
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0054170093290053165
440, epoch_train_loss=0.0054170093290053165
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.001922524764572358
441, epoch_train_loss=0.001922524764572358
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0024123323022283982
442, epoch_train_loss=0.0024123323022283982
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0036940705029466776
443, epoch_train_loss=0.0036940705029466776
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.0006353410539192327
444, epoch_train_loss=0.0006353410539192327
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.003882365034366107
445, epoch_train_loss=0.003882365034366107
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0008560149913168654
446, epoch_train_loss=0.0008560149913168654
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.002193666125933622
447, epoch_train_loss=0.002193666125933622
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.0018958634783270989
448, epoch_train_loss=0.0018958634783270989
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.0007067831405883885
449, epoch_train_loss=0.0007067831405883885
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.002279898722613154
450, epoch_train_loss=0.002279898722613154
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0004173442990498503
451, epoch_train_loss=0.0004173442990498503
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.0017533930521805552
452, epoch_train_loss=0.0017533930521805552
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0009874196060916042
453, epoch_train_loss=0.0009874196060916042
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0008026335249190324
454, epoch_train_loss=0.0008026335249190324
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0014602402364937896
455, epoch_train_loss=0.0014602402364937896
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.0003588063085888282
456, epoch_train_loss=0.0003588063085888282
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.001230606806078007
457, epoch_train_loss=0.001230606806078007
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.0005776903759734588
458, epoch_train_loss=0.0005776903759734588
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.0006826121851100673
459, epoch_train_loss=0.0006826121851100673
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.0009107214677831419
460, epoch_train_loss=0.0009107214677831419
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.0003444896339486497
461, epoch_train_loss=0.0003444896339486497
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0008942703483303574
462, epoch_train_loss=0.0008942703483303574
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0004271818759879408
463, epoch_train_loss=0.0004271818759879408
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.0005562443332508459
464, epoch_train_loss=0.0005562443332508459
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0006363880167323601
465, epoch_train_loss=0.0006363880167323601
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0003130476109880017
466, epoch_train_loss=0.0003130476109880017
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.000629466287142369
467, epoch_train_loss=0.000629466287142369
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.00034486372720351214
468, epoch_train_loss=0.00034486372720351214
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0004359383305993014
469, epoch_train_loss=0.0004359383305993014
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.00047363277468457255
470, epoch_train_loss=0.00047363277468457255
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.00028558906857371137
471, epoch_train_loss=0.00028558906857371137
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.0004768275745344361
472, epoch_train_loss=0.0004768275745344361
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.00030625777917370786
473, epoch_train_loss=0.00030625777917370786
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0003470353907145487
474, epoch_train_loss=0.0003470353907145487
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.0003836067773578329
475, epoch_train_loss=0.0003836067773578329
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.0002577717572173006
476, epoch_train_loss=0.0002577717572173006
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.0003686238684061865
477, epoch_train_loss=0.0003686238684061865
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.00027982646906963714
478, epoch_train_loss=0.00027982646906963714
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.000284177803902325
479, epoch_train_loss=0.000284177803902325
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.00032264001984908403
480, epoch_train_loss=0.00032264001984908403
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.00023923678277460228
481, epoch_train_loss=0.00023923678277460228
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.00030091143700434125
482, epoch_train_loss=0.00030091143700434125
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.00026219223071425175
483, epoch_train_loss=0.00026219223071425175
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.0002445141567604464
484, epoch_train_loss=0.0002445141567604464
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.00028137234517333425
485, epoch_train_loss=0.00028137234517333425
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.00022765017974743295
486, epoch_train_loss=0.00022765017974743295
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0002537131354572515
487, epoch_train_loss=0.0002537131354572515
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0002462477145889479
488, epoch_train_loss=0.0002462477145889479
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.00022018522957615048
489, epoch_train_loss=0.00022018522957615048
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0002473658327109779
490, epoch_train_loss=0.0002473658327109779
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0002194510691378679
491, epoch_train_loss=0.0002194510691378679
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.00022243893926633283
492, epoch_train_loss=0.00022243893926633283
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0002301347092346352
493, epoch_train_loss=0.0002301347092346352
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.00020704722582814397
494, epoch_train_loss=0.00020704722582814397
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.00022125857231740321
495, epoch_train_loss=0.00022125857231740321
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.00021237685311483633
496, epoch_train_loss=0.00021237685311483633
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0002033679056951398
497, epoch_train_loss=0.0002033679056951398
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.00021385371408677215
498, epoch_train_loss=0.00021385371408677215
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.0001998914962336898
499, epoch_train_loss=0.0001998914962336898
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.00020153738783762405
500, epoch_train_loss=0.00020153738783762405
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.00020368247959185823
501, epoch_train_loss=0.00020368247959185823
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.0001928434405046684
502, epoch_train_loss=0.0001928434405046684
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.00019820170670055762
503, epoch_train_loss=0.00019820170670055762
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.00019422298873425598
504, epoch_train_loss=0.00019422298873425598
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.00018890904798781808
505, epoch_train_loss=0.00018890904798781808
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.00019308572848559396
506, epoch_train_loss=0.00019308572848559396
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.00018696354289767474
507, epoch_train_loss=0.00018696354289767474
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.00018591221132191528
508, epoch_train_loss=0.00018591221132191528
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.0001873010127442955
509, epoch_train_loss=0.0001873010127442955
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.000181806513533349
510, epoch_train_loss=0.000181806513533349
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.00018275658953277672
511, epoch_train_loss=0.00018275658953277672
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.0001818130745049221
512, epoch_train_loss=0.0001818130745049221
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.00017798983416588186
513, epoch_train_loss=0.00017798983416588186
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0001792376748050601
514, epoch_train_loss=0.0001792376748050601
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.00017704416572556975
515, epoch_train_loss=0.00017704416572556975
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.00017483539146621364
516, epoch_train_loss=0.00017483539146621364
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0001755648049922043
517, epoch_train_loss=0.0001755648049922043
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.00017305486475308485
518, epoch_train_loss=0.00017305486475308485
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.00017193542824844754
519, epoch_train_loss=0.00017193542824844754
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.0001719819203801663
520, epoch_train_loss=0.0001719819203801663
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.0001696760624066499
521, epoch_train_loss=0.0001696760624066499
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.00016912483388285284
522, epoch_train_loss=0.00016912483388285284
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0001686271813632012
523, epoch_train_loss=0.0001686271813632012
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.00016672244340860758
524, epoch_train_loss=0.00016672244340860758
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0001663833193582832
525, epoch_train_loss=0.0001663833193582832
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.00016556323951837974
526, epoch_train_loss=0.00016556323951837974
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.00016405591283691115
527, epoch_train_loss=0.00016405591283691115
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.00016373633231816048
528, epoch_train_loss=0.00016373633231816048
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0001627759295003407
529, epoch_train_loss=0.0001627759295003407
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.00016158126831614615
530, epoch_train_loss=0.00016158126831614615
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.00016120696707352735
531, epoch_train_loss=0.00016120696707352735
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.00016022345075777505
532, epoch_train_loss=0.00016022345075777505
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.00015925168677572742
533, epoch_train_loss=0.00015925168677572742
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.0001588111448168696
534, epoch_train_loss=0.0001588111448168696
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.00015786863301548465
535, epoch_train_loss=0.00015786863301548465
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0001570431593242858
536, epoch_train_loss=0.0001570431593242858
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.00015655074770125243
537, epoch_train_loss=0.00015655074770125243
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.0001556731470292921
538, epoch_train_loss=0.0001556731470292921
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.0001549418973058104
539, epoch_train_loss=0.0001549418973058104
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.00015441776288858584
540, epoch_train_loss=0.00015441776288858584
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.00015361011373785433
541, epoch_train_loss=0.00015361011373785433
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.00015294096235843836
542, epoch_train_loss=0.00015294096235843836
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0001524036693499599
543, epoch_train_loss=0.0001524036693499599
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.00015166147240647254
544, epoch_train_loss=0.00015166147240647254
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.000151034323698894
545, epoch_train_loss=0.000151034323698894
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.00015049703470306676
546, epoch_train_loss=0.00015049703470306676
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.00014981222926518492
547, epoch_train_loss=0.00014981222926518492
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.00014921635805489948
548, epoch_train_loss=0.00014921635805489948
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.00014868685990876407
549, epoch_train_loss=0.00014868685990876407
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.000148051952790607
550, epoch_train_loss=0.000148051952790607
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0001474815727938866
551, epoch_train_loss=0.0001474815727938866
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.0001469643755027493
552, epoch_train_loss=0.0001469643755027493
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0001463719898951536
553, epoch_train_loss=0.0001463719898951536
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.0001458238345191191
554, epoch_train_loss=0.0001458238345191191
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.000145321026669182
555, epoch_train_loss=0.000145321026669182
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0001447651863424981
556, epoch_train_loss=0.0001447651863424981
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.00014423748777543202
557, epoch_train_loss=0.00014423748777543202
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.00014374957686384243
558, epoch_train_loss=0.00014374957686384243
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.00014322566844832656
559, epoch_train_loss=0.00014322566844832656
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.00014271729635912447
560, epoch_train_loss=0.00014271729635912447
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.00014224386610210503
561, epoch_train_loss=0.00014224386610210503
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.00014174772512496453
562, epoch_train_loss=0.00014174772512496453
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.00014125810649344368
563, epoch_train_loss=0.00014125810649344368
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.00014079839411022522
564, epoch_train_loss=0.00014079839411022522
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.00014032649877717196
565, epoch_train_loss=0.00014032649877717196
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.00013985520061402467
566, epoch_train_loss=0.00013985520061402467
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0001394084632501093
567, epoch_train_loss=0.0001394084632501093
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0001389577121291165
568, epoch_train_loss=0.0001389577121291165
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.0001385041877301338
569, epoch_train_loss=0.0001385041877301338
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0001380697668945553
570, epoch_train_loss=0.0001380697668945553
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.00013763733968010224
571, epoch_train_loss=0.00013763733968010224
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.00013720104110186306
572, epoch_train_loss=0.00013720104110186306
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.00013677849453720497
573, epoch_train_loss=0.00013677849453720497
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.00013636192942493623
574, epoch_train_loss=0.00013636192942493623
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.0001359421102158091
575, epoch_train_loss=0.0001359421102158091
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.00013553124893853804
576, epoch_train_loss=0.00013553124893853804
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.0001351283942127869
577, epoch_train_loss=0.0001351283942127869
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.00013472401548974143
578, epoch_train_loss=0.00013472401548974143
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.00013432481532559413
579, epoch_train_loss=0.00013432481532559413
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0001339339388286437
580, epoch_train_loss=0.0001339339388286437
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.00013354375112396459
581, epoch_train_loss=0.00013354375112396459
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.00013315622013551412
582, epoch_train_loss=0.00013315622013551412
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.00013277607852775822
583, epoch_train_loss=0.00013277607852775822
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.0001323986576331075
584, epoch_train_loss=0.0001323986576331075
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.0001320226940514498
585, epoch_train_loss=0.0001320226940514498
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.00013165249054638767
586, epoch_train_loss=0.00013165249054638767
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.00013128638513200505
587, epoch_train_loss=0.00013128638513200505
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.00013092165964249732
588, epoch_train_loss=0.00013092165964249732
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.00013056097896831226
589, epoch_train_loss=0.00013056097896831226
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.00013020490003071627
590, epoch_train_loss=0.00013020490003071627
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0001298507953030949
591, epoch_train_loss=0.0001298507953030949
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.00012949944056235744
592, epoch_train_loss=0.00012949944056235744
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.00012915239025023116
593, epoch_train_loss=0.00012915239025023116
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.00012880806191944503
594, epoch_train_loss=0.00012880806191944503
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.00012846584672211313
595, epoch_train_loss=0.00012846584672211313
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.00012812717541770953
596, epoch_train_loss=0.00012812717541770953
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0001277917033160765
597, epoch_train_loss=0.0001277917033160765
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.00012745830075527385
598, epoch_train_loss=0.00012745830075527385
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.00012712764261974633
599, epoch_train_loss=0.00012712764261974633
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.00012680020113063083
600, epoch_train_loss=0.00012680020113063083
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.00012647509672611307
601, epoch_train_loss=0.00012647509672611307
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0001261522150383574
602, epoch_train_loss=0.0001261522150383574
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.00012583219615070233
603, epoch_train_loss=0.00012583219615070233
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.0001255147538834903
604, epoch_train_loss=0.0001255147538834903
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.00012519937976545684
605, epoch_train_loss=0.00012519937976545684
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.00012488640229061214
606, epoch_train_loss=0.00012488640229061214
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.00012457600229733061
607, epoch_train_loss=0.00012457600229733061
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.0001242677478205456
608, epoch_train_loss=0.0001242677478205456
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.00012396155751680007
609, epoch_train_loss=0.00012396155751680007
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.00012365771767735155
610, epoch_train_loss=0.00012365771767735155
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0001233561038806736
611, epoch_train_loss=0.0001233561038806736
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.00012305644118247908
612, epoch_train_loss=0.00012305644118247908
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.0001227588388788671
613, epoch_train_loss=0.0001227588388788671
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.00012246340119801148
614, epoch_train_loss=0.00012246340119801148
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.0001221699298570318
615, epoch_train_loss=0.0001221699298570318
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.00012187832570879608
616, epoch_train_loss=0.00012187832570879608
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.00012158870343050456
617, epoch_train_loss=0.00012158870343050456
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.00012130104019461587
618, epoch_train_loss=0.00012130104019461587
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.00012101518107421756
619, epoch_train_loss=0.00012101518107421756
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.00012073111863304408
620, epoch_train_loss=0.00012073111863304408
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.00012044891553124722
621, epoch_train_loss=0.00012044891553124722
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.0001201684999144442
622, epoch_train_loss=0.0001201684999144442
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.00011988977766411755
623, epoch_train_loss=0.00011988977766411755
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.00011961276969435712
624, epoch_train_loss=0.00011961276969435712
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.00011933749029313035
625, epoch_train_loss=0.00011933749029313035
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.00011906386493947441
626, epoch_train_loss=0.00011906386493947441
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.00011879184381547673
627, epoch_train_loss=0.00011879184381547673
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0001185214440486386
628, epoch_train_loss=0.0001185214440486386
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0001182526532479918
629, epoch_train_loss=0.0001182526532479918
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.00011798541127600264
630, epoch_train_loss=0.00011798541127600264
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.00011771969026911707
631, epoch_train_loss=0.00011771969026911707
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.00011745549761463799
632, epoch_train_loss=0.00011745549761463799
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.00011719281046624935
633, epoch_train_loss=0.00011719281046624935
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.00011693158315245549
634, epoch_train_loss=0.00011693158315245549
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.00011667179807822722
635, epoch_train_loss=0.00011667179807822722
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.00011641345342207027
636, epoch_train_loss=0.00011641345342207027
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.00011615652489527441
637, epoch_train_loss=0.00011615652489527441
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.00011590097827417641
638, epoch_train_loss=0.00011590097827417641
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.00011564679891014321
639, epoch_train_loss=0.00011564679891014321
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.00011539397998224734
640, epoch_train_loss=0.00011539397998224734
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.00011514249920049228
641, epoch_train_loss=0.00011514249920049228
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.00011489232960330518
642, epoch_train_loss=0.00011489232960330518
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.00011464345780626693
643, epoch_train_loss=0.00011464345780626693
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.00011439587420548078
644, epoch_train_loss=0.00011439587420548078
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0001141495593403889
645, epoch_train_loss=0.0001141495593403889
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0001139044914835821
646, epoch_train_loss=0.0001139044914835821
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.00011366065722604172
647, epoch_train_loss=0.00011366065722604172
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0001134180461189805
648, epoch_train_loss=0.0001134180461189805
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.00011317664158338844
649, epoch_train_loss=0.00011317664158338844
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.00011293642508652438
650, epoch_train_loss=0.00011293642508652438
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.00011269738369568232
651, epoch_train_loss=0.00011269738369568232
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.00011245950667410357
652, epoch_train_loss=0.00011245950667410357
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.00011222277974062685
653, epoch_train_loss=0.00011222277974062685
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.00011198718710160263
654, epoch_train_loss=0.00011198718710160263
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0001117527160347038
655, epoch_train_loss=0.0001117527160347038
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.00011151935605765022
656, epoch_train_loss=0.00011151935605765022
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.00011128709479809236
657, epoch_train_loss=0.00011128709479809236
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.00011105591841407464
658, epoch_train_loss=0.00011105591841407464
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.00011082581490944782
659, epoch_train_loss=0.00011082581490944782
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.00011059677397352951
660, epoch_train_loss=0.00011059677397352951
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0001103687847136464
661, epoch_train_loss=0.0001103687847136464
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.00011014183510583899
662, epoch_train_loss=0.00011014183510583899
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.00010991591372713105
663, epoch_train_loss=0.00010991591372713105
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0001096910107534348
664, epoch_train_loss=0.0001096910107534348
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.00010946711632704691
665, epoch_train_loss=0.00010946711632704691
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.00010924421986227118
666, epoch_train_loss=0.00010924421986227118
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0001090223108723575
667, epoch_train_loss=0.0001090223108723575
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.00010880137983747952
668, epoch_train_loss=0.00010880137983747952
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.00010858141770030983
669, epoch_train_loss=0.00010858141770030983
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.00010836241510561303
670, epoch_train_loss=0.00010836241510561303
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.00010814436246624433
671, epoch_train_loss=0.00010814436246624433
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.00010792725077604583
672, epoch_train_loss=0.00010792725077604583
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.00010771107150954178
673, epoch_train_loss=0.00010771107150954178
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.00010749581625154856
674, epoch_train_loss=0.00010749581625154856
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.00010728147634792419
675, epoch_train_loss=0.00010728147634792419
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0001070680433523571
676, epoch_train_loss=0.0001070680433523571
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.00010685550923410758
677, epoch_train_loss=0.00010685550923410758
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.00010664386621971893
678, epoch_train_loss=0.00010664386621971893
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.0001064331065014687
679, epoch_train_loss=0.0001064331065014687
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.00010622322229146154
680, epoch_train_loss=0.00010622322229146154
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.00010601420599604049
681, epoch_train_loss=0.00010601420599604049
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0001058060503762491
682, epoch_train_loss=0.0001058060503762491
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.00010559874826927215
683, epoch_train_loss=0.00010559874826927215
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.00010539229252880426
684, epoch_train_loss=0.00010539229252880426
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.00010518667611647702
685, epoch_train_loss=0.00010518667611647702
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.00010498189215815625
686, epoch_train_loss=0.00010498189215815625
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0001047779340256719
687, epoch_train_loss=0.0001047779340256719
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.00010457479512915218
688, epoch_train_loss=0.00010457479512915218
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.00010437246895957873
689, epoch_train_loss=0.00010437246895957873
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0001041709491129618
690, epoch_train_loss=0.0001041709491129618
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.00010397022931052369
691, epoch_train_loss=0.00010397022931052369
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.00010377030346289784
692, epoch_train_loss=0.00010377030346289784
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.00010357116551752452
693, epoch_train_loss=0.00010357116551752452
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.0001033728095028204
694, epoch_train_loss=0.0001033728095028204
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.00010317522957370316
695, epoch_train_loss=0.00010317522957370316
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0001029784199628864
696, epoch_train_loss=0.0001029784199628864
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.00010278237505942103
697, epoch_train_loss=0.00010278237505942103
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.00010258708929264106
698, epoch_train_loss=0.00010258708929264106
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.00010239255717681072
699, epoch_train_loss=0.00010239255717681072
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0001021987733345988
700, epoch_train_loss=0.0001021987733345988
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.00010200573244701197
701, epoch_train_loss=0.00010200573244701197
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.00010181342931671158
702, epoch_train_loss=0.00010181342931671158
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0001016218588134068
703, epoch_train_loss=0.0001016218588134068
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.00010143101589088584
704, epoch_train_loss=0.00010143101589088584
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.00010124089555312634
705, epoch_train_loss=0.00010124089555312634
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.00010105149289141191
706, epoch_train_loss=0.00010105149289141191
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.00010086280308797971
707, epoch_train_loss=0.00010086280308797971
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.00010067482140360676
708, epoch_train_loss=0.00010067482140360676
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0001004875431228936
709, epoch_train_loss=0.0001004875431228936
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.00010030096363979543
710, epoch_train_loss=0.00010030096363979543
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.0001001150784110252
711, epoch_train_loss=0.0001001150784110252
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 9.992988294230972e-05
712, epoch_train_loss=9.992988294230972e-05
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 9.974537279766715e-05
713, epoch_train_loss=9.974537279766715e-05
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 9.956154364829002e-05
714, epoch_train_loss=9.956154364829002e-05
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 9.937839118009545e-05
715, epoch_train_loss=9.937839118009545e-05
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 9.919591114829924e-05
716, epoch_train_loss=9.919591114829924e-05
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 9.90140993591698e-05
717, epoch_train_loss=9.90140993591698e-05
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 9.883295169980884e-05
718, epoch_train_loss=9.883295169980884e-05
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 9.86524641036642e-05
719, epoch_train_loss=9.86524641036642e-05
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 9.847263255417293e-05
720, epoch_train_loss=9.847263255417293e-05
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 9.829345308634801e-05
721, epoch_train_loss=9.829345308634801e-05
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 9.8114921775439e-05
722, epoch_train_loss=9.8114921775439e-05
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 9.79370347710937e-05
723, epoch_train_loss=9.79370347710937e-05
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 9.77597882641155e-05
724, epoch_train_loss=9.77597882641155e-05
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 9.75831784899735e-05
725, epoch_train_loss=9.75831784899735e-05
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 9.740720173248824e-05
726, epoch_train_loss=9.740720173248824e-05
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 9.723185430765285e-05
727, epoch_train_loss=9.723185430765285e-05
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 9.705713260167717e-05
728, epoch_train_loss=9.705713260167717e-05
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 9.688303302118282e-05
729, epoch_train_loss=9.688303302118282e-05
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 9.670955203981699e-05
730, epoch_train_loss=9.670955203981699e-05
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 9.653668616324678e-05
731, epoch_train_loss=9.653668616324678e-05
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 9.636443193624288e-05
732, epoch_train_loss=9.636443193624288e-05
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 9.619278593108888e-05
733, epoch_train_loss=9.619278593108888e-05
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 9.602174477377517e-05
734, epoch_train_loss=9.602174477377517e-05
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 9.585130512719204e-05
735, epoch_train_loss=9.585130512719204e-05
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 9.568146370773334e-05
736, epoch_train_loss=9.568146370773334e-05
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 9.551221724071049e-05
737, epoch_train_loss=9.551221724071049e-05
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 9.534356251573904e-05
738, epoch_train_loss=9.534356251573904e-05
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 9.517549633088807e-05
739, epoch_train_loss=9.517549633088807e-05
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 9.50080155451378e-05
740, epoch_train_loss=9.50080155451378e-05
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 9.484111702668313e-05
741, epoch_train_loss=9.484111702668313e-05
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 9.467479770145861e-05
742, epoch_train_loss=9.467479770145861e-05
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 9.450905450458358e-05
743, epoch_train_loss=9.450905450458358e-05
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 9.434388441458858e-05
744, epoch_train_loss=9.434388441458858e-05
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 9.417928444294845e-05
745, epoch_train_loss=9.417928444294845e-05
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 9.401525163123297e-05
746, epoch_train_loss=9.401525163123297e-05
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 9.385178305168586e-05
747, epoch_train_loss=9.385178305168586e-05
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 9.368887580660132e-05
748, epoch_train_loss=9.368887580660132e-05
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 9.352652702666761e-05
749, epoch_train_loss=9.352652702666761e-05
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 9.336473388489317e-05
750, epoch_train_loss=9.336473388489317e-05
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 9.320349355625582e-05
751, epoch_train_loss=9.320349355625582e-05
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 9.304280325699866e-05
752, epoch_train_loss=9.304280325699866e-05
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 9.288266022961892e-05
753, epoch_train_loss=9.288266022961892e-05
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 9.272306174374462e-05
754, epoch_train_loss=9.272306174374462e-05
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 9.256400509491158e-05
755, epoch_train_loss=9.256400509491158e-05
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 9.240548760412024e-05
756, epoch_train_loss=9.240548760412024e-05
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 9.22475066180761e-05
757, epoch_train_loss=9.22475066180761e-05
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 9.209005950744646e-05
758, epoch_train_loss=9.209005950744646e-05
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 9.193314366811266e-05
759, epoch_train_loss=9.193314366811266e-05
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 9.177675650700326e-05
760, epoch_train_loss=9.177675650700326e-05
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 9.16208954792878e-05
761, epoch_train_loss=9.16208954792878e-05
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 9.146555805058078e-05
762, epoch_train_loss=9.146555805058078e-05
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 9.131074170950887e-05
763, epoch_train_loss=9.131074170950887e-05
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 9.11564439668203e-05
764, epoch_train_loss=9.11564439668203e-05
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 9.100266235507712e-05
765, epoch_train_loss=9.100266235507712e-05
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 9.084939442870118e-05
766, epoch_train_loss=9.084939442870118e-05
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 9.069663775110986e-05
767, epoch_train_loss=9.069663775110986e-05
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 9.054438993061561e-05
768, epoch_train_loss=9.054438993061561e-05
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 9.039264858368514e-05
769, epoch_train_loss=9.039264858368514e-05
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 9.024141133587575e-05
770, epoch_train_loss=9.024141133587575e-05
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 9.009067585536512e-05
771, epoch_train_loss=9.009067585536512e-05
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 8.99404398070965e-05
772, epoch_train_loss=8.99404398070965e-05
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 8.979070089803795e-05
773, epoch_train_loss=8.979070089803795e-05
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 8.964145683122448e-05
774, epoch_train_loss=8.964145683122448e-05
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 8.949270535123741e-05
775, epoch_train_loss=8.949270535123741e-05
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 8.934444420944178e-05
776, epoch_train_loss=8.934444420944178e-05
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 8.919667116403774e-05
777, epoch_train_loss=8.919667116403774e-05
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 8.904938400228098e-05
778, epoch_train_loss=8.904938400228098e-05
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 8.890258054049645e-05
779, epoch_train_loss=8.890258054049645e-05
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 8.875625858935077e-05
780, epoch_train_loss=8.875625858935077e-05
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 8.86104159882283e-05
781, epoch_train_loss=8.86104159882283e-05
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 8.846505060408489e-05
782, epoch_train_loss=8.846505060408489e-05
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 8.832016029837171e-05
783, epoch_train_loss=8.832016029837171e-05
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 8.817574297080864e-05
784, epoch_train_loss=8.817574297080864e-05
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 8.803179651527569e-05
785, epoch_train_loss=8.803179651527569e-05
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 8.788831885231885e-05
786, epoch_train_loss=8.788831885231885e-05
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 8.774530791841648e-05
787, epoch_train_loss=8.774530791841648e-05
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 8.760276167612885e-05
788, epoch_train_loss=8.760276167612885e-05
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 8.746067808149574e-05
789, epoch_train_loss=8.746067808149574e-05
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 8.731905511633273e-05
790, epoch_train_loss=8.731905511633273e-05
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 8.717789077746025e-05
791, epoch_train_loss=8.717789077746025e-05
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 8.703718307609209e-05
792, epoch_train_loss=8.703718307609209e-05
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 8.689693003803209e-05
793, epoch_train_loss=8.689693003803209e-05
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 8.6757129703133e-05
794, epoch_train_loss=8.6757129703133e-05
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 8.661778012543281e-05
795, epoch_train_loss=8.661778012543281e-05
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 8.647887937266459e-05
796, epoch_train_loss=8.647887937266459e-05
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 8.634042552639899e-05
797, epoch_train_loss=8.634042552639899e-05
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 8.620241668153914e-05
798, epoch_train_loss=8.620241668153914e-05
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 8.606485094649996e-05
799, epoch_train_loss=8.606485094649996e-05
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 8.592772644267776e-05
800, epoch_train_loss=8.592772644267776e-05
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 8.579104130468232e-05
801, epoch_train_loss=8.579104130468232e-05
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 8.565479367973342e-05
802, epoch_train_loss=8.565479367973342e-05
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 8.551898171757844e-05
803, epoch_train_loss=8.551898171757844e-05
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 8.538360361152519e-05
804, epoch_train_loss=8.538360361152519e-05
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 8.524865752591179e-05
805, epoch_train_loss=8.524865752591179e-05
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 8.511414166813791e-05
806, epoch_train_loss=8.511414166813791e-05
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 8.498005424782087e-05
807, epoch_train_loss=8.498005424782087e-05
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 8.484639347559029e-05
808, epoch_train_loss=8.484639347559029e-05
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 8.471315759533926e-05
809, epoch_train_loss=8.471315759533926e-05
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 8.458034485128962e-05
810, epoch_train_loss=8.458034485128962e-05
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 8.444795349032913e-05
811, epoch_train_loss=8.444795349032913e-05
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 8.43159817895853e-05
812, epoch_train_loss=8.43159817895853e-05
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 8.418442802932876e-05
813, epoch_train_loss=8.418442802932876e-05
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 8.40532904883408e-05
814, epoch_train_loss=8.40532904883408e-05
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 8.392256747010894e-05
815, epoch_train_loss=8.392256747010894e-05
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 8.379225730489117e-05
816, epoch_train_loss=8.379225730489117e-05
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 8.36623582996404e-05
817, epoch_train_loss=8.36623582996404e-05
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 8.35328687852987e-05
818, epoch_train_loss=8.35328687852987e-05
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 8.340378712453696e-05
819, epoch_train_loss=8.340378712453696e-05
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 8.32751116597955e-05
820, epoch_train_loss=8.32751116597955e-05
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 8.314684078612146e-05
821, epoch_train_loss=8.314684078612146e-05
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 8.301897287440502e-05
822, epoch_train_loss=8.301897287440502e-05
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 8.289150636581393e-05
823, epoch_train_loss=8.289150636581393e-05
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 8.276443971329378e-05
824, epoch_train_loss=8.276443971329378e-05
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 8.263777149151362e-05
825, epoch_train_loss=8.263777149151362e-05
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 8.251150035675311e-05
826, epoch_train_loss=8.251150035675311e-05
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 8.238562538283856e-05
827, epoch_train_loss=8.238562538283856e-05
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 8.226014610854875e-05
828, epoch_train_loss=8.226014610854875e-05
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 8.213506353593794e-05
829, epoch_train_loss=8.213506353593794e-05
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 8.201038099434836e-05
830, epoch_train_loss=8.201038099434836e-05
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 8.188610778377912e-05
831, epoch_train_loss=8.188610778377912e-05
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 8.176226434950899e-05
832, epoch_train_loss=8.176226434950899e-05
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 8.163889726138327e-05
833, epoch_train_loss=8.163889726138327e-05
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 8.151610643788833e-05
834, epoch_train_loss=8.151610643788833e-05
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 8.139411279556483e-05
835, epoch_train_loss=8.139411279556483e-05
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 8.127339723653673e-05
836, epoch_train_loss=8.127339723653673e-05
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 8.115502615863472e-05
837, epoch_train_loss=8.115502615863472e-05
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 8.104136614101005e-05
838, epoch_train_loss=8.104136614101005e-05
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 8.093772456919593e-05
839, epoch_train_loss=8.093772456919593e-05
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 8.08561103419697e-05
840, epoch_train_loss=8.08561103419697e-05
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 8.082380040786935e-05
841, epoch_train_loss=8.082380040786935e-05
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 8.090376182595759e-05
842, epoch_train_loss=8.090376182595759e-05
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 8.124061392055106e-05
843, epoch_train_loss=8.124061392055106e-05
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 8.217590279058607e-05
844, epoch_train_loss=8.217590279058607e-05
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 8.44987580744569e-05
845, epoch_train_loss=8.44987580744569e-05
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 9.012967207661282e-05
846, epoch_train_loss=9.012967207661282e-05
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.00010347857106839426
847, epoch_train_loss=0.00010347857106839426
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.00013579237855475016
848, epoch_train_loss=0.00013579237855475016
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0002120103311317223
849, epoch_train_loss=0.0002120103311317223
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.00040135490259569397
850, epoch_train_loss=0.00040135490259569397
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0008415511510205772
851, epoch_train_loss=0.0008415511510205772
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.001984759439431879
852, epoch_train_loss=0.001984759439431879
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.004470981994424549
853, epoch_train_loss=0.004470981994424549
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.011334188356613342
854, epoch_train_loss=0.011334188356613342
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.022625103610726584
855, epoch_train_loss=0.022625103610726584
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.05397053349142979
856, epoch_train_loss=0.05397053349142979
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.059160200631056405
857, epoch_train_loss=0.059160200631056405
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.07313982435700862
858, epoch_train_loss=0.07313982435700862
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.01536161838150514
859, epoch_train_loss=0.01536161838150514
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.008369894426606562
860, epoch_train_loss=0.008369894426606562
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.04185298652232996
861, epoch_train_loss=0.04185298652232996
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.02350271045756522
862, epoch_train_loss=0.02350271045756522
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.002590023438465277
863, epoch_train_loss=0.002590023438465277
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.011936121557671675
864, epoch_train_loss=0.011936121557671675
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.01705307172465724
865, epoch_train_loss=0.01705307172465724
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.00575126479408222
866, epoch_train_loss=0.00575126479408222
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.003616967815137272
867, epoch_train_loss=0.003616967815137272
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.010926973591037113
868, epoch_train_loss=0.010926973591037113
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.0076327399430752806
869, epoch_train_loss=0.0076327399430752806
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0023138214900335742
870, epoch_train_loss=0.0023138214900335742
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.00718546643471071
871, epoch_train_loss=0.00718546643471071
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.008147667246586115
872, epoch_train_loss=0.008147667246586115
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0024263094311968068
873, epoch_train_loss=0.0024263094311968068
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.004861647806734598
874, epoch_train_loss=0.004861647806734598
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.007284374871923478
875, epoch_train_loss=0.007284374871923478
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.002492354703638617
876, epoch_train_loss=0.002492354703638617
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.0038600834834732396
877, epoch_train_loss=0.0038600834834732396
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.006663027377594709
878, epoch_train_loss=0.006663027377594709
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.001827764926015751
879, epoch_train_loss=0.001827764926015751
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.0033493982736921783
880, epoch_train_loss=0.0033493982736921783
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.005815282152181883
881, epoch_train_loss=0.005815282152181883
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.000798047346724546
882, epoch_train_loss=0.000798047346724546
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0030722727178000087
883, epoch_train_loss=0.0030722727178000087
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0040251443091472335
884, epoch_train_loss=0.0040251443091472335
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0004773749753411481
885, epoch_train_loss=0.0004773749753411481
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.002654054021888795
886, epoch_train_loss=0.002654054021888795
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0026046770161846197
887, epoch_train_loss=0.0026046770161846197
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0009205795325827283
888, epoch_train_loss=0.0009205795325827283
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0017661556654733708
889, epoch_train_loss=0.0017661556654733708
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.002330719905372719
890, epoch_train_loss=0.002330719905372719
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0008252625595271703
891, epoch_train_loss=0.0008252625595271703
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0011617036554391427
892, epoch_train_loss=0.0011617036554391427
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.002143379779958385
893, epoch_train_loss=0.002143379779958385
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.00041589205561896956
894, epoch_train_loss=0.00041589205561896956
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0011342606172363798
895, epoch_train_loss=0.0011342606172363798
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.0015713260763635494
896, epoch_train_loss=0.0015713260763635494
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.0004895647065699665
897, epoch_train_loss=0.0004895647065699665
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0008431697277463115
898, epoch_train_loss=0.0008431697277463115
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0012174834217382885
899, epoch_train_loss=0.0012174834217382885
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0005675454062678357
900, epoch_train_loss=0.0005675454062678357
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.000484979054993903
901, epoch_train_loss=0.000484979054993903
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0010989901409503295
902, epoch_train_loss=0.0010989901409503295
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.00042398284385407434
903, epoch_train_loss=0.00042398284385407434
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0004223913188681843
904, epoch_train_loss=0.0004223913188681843
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007996424455970236
905, epoch_train_loss=0.0007996424455970236
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.00040983115389792683
906, epoch_train_loss=0.00040983115389792683
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.00032952995903132257
907, epoch_train_loss=0.00032952995903132257
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.0005594042103244013
908, epoch_train_loss=0.0005594042103244013
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.00044259582327352173
909, epoch_train_loss=0.00044259582327352173
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.00020456375617874083
910, epoch_train_loss=0.00020456375617874083
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0004609715964406292
911, epoch_train_loss=0.0004609715964406292
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.00036646912549178224
912, epoch_train_loss=0.00036646912549178224
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.00020481152319418253
913, epoch_train_loss=0.00020481152319418253
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.00033087569067658836
914, epoch_train_loss=0.00033087569067658836
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0003280863701781449
915, epoch_train_loss=0.0003280863701781449
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.00021238524573370437
916, epoch_train_loss=0.00021238524573370437
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.00022703438747480973
917, epoch_train_loss=0.00022703438747480973
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.00031000283739999513
918, epoch_train_loss=0.00031000283739999513
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0001904352395871956
919, epoch_train_loss=0.0001904352395871956
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.00019765163857984465
920, epoch_train_loss=0.00019765163857984465
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.00025331113968657474
921, epoch_train_loss=0.00025331113968657474
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.00020143393013501571
922, epoch_train_loss=0.00020143393013501571
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.0001689678450351305
923, epoch_train_loss=0.0001689678450351305
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.00020819268496957637
924, epoch_train_loss=0.00020819268496957637
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.00020830929870268523
925, epoch_train_loss=0.00020830929870268523
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0001482460766129204
926, epoch_train_loss=0.0001482460766129204
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.00018314210786169035
927, epoch_train_loss=0.00018314210786169035
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.00018941420738880562
928, epoch_train_loss=0.00018941420738880562
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0001543970214613761
929, epoch_train_loss=0.0001543970214613761
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.00015412545396744956
930, epoch_train_loss=0.00015412545396744956
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.00017394606209381652
931, epoch_train_loss=0.00017394606209381652
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.00015728783526727458
932, epoch_train_loss=0.00015728783526727458
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.00013720695324371537
933, epoch_train_loss=0.00013720695324371537
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.00015938443627351977
934, epoch_train_loss=0.00015938443627351977
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.00015150798729736905
935, epoch_train_loss=0.00015150798729736905
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.0001361707598809276
936, epoch_train_loss=0.0001361707598809276
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.00013984308392933279
937, epoch_train_loss=0.00013984308392933279
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.00014699063594142024
938, epoch_train_loss=0.00014699063594142024
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.00013521726043013
939, epoch_train_loss=0.00013521726043013
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.00012843017509444154
940, epoch_train_loss=0.00012843017509444154
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.000138798853731658
941, epoch_train_loss=0.000138798853731658
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.0001329034155028285
942, epoch_train_loss=0.0001329034155028285
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.00012573676271043907
943, epoch_train_loss=0.00012573676271043907
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.00012739611539032845
944, epoch_train_loss=0.00012739611539032845
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.00013062853293053004
945, epoch_train_loss=0.00013062853293053004
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.00012395437833905983
946, epoch_train_loss=0.00012395437833905983
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.00012059285979809124
947, epoch_train_loss=0.00012059285979809124
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.00012508182589422172
948, epoch_train_loss=0.00012508182589422172
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.00012205561987076538
949, epoch_train_loss=0.00012205561987076538
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.00011820370522643249
950, epoch_train_loss=0.00011820370522643249
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0001181855568334534
951, epoch_train_loss=0.0001181855568334534
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.0001198352210802545
952, epoch_train_loss=0.0001198352210802545
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.0001165400733742866
953, epoch_train_loss=0.0001165400733742866
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.00011413118013800439
954, epoch_train_loss=0.00011413118013800439
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.0001158210029805692
955, epoch_train_loss=0.0001158210029805692
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.00011472480811549522
956, epoch_train_loss=0.00011472480811549522
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.00011244957857701275
957, epoch_train_loss=0.00011244957857701275
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.00011154488314113389
958, epoch_train_loss=0.00011154488314113389
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.00011240356713549383
959, epoch_train_loss=0.00011240356713549383
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.00011098466997619489
960, epoch_train_loss=0.00011098466997619489
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.00010910556729904897
961, epoch_train_loss=0.00010910556729904897
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.00010936020773708613
962, epoch_train_loss=0.00010936020773708613
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.00010908015546946318
963, epoch_train_loss=0.00010908015546946318
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.00010787796500473214
964, epoch_train_loss=0.00010787796500473214
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.00010669904139397095
965, epoch_train_loss=0.00010669904139397095
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.00010685826706185817
966, epoch_train_loss=0.00010685826706185817
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.00010641373359878016
967, epoch_train_loss=0.00010641373359878016
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.00010515698599689627
968, epoch_train_loss=0.00010515698599689627
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.00010467981165497639
969, epoch_train_loss=0.00010467981165497639
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.00010449477348504033
970, epoch_train_loss=0.00010449477348504033
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.00010399561046416793
971, epoch_train_loss=0.00010399561046416793
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.00010301616947091395
972, epoch_train_loss=0.00010301616947091395
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.000102641985714142
973, epoch_train_loss=0.000102641985714142
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.00010246127792002729
974, epoch_train_loss=0.00010246127792002729
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.00010180235208000903
975, epoch_train_loss=0.00010180235208000903
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.00010116501078942721
976, epoch_train_loss=0.00010116501078942721
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.00010077538571901533
977, epoch_train_loss=0.00010077538571901533
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.00010054074706133687
978, epoch_train_loss=0.00010054074706133687
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 9.99583756464431e-05
979, epoch_train_loss=9.99583756464431e-05
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 9.940158520006433e-05
980, epoch_train_loss=9.940158520006433e-05
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 9.911221371989926e-05
981, epoch_train_loss=9.911221371989926e-05
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 9.876846843150089e-05
982, epoch_train_loss=9.876846843150089e-05
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 9.830682448471712e-05
983, epoch_train_loss=9.830682448471712e-05
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 9.781744000404523e-05
984, epoch_train_loss=9.781744000404523e-05
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 9.75272058840584e-05
985, epoch_train_loss=9.75272058840584e-05
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 9.720663427488408e-05
986, epoch_train_loss=9.720663427488408e-05
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 9.676328593999093e-05
987, epoch_train_loss=9.676328593999093e-05
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 9.637363414482489e-05
988, epoch_train_loss=9.637363414482489e-05
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 9.605650759954332e-05
989, epoch_train_loss=9.605650759954332e-05
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 9.575933463565857e-05
990, epoch_train_loss=9.575933463565857e-05
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 9.536828514862342e-05
991, epoch_train_loss=9.536828514862342e-05
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 9.500461076932448e-05
992, epoch_train_loss=9.500461076932448e-05
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 9.471577571766678e-05
993, epoch_train_loss=9.471577571766678e-05
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 9.441071354902508e-05
994, epoch_train_loss=9.441071354902508e-05
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 9.40765907901122e-05
995, epoch_train_loss=9.40765907901122e-05
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 9.373584275600225e-05
996, epoch_train_loss=9.373584275600225e-05
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 9.345343438128951e-05
997, epoch_train_loss=9.345343438128951e-05
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 9.317233204219767e-05
998, epoch_train_loss=9.317233204219767e-05
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 9.285834756497856e-05
999, epoch_train_loss=9.285834756497856e-05
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 9.2554705132211e-05
1000, epoch_train_loss=9.2554705132211e-05
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 9.227345568411562e-05
1001, epoch_train_loss=9.227345568411562e-05
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 9.200990886202697e-05
1002, epoch_train_loss=9.200990886202697e-05
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 9.172429082463646e-05
1003, epoch_train_loss=9.172429082463646e-05
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 9.143687894629584e-05
1004, epoch_train_loss=9.143687894629584e-05
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 9.11731730750802e-05
1005, epoch_train_loss=9.11731730750802e-05
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 9.091600561703423e-05
1006, epoch_train_loss=9.091600561703423e-05
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 9.065573010964355e-05
1007, epoch_train_loss=9.065573010964355e-05
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 9.038724397459682e-05
1008, epoch_train_loss=9.038724397459682e-05
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 9.01326303135682e-05
1009, epoch_train_loss=9.01326303135682e-05
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 8.989029815201276e-05
1010, epoch_train_loss=8.989029815201276e-05
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 8.964359482523122e-05
1011, epoch_train_loss=8.964359482523122e-05
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 8.939579070851674e-05
1012, epoch_train_loss=8.939579070851674e-05
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 8.915146975065516e-05
1013, epoch_train_loss=8.915146975065516e-05
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 8.891850701100641e-05
1014, epoch_train_loss=8.891850701100641e-05
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 8.868768624479225e-05
1015, epoch_train_loss=8.868768624479225e-05
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 8.845327158870105e-05
1016, epoch_train_loss=8.845327158870105e-05
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 8.822282324147016e-05
1017, epoch_train_loss=8.822282324147016e-05
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 8.799793816056073e-05
1018, epoch_train_loss=8.799793816056073e-05
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 8.777859947200587e-05
1019, epoch_train_loss=8.777859947200587e-05
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 8.755861838661208e-05
1020, epoch_train_loss=8.755861838661208e-05
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 8.733869099661375e-05
1021, epoch_train_loss=8.733869099661375e-05
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 8.712413413888957e-05
1022, epoch_train_loss=8.712413413888957e-05
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 8.691342513709958e-05
1023, epoch_train_loss=8.691342513709958e-05
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 8.670508307036874e-05
1024, epoch_train_loss=8.670508307036874e-05
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 8.649677953626356e-05
1025, epoch_train_loss=8.649677953626356e-05
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 8.629063874676866e-05
1026, epoch_train_loss=8.629063874676866e-05
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 8.608898920592427e-05
1027, epoch_train_loss=8.608898920592427e-05
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 8.588958082021285e-05
1028, epoch_train_loss=8.588958082021285e-05
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 8.569164575622409e-05
1029, epoch_train_loss=8.569164575622409e-05
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 8.549480199619758e-05
1030, epoch_train_loss=8.549480199619758e-05
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 8.530058441357313e-05
1031, epoch_train_loss=8.530058441357313e-05
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 8.51096384060262e-05
1032, epoch_train_loss=8.51096384060262e-05
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 8.492021245681337e-05
1033, epoch_train_loss=8.492021245681337e-05
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 8.473219818844913e-05
1034, epoch_train_loss=8.473219818844913e-05
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 8.454578861927956e-05
1035, epoch_train_loss=8.454578861927956e-05
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 8.436176354438968e-05
1036, epoch_train_loss=8.436176354438968e-05
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 8.418015008246029e-05
1037, epoch_train_loss=8.418015008246029e-05
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 8.399984859728739e-05
1038, epoch_train_loss=8.399984859728739e-05
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 8.38210099336898e-05
1039, epoch_train_loss=8.38210099336898e-05
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 8.364387173295508e-05
1040, epoch_train_loss=8.364387173295508e-05
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 8.346874504166299e-05
1041, epoch_train_loss=8.346874504166299e-05
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 8.329553050614937e-05
1042, epoch_train_loss=8.329553050614937e-05
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 8.312359072704661e-05
1043, epoch_train_loss=8.312359072704661e-05
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 8.295308729033989e-05
1044, epoch_train_loss=8.295308729033989e-05
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 8.278418827493174e-05
1045, epoch_train_loss=8.278418827493174e-05
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 8.261699446145647e-05
1046, epoch_train_loss=8.261699446145647e-05
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 8.245142498100717e-05
1047, epoch_train_loss=8.245142498100717e-05
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 8.228710667585005e-05
1048, epoch_train_loss=8.228710667585005e-05
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 8.212413970376535e-05
1049, epoch_train_loss=8.212413970376535e-05
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 8.19626344792384e-05
1050, epoch_train_loss=8.19626344792384e-05
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 8.180260986714791e-05
1051, epoch_train_loss=8.180260986714791e-05
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 8.164401933826624e-05
1052, epoch_train_loss=8.164401933826624e-05
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 8.148663833911135e-05
1053, epoch_train_loss=8.148663833911135e-05
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 8.133050602879015e-05
1054, epoch_train_loss=8.133050602879015e-05
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 8.117569363821407e-05
1055, epoch_train_loss=8.117569363821407e-05
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 8.102219347496567e-05
1056, epoch_train_loss=8.102219347496567e-05
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 8.086998431387165e-05
1057, epoch_train_loss=8.086998431387165e-05
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 8.071892934769069e-05
1058, epoch_train_loss=8.071892934769069e-05
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 8.056902453683562e-05
1059, epoch_train_loss=8.056902453683562e-05
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 8.042031286137008e-05
1060, epoch_train_loss=8.042031286137008e-05
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 8.027278095943574e-05
1061, epoch_train_loss=8.027278095943574e-05
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 8.012642150849743e-05
1062, epoch_train_loss=8.012642150849743e-05
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 7.998115306358141e-05
1063, epoch_train_loss=7.998115306358141e-05
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 7.983694772442964e-05
1064, epoch_train_loss=7.983694772442964e-05
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 7.969382624888863e-05
1065, epoch_train_loss=7.969382624888863e-05
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 7.955177608149575e-05
1066, epoch_train_loss=7.955177608149575e-05
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 7.941079617917596e-05
1067, epoch_train_loss=7.941079617917596e-05
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 7.92708408053212e-05
1068, epoch_train_loss=7.92708408053212e-05
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 7.913187339426494e-05
1069, epoch_train_loss=7.913187339426494e-05
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 7.899389804468025e-05
1070, epoch_train_loss=7.899389804468025e-05
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 7.885690315086797e-05
1071, epoch_train_loss=7.885690315086797e-05
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 7.872088737621554e-05
1072, epoch_train_loss=7.872088737621554e-05
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 7.858582793517161e-05
1073, epoch_train_loss=7.858582793517161e-05
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 7.845169175677937e-05
1074, epoch_train_loss=7.845169175677937e-05
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 7.83184714047447e-05
1075, epoch_train_loss=7.83184714047447e-05
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 7.818615434660631e-05
1076, epoch_train_loss=7.818615434660631e-05
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 7.80547361022217e-05
1077, epoch_train_loss=7.80547361022217e-05
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 7.792420677096524e-05
1078, epoch_train_loss=7.792420677096524e-05
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 7.77945419527644e-05
1079, epoch_train_loss=7.77945419527644e-05
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 7.766572887472057e-05
1080, epoch_train_loss=7.766572887472057e-05
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 7.7537754202302e-05
1081, epoch_train_loss=7.7537754202302e-05
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 7.741060899939824e-05
1082, epoch_train_loss=7.741060899939824e-05
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 7.728428796504742e-05
1083, epoch_train_loss=7.728428796504742e-05
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 7.715877588746607e-05
1084, epoch_train_loss=7.715877588746607e-05
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 7.703405953141049e-05
1085, epoch_train_loss=7.703405953141049e-05
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 7.691012631572445e-05
1086, epoch_train_loss=7.691012631572445e-05
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 7.678696450154977e-05
1087, epoch_train_loss=7.678696450154977e-05
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 7.666456767449659e-05
1088, epoch_train_loss=7.666456767449659e-05
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 7.654292631428263e-05
1089, epoch_train_loss=7.654292631428263e-05
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 7.642202954638688e-05
1090, epoch_train_loss=7.642202954638688e-05
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 7.630186713725538e-05
1091, epoch_train_loss=7.630186713725538e-05
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 7.618242713625856e-05
1092, epoch_train_loss=7.618242713625856e-05
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 7.606370078731253e-05
1093, epoch_train_loss=7.606370078731253e-05
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 7.5945680413247e-05
1094, epoch_train_loss=7.5945680413247e-05
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 7.582835690470613e-05
1095, epoch_train_loss=7.582835690470613e-05
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 7.571172235846218e-05
1096, epoch_train_loss=7.571172235846218e-05
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 7.559576706550775e-05
1097, epoch_train_loss=7.559576706550775e-05
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 7.548048151491617e-05
1098, epoch_train_loss=7.548048151491617e-05
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 7.53658580021793e-05
1099, epoch_train_loss=7.53658580021793e-05
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 7.525188811474638e-05
1100, epoch_train_loss=7.525188811474638e-05
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 7.513856472407092e-05
1101, epoch_train_loss=7.513856472407092e-05
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 7.50258803250922e-05
1102, epoch_train_loss=7.50258803250922e-05
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 7.491382669138617e-05
1103, epoch_train_loss=7.491382669138617e-05
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 7.480239634259277e-05
1104, epoch_train_loss=7.480239634259277e-05
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 7.469158143109054e-05
1105, epoch_train_loss=7.469158143109054e-05
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 7.458137477391577e-05
1106, epoch_train_loss=7.458137477391577e-05
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 7.447176967108748e-05
1107, epoch_train_loss=7.447176967108748e-05
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 7.436275920808276e-05
1108, epoch_train_loss=7.436275920808276e-05
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 7.425433666063043e-05
1109, epoch_train_loss=7.425433666063043e-05
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 7.414649530995132e-05
1110, epoch_train_loss=7.414649530995132e-05
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 7.403922827495853e-05
1111, epoch_train_loss=7.403922827495853e-05
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 7.39325290976456e-05
1112, epoch_train_loss=7.39325290976456e-05
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 7.38263914977353e-05
1113, epoch_train_loss=7.38263914977353e-05
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 7.372080919521251e-05
1114, epoch_train_loss=7.372080919521251e-05
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 7.361577634287881e-05
1115, epoch_train_loss=7.361577634287881e-05
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 7.35112868856127e-05
1116, epoch_train_loss=7.35112868856127e-05
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 7.340733486701381e-05
1117, epoch_train_loss=7.340733486701381e-05
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 7.330391453605012e-05
1118, epoch_train_loss=7.330391453605012e-05
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 7.320102004454397e-05
1119, epoch_train_loss=7.320102004454397e-05
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 7.309864584417787e-05
1120, epoch_train_loss=7.309864584417787e-05
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 7.29967864491104e-05
1121, epoch_train_loss=7.29967864491104e-05
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 7.289543648765564e-05
1122, epoch_train_loss=7.289543648765564e-05
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 7.279459069377073e-05
1123, epoch_train_loss=7.279459069377073e-05
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 7.269424385591966e-05
1124, epoch_train_loss=7.269424385591966e-05
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 7.25943908004849e-05
1125, epoch_train_loss=7.25943908004849e-05
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 7.249502646821982e-05
1126, epoch_train_loss=7.249502646821982e-05
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 7.239614586303826e-05
1127, epoch_train_loss=7.239614586303826e-05
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 7.229774408908487e-05
1128, epoch_train_loss=7.229774408908487e-05
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 7.219981638697952e-05
1129, epoch_train_loss=7.219981638697952e-05
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 7.210235799266388e-05
1130, epoch_train_loss=7.210235799266388e-05
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 7.200536429776146e-05
1131, epoch_train_loss=7.200536429776146e-05
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 7.190883072606368e-05
1132, epoch_train_loss=7.190883072606368e-05
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 7.181275274559762e-05
1133, epoch_train_loss=7.181275274559762e-05
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 7.171712593643162e-05
1134, epoch_train_loss=7.171712593643162e-05
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 7.162194590469813e-05
1135, epoch_train_loss=7.162194590469813e-05
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 7.152720836100555e-05
1136, epoch_train_loss=7.152720836100555e-05
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 7.143290906329873e-05
1137, epoch_train_loss=7.143290906329873e-05
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 7.133904385127382e-05
1138, epoch_train_loss=7.133904385127382e-05
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 7.124560860869949e-05
1139, epoch_train_loss=7.124560860869949e-05
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 7.115259931785324e-05
1140, epoch_train_loss=7.115259931785324e-05
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 7.106001198638007e-05
1141, epoch_train_loss=7.106001198638007e-05
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 7.096784268205482e-05
1142, epoch_train_loss=7.096784268205482e-05
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 7.087608756004269e-05
1143, epoch_train_loss=7.087608756004269e-05
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 7.078474278683226e-05
1144, epoch_train_loss=7.078474278683226e-05
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 7.069380461303383e-05
1145, epoch_train_loss=7.069380461303383e-05
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 7.060326934714322e-05
1146, epoch_train_loss=7.060326934714322e-05
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 7.051313333719648e-05
1147, epoch_train_loss=7.051313333719648e-05
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 7.042339298076897e-05
1148, epoch_train_loss=7.042339298076897e-05
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 7.033404475380791e-05
1149, epoch_train_loss=7.033404475380791e-05
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 7.024508515768234e-05
1150, epoch_train_loss=7.024508515768234e-05
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 7.015651075013078e-05
1151, epoch_train_loss=7.015651075013078e-05
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 7.006831813964249e-05
1152, epoch_train_loss=7.006831813964249e-05
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 6.998050397486358e-05
1153, epoch_train_loss=6.998050397486358e-05
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 6.989306496179545e-05
1154, epoch_train_loss=6.989306496179545e-05
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 6.980599783508199e-05
1155, epoch_train_loss=6.980599783508199e-05
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 6.971929938754742e-05
1156, epoch_train_loss=6.971929938754742e-05
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 6.963296645503372e-05
1157, epoch_train_loss=6.963296645503372e-05
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 6.954699590986547e-05
1158, epoch_train_loss=6.954699590986547e-05
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 6.946138467302303e-05
1159, epoch_train_loss=6.946138467302303e-05
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 6.937612970275854e-05
1160, epoch_train_loss=6.937612970275854e-05
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 6.929122799217918e-05
1161, epoch_train_loss=6.929122799217918e-05
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 6.920667659417098e-05
1162, epoch_train_loss=6.920667659417098e-05
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 6.912247256948014e-05
1163, epoch_train_loss=6.912247256948014e-05
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 6.903861305123571e-05
1164, epoch_train_loss=6.903861305123571e-05
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 6.895509518512858e-05
1165, epoch_train_loss=6.895509518512858e-05
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 6.887191617242751e-05
1166, epoch_train_loss=6.887191617242751e-05
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 6.878907322424742e-05
1167, epoch_train_loss=6.878907322424742e-05
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 6.870656362017382e-05
1168, epoch_train_loss=6.870656362017382e-05
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 6.862438465059874e-05
1169, epoch_train_loss=6.862438465059874e-05
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 6.854253364825027e-05
1170, epoch_train_loss=6.854253364825027e-05
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 6.846100798010323e-05
1171, epoch_train_loss=6.846100798010323e-05
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 6.83798050459733e-05
1172, epoch_train_loss=6.83798050459733e-05
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 6.829892227767223e-05
1173, epoch_train_loss=6.829892227767223e-05
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 6.821835713992625e-05
1174, epoch_train_loss=6.821835713992625e-05
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 6.813810712953039e-05
1175, epoch_train_loss=6.813810712953039e-05
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 6.80581697716172e-05
1176, epoch_train_loss=6.80581697716172e-05
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 6.797854262555361e-05
1177, epoch_train_loss=6.797854262555361e-05
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 6.789922327704408e-05
1178, epoch_train_loss=6.789922327704408e-05
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 6.78202093440591e-05
1179, epoch_train_loss=6.78202093440591e-05
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 6.774149847083842e-05
1180, epoch_train_loss=6.774149847083842e-05
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 6.766308832777052e-05
1181, epoch_train_loss=6.766308832777052e-05
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 6.758497662027893e-05
1182, epoch_train_loss=6.758497662027893e-05
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 6.750716108145502e-05
1183, epoch_train_loss=6.750716108145502e-05
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 6.742963946506976e-05
1184, epoch_train_loss=6.742963946506976e-05
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 6.735240955190693e-05
1185, epoch_train_loss=6.735240955190693e-05
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 6.727546915421928e-05
1186, epoch_train_loss=6.727546915421928e-05
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 6.719881611251644e-05
1187, epoch_train_loss=6.719881611251644e-05
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 6.712244827650194e-05
1188, epoch_train_loss=6.712244827650194e-05
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 6.704636354528031e-05
1189, epoch_train_loss=6.704636354528031e-05
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 6.697055981715553e-05
1190, epoch_train_loss=6.697055981715553e-05
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 6.689503504256457e-05
1191, epoch_train_loss=6.689503504256457e-05
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 6.681978717230279e-05
1192, epoch_train_loss=6.681978717230279e-05
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 6.674481419808701e-05
1193, epoch_train_loss=6.674481419808701e-05
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 6.667011412136158e-05
1194, epoch_train_loss=6.667011412136158e-05
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 6.659568499050692e-05
1195, epoch_train_loss=6.659568499050692e-05
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 6.652152485361876e-05
1196, epoch_train_loss=6.652152485361876e-05
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 6.644763183139051e-05
1197, epoch_train_loss=6.644763183139051e-05
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 6.637400401015301e-05
1198, epoch_train_loss=6.637400401015301e-05
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 6.63006396180237e-05
1199, epoch_train_loss=6.63006396180237e-05
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 6.62275368423431e-05
1200, epoch_train_loss=6.62275368423431e-05
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 6.615469407123787e-05
1201, epoch_train_loss=6.615469407123787e-05
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 6.608210969808572e-05
1202, epoch_train_loss=6.608210969808572e-05
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 6.600978254070815e-05
1203, epoch_train_loss=6.600978254070815e-05
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 6.593771157464428e-05
1204, epoch_train_loss=6.593771157464428e-05
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 6.586589677866345e-05
1205, epoch_train_loss=6.586589677866345e-05
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 6.579433899317724e-05
1206, epoch_train_loss=6.579433899317724e-05
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 6.572304176893973e-05
1207, epoch_train_loss=6.572304176893973e-05
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 6.565201208375995e-05
1208, epoch_train_loss=6.565201208375995e-05
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 6.558126518807242e-05
1209, epoch_train_loss=6.558126518807242e-05
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 6.551082899483555e-05
1210, epoch_train_loss=6.551082899483555e-05
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 6.544075864792243e-05
1211, epoch_train_loss=6.544075864792243e-05
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 6.537115572251905e-05
1212, epoch_train_loss=6.537115572251905e-05
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 6.530221653039273e-05
1213, epoch_train_loss=6.530221653039273e-05
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 6.523430925406153e-05
1214, epoch_train_loss=6.523430925406153e-05
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 6.516814683405979e-05
1215, epoch_train_loss=6.516814683405979e-05
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 6.510509075728814e-05
1216, epoch_train_loss=6.510509075728814e-05
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 6.504780610154217e-05
1217, epoch_train_loss=6.504780610154217e-05
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 6.500146246851446e-05
1218, epoch_train_loss=6.500146246851446e-05
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 6.497633556232272e-05
1219, epoch_train_loss=6.497633556232272e-05
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 6.49926091872264e-05
1220, epoch_train_loss=6.49926091872264e-05
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 6.509116981476487e-05
1221, epoch_train_loss=6.509116981476487e-05
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 6.535299632373161e-05
1222, epoch_train_loss=6.535299632373161e-05
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 6.59460981104767e-05
1223, epoch_train_loss=6.59460981104767e-05
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 6.720364261874171e-05
1224, epoch_train_loss=6.720364261874171e-05
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 6.983988595867115e-05
1225, epoch_train_loss=6.983988595867115e-05
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 7.525442953168788e-05
1226, epoch_train_loss=7.525442953168788e-05
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 8.660095675773462e-05
1227, epoch_train_loss=8.660095675773462e-05
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.00010982797558626877
1228, epoch_train_loss=0.00010982797558626877
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.00015950162571465117
1229, epoch_train_loss=0.00015950162571465117
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.00026064108012793384
1230, epoch_train_loss=0.00026064108012793384
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0004843819824996677
1231, epoch_train_loss=0.0004843819824996677
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0009282723718651652
1232, epoch_train_loss=0.0009282723718651652
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0019621496244033145
1233, epoch_train_loss=0.0019621496244033145
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0038463085100939815
1234, epoch_train_loss=0.0038463085100939815
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.00855720971457789
1235, epoch_train_loss=0.00855720971457789
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.01504285472624491
1236, epoch_train_loss=0.01504285472624491
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.03219952947189826
1237, epoch_train_loss=0.03219952947189826
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.03756065368363035
1238, epoch_train_loss=0.03756065368363035
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.05408940265743603
1239, epoch_train_loss=0.05408940265743603
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.022880660384710778
1240, epoch_train_loss=0.022880660384710778
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0033243569489054985
1241, epoch_train_loss=0.0033243569489054985
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.004678196272957985
1242, epoch_train_loss=0.004678196272957985
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.018202457829686818
1243, epoch_train_loss=0.018202457829686818
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.02615436690341543
1244, epoch_train_loss=0.02615436690341543
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.007834178716985779
1245, epoch_train_loss=0.007834178716985779
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0009608359129001521
1246, epoch_train_loss=0.0009608359129001521
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.010232407111574172
1247, epoch_train_loss=0.010232407111574172
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.011776653801515387
1248, epoch_train_loss=0.011776653801515387
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.004487058392741023
1249, epoch_train_loss=0.004487058392741023
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0007359889595260599
1250, epoch_train_loss=0.0007359889595260599
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.006473496309900476
1251, epoch_train_loss=0.006473496309900476
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.00936202201092353
1252, epoch_train_loss=0.00936202201092353
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.0025099627829386034
1253, epoch_train_loss=0.0025099627829386034
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0011794859216180682
1254, epoch_train_loss=0.0011794859216180682
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0057097101069663305
1255, epoch_train_loss=0.0057097101069663305
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.004192659203773211
1256, epoch_train_loss=0.004192659203773211
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0006173309633192424
1257, epoch_train_loss=0.0006173309633192424
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0018746152643989644
1258, epoch_train_loss=0.0018746152643989644
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.0036556694609533747
1259, epoch_train_loss=0.0036556694609533747
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0018795654440129502
1260, epoch_train_loss=0.0018795654440129502
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0003797379933088756
1261, epoch_train_loss=0.0003797379933088756
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0019565917792446668
1262, epoch_train_loss=0.0019565917792446668
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0024952284402043954
1263, epoch_train_loss=0.0024952284402043954
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0006558897151791125
1264, epoch_train_loss=0.0006558897151791125
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0006487781166084029
1265, epoch_train_loss=0.0006487781166084029
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0019290691572426907
1266, epoch_train_loss=0.0019290691572426907
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0012251686471977494
1267, epoch_train_loss=0.0012251686471977494
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.00023763526751232423
1268, epoch_train_loss=0.00023763526751232423
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0009147147213553742
1269, epoch_train_loss=0.0009147147213553742
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0013478806534304134
1270, epoch_train_loss=0.0013478806534304134
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0005515849752642085
1271, epoch_train_loss=0.0005515849752642085
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.00026560580136235053
1272, epoch_train_loss=0.00026560580136235053
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.0008713144577172958
1273, epoch_train_loss=0.0008713144577172958
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.0008557074268041679
1274, epoch_train_loss=0.0008557074268041679
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.0002750122143805307
1275, epoch_train_loss=0.0002750122143805307
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0003450620828845214
1276, epoch_train_loss=0.0003450620828845214
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007050851835296677
1277, epoch_train_loss=0.0007050851835296677
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0005050162434762536
1278, epoch_train_loss=0.0005050162434762536
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0001997306793438379
1279, epoch_train_loss=0.0001997306793438379
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.00033457919807803406
1280, epoch_train_loss=0.00033457919807803406
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.0005073414584303817
1281, epoch_train_loss=0.0005073414584303817
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.00032670441590072264
1282, epoch_train_loss=0.00032670441590072264
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0001561941268513938
1283, epoch_train_loss=0.0001561941268513938
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.00030520033479024695
1284, epoch_train_loss=0.00030520033479024695
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0003932157716194259
1285, epoch_train_loss=0.0003932157716194259
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.00021405929624416115
1286, epoch_train_loss=0.00021405929624416115
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.00014586305428213595
1287, epoch_train_loss=0.00014586305428213595
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0002732631865762701
1288, epoch_train_loss=0.0002732631865762701
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0002804124953059283
1289, epoch_train_loss=0.0002804124953059283
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.00015971307260322136
1290, epoch_train_loss=0.00015971307260322136
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0001463988455799799
1291, epoch_train_loss=0.0001463988455799799
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.00022383588222806182
1292, epoch_train_loss=0.00022383588222806182
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.0002145644384385275
1293, epoch_train_loss=0.0002145644384385275
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.000138316806725231
1294, epoch_train_loss=0.000138316806725231
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.00013545186954766694
1295, epoch_train_loss=0.00013545186954766694
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.0001845885045971868
1296, epoch_train_loss=0.0001845885045971868
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.00017423478670579429
1297, epoch_train_loss=0.00017423478670579429
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.00012371326772275397
1298, epoch_train_loss=0.00012371326772275397
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.00012328444190775242
1299, epoch_train_loss=0.00012328444190775242
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.00015760770923188122
1300, epoch_train_loss=0.00015760770923188122
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.00014943477543900198
1301, epoch_train_loss=0.00014943477543900198
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.00011298101408947467
1302, epoch_train_loss=0.00011298101408947467
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.00011393131292492206
1303, epoch_train_loss=0.00011393131292492206
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0001369580626448915
1304, epoch_train_loss=0.0001369580626448915
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.00013027947687136847
1305, epoch_train_loss=0.00013027947687136847
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0001074289520004809
1306, epoch_train_loss=0.0001074289520004809
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.00010672887822540214
1307, epoch_train_loss=0.00010672887822540214
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.0001201701358671716
1308, epoch_train_loss=0.0001201701358671716
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.00011866644607790455
1309, epoch_train_loss=0.00011866644607790455
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.00010401053907505482
1310, epoch_train_loss=0.00010401053907505482
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 9.965897554879076e-05
1311, epoch_train_loss=9.965897554879076e-05
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.00010814888686808689
1312, epoch_train_loss=0.00010814888686808689
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.00011010758338585562
1313, epoch_train_loss=0.00011010758338585562
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.00010033503778871895
1314, epoch_train_loss=0.00010033503778871895
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 9.48172955845408e-05
1315, epoch_train_loss=9.48172955845408e-05
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.00010003156627598577
1316, epoch_train_loss=0.00010003156627598577
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.00010296318457845186
1317, epoch_train_loss=0.00010296318457845186
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 9.711033811919589e-05
1318, epoch_train_loss=9.711033811919589e-05
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 9.212073559917941e-05
1319, epoch_train_loss=9.212073559917941e-05
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 9.390064730880735e-05
1320, epoch_train_loss=9.390064730880735e-05
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 9.646543115518141e-05
1321, epoch_train_loss=9.646543115518141e-05
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 9.422705882788036e-05
1322, epoch_train_loss=9.422705882788036e-05
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 9.004845676405342e-05
1323, epoch_train_loss=9.004845676405342e-05
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 8.936750950951707e-05
1324, epoch_train_loss=8.936750950951707e-05
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 9.147020138148145e-05
1325, epoch_train_loss=9.147020138148145e-05
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 9.134326036417191e-05
1326, epoch_train_loss=9.134326036417191e-05
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 8.831863231431289e-05
1327, epoch_train_loss=8.831863231431289e-05
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 8.65682301757471e-05
1328, epoch_train_loss=8.65682301757471e-05
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 8.752936947178972e-05
1329, epoch_train_loss=8.752936947178972e-05
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 8.812520765907998e-05
1330, epoch_train_loss=8.812520765907998e-05
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 8.661288642080448e-05
1331, epoch_train_loss=8.661288642080448e-05
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 8.48443254165686e-05
1332, epoch_train_loss=8.48443254165686e-05
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 8.456962751885103e-05
1333, epoch_train_loss=8.456962751885103e-05
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 8.509624297418297e-05
1334, epoch_train_loss=8.509624297418297e-05
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 8.481220763469419e-05
1335, epoch_train_loss=8.481220763469419e-05
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 8.352641934345377e-05
1336, epoch_train_loss=8.352641934345377e-05
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 8.257314927591773e-05
1337, epoch_train_loss=8.257314927591773e-05
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 8.264140950593403e-05
1338, epoch_train_loss=8.264140950593403e-05
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 8.279814908611416e-05
1339, epoch_train_loss=8.279814908611416e-05
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 8.217284325015739e-05
1340, epoch_train_loss=8.217284325015739e-05
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 8.124189324180432e-05
1341, epoch_train_loss=8.124189324180432e-05
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 8.0816954851791e-05
1342, epoch_train_loss=8.0816954851791e-05
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 8.083304788244907e-05
1343, epoch_train_loss=8.083304788244907e-05
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 8.069312277460084e-05
1344, epoch_train_loss=8.069312277460084e-05
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 8.014977953467209e-05
1345, epoch_train_loss=8.014977953467209e-05
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 7.95241941930296e-05
1346, epoch_train_loss=7.95241941930296e-05
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 7.922440755811246e-05
1347, epoch_train_loss=7.922440755811246e-05
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 7.91762171124838e-05
1348, epoch_train_loss=7.91762171124838e-05
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 7.896802223630787e-05
1349, epoch_train_loss=7.896802223630787e-05
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 7.849428233504792e-05
1350, epoch_train_loss=7.849428233504792e-05
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 7.805281610950238e-05
1351, epoch_train_loss=7.805281610950238e-05
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 7.783981032812478e-05
1352, epoch_train_loss=7.783981032812478e-05
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 7.771688057084886e-05
1353, epoch_train_loss=7.771688057084886e-05
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 7.748253484554086e-05
1354, epoch_train_loss=7.748253484554086e-05
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 7.712530521170745e-05
1355, epoch_train_loss=7.712530521170745e-05
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 7.678731581238495e-05
1356, epoch_train_loss=7.678731581238495e-05
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 7.657495058504083e-05
1357, epoch_train_loss=7.657495058504083e-05
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 7.642901854400888e-05
1358, epoch_train_loss=7.642901854400888e-05
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 7.621823823386155e-05
1359, epoch_train_loss=7.621823823386155e-05
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 7.592657951318972e-05
1360, epoch_train_loss=7.592657951318972e-05
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 7.565163729422194e-05
1361, epoch_train_loss=7.565163729422194e-05
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 7.545230536145634e-05
1362, epoch_train_loss=7.545230536145634e-05
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 7.528961588367452e-05
1363, epoch_train_loss=7.528961588367452e-05
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 7.510017707159546e-05
1364, epoch_train_loss=7.510017707159546e-05
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 7.48677117353931e-05
1365, epoch_train_loss=7.48677117353931e-05
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 7.463002148234362e-05
1366, epoch_train_loss=7.463002148234362e-05
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 7.443295338578327e-05
1367, epoch_train_loss=7.443295338578327e-05
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 7.42726784210479e-05
1368, epoch_train_loss=7.42726784210479e-05
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 7.410412507415308e-05
1369, epoch_train_loss=7.410412507415308e-05
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 7.390588661356871e-05
1370, epoch_train_loss=7.390588661356871e-05
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 7.370125323807492e-05
1371, epoch_train_loss=7.370125323807492e-05
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 7.351764617285099e-05
1372, epoch_train_loss=7.351764617285099e-05
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 7.335595628930641e-05
1373, epoch_train_loss=7.335595628930641e-05
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 7.31990187838311e-05
1374, epoch_train_loss=7.31990187838311e-05
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 7.303128880122976e-05
1375, epoch_train_loss=7.303128880122976e-05
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 7.285304190076911e-05
1376, epoch_train_loss=7.285304190076911e-05
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 7.267994552706838e-05
1377, epoch_train_loss=7.267994552706838e-05
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 7.252307372053212e-05
1378, epoch_train_loss=7.252307372053212e-05
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 7.237589218714007e-05
1379, epoch_train_loss=7.237589218714007e-05
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 7.222571276018713e-05
1380, epoch_train_loss=7.222571276018713e-05
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 7.206900418534095e-05
1381, epoch_train_loss=7.206900418534095e-05
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 7.191170167608657e-05
1382, epoch_train_loss=7.191170167608657e-05
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 7.176095181245836e-05
1383, epoch_train_loss=7.176095181245836e-05
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 7.161887865417041e-05
1384, epoch_train_loss=7.161887865417041e-05
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 7.148083377633081e-05
1385, epoch_train_loss=7.148083377633081e-05
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 7.134064569454876e-05
1386, epoch_train_loss=7.134064569454876e-05
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 7.119778462015344e-05
1387, epoch_train_loss=7.119778462015344e-05
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 7.105664020813491e-05
1388, epoch_train_loss=7.105664020813491e-05
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 7.092057975611061e-05
1389, epoch_train_loss=7.092057975611061e-05
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 7.078916326828077e-05
1390, epoch_train_loss=7.078916326828077e-05
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 7.065978627614402e-05
1391, epoch_train_loss=7.065978627614402e-05
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 7.053004521912065e-05
1392, epoch_train_loss=7.053004521912065e-05
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 7.039961630936335e-05
1393, epoch_train_loss=7.039961630936335e-05
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 7.027063707739838e-05
1394, epoch_train_loss=7.027063707739838e-05
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 7.014513249733174e-05
1395, epoch_train_loss=7.014513249733174e-05
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 7.002280124763972e-05
1396, epoch_train_loss=7.002280124763972e-05
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 6.990191355350808e-05
1397, epoch_train_loss=6.990191355350808e-05
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 6.978134708887515e-05
1398, epoch_train_loss=6.978134708887515e-05
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 6.966115876053393e-05
1399, epoch_train_loss=6.966115876053393e-05
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 6.954207552150502e-05
1400, epoch_train_loss=6.954207552150502e-05
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 6.94250238654978e-05
1401, epoch_train_loss=6.94250238654978e-05
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 6.931027484161675e-05
1402, epoch_train_loss=6.931027484161675e-05
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 6.919709019563549e-05
1403, epoch_train_loss=6.919709019563549e-05
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 6.908459736004459e-05
1404, epoch_train_loss=6.908459736004459e-05
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 6.897264797238953e-05
1405, epoch_train_loss=6.897264797238953e-05
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 6.886165675697364e-05
1406, epoch_train_loss=6.886165675697364e-05
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 6.875201442782549e-05
1407, epoch_train_loss=6.875201442782549e-05
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 6.864391450999e-05
1408, epoch_train_loss=6.864391450999e-05
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 6.853723756092853e-05
1409, epoch_train_loss=6.853723756092853e-05
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 6.843157608456396e-05
1410, epoch_train_loss=6.843157608456396e-05
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 6.832661224248472e-05
1411, epoch_train_loss=6.832661224248472e-05
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 6.822237736437587e-05
1412, epoch_train_loss=6.822237736437587e-05
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 6.811911633273022e-05
1413, epoch_train_loss=6.811911633273022e-05
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 6.801698327946259e-05
1414, epoch_train_loss=6.801698327946259e-05
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 6.79159865387432e-05
1415, epoch_train_loss=6.79159865387432e-05
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 6.781601815357417e-05
1416, epoch_train_loss=6.781601815357417e-05
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 6.77168949798487e-05
1417, epoch_train_loss=6.77168949798487e-05
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 6.761848802152498e-05
1418, epoch_train_loss=6.761848802152498e-05
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 6.752080811672209e-05
1419, epoch_train_loss=6.752080811672209e-05
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 6.74239608882368e-05
1420, epoch_train_loss=6.74239608882368e-05
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 6.732800845034424e-05
1421, epoch_train_loss=6.732800845034424e-05
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 6.723294527752944e-05
1422, epoch_train_loss=6.723294527752944e-05
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 6.713871789891022e-05
1423, epoch_train_loss=6.713871789891022e-05
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 6.704524187906969e-05
1424, epoch_train_loss=6.704524187906969e-05
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 6.695244731112761e-05
1425, epoch_train_loss=6.695244731112761e-05
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 6.686031625896615e-05
1426, epoch_train_loss=6.686031625896615e-05
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 6.676888205766804e-05
1427, epoch_train_loss=6.676888205766804e-05
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 6.667816927755104e-05
1428, epoch_train_loss=6.667816927755104e-05
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 6.658818084250473e-05
1429, epoch_train_loss=6.658818084250473e-05
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 6.649889862406841e-05
1430, epoch_train_loss=6.649889862406841e-05
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 6.641028530314323e-05
1431, epoch_train_loss=6.641028530314323e-05
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 6.632229905250764e-05
1432, epoch_train_loss=6.632229905250764e-05
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 6.623491173058704e-05
1433, epoch_train_loss=6.623491173058704e-05
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 6.614812097306484e-05
1434, epoch_train_loss=6.614812097306484e-05
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 6.60619300592522e-05
1435, epoch_train_loss=6.60619300592522e-05
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 6.597634184101043e-05
1436, epoch_train_loss=6.597634184101043e-05
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 6.589135176784354e-05
1437, epoch_train_loss=6.589135176784354e-05
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 6.580694846908135e-05
1438, epoch_train_loss=6.580694846908135e-05
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 6.572311142890176e-05
1439, epoch_train_loss=6.572311142890176e-05
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 6.56398173709953e-05
1440, epoch_train_loss=6.56398173709953e-05
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 6.555705221708875e-05
1441, epoch_train_loss=6.555705221708875e-05
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 6.547480628340529e-05
1442, epoch_train_loss=6.547480628340529e-05
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 6.539307457995846e-05
1443, epoch_train_loss=6.539307457995846e-05
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 6.53118524449777e-05
1444, epoch_train_loss=6.53118524449777e-05
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 6.523113670724528e-05
1445, epoch_train_loss=6.523113670724528e-05
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 6.515091986219722e-05
1446, epoch_train_loss=6.515091986219722e-05
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 6.507119081197751e-05
1447, epoch_train_loss=6.507119081197751e-05
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 6.499193786021767e-05
1448, epoch_train_loss=6.499193786021767e-05
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 6.491314988886511e-05
1449, epoch_train_loss=6.491314988886511e-05
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 6.483481766847646e-05
1450, epoch_train_loss=6.483481766847646e-05
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 6.475693208682779e-05
1451, epoch_train_loss=6.475693208682779e-05
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 6.467948749852304e-05
1452, epoch_train_loss=6.467948749852304e-05
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 6.460247823617518e-05
1453, epoch_train_loss=6.460247823617518e-05
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 6.452589913381655e-05
1454, epoch_train_loss=6.452589913381655e-05
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 6.44497435644736e-05
1455, epoch_train_loss=6.44497435644736e-05
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 6.437400504868816e-05
1456, epoch_train_loss=6.437400504868816e-05
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 6.42986767312583e-05
1457, epoch_train_loss=6.42986767312583e-05
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 6.422375103179476e-05
1458, epoch_train_loss=6.422375103179476e-05
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 6.414922081958718e-05
1459, epoch_train_loss=6.414922081958718e-05
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 6.407507927241415e-05
1460, epoch_train_loss=6.407507927241415e-05
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 6.400132071502873e-05
1461, epoch_train_loss=6.400132071502873e-05
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 6.392793903652886e-05
1462, epoch_train_loss=6.392793903652886e-05
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 6.385492919194347e-05
1463, epoch_train_loss=6.385492919194347e-05
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 6.378228583123479e-05
1464, epoch_train_loss=6.378228583123479e-05
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 6.371000430465257e-05
1465, epoch_train_loss=6.371000430465257e-05
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 6.363807934119341e-05
1466, epoch_train_loss=6.363807934119341e-05
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 6.35665059074611e-05
1467, epoch_train_loss=6.35665059074611e-05
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 6.349527900423142e-05
1468, epoch_train_loss=6.349527900423142e-05
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 6.342439369879208e-05
1469, epoch_train_loss=6.342439369879208e-05
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 6.33538450526902e-05
1470, epoch_train_loss=6.33538450526902e-05
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 6.328362814128166e-05
1471, epoch_train_loss=6.328362814128166e-05
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 6.32137384902386e-05
1472, epoch_train_loss=6.32137384902386e-05
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 6.314417150601718e-05
1473, epoch_train_loss=6.314417150601718e-05
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 6.307492298382632e-05
1474, epoch_train_loss=6.307492298382632e-05
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 6.30059884801605e-05
1475, epoch_train_loss=6.30059884801605e-05
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 6.293736414583927e-05
1476, epoch_train_loss=6.293736414583927e-05
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 6.286904586513566e-05
1477, epoch_train_loss=6.286904586513566e-05
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 6.2801029860139e-05
1478, epoch_train_loss=6.2801029860139e-05
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 6.273331216983967e-05
1479, epoch_train_loss=6.273331216983967e-05
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 6.266588922022646e-05
1480, epoch_train_loss=6.266588922022646e-05
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 6.25987572601023e-05
1481, epoch_train_loss=6.25987572601023e-05
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 6.253191276933563e-05
1482, epoch_train_loss=6.253191276933563e-05
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 6.246535213359943e-05
1483, epoch_train_loss=6.246535213359943e-05
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 6.239907200866511e-05
1484, epoch_train_loss=6.239907200866511e-05
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 6.233306898373745e-05
1485, epoch_train_loss=6.233306898373745e-05
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 6.226733977370383e-05
1486, epoch_train_loss=6.226733977370383e-05
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 6.220188113310034e-05
1487, epoch_train_loss=6.220188113310034e-05
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 6.213668991379119e-05
1488, epoch_train_loss=6.213668991379119e-05
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 6.207176304405281e-05
1489, epoch_train_loss=6.207176304405281e-05
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 6.200709747640885e-05
1490, epoch_train_loss=6.200709747640885e-05
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 6.194269025559533e-05
1491, epoch_train_loss=6.194269025559533e-05
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 6.187853848088863e-05
1492, epoch_train_loss=6.187853848088863e-05
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 6.181463934969267e-05
1493, epoch_train_loss=6.181463934969267e-05
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 6.175099003333709e-05
1494, epoch_train_loss=6.175099003333709e-05
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 6.168758786937996e-05
1495, epoch_train_loss=6.168758786937996e-05
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 6.162443013554237e-05
1496, epoch_train_loss=6.162443013554237e-05
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 6.156151429606781e-05
1497, epoch_train_loss=6.156151429606781e-05
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 6.149883772132804e-05
1498, epoch_train_loss=6.149883772132804e-05
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 6.143639798486575e-05
1499, epoch_train_loss=6.143639798486575e-05
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 6.137419256862527e-05
1500, epoch_train_loss=6.137419256862527e-05
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 6.131221917992166e-05
1501, epoch_train_loss=6.131221917992166e-05
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 6.125047538237242e-05
1502, epoch_train_loss=6.125047538237242e-05
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 6.118895903728233e-05
1503, epoch_train_loss=6.118895903728233e-05
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 6.112766780502505e-05
1504, epoch_train_loss=6.112766780502505e-05
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 6.106659975633596e-05
1505, epoch_train_loss=6.106659975633596e-05
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 6.100575270179947e-05
1506, epoch_train_loss=6.100575270179947e-05
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 6.094512502956457e-05
1507, epoch_train_loss=6.094512502956457e-05
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 6.0884714826161596e-05
1508, epoch_train_loss=6.0884714826161596e-05
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 6.08245210781861e-05
1509, epoch_train_loss=6.08245210781861e-05
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 6.07645425212349e-05
1510, epoch_train_loss=6.07645425212349e-05
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 6.070477945326526e-05
1511, epoch_train_loss=6.070477945326526e-05
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 6.0645232270774865e-05
1512, epoch_train_loss=6.0645232270774865e-05
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 6.058590444958085e-05
1513, epoch_train_loss=6.058590444958085e-05
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 6.052680089908447e-05
1514, epoch_train_loss=6.052680089908447e-05
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 6.046793333409515e-05
1515, epoch_train_loss=6.046793333409515e-05
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 6.040931932851236e-05
1516, epoch_train_loss=6.040931932851236e-05
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 6.035099315965056e-05
1517, epoch_train_loss=6.035099315965056e-05
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 6.029300888199484e-05
1518, epoch_train_loss=6.029300888199484e-05
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 6.023546527476952e-05
1519, epoch_train_loss=6.023546527476952e-05
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 6.017852429523199e-05
1520, epoch_train_loss=6.017852429523199e-05
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 6.0122476056132345e-05
1521, epoch_train_loss=6.0122476056132345e-05
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 6.006781068607368e-05
1522, epoch_train_loss=6.006781068607368e-05
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 6.001540546029287e-05
1523, epoch_train_loss=6.001540546029287e-05
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 5.996677681757177e-05
1524, epoch_train_loss=5.996677681757177e-05
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 5.992466323632061e-05
1525, epoch_train_loss=5.992466323632061e-05
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 5.98938812589243e-05
1526, epoch_train_loss=5.98938812589243e-05
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 5.988325874571642e-05
1527, epoch_train_loss=5.988325874571642e-05
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 5.990851651979892e-05
1528, epoch_train_loss=5.990851651979892e-05
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 5.9999043348706256e-05
1529, epoch_train_loss=5.9999043348706256e-05
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 6.020753618299479e-05
1530, epoch_train_loss=6.020753618299479e-05
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 6.063507907539987e-05
1531, epoch_train_loss=6.063507907539987e-05
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 6.146274363626344e-05
1532, epoch_train_loss=6.146274363626344e-05
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 6.305025161202675e-05
1533, epoch_train_loss=6.305025161202675e-05
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 6.603302740536535e-05
1534, epoch_train_loss=6.603302740536535e-05
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 7.17394068555954e-05
1535, epoch_train_loss=7.17394068555954e-05
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 8.243028830595086e-05
1536, epoch_train_loss=8.243028830595086e-05
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.00010322237887161173
1537, epoch_train_loss=0.00010322237887161173
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.00014214748076313982
1538, epoch_train_loss=0.00014214748076313982
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0002199314822353178
1539, epoch_train_loss=0.0002199314822353178
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.0003639971960932593
1540, epoch_train_loss=0.0003639971960932593
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.0006634085075175192
1541, epoch_train_loss=0.0006634085075175192
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.001197611115253199
1542, epoch_train_loss=0.001197611115253199
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.002371889279362385
1543, epoch_train_loss=0.002371889279362385
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0042566907948890205
1544, epoch_train_loss=0.0042566907948890205
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.008709298474873907
1545, epoch_train_loss=0.008709298474873907
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.013912517068106924
1546, epoch_train_loss=0.013912517068106924
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.026974117628723912
1547, epoch_train_loss=0.026974117628723912
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.03001237260321003
1548, epoch_train_loss=0.03001237260321003
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.040437238263696294
1549, epoch_train_loss=0.040437238263696294
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.02059906850903694
1550, epoch_train_loss=0.02059906850903694
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.006006419549307954
1551, epoch_train_loss=0.006006419549307954
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.001369615674996801
1552, epoch_train_loss=0.001369615674996801
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.00880223184994787
1553, epoch_train_loss=0.00880223184994787
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0189781834151267
1554, epoch_train_loss=0.0189781834151267
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.013160559714050332
1555, epoch_train_loss=0.013160559714050332
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.004598292404089893
1556, epoch_train_loss=0.004598292404089893
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0015538355583038569
1557, epoch_train_loss=0.0015538355583038569
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.005480354443018973
1558, epoch_train_loss=0.005480354443018973
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.009423527303878345
1559, epoch_train_loss=0.009423527303878345
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.005826670240840223
1560, epoch_train_loss=0.005826670240840223
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0015028544738160809
1561, epoch_train_loss=0.0015028544738160809
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.0021327230468174115
1562, epoch_train_loss=0.0021327230468174115
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.004662561851393794
1563, epoch_train_loss=0.004662561851393794
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.004467644534239166
1564, epoch_train_loss=0.004467644534239166
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.0014936585318066986
1565, epoch_train_loss=0.0014936585318066986
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0008766502731872614
1566, epoch_train_loss=0.0008766502731872614
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.003195081979369108
1567, epoch_train_loss=0.003195081979369108
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0033328759235525186
1568, epoch_train_loss=0.0033328759235525186
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.000862321484243586
1569, epoch_train_loss=0.000862321484243586
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0005302739137891005
1570, epoch_train_loss=0.0005302739137891005
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.002193580720303329
1571, epoch_train_loss=0.002193580720303329
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.001992923930913878
1572, epoch_train_loss=0.001992923930913878
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.0006438697257423571
1573, epoch_train_loss=0.0006438697257423571
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.0006213087599045733
1574, epoch_train_loss=0.0006213087599045733
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0011839313441039155
1575, epoch_train_loss=0.0011839313441039155
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0012400218108403645
1576, epoch_train_loss=0.0012400218108403645
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0008200412189582265
1577, epoch_train_loss=0.0008200412189582265
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.00029010770658018743
1578, epoch_train_loss=0.00029010770658018743
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.0005652199608751979
1579, epoch_train_loss=0.0005652199608751979
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.001071729283047596
1580, epoch_train_loss=0.001071729283047596
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.0006387523356546325
1581, epoch_train_loss=0.0006387523356546325
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.00017669641423657118
1582, epoch_train_loss=0.00017669641423657118
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0004038293662809486
1583, epoch_train_loss=0.0004038293662809486
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.000632494093982801
1584, epoch_train_loss=0.000632494093982801
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.0005231309146569081
1585, epoch_train_loss=0.0005231309146569081
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.00027481682748611516
1586, epoch_train_loss=0.00027481682748611516
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.00019206041669911177
1587, epoch_train_loss=0.00019206041669911177
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.0003895170481154161
1588, epoch_train_loss=0.0003895170481154161
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0004664621109852745
1589, epoch_train_loss=0.0004664621109852745
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.00023884965708840855
1590, epoch_train_loss=0.00023884965708840855
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.0001295788052701091
1591, epoch_train_loss=0.0001295788052701091
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.00025940226491989195
1592, epoch_train_loss=0.00025940226491989195
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.00032394326047550844
1593, epoch_train_loss=0.00032394326047550844
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.00025039768640461947
1594, epoch_train_loss=0.00025039768640461947
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.00015157532396481543
1595, epoch_train_loss=0.00015157532396481543
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.00013338753449697506
1596, epoch_train_loss=0.00013338753449697506
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.00022228533935244698
1597, epoch_train_loss=0.00022228533935244698
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.00024211163256654102
1598, epoch_train_loss=0.00024211163256654102
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.00014487037597268404
1599, epoch_train_loss=0.00014487037597268404
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.00011049542603411675
1600, epoch_train_loss=0.00011049542603411675
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.0001534485610867516
1601, epoch_train_loss=0.0001534485610867516
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.00017706170788008298
1602, epoch_train_loss=0.00017706170788008298
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.00016229542007865043
1603, epoch_train_loss=0.00016229542007865043
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.00011785071997553017
1604, epoch_train_loss=0.00011785071997553017
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 9.986373207394418e-05
1605, epoch_train_loss=9.986373207394418e-05
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.0001347218361200007
1606, epoch_train_loss=0.0001347218361200007
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.00014849262510946575
1607, epoch_train_loss=0.00014849262510946575
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.00011839570398512485
1608, epoch_train_loss=0.00011839570398512485
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 9.783751146111633e-05
1609, epoch_train_loss=9.783751146111633e-05
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.00010073742964871623
1610, epoch_train_loss=0.00010073742964871623
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.00011339075695524807
1611, epoch_train_loss=0.00011339075695524807
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.00012030705209112637
1612, epoch_train_loss=0.00012030705209112637
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0001040320710860798
1613, epoch_train_loss=0.0001040320710860798
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 8.612216317836424e-05
1614, epoch_train_loss=8.612216317836424e-05
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 9.272132478933804e-05
1615, epoch_train_loss=9.272132478933804e-05
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.00010329750689116444
1616, epoch_train_loss=0.00010329750689116444
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.00010087834270808868
1617, epoch_train_loss=0.00010087834270808868
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 9.275288640800095e-05
1618, epoch_train_loss=9.275288640800095e-05
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 8.43110786681196e-05
1619, epoch_train_loss=8.43110786681196e-05
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 8.436537305944007e-05
1620, epoch_train_loss=8.436537305944007e-05
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 9.224006719670832e-05
1621, epoch_train_loss=9.224006719670832e-05
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 9.246018745495013e-05
1622, epoch_train_loss=9.246018745495013e-05
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 8.512452917437779e-05
1623, epoch_train_loss=8.512452917437779e-05
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 8.104584055918971e-05
1624, epoch_train_loss=8.104584055918971e-05
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 8.100273026222228e-05
1625, epoch_train_loss=8.100273026222228e-05
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 8.331184977250605e-05
1626, epoch_train_loss=8.331184977250605e-05
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 8.53481384832498e-05
1627, epoch_train_loss=8.53481384832498e-05
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 8.224735152044514e-05
1628, epoch_train_loss=8.224735152044514e-05
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 7.760028966053669e-05
1629, epoch_train_loss=7.760028966053669e-05
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 7.73374652839268e-05
1630, epoch_train_loss=7.73374652839268e-05
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 7.898366283453433e-05
1631, epoch_train_loss=7.898366283453433e-05
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 7.958451521139742e-05
1632, epoch_train_loss=7.958451521139742e-05
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 7.889612262601665e-05
1633, epoch_train_loss=7.889612262601665e-05
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 7.643391793267755e-05
1634, epoch_train_loss=7.643391793267755e-05
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 7.456112074148747e-05
1635, epoch_train_loss=7.456112074148747e-05
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 7.52572149983089e-05
1636, epoch_train_loss=7.52572149983089e-05
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 7.617011351218897e-05
1637, epoch_train_loss=7.617011351218897e-05
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 7.576172536839611e-05
1638, epoch_train_loss=7.576172536839611e-05
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 7.476788892783862e-05
1639, epoch_train_loss=7.476788892783862e-05
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 7.346349663468314e-05
1640, epoch_train_loss=7.346349663468314e-05
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 7.271907482222118e-05
1641, epoch_train_loss=7.271907482222118e-05
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 7.322110001099978e-05
1642, epoch_train_loss=7.322110001099978e-05
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 7.358948296603135e-05
1643, epoch_train_loss=7.358948296603135e-05
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 7.300437064465397e-05
1644, epoch_train_loss=7.300437064465397e-05
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 7.222537635682915e-05
1645, epoch_train_loss=7.222537635682915e-05
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 7.157200026363437e-05
1646, epoch_train_loss=7.157200026363437e-05
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 7.122148653578199e-05
1647, epoch_train_loss=7.122148653578199e-05
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 7.14005302209429e-05
1648, epoch_train_loss=7.14005302209429e-05
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 7.148650001060065e-05
1649, epoch_train_loss=7.148650001060065e-05
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 7.104879225781275e-05
1650, epoch_train_loss=7.104879225781275e-05
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 7.050948247008523e-05
1651, epoch_train_loss=7.050948247008523e-05
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 7.010341331543985e-05
1652, epoch_train_loss=7.010341331543985e-05
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 6.984622367813988e-05
1653, epoch_train_loss=6.984622367813988e-05
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 6.984640813385226e-05
1654, epoch_train_loss=6.984640813385226e-05
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 6.983952371022171e-05
1655, epoch_train_loss=6.983952371022171e-05
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 6.954600071802891e-05
1656, epoch_train_loss=6.954600071802891e-05
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 6.917067492743422e-05
1657, epoch_train_loss=6.917067492743422e-05
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 6.888003279197514e-05
1658, epoch_train_loss=6.888003279197514e-05
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 6.865132389282707e-05
1659, epoch_train_loss=6.865132389282707e-05
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 6.854563197802861e-05
1660, epoch_train_loss=6.854563197802861e-05
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 6.849354344891538e-05
1661, epoch_train_loss=6.849354344891538e-05
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 6.831425219874715e-05
1662, epoch_train_loss=6.831425219874715e-05
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 6.804998150101238e-05
1663, epoch_train_loss=6.804998150101238e-05
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 6.781489944175362e-05
1664, epoch_train_loss=6.781489944175362e-05
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 6.760876316662051e-05
1665, epoch_train_loss=6.760876316662051e-05
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 6.74584789903883e-05
1666, epoch_train_loss=6.74584789903883e-05
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 6.736760891809786e-05
1667, epoch_train_loss=6.736760891809786e-05
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 6.724331297495812e-05
1668, epoch_train_loss=6.724331297495812e-05
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 6.706233478826161e-05
1669, epoch_train_loss=6.706233478826161e-05
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 6.687560611587575e-05
1670, epoch_train_loss=6.687560611587575e-05
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 6.669216834569106e-05
1671, epoch_train_loss=6.669216834569106e-05
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 6.652655920565783e-05
1672, epoch_train_loss=6.652655920565783e-05
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 6.640589293453587e-05
1673, epoch_train_loss=6.640589293453587e-05
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 6.629642581622369e-05
1674, epoch_train_loss=6.629642581622369e-05
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 6.616248276269968e-05
1675, epoch_train_loss=6.616248276269968e-05
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 6.601782666564162e-05
1676, epoch_train_loss=6.601782666564162e-05
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 6.58674486812578e-05
1677, epoch_train_loss=6.58674486812578e-05
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 6.571143157467683e-05
1678, epoch_train_loss=6.571143157467683e-05
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 6.557340606486727e-05
1679, epoch_train_loss=6.557340606486727e-05
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 6.545707712742538e-05
1680, epoch_train_loss=6.545707712742538e-05
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 6.534115494434645e-05
1681, epoch_train_loss=6.534115494434645e-05
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 6.522153676487669e-05
1682, epoch_train_loss=6.522153676487669e-05
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 6.51000572958213e-05
1683, epoch_train_loss=6.51000572958213e-05
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 6.496974211295188e-05
1684, epoch_train_loss=6.496974211295188e-05
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 6.483723771668949e-05
1685, epoch_train_loss=6.483723771668949e-05
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 6.471461526117198e-05
1686, epoch_train_loss=6.471461526117198e-05
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 6.459912165213405e-05
1687, epoch_train_loss=6.459912165213405e-05
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 6.448681578600889e-05
1688, epoch_train_loss=6.448681578600889e-05
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 6.437875396284212e-05
1689, epoch_train_loss=6.437875396284212e-05
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 6.426974921998312e-05
1690, epoch_train_loss=6.426974921998312e-05
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 6.415586041442001e-05
1691, epoch_train_loss=6.415586041442001e-05
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 6.404176538435872e-05
1692, epoch_train_loss=6.404176538435872e-05
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 6.392982124224819e-05
1693, epoch_train_loss=6.392982124224819e-05
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 6.381928102545964e-05
1694, epoch_train_loss=6.381928102545964e-05
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 6.371266249447687e-05
1695, epoch_train_loss=6.371266249447687e-05
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 6.361037105151656e-05
1696, epoch_train_loss=6.361037105151656e-05
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 6.350872747428448e-05
1697, epoch_train_loss=6.350872747428448e-05
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 6.340687289023897e-05
1698, epoch_train_loss=6.340687289023897e-05
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 6.330569615799104e-05
1699, epoch_train_loss=6.330569615799104e-05
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 6.32039582831398e-05
1700, epoch_train_loss=6.32039582831398e-05
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 6.310198509693212e-05
1701, epoch_train_loss=6.310198509693212e-05
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 6.300197153128541e-05
1702, epoch_train_loss=6.300197153128541e-05
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 6.290396266621763e-05
1703, epoch_train_loss=6.290396266621763e-05
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 6.280715730702835e-05
1704, epoch_train_loss=6.280715730702835e-05
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 6.271211473619898e-05
1705, epoch_train_loss=6.271211473619898e-05
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 6.261852091689087e-05
1706, epoch_train_loss=6.261852091689087e-05
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 6.252510513090106e-05
1707, epoch_train_loss=6.252510513090106e-05
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 6.243195906352036e-05
1708, epoch_train_loss=6.243195906352036e-05
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 6.233955034888269e-05
1709, epoch_train_loss=6.233955034888269e-05
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 6.224754702803663e-05
1710, epoch_train_loss=6.224754702803663e-05
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 6.215608220639109e-05
1711, epoch_train_loss=6.215608220639109e-05
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 6.206582130647703e-05
1712, epoch_train_loss=6.206582130647703e-05
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 6.19766677914663e-05
1713, epoch_train_loss=6.19766677914663e-05
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 6.188832875266069e-05
1714, epoch_train_loss=6.188832875266069e-05
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 6.180098318325468e-05
1715, epoch_train_loss=6.180098318325468e-05
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 6.171453441904762e-05
1716, epoch_train_loss=6.171453441904762e-05
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 6.162859574986868e-05
1717, epoch_train_loss=6.162859574986868e-05
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 6.154317737705577e-05
1718, epoch_train_loss=6.154317737705577e-05
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 6.145840621413158e-05
1719, epoch_train_loss=6.145840621413158e-05
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 6.13741261702788e-05
1720, epoch_train_loss=6.13741261702788e-05
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 6.129035040387581e-05
1721, epoch_train_loss=6.129035040387581e-05
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 6.120726704421936e-05
1722, epoch_train_loss=6.120726704421936e-05
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 6.11248605169285e-05
1723, epoch_train_loss=6.11248605169285e-05
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 6.104305191012021e-05
1724, epoch_train_loss=6.104305191012021e-05
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 6.096192869280128e-05
1725, epoch_train_loss=6.096192869280128e-05
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 6.0881493034380184e-05
1726, epoch_train_loss=6.0881493034380184e-05
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 6.0801623308051165e-05
1727, epoch_train_loss=6.0801623308051165e-05
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 6.072230921552945e-05
1728, epoch_train_loss=6.072230921552945e-05
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 6.064357693510333e-05
1729, epoch_train_loss=6.064357693510333e-05
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 6.056535377656721e-05
1730, epoch_train_loss=6.056535377656721e-05
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 6.0487594208565346e-05
1731, epoch_train_loss=6.0487594208565346e-05
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 6.041034340877675e-05
1732, epoch_train_loss=6.041034340877675e-05
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 6.0333586610741624e-05
1733, epoch_train_loss=6.0333586610741624e-05
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 6.0257282815869705e-05
1734, epoch_train_loss=6.0257282815869705e-05
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 6.0181451727304995e-05
1735, epoch_train_loss=6.0181451727304995e-05
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 6.010611619443269e-05
1736, epoch_train_loss=6.010611619443269e-05
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 6.0031240385340765e-05
1737, epoch_train_loss=6.0031240385340765e-05
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 5.9956816908659966e-05
1738, epoch_train_loss=5.9956816908659966e-05
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 5.988286416999436e-05
1739, epoch_train_loss=5.988286416999436e-05
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 5.9809368033093085e-05
1740, epoch_train_loss=5.9809368033093085e-05
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 5.9736301341454765e-05
1741, epoch_train_loss=5.9736301341454765e-05
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 5.966367041262573e-05
1742, epoch_train_loss=5.966367041262573e-05
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 5.9591474777752614e-05
1743, epoch_train_loss=5.9591474777752614e-05
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 5.9519690784942184e-05
1744, epoch_train_loss=5.9519690784942184e-05
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 5.9448309381705846e-05
1745, epoch_train_loss=5.9448309381705846e-05
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 5.937733543743468e-05
1746, epoch_train_loss=5.937733543743468e-05
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 5.930675734879083e-05
1747, epoch_train_loss=5.930675734879083e-05
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 5.9236559081418544e-05
1748, epoch_train_loss=5.9236559081418544e-05
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 5.916674207684767e-05
1749, epoch_train_loss=5.916674207684767e-05
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 5.909730341023056e-05
1750, epoch_train_loss=5.909730341023056e-05
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 5.9028230758306016e-05
1751, epoch_train_loss=5.9028230758306016e-05
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 5.895951743348082e-05
1752, epoch_train_loss=5.895951743348082e-05
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 5.889116546436417e-05
1753, epoch_train_loss=5.889116546436417e-05
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 5.882316695849469e-05
1754, epoch_train_loss=5.882316695849469e-05
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 5.8755514913768676e-05
1755, epoch_train_loss=5.8755514913768676e-05
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 5.86882073634009e-05
1756, epoch_train_loss=5.86882073634009e-05
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 5.862124544480553e-05
1757, epoch_train_loss=5.862124544480553e-05
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 5.85546224925812e-05
1758, epoch_train_loss=5.85546224925812e-05
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 5.848833960910556e-05
1759, epoch_train_loss=5.848833960910556e-05
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 5.842239970293216e-05
1760, epoch_train_loss=5.842239970293216e-05
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 5.835680999527583e-05
1761, epoch_train_loss=5.835680999527583e-05
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 5.829157550267496e-05
1762, epoch_train_loss=5.829157550267496e-05
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 5.8226717683843725e-05
1763, epoch_train_loss=5.8226717683843725e-05
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 5.816226192867944e-05
1764, epoch_train_loss=5.816226192867944e-05
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 5.8098254956675074e-05
1765, epoch_train_loss=5.8098254956675074e-05
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 5.803475977438262e-05
1766, epoch_train_loss=5.803475977438262e-05
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 5.7971890856834256e-05
1767, epoch_train_loss=5.7971890856834256e-05
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 5.7909808179409474e-05
1768, epoch_train_loss=5.7909808179409474e-05
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 5.7848782016515785e-05
1769, epoch_train_loss=5.7848782016515785e-05
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 5.778921326289196e-05
1770, epoch_train_loss=5.778921326289196e-05
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 5.773177264019833e-05
1771, epoch_train_loss=5.773177264019833e-05
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 5.767748106194236e-05
1772, epoch_train_loss=5.767748106194236e-05
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 5.7628047823668024e-05
1773, epoch_train_loss=5.7628047823668024e-05
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 5.758614067718407e-05
1774, epoch_train_loss=5.758614067718407e-05
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 5.755627764880836e-05
1775, epoch_train_loss=5.755627764880836e-05
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 5.754561530627829e-05
1776, epoch_train_loss=5.754561530627829e-05
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 5.756651102129352e-05
1777, epoch_train_loss=5.756651102129352e-05
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 5.7638711073437354e-05
1778, epoch_train_loss=5.7638711073437354e-05
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 5.779721215860287e-05
1779, epoch_train_loss=5.779721215860287e-05
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 5.809797036929676e-05
1780, epoch_train_loss=5.809797036929676e-05
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 5.864367079785709e-05
1781, epoch_train_loss=5.864367079785709e-05
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 5.9596794952796756e-05
1782, epoch_train_loss=5.9596794952796756e-05
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 6.126998116350117e-05
1783, epoch_train_loss=6.126998116350117e-05
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 6.414452988015042e-05
1784, epoch_train_loss=6.414452988015042e-05
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 6.921096519646852e-05
1785, epoch_train_loss=6.921096519646852e-05
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 7.79117498595738e-05
1786, epoch_train_loss=7.79117498595738e-05
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 9.352761757747106e-05
1787, epoch_train_loss=9.352761757747106e-05
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.00012035949412371955
1788, epoch_train_loss=0.00012035949412371955
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.00016983998065130113
1789, epoch_train_loss=0.00016983998065130113
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0002542335463441097
1790, epoch_train_loss=0.0002542335463441097
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0004157341737730535
1791, epoch_train_loss=0.0004157341737730535
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0006839393120865253
1792, epoch_train_loss=0.0006839393120865253
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.001223839095938485
1793, epoch_train_loss=0.001223839095938485
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.002059708424885757
1794, epoch_train_loss=0.002059708424885757
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.003859050879398834
1795, epoch_train_loss=0.003859050879398834
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.006184784286541562
1796, epoch_train_loss=0.006184784286541562
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.011593001811212908
1797, epoch_train_loss=0.011593001811212908
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.01563144022710497
1798, epoch_train_loss=0.01563144022710497
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.02587505716183607
1799, epoch_train_loss=0.02587505716183607
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.022838685806362693
1800, epoch_train_loss=0.022838685806362693
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.022575925879162618
1801, epoch_train_loss=0.022575925879162618
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.008736879363394491
1802, epoch_train_loss=0.008736879363394491
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.001078207049424212
1803, epoch_train_loss=0.001078207049424212
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.0019601673863327636
1804, epoch_train_loss=0.0019601673863327636
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.007869387480016409
1805, epoch_train_loss=0.007869387480016409
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.013273717026266682
1806, epoch_train_loss=0.013273717026266682
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.00830799989607549
1807, epoch_train_loss=0.00830799989607549
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0025920193436504146
1808, epoch_train_loss=0.0025920193436504146
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.00048072439295717394
1809, epoch_train_loss=0.00048072439295717394
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.003489516959044966
1810, epoch_train_loss=0.003489516959044966
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.006960145814308566
1811, epoch_train_loss=0.006960145814308566
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.00482450249271516
1812, epoch_train_loss=0.00482450249271516
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.0014073290599394925
1813, epoch_train_loss=0.0014073290599394925
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.00039908652712354386
1814, epoch_train_loss=0.00039908652712354386
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.002359769667864981
1815, epoch_train_loss=0.002359769667864981
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.003922194985822232
1816, epoch_train_loss=0.003922194985822232
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.002282742408995254
1817, epoch_train_loss=0.002282742408995254
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0004552891521794538
1818, epoch_train_loss=0.0004552891521794538
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0006636024209154966
1819, epoch_train_loss=0.0006636024209154966
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0019438029983512434
1820, epoch_train_loss=0.0019438029983512434
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0022446841908770675
1821, epoch_train_loss=0.0022446841908770675
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0009877929704716327
1822, epoch_train_loss=0.0009877929704716327
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.00019864137905187723
1823, epoch_train_loss=0.00019864137905187723
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.0007498864519794135
1824, epoch_train_loss=0.0007498864519794135
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0014211876989930548
1825, epoch_train_loss=0.0014211876989930548
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.001161966362002099
1826, epoch_train_loss=0.001161966362002099
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.00035628700663878273
1827, epoch_train_loss=0.00035628700663878273
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.00019560784356956981
1828, epoch_train_loss=0.00019560784356956981
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007098591643749465
1829, epoch_train_loss=0.0007098591643749465
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.0009586288446193528
1830, epoch_train_loss=0.0009586288446193528
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0006035591461622039
1831, epoch_train_loss=0.0006035591461622039
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.0001751483048288947
1832, epoch_train_loss=0.0001751483048288947
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.00023751359521159715
1833, epoch_train_loss=0.00023751359521159715
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0005463599921290077
1834, epoch_train_loss=0.0005463599921290077
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.0005802385553614738
1835, epoch_train_loss=0.0005802385553614738
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.00033793595398505245
1836, epoch_train_loss=0.00033793595398505245
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.00014293455367359186
1837, epoch_train_loss=0.00014293455367359186
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.00020761401037664866
1838, epoch_train_loss=0.00020761401037664866
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0003693666159595837
1839, epoch_train_loss=0.0003693666159595837
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.00037428061962778506
1840, epoch_train_loss=0.00037428061962778506
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0002307201505239008
1841, epoch_train_loss=0.0002307201505239008
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.0001120085965240024
1842, epoch_train_loss=0.0001120085965240024
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.00015241656693758656
1843, epoch_train_loss=0.00015241656693758656
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.00026179356687264677
1844, epoch_train_loss=0.00026179356687264677
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.00026839986711376155
1845, epoch_train_loss=0.00026839986711376155
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.000171063243691142
1846, epoch_train_loss=0.000171063243691142
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 9.392396551779744e-05
1847, epoch_train_loss=9.392396551779744e-05
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.00012298494195056182
1848, epoch_train_loss=0.00012298494195056182
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.00019065174330754316
1849, epoch_train_loss=0.00019065174330754316
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.00019329471769757758
1850, epoch_train_loss=0.00019329471769757758
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.00013777048146595646
1851, epoch_train_loss=0.00013777048146595646
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 9.252830854560392e-05
1852, epoch_train_loss=9.252830854560392e-05
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.00010060945490782407
1853, epoch_train_loss=0.00010060945490782407
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.00013460285732494874
1854, epoch_train_loss=0.00013460285732494874
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.00014520754135284206
1855, epoch_train_loss=0.00014520754135284206
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.00012241366845406392
1856, epoch_train_loss=0.00012241366845406392
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 9.080781247052888e-05
1857, epoch_train_loss=9.080781247052888e-05
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 8.252193726720206e-05
1858, epoch_train_loss=8.252193726720206e-05
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.00010034378393974888
1859, epoch_train_loss=0.00010034378393974888
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.00011672368416785674
1860, epoch_train_loss=0.00011672368416785674
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.00011005494184649388
1861, epoch_train_loss=0.00011005494184649388
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 8.812213198568105e-05
1862, epoch_train_loss=8.812213198568105e-05
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 7.589496045149618e-05
1863, epoch_train_loss=7.589496045149618e-05
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 8.217149984564236e-05
1864, epoch_train_loss=8.217149984564236e-05
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 9.360814425976531e-05
1865, epoch_train_loss=9.360814425976531e-05
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 9.559257414320809e-05
1866, epoch_train_loss=9.559257414320809e-05
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 8.706903517263349e-05
1867, epoch_train_loss=8.706903517263349e-05
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 7.71793967821971e-05
1868, epoch_train_loss=7.71793967821971e-05
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 7.347196927504795e-05
1869, epoch_train_loss=7.347196927504795e-05
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 7.718983539892149e-05
1870, epoch_train_loss=7.718983539892149e-05
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 8.28370982933164e-05
1871, epoch_train_loss=8.28370982933164e-05
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 8.336447596742399e-05
1872, epoch_train_loss=8.336447596742399e-05
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 7.777348846455686e-05
1873, epoch_train_loss=7.777348846455686e-05
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 7.144637937101241e-05
1874, epoch_train_loss=7.144637937101241e-05
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 7.005129552676568e-05
1875, epoch_train_loss=7.005129552676568e-05
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 7.296083853466997e-05
1876, epoch_train_loss=7.296083853466997e-05
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 7.556669048652832e-05
1877, epoch_train_loss=7.556669048652832e-05
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 7.514220266737021e-05
1878, epoch_train_loss=7.514220266737021e-05
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 7.223940622265371e-05
1879, epoch_train_loss=7.223940622265371e-05
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 6.919741864927842e-05
1880, epoch_train_loss=6.919741864927842e-05
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 6.787090678599258e-05
1881, epoch_train_loss=6.787090678599258e-05
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 6.8654132176669e-05
1882, epoch_train_loss=6.8654132176669e-05
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 7.022862207082522e-05
1883, epoch_train_loss=7.022862207082522e-05
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 7.061022825263233e-05
1884, epoch_train_loss=7.061022825263233e-05
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 6.919736571168993e-05
1885, epoch_train_loss=6.919736571168993e-05
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 6.71828580361624e-05
1886, epoch_train_loss=6.71828580361624e-05
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 6.606531846579415e-05
1887, epoch_train_loss=6.606531846579415e-05
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 6.618499587006446e-05
1888, epoch_train_loss=6.618499587006446e-05
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 6.684212092539758e-05
1889, epoch_train_loss=6.684212092539758e-05
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 6.718782833524689e-05
1890, epoch_train_loss=6.718782833524689e-05
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 6.683207040979835e-05
1891, epoch_train_loss=6.683207040979835e-05
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 6.593272533588541e-05
1892, epoch_train_loss=6.593272533588541e-05
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 6.496809425769935e-05
1893, epoch_train_loss=6.496809425769935e-05
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 6.445915943077114e-05
1894, epoch_train_loss=6.445915943077114e-05
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 6.452900007050574e-05
1895, epoch_train_loss=6.452900007050574e-05
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 6.483006066700679e-05
1896, epoch_train_loss=6.483006066700679e-05
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 6.490062912726148e-05
1897, epoch_train_loss=6.490062912726148e-05
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 6.455863932612663e-05
1898, epoch_train_loss=6.455863932612663e-05
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 6.399844928689119e-05
1899, epoch_train_loss=6.399844928689119e-05
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 6.349633944385756e-05
1900, epoch_train_loss=6.349633944385756e-05
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 6.320102608179129e-05
1901, epoch_train_loss=6.320102608179129e-05
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 6.312279522994739e-05
1902, epoch_train_loss=6.312279522994739e-05
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 6.316886252983071e-05
1903, epoch_train_loss=6.316886252983071e-05
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 6.31772729384718e-05
1904, epoch_train_loss=6.31772729384718e-05
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 6.301433639489087e-05
1905, epoch_train_loss=6.301433639489087e-05
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 6.269341277013813e-05
1906, epoch_train_loss=6.269341277013813e-05
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 6.235194711232173e-05
1907, epoch_train_loss=6.235194711232173e-05
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 6.210791869590691e-05
1908, epoch_train_loss=6.210791869590691e-05
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 6.197329691381952e-05
1909, epoch_train_loss=6.197329691381952e-05
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 6.190572532044995e-05
1910, epoch_train_loss=6.190572532044995e-05
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 6.185581290371627e-05
1911, epoch_train_loss=6.185581290371627e-05
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 6.177189178786698e-05
1912, epoch_train_loss=6.177189178786698e-05
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 6.161999357250841e-05
1913, epoch_train_loss=6.161999357250841e-05
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 6.141115376276302e-05
1914, epoch_train_loss=6.141115376276302e-05
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 6.119936968983602e-05
1915, epoch_train_loss=6.119936968983602e-05
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 6.102955031485536e-05
1916, epoch_train_loss=6.102955031485536e-05
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 6.090825957994864e-05
1917, epoch_train_loss=6.090825957994864e-05
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 6.081783265040658e-05
1918, epoch_train_loss=6.081783265040658e-05
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 6.073606282485775e-05
1919, epoch_train_loss=6.073606282485775e-05
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 6.064435791738256e-05
1920, epoch_train_loss=6.064435791738256e-05
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 6.053031037871238e-05
1921, epoch_train_loss=6.053031037871238e-05
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 6.0392674095055946e-05
1922, epoch_train_loss=6.0392674095055946e-05
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 6.024406842811846e-05
1923, epoch_train_loss=6.024406842811846e-05
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 6.010387899345251e-05
1924, epoch_train_loss=6.010387899345251e-05
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 5.998296345982081e-05
1925, epoch_train_loss=5.998296345982081e-05
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 5.987957149903752e-05
1926, epoch_train_loss=5.987957149903752e-05
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 5.978578410006202e-05
1927, epoch_train_loss=5.978578410006202e-05
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 5.969522998818705e-05
1928, epoch_train_loss=5.969522998818705e-05
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 5.9603034753252825e-05
1929, epoch_train_loss=5.9603034753252825e-05
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 5.950335465439319e-05
1930, epoch_train_loss=5.950335465439319e-05
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 5.9394528196002786e-05
1931, epoch_train_loss=5.9394528196002786e-05
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 5.92813843918043e-05
1932, epoch_train_loss=5.92813843918043e-05
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 5.917058577993044e-05
1933, epoch_train_loss=5.917058577993044e-05
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 5.906524689478346e-05
1934, epoch_train_loss=5.906524689478346e-05
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 5.896547820640703e-05
1935, epoch_train_loss=5.896547820640703e-05
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 5.887100386818433e-05
1936, epoch_train_loss=5.887100386818433e-05
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 5.878118382543891e-05
1937, epoch_train_loss=5.878118382543891e-05
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 5.8693647228525395e-05
1938, epoch_train_loss=5.8693647228525395e-05
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 5.860548827631535e-05
1939, epoch_train_loss=5.860548827631535e-05
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 5.851526606030274e-05
1940, epoch_train_loss=5.851526606030274e-05
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 5.842313572284307e-05
1941, epoch_train_loss=5.842313572284307e-05
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 5.833023784822638e-05
1942, epoch_train_loss=5.833023784822638e-05
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 5.8237401946238376e-05
1943, epoch_train_loss=5.8237401946238376e-05
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 5.8145238474606246e-05
1944, epoch_train_loss=5.8145238474606246e-05
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 5.8054526904270476e-05
1945, epoch_train_loss=5.8054526904270476e-05
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 5.796609069846433e-05
1946, epoch_train_loss=5.796609069846433e-05
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 5.78800632288881e-05
1947, epoch_train_loss=5.78800632288881e-05
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 5.7795770551901106e-05
1948, epoch_train_loss=5.7795770551901106e-05
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 5.771250539700865e-05
1949, epoch_train_loss=5.771250539700865e-05
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 5.7630069635894756e-05
1950, epoch_train_loss=5.7630069635894756e-05
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 5.7548316030766754e-05
1951, epoch_train_loss=5.7548316030766754e-05
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 5.746680080174738e-05
1952, epoch_train_loss=5.746680080174738e-05
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 5.738523882977508e-05
1953, epoch_train_loss=5.738523882977508e-05
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 5.730368307219704e-05
1954, epoch_train_loss=5.730368307219704e-05
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 5.722241454006962e-05
1955, epoch_train_loss=5.722241454006962e-05
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 5.7141562215508185e-05
1956, epoch_train_loss=5.7141562215508185e-05
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 5.706116423020148e-05
1957, epoch_train_loss=5.706116423020148e-05
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 5.698126918286844e-05
1958, epoch_train_loss=5.698126918286844e-05
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 5.6902011174210176e-05
1959, epoch_train_loss=5.6902011174210176e-05
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 5.682349999772342e-05
1960, epoch_train_loss=5.682349999772342e-05
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 5.6745754950315065e-05
1961, epoch_train_loss=5.6745754950315065e-05
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 5.666866436128723e-05
1962, epoch_train_loss=5.666866436128723e-05
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 5.659216571034527e-05
1963, epoch_train_loss=5.659216571034527e-05
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 5.651628131565701e-05
1964, epoch_train_loss=5.651628131565701e-05
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 5.6441011164794475e-05
1965, epoch_train_loss=5.6441011164794475e-05
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 5.6366278886391786e-05
1966, epoch_train_loss=5.6366278886391786e-05
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 5.629199900842682e-05
1967, epoch_train_loss=5.629199900842682e-05
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 5.621816542264689e-05
1968, epoch_train_loss=5.621816542264689e-05
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 5.614479453244361e-05
1969, epoch_train_loss=5.614479453244361e-05
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 5.607187518721233e-05
1970, epoch_train_loss=5.607187518721233e-05
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 5.59993713137401e-05
1971, epoch_train_loss=5.59993713137401e-05
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 5.592727146824657e-05
1972, epoch_train_loss=5.592727146824657e-05
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 5.585557478818049e-05
1973, epoch_train_loss=5.585557478818049e-05
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 5.578431057342817e-05
1974, epoch_train_loss=5.578431057342817e-05
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 5.5713481583502026e-05
1975, epoch_train_loss=5.5713481583502026e-05
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 5.56430921150978e-05
1976, epoch_train_loss=5.56430921150978e-05
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 5.5573140105797804e-05
1977, epoch_train_loss=5.5573140105797804e-05
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 5.550366903665974e-05
1978, epoch_train_loss=5.550366903665974e-05
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 5.543472007391073e-05
1979, epoch_train_loss=5.543472007391073e-05
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 5.536635231405983e-05
1980, epoch_train_loss=5.536635231405983e-05
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 5.529861675646905e-05
1981, epoch_train_loss=5.529861675646905e-05
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 5.5231636044485025e-05
1982, epoch_train_loss=5.5231636044485025e-05
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 5.516555663950874e-05
1983, epoch_train_loss=5.516555663950874e-05
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 5.510062851411931e-05
1984, epoch_train_loss=5.510062851411931e-05
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 5.503715749934874e-05
1985, epoch_train_loss=5.503715749934874e-05
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 5.497565238913127e-05
1986, epoch_train_loss=5.497565238913127e-05
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 5.491679236503812e-05
1987, epoch_train_loss=5.491679236503812e-05
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 5.486169409020755e-05
1988, epoch_train_loss=5.486169409020755e-05
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 5.4811895166262636e-05
1989, epoch_train_loss=5.4811895166262636e-05
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 5.476990579165922e-05
1990, epoch_train_loss=5.476990579165922e-05
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 5.473926264228009e-05
1991, epoch_train_loss=5.473926264228009e-05
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 5.472583943534914e-05
1992, epoch_train_loss=5.472583943534914e-05
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 5.4738043980038046e-05
1993, epoch_train_loss=5.4738043980038046e-05
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 5.479013019362183e-05
1994, epoch_train_loss=5.479013019362183e-05
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 5.4902604913842945e-05
1995, epoch_train_loss=5.4902604913842945e-05
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 5.511133640756692e-05
1996, epoch_train_loss=5.511133640756692e-05
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 5.546769987196677e-05
1997, epoch_train_loss=5.546769987196677e-05
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 5.606540805832711e-05
1998, epoch_train_loss=5.606540805832711e-05
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 5.7036285566903804e-05
1999, epoch_train_loss=5.7036285566903804e-05
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 5.86348153916673e-05
2000, epoch_train_loss=5.86348153916673e-05
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 6.120584223609792e-05
2001, epoch_train_loss=6.120584223609792e-05
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 6.54692928472936e-05
2002, epoch_train_loss=6.54692928472936e-05
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 7.233716330091833e-05
2003, epoch_train_loss=7.233716330091833e-05
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 8.393874724009214e-05
2004, epoch_train_loss=8.393874724009214e-05
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.00010267250133393787
2005, epoch_train_loss=0.00010267250133393787
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.00013515459161448571
2006, epoch_train_loss=0.00013515459161448571
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.00018742879300450474
2007, epoch_train_loss=0.00018742879300450474
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.00028119784752060113
2008, epoch_train_loss=0.00028119784752060113
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0004295567544458357
2009, epoch_train_loss=0.0004295567544458357
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007077538189754894
2010, epoch_train_loss=0.0007077538189754894
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0011284312548270616
2011, epoch_train_loss=0.0011284312548270616
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0019641881069669743
2012, epoch_train_loss=0.0019641881069669743
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.0030987775492755595
2013, epoch_train_loss=0.0030987775492755595
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.005518320029440655
2014, epoch_train_loss=0.005518320029440655
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.008024534913867993
2015, epoch_train_loss=0.008024534913867993
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.013791168157494746
2016, epoch_train_loss=0.013791168157494746
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.016155348958657622
2017, epoch_train_loss=0.016155348958657622
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.022740459981581067
2018, epoch_train_loss=0.022740459981581067
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.017132656941375203
2019, epoch_train_loss=0.017132656941375203
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.012750937231183269
2020, epoch_train_loss=0.012750937231183269
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.004144378854413588
2021, epoch_train_loss=0.004144378854413588
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0005599915238833922
2022, epoch_train_loss=0.0005599915238833922
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.002592635548165922
2023, epoch_train_loss=0.002592635548165922
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.006432561910339757
2024, epoch_train_loss=0.006432561910339757
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.00950008900969439
2025, epoch_train_loss=0.00950008900969439
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.006593591841356744
2026, epoch_train_loss=0.006593591841356744
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.002758657102208104
2027, epoch_train_loss=0.002758657102208104
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.0006876024971800573
2028, epoch_train_loss=0.0006876024971800573
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.0016956242846722235
2029, epoch_train_loss=0.0016956242846722235
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.004165254688218287
2030, epoch_train_loss=0.004165254688218287
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.004372523921183564
2031, epoch_train_loss=0.004372523921183564
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0026477058188121784
2032, epoch_train_loss=0.0026477058188121784
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0006786026002544527
2033, epoch_train_loss=0.0006786026002544527
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0005098179365914033
2034, epoch_train_loss=0.0005098179365914033
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.001917678697431855
2035, epoch_train_loss=0.001917678697431855
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0026727083920156593
2036, epoch_train_loss=0.0026727083920156593
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0018685339213460556
2037, epoch_train_loss=0.0018685339213460556
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.0004888633121385336
2038, epoch_train_loss=0.0004888633121385336
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.00020890767822988665
2039, epoch_train_loss=0.00020890767822988665
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0010297354637688193
2040, epoch_train_loss=0.0010297354637688193
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.0015502977053535687
2041, epoch_train_loss=0.0015502977053535687
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.001106841825543996
2042, epoch_train_loss=0.001106841825543996
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.00039692936307723047
2043, epoch_train_loss=0.00039692936307723047
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.00026968776318788134
2044, epoch_train_loss=0.00026968776318788134
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.0005312360624619485
2045, epoch_train_loss=0.0005312360624619485
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007769785515625045
2046, epoch_train_loss=0.0007769785515625045
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.0008195917801433857
2047, epoch_train_loss=0.0008195917801433857
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.000523846433430797
2048, epoch_train_loss=0.000523846433430797
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.0001975837413779013
2049, epoch_train_loss=0.0001975837413779013
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.00016242258129726047
2050, epoch_train_loss=0.00016242258129726047
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.00043149088433555675
2051, epoch_train_loss=0.00043149088433555675
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0006011808792244983
2052, epoch_train_loss=0.0006011808792244983
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0004085244550538393
2053, epoch_train_loss=0.0004085244550538393
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.000179125861140899
2054, epoch_train_loss=0.000179125861140899
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.00013485690545270927
2055, epoch_train_loss=0.00013485690545270927
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0002177809604693758
2056, epoch_train_loss=0.0002177809604693758
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.000305830689530602
2057, epoch_train_loss=0.000305830689530602
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.0003173712844087407
2058, epoch_train_loss=0.0003173712844087407
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.00024260345219101899
2059, epoch_train_loss=0.00024260345219101899
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.00012386743933534658
2060, epoch_train_loss=0.00012386743933534658
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 8.843878480829112e-05
2061, epoch_train_loss=8.843878480829112e-05
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.00016443691881840524
2062, epoch_train_loss=0.00016443691881840524
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0002278210328753278
2063, epoch_train_loss=0.0002278210328753278
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.00020262119196636568
2064, epoch_train_loss=0.00020262119196636568
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.000137606714676768
2065, epoch_train_loss=0.000137606714676768
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 9.940347961867946e-05
2066, epoch_train_loss=9.940347961867946e-05
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 9.37364141382206e-05
2067, epoch_train_loss=9.37364141382206e-05
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.00011558670253885625
2068, epoch_train_loss=0.00011558670253885625
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0001475931676663307
2069, epoch_train_loss=0.0001475931676663307
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0001490635694724646
2070, epoch_train_loss=0.0001490635694724646
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.00011281371531782688
2071, epoch_train_loss=0.00011281371531782688
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 7.755075627521478e-05
2072, epoch_train_loss=7.755075627521478e-05
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 7.716380302884017e-05
2073, epoch_train_loss=7.716380302884017e-05
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 9.536905694268443e-05
2074, epoch_train_loss=9.536905694268443e-05
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.00010693777841160729
2075, epoch_train_loss=0.00010693777841160729
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.00010844067390476569
2076, epoch_train_loss=0.00010844067390476569
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 9.863021964905481e-05
2077, epoch_train_loss=9.863021964905481e-05
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 8.047044826475929e-05
2078, epoch_train_loss=8.047044826475929e-05
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 6.767950744876797e-05
2079, epoch_train_loss=6.767950744876797e-05
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 7.18615595630135e-05
2080, epoch_train_loss=7.18615595630135e-05
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 8.390117940541519e-05
2081, epoch_train_loss=8.390117940541519e-05
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 8.841079834035091e-05
2082, epoch_train_loss=8.841079834035091e-05
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 8.453327961535408e-05
2083, epoch_train_loss=8.453327961535408e-05
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 7.757044418504604e-05
2084, epoch_train_loss=7.757044418504604e-05
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 7.016701580774294e-05
2085, epoch_train_loss=7.016701580774294e-05
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 6.518307373659702e-05
2086, epoch_train_loss=6.518307373659702e-05
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 6.674967843926797e-05
2087, epoch_train_loss=6.674967843926797e-05
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 7.255666805710412e-05
2088, epoch_train_loss=7.255666805710412e-05
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 7.535584087085195e-05
2089, epoch_train_loss=7.535584087085195e-05
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 7.3181597739015e-05
2090, epoch_train_loss=7.3181597739015e-05
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 6.92541018407319e-05
2091, epoch_train_loss=6.92541018407319e-05
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 6.57807094385345e-05
2092, epoch_train_loss=6.57807094385345e-05
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 6.309820036807635e-05
2093, epoch_train_loss=6.309820036807635e-05
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 6.266084314314074e-05
2094, epoch_train_loss=6.266084314314074e-05
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 6.47914644704458e-05
2095, epoch_train_loss=6.47914644704458e-05
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 6.692899687665965e-05
2096, epoch_train_loss=6.692899687665965e-05
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 6.687469145799985e-05
2097, epoch_train_loss=6.687469145799985e-05
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 6.52070974533954e-05
2098, epoch_train_loss=6.52070974533954e-05
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 6.34083091399175e-05
2099, epoch_train_loss=6.34083091399175e-05
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 6.173860370594049e-05
2100, epoch_train_loss=6.173860370594049e-05
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 6.057678522915146e-05
2101, epoch_train_loss=6.057678522915146e-05
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 6.064667929011094e-05
2102, epoch_train_loss=6.064667929011094e-05
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 6.162911393555896e-05
2103, epoch_train_loss=6.162911393555896e-05
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 6.233521208574302e-05
2104, epoch_train_loss=6.233521208574302e-05
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 6.218926725023397e-05
2105, epoch_train_loss=6.218926725023397e-05
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 6.15815747784745e-05
2106, epoch_train_loss=6.15815747784745e-05
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 6.0792738628918205e-05
2107, epoch_train_loss=6.0792738628918205e-05
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 5.985179923833417e-05
2108, epoch_train_loss=5.985179923833417e-05
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 5.908165126746549e-05
2109, epoch_train_loss=5.908165126746549e-05
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 5.888210731226113e-05
2110, epoch_train_loss=5.888210731226113e-05
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 5.910976603579816e-05
2111, epoch_train_loss=5.910976603579816e-05
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 5.933076307982502e-05
2112, epoch_train_loss=5.933076307982502e-05
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 5.937485407915997e-05
2113, epoch_train_loss=5.937485407915997e-05
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 5.929618272586711e-05
2114, epoch_train_loss=5.929618272586711e-05
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 5.9058422255354864e-05
2115, epoch_train_loss=5.9058422255354864e-05
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 5.859388570406626e-05
2116, epoch_train_loss=5.859388570406626e-05
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 5.808444647016711e-05
2117, epoch_train_loss=5.808444647016711e-05
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 5.774643001684881e-05
2118, epoch_train_loss=5.774643001684881e-05
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 5.75759466827463e-05
2119, epoch_train_loss=5.75759466827463e-05
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 5.7472877131728965e-05
2120, epoch_train_loss=5.7472877131728965e-05
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 5.742853736677727e-05
2121, epoch_train_loss=5.742853736677727e-05
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 5.745332545856673e-05
2122, epoch_train_loss=5.745332545856673e-05
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 5.745180963122496e-05
2123, epoch_train_loss=5.745180963122496e-05
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 5.733466206555598e-05
2124, epoch_train_loss=5.733466206555598e-05
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 5.714208175524845e-05
2125, epoch_train_loss=5.714208175524845e-05
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 5.694438292188646e-05
2126, epoch_train_loss=5.694438292188646e-05
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 5.6735947336708704e-05
2127, epoch_train_loss=5.6735947336708704e-05
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 5.651181114459483e-05
2128, epoch_train_loss=5.651181114459483e-05
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 5.6318480564462504e-05
2129, epoch_train_loss=5.6318480564462504e-05
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 5.619145925923773e-05
2130, epoch_train_loss=5.619145925923773e-05
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 5.610185098129905e-05
2131, epoch_train_loss=5.610185098129905e-05
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 5.601535007304411e-05
2132, epoch_train_loss=5.601535007304411e-05
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 5.593918104614872e-05
2133, epoch_train_loss=5.593918104614872e-05
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 5.58763906260032e-05
2134, epoch_train_loss=5.58763906260032e-05
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 5.580262379396104e-05
2135, epoch_train_loss=5.580262379396104e-05
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 5.570174190167986e-05
2136, epoch_train_loss=5.570174190167986e-05
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 5.5586321409490256e-05
2137, epoch_train_loss=5.5586321409490256e-05
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 5.547010686006329e-05
2138, epoch_train_loss=5.547010686006329e-05
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 5.534906397079073e-05
2139, epoch_train_loss=5.534906397079073e-05
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 5.521905952407825e-05
2140, epoch_train_loss=5.521905952407825e-05
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 5.509169333154039e-05
2141, epoch_train_loss=5.509169333154039e-05
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 5.4976461259310115e-05
2142, epoch_train_loss=5.4976461259310115e-05
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 5.487014044497277e-05
2143, epoch_train_loss=5.487014044497277e-05
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 5.476652233391163e-05
2144, epoch_train_loss=5.476652233391163e-05
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 5.466781731562485e-05
2145, epoch_train_loss=5.466781731562485e-05
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 5.4578590913266986e-05
2146, epoch_train_loss=5.4578590913266986e-05
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 5.449499663548424e-05
2147, epoch_train_loss=5.449499663548424e-05
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 5.44107338480395e-05
2148, epoch_train_loss=5.44107338480395e-05
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 5.432624203740403e-05
2149, epoch_train_loss=5.432624203740403e-05
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 5.4244790114624556e-05
2150, epoch_train_loss=5.4244790114624556e-05
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 5.41650283039715e-05
2151, epoch_train_loss=5.41650283039715e-05
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 5.408321756962597e-05
2152, epoch_train_loss=5.408321756962597e-05
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 5.399968346789578e-05
2153, epoch_train_loss=5.399968346789578e-05
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 5.391766786802141e-05
2154, epoch_train_loss=5.391766786802141e-05
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 5.383689832037512e-05
2155, epoch_train_loss=5.383689832037512e-05
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 5.375542450666579e-05
2156, epoch_train_loss=5.375542450666579e-05
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 5.367342587827224e-05
2157, epoch_train_loss=5.367342587827224e-05
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 5.359305962790429e-05
2158, epoch_train_loss=5.359305962790429e-05
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 5.3514746508136105e-05
2159, epoch_train_loss=5.3514746508136105e-05
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 5.3437519547210446e-05
2160, epoch_train_loss=5.3437519547210446e-05
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 5.336123554944054e-05
2161, epoch_train_loss=5.336123554944054e-05
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 5.328749866678418e-05
2162, epoch_train_loss=5.328749866678418e-05
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 5.321706890982663e-05
2163, epoch_train_loss=5.321706890982663e-05
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 5.315017050422606e-05
2164, epoch_train_loss=5.315017050422606e-05
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 5.308698559339661e-05
2165, epoch_train_loss=5.308698559339661e-05
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 5.302948988084687e-05
2166, epoch_train_loss=5.302948988084687e-05
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 5.297971761991632e-05
2167, epoch_train_loss=5.297971761991632e-05
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 5.294025889268196e-05
2168, epoch_train_loss=5.294025889268196e-05
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 5.291361529750485e-05
2169, epoch_train_loss=5.291361529750485e-05
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 5.290565268364569e-05
2170, epoch_train_loss=5.290565268364569e-05
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 5.2923129580650214e-05
2171, epoch_train_loss=5.2923129580650214e-05
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 5.297791453665462e-05
2172, epoch_train_loss=5.297791453665462e-05
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 5.3083093427810904e-05
2173, epoch_train_loss=5.3083093427810904e-05
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 5.3264318409890106e-05
2174, epoch_train_loss=5.3264318409890106e-05
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 5.3551246368218974e-05
2175, epoch_train_loss=5.3551246368218974e-05
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 5.400190782522843e-05
2176, epoch_train_loss=5.400190782522843e-05
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 5.468134270094058e-05
2177, epoch_train_loss=5.468134270094058e-05
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 5.572581912766425e-05
2178, epoch_train_loss=5.572581912766425e-05
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 5.7283409485837654e-05
2179, epoch_train_loss=5.7283409485837654e-05
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 5.968865312280814e-05
2180, epoch_train_loss=5.968865312280814e-05
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 6.328096411079598e-05
2181, epoch_train_loss=6.328096411079598e-05
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 6.891689585166983e-05
2182, epoch_train_loss=6.891689585166983e-05
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 7.737353936448913e-05
2183, epoch_train_loss=7.737353936448913e-05
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 9.095305355010429e-05
2184, epoch_train_loss=9.095305355010429e-05
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.00011138132683673438
2185, epoch_train_loss=0.00011138132683673438
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.00014516600378887114
2186, epoch_train_loss=0.00014516600378887114
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0001957643705141412
2187, epoch_train_loss=0.0001957643705141412
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.00028255812008870973
2188, epoch_train_loss=0.00028255812008870973
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.00041017497697404037
2189, epoch_train_loss=0.00041017497697404037
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0006393502211805573
2190, epoch_train_loss=0.0006393502211805573
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0009614154525201075
2191, epoch_train_loss=0.0009614154525201075
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.001574242149683401
2192, epoch_train_loss=0.001574242149683401
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.002353035213022802
2193, epoch_train_loss=0.002353035213022802
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.003943823156950456
2194, epoch_train_loss=0.003943823156950456
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.00554658599290764
2195, epoch_train_loss=0.00554658599290764
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.009104964962182514
2196, epoch_train_loss=0.009104964962182514
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.010938650996904466
2197, epoch_train_loss=0.010938650996904466
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.015748825716093304
2198, epoch_train_loss=0.015748825716093304
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.01373286132675786
2199, epoch_train_loss=0.01373286132675786
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.013252067677201726
2200, epoch_train_loss=0.013252067677201726
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.006547372554066722
2201, epoch_train_loss=0.006547372554066722
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.001988190419705873
2202, epoch_train_loss=0.001988190419705873
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.00021159824031937732
2203, epoch_train_loss=0.00021159824031937732
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0017850309075156687
2204, epoch_train_loss=0.0017850309075156687
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.004965614986992523
2205, epoch_train_loss=0.004965614986992523
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.005983554611124272
2206, epoch_train_loss=0.005983554611124272
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.005593847101796669
2207, epoch_train_loss=0.005593847101796669
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0025480742614388506
2208, epoch_train_loss=0.0025480742614388506
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.0004750229651349946
2209, epoch_train_loss=0.0004750229651349946
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.00047402009276061496
2210, epoch_train_loss=0.00047402009276061496
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0019235337593307834
2211, epoch_train_loss=0.0019235337593307834
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.0033058404903138906
2212, epoch_train_loss=0.0033058404903138906
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.0028037248281390383
2213, epoch_train_loss=0.0028037248281390383
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0015294295105736228
2214, epoch_train_loss=0.0015294295105736228
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.00035869960346259953
2215, epoch_train_loss=0.00035869960346259953
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.0003044624022721236
2216, epoch_train_loss=0.0003044624022721236
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0011174364449652839
2217, epoch_train_loss=0.0011174364449652839
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0016906437239949277
2218, epoch_train_loss=0.0016906437239949277
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0015846140297587825
2219, epoch_train_loss=0.0015846140297587825
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007851463484055623
2220, epoch_train_loss=0.0007851463484055623
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.00018582296699282434
2221, epoch_train_loss=0.00018582296699282434
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.00021672154174593716
2222, epoch_train_loss=0.00021672154174593716
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.000665369952643593
2223, epoch_train_loss=0.000665369952643593
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.001028075804804959
2224, epoch_train_loss=0.001028075804804959
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.0008852587403386954
2225, epoch_train_loss=0.0008852587403386954
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.00046491691828830906
2226, epoch_train_loss=0.00046491691828830906
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0001278299339264892
2227, epoch_train_loss=0.0001278299339264892
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.00013955728439069421
2228, epoch_train_loss=0.00013955728439069421
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.00037994048507316344
2229, epoch_train_loss=0.00037994048507316344
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0005473110459768248
2230, epoch_train_loss=0.0005473110459768248
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0005054451137813476
2231, epoch_train_loss=0.0005054451137813476
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.0002938441500046629
2232, epoch_train_loss=0.0002938441500046629
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.00012474163630208146
2233, epoch_train_loss=0.00012474163630208146
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.00010392296716022032
2234, epoch_train_loss=0.00010392296716022032
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.00020358844712816898
2235, epoch_train_loss=0.00020358844712816898
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.00030525417499545956
2236, epoch_train_loss=0.00030525417499545956
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0003096883144920422
2237, epoch_train_loss=0.0003096883144920422
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.00023545579794491482
2238, epoch_train_loss=0.00023545579794491482
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.00013288433511763104
2239, epoch_train_loss=0.00013288433511763104
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 8.032935507966211e-05
2240, epoch_train_loss=8.032935507966211e-05
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.00010008650274804761
2241, epoch_train_loss=0.00010008650274804761
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.00015923808123482472
2242, epoch_train_loss=0.00015923808123482472
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.00020047336882721343
2243, epoch_train_loss=0.00020047336882721343
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0001830093809215234
2244, epoch_train_loss=0.0001830093809215234
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.00013084194917651446
2245, epoch_train_loss=0.00013084194917651446
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 8.116937201313282e-05
2246, epoch_train_loss=8.116937201313282e-05
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 6.757009693607878e-05
2247, epoch_train_loss=6.757009693607878e-05
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 8.893682524569165e-05
2248, epoch_train_loss=8.893682524569165e-05
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.00011880181907290678
2249, epoch_train_loss=0.00011880181907290678
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.00013173190028134617
2250, epoch_train_loss=0.00013173190028134617
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.00011765419262252119
2251, epoch_train_loss=0.00011765419262252119
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 9.222323217725812e-05
2252, epoch_train_loss=9.222323217725812e-05
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 7.102990205015609e-05
2253, epoch_train_loss=7.102990205015609e-05
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 6.416967515773178e-05
2254, epoch_train_loss=6.416967515773178e-05
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 7.10672401566144e-05
2255, epoch_train_loss=7.10672401566144e-05
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 8.371081387322912e-05
2256, epoch_train_loss=8.371081387322912e-05
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 9.276512359753052e-05
2257, epoch_train_loss=9.276512359753052e-05
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 9.152973457843032e-05
2258, epoch_train_loss=9.152973457843032e-05
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 8.188312655934342e-05
2259, epoch_train_loss=8.188312655934342e-05
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 6.926470537366374e-05
2260, epoch_train_loss=6.926470537366374e-05
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 6.068135440478038e-05
2261, epoch_train_loss=6.068135440478038e-05
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 5.964986834906586e-05
2262, epoch_train_loss=5.964986834906586e-05
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 6.455481760041973e-05
2263, epoch_train_loss=6.455481760041973e-05
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 7.057320985697525e-05
2264, epoch_train_loss=7.057320985697525e-05
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 7.346733398962577e-05
2265, epoch_train_loss=7.346733398962577e-05
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 7.226213214836555e-05
2266, epoch_train_loss=7.226213214836555e-05
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 6.792790599882914e-05
2267, epoch_train_loss=6.792790599882914e-05
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 6.282262054909472e-05
2268, epoch_train_loss=6.282262054909472e-05
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 5.882674655469212e-05
2269, epoch_train_loss=5.882674655469212e-05
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 5.715763462439942e-05
2270, epoch_train_loss=5.715763462439942e-05
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 5.779442511035627e-05
2271, epoch_train_loss=5.779442511035627e-05
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 5.986710282406732e-05
2272, epoch_train_loss=5.986710282406732e-05
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 6.201800747681188e-05
2273, epoch_train_loss=6.201800747681188e-05
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 6.290695162163846e-05
2274, epoch_train_loss=6.290695162163846e-05
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 6.215545580811291e-05
2275, epoch_train_loss=6.215545580811291e-05
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 6.016226217744618e-05
2276, epoch_train_loss=6.016226217744618e-05
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 5.7951772349037286e-05
2277, epoch_train_loss=5.7951772349037286e-05
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 5.620901003667241e-05
2278, epoch_train_loss=5.620901003667241e-05
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 5.528998929325508e-05
2279, epoch_train_loss=5.528998929325508e-05
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 5.5179929338054836e-05
2280, epoch_train_loss=5.5179929338054836e-05
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 5.562133895700605e-05
2281, epoch_train_loss=5.562133895700605e-05
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 5.630032200056376e-05
2282, epoch_train_loss=5.630032200056376e-05
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 5.6885799894508453e-05
2283, epoch_train_loss=5.6885799894508453e-05
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 5.711036629773859e-05
2284, epoch_train_loss=5.711036629773859e-05
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 5.681313350544926e-05
2285, epoch_train_loss=5.681313350544926e-05
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 5.6116464328661196e-05
2286, epoch_train_loss=5.6116464328661196e-05
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 5.52622619810639e-05
2287, epoch_train_loss=5.52622619810639e-05
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 5.4486660684119216e-05
2288, epoch_train_loss=5.4486660684119216e-05
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 5.3908251842020877e-05
2289, epoch_train_loss=5.3908251842020877e-05
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 5.356528133804943e-05
2290, epoch_train_loss=5.356528133804943e-05
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 5.3426827665008564e-05
2291, epoch_train_loss=5.3426827665008564e-05
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 5.344563002321304e-05
2292, epoch_train_loss=5.344563002321304e-05
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 5.3567267973396305e-05
2293, epoch_train_loss=5.3567267973396305e-05
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 5.371470994538717e-05
2294, epoch_train_loss=5.371470994538717e-05
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 5.3801106229442054e-05
2295, epoch_train_loss=5.3801106229442054e-05
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 5.3769051819178614e-05
2296, epoch_train_loss=5.3769051819178614e-05
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 5.363116383261535e-05
2297, epoch_train_loss=5.363116383261535e-05
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 5.341300362292158e-05
2298, epoch_train_loss=5.341300362292158e-05
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 5.315523383569655e-05
2299, epoch_train_loss=5.315523383569655e-05
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 5.28817558247973e-05
2300, epoch_train_loss=5.28817558247973e-05
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 5.261177155024115e-05
2301, epoch_train_loss=5.261177155024115e-05
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 5.2357498852982645e-05
2302, epoch_train_loss=5.2357498852982645e-05
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 5.213801908156054e-05
2303, epoch_train_loss=5.213801908156054e-05
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 5.196755463348436e-05
2304, epoch_train_loss=5.196755463348436e-05
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 5.184298101534453e-05
2305, epoch_train_loss=5.184298101534453e-05
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 5.175028577788395e-05
2306, epoch_train_loss=5.175028577788395e-05
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 5.167798074784615e-05
2307, epoch_train_loss=5.167798074784615e-05
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 5.161763894228308e-05
2308, epoch_train_loss=5.161763894228308e-05
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 5.156495334011918e-05
2309, epoch_train_loss=5.156495334011918e-05
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 5.151832410902753e-05
2310, epoch_train_loss=5.151832410902753e-05
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 5.147365953864545e-05
2311, epoch_train_loss=5.147365953864545e-05
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 5.1425338811567936e-05
2312, epoch_train_loss=5.1425338811567936e-05
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 5.13691753818567e-05
2313, epoch_train_loss=5.13691753818567e-05
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 5.130829090195275e-05
2314, epoch_train_loss=5.130829090195275e-05
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 5.1244743737469146e-05
2315, epoch_train_loss=5.1244743737469146e-05
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 5.1181842757673804e-05
2316, epoch_train_loss=5.1181842757673804e-05
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 5.1119940815452816e-05
2317, epoch_train_loss=5.1119940815452816e-05
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 5.106041025868437e-05
2318, epoch_train_loss=5.106041025868437e-05
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 5.100249061644476e-05
2319, epoch_train_loss=5.100249061644476e-05
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 5.0950398849235145e-05
2320, epoch_train_loss=5.0950398849235145e-05
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 5.090685721728807e-05
2321, epoch_train_loss=5.090685721728807e-05
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 5.0877254268486055e-05
2322, epoch_train_loss=5.0877254268486055e-05
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 5.086244400772111e-05
2323, epoch_train_loss=5.086244400772111e-05
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 5.086925752751846e-05
2324, epoch_train_loss=5.086925752751846e-05
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 5.090073132214445e-05
2325, epoch_train_loss=5.090073132214445e-05
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 5.096976333290805e-05
2326, epoch_train_loss=5.096976333290805e-05
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 5.108506637104277e-05
2327, epoch_train_loss=5.108506637104277e-05
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 5.127063954839257e-05
2328, epoch_train_loss=5.127063954839257e-05
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 5.154295436711997e-05
2329, epoch_train_loss=5.154295436711997e-05
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 5.1947589205430874e-05
2330, epoch_train_loss=5.1947589205430874e-05
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 5.252001669390815e-05
2331, epoch_train_loss=5.252001669390815e-05
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 5.3356236503077175e-05
2332, epoch_train_loss=5.3356236503077175e-05
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 5.453111969306703e-05
2333, epoch_train_loss=5.453111969306703e-05
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 5.625492630547909e-05
2334, epoch_train_loss=5.625492630547909e-05
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 5.8684604042838435e-05
2335, epoch_train_loss=5.8684604042838435e-05
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 6.230124443569147e-05
2336, epoch_train_loss=6.230124443569147e-05
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 6.743234349426828e-05
2337, epoch_train_loss=6.743234349426828e-05
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 7.523301652182308e-05
2338, epoch_train_loss=7.523301652182308e-05
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 8.636950818753693e-05
2339, epoch_train_loss=8.636950818753693e-05
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.00010375250591764485
2340, epoch_train_loss=0.00010375250591764485
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.00012863002855795583
2341, epoch_train_loss=0.00012863002855795583
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.00016871769403957386
2342, epoch_train_loss=0.00016871769403957386
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.0002257612146157275
2343, epoch_train_loss=0.0002257612146157275
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.000321271072260948
2344, epoch_train_loss=0.000321271072260948
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0004543813126815868
2345, epoch_train_loss=0.0004543813126815868
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0006879082277334455
2346, epoch_train_loss=0.0006879082277334455
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.000998025310759612
2347, epoch_train_loss=0.000998025310759612
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0015741580845870296
2348, epoch_train_loss=0.0015741580845870296
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.002264518395575564
2349, epoch_train_loss=0.002264518395575564
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0036379312488782774
2350, epoch_train_loss=0.0036379312488782774
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.004949296682195514
2351, epoch_train_loss=0.004949296682195514
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.007777099638133805
2352, epoch_train_loss=0.007777099638133805
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.00923545539878948
2353, epoch_train_loss=0.00923545539878948
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.012922497612561513
2354, epoch_train_loss=0.012922497612561513
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.01180199964640135
2355, epoch_train_loss=0.01180199964640135
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.011953140076038874
2356, epoch_train_loss=0.011953140076038874
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.007090100491132135
2357, epoch_train_loss=0.007090100491132135
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.00331654134133601
2358, epoch_train_loss=0.00331654134133601
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007225119510599306
2359, epoch_train_loss=0.0007225119510599306
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.0005798270224704448
2360, epoch_train_loss=0.0005798270224704448
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.0023042258024286786
2361, epoch_train_loss=0.0023042258024286786
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.003964752076221971
2362, epoch_train_loss=0.003964752076221971
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0051085274624351525
2363, epoch_train_loss=0.0051085274624351525
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.0038435853379807563
2364, epoch_train_loss=0.0038435853379807563
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0020670583990880097
2365, epoch_train_loss=0.0020670583990880097
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0005914664232986368
2366, epoch_train_loss=0.0005914664232986368
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.00033991483414210513
2367, epoch_train_loss=0.00033991483414210513
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.001189913082414078
2368, epoch_train_loss=0.001189913082414078
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.002085639905292893
2369, epoch_train_loss=0.002085639905292893
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0024453085087855235
2370, epoch_train_loss=0.0024453085087855235
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0017167971089542546
2371, epoch_train_loss=0.0017167971089542546
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0007044377693327588
2372, epoch_train_loss=0.0007044377693327588
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.00012927489064526974
2373, epoch_train_loss=0.00012927489064526974
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.00030594319585857185
2374, epoch_train_loss=0.00030594319585857185
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0009009332687143717
2375, epoch_train_loss=0.0009009332687143717
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0012444702611910613
2376, epoch_train_loss=0.0012444702611910613
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0011082141768901275
2377, epoch_train_loss=0.0011082141768901275
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.0005791272356725467
2378, epoch_train_loss=0.0005791272356725467
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.00018640988555420994
2379, epoch_train_loss=0.00018640988555420994
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0001443121915284723
2380, epoch_train_loss=0.0001443121915284723
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.00035753403854119076
2381, epoch_train_loss=0.00035753403854119076
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0005732169587725903
2382, epoch_train_loss=0.0005732169587725903
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.0006237202265811956
2383, epoch_train_loss=0.0006237202265811956
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.0005484944606516881
2384, epoch_train_loss=0.0005484944606516881
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.0003412127235259125
2385, epoch_train_loss=0.0003412127235259125
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.00015804216420715894
2386, epoch_train_loss=0.00015804216420715894
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 9.400881242204134e-05
2387, epoch_train_loss=9.400881242204134e-05
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.00017933145590414586
2388, epoch_train_loss=0.00017933145590414586
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0003242418555202024
2389, epoch_train_loss=0.0003242418555202024
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.000386209724343437
2390, epoch_train_loss=0.000386209724343437
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0003397152212119842
2391, epoch_train_loss=0.0003397152212119842
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.00020567072816784804
2392, epoch_train_loss=0.00020567072816784804
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.00010266185200457426
2393, epoch_train_loss=0.00010266185200457426
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 7.969770852331366e-05
2394, epoch_train_loss=7.969770852331366e-05
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.00011739083612309562
2395, epoch_train_loss=0.00011739083612309562
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.00016985741322028908
2396, epoch_train_loss=0.00016985741322028908
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.00020174284762690932
2397, epoch_train_loss=0.00020174284762690932
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0002063458504677999
2398, epoch_train_loss=0.0002063458504677999
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.00016975856616911457
2399, epoch_train_loss=0.00016975856616911457
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.00011485187799620845
2400, epoch_train_loss=0.00011485187799620845
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 7.147388205788692e-05
2401, epoch_train_loss=7.147388205788692e-05
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 6.271569620894588e-05
2402, epoch_train_loss=6.271569620894588e-05
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 8.49529192378839e-05
2403, epoch_train_loss=8.49529192378839e-05
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.00011507914345127915
2404, epoch_train_loss=0.00011507914345127915
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0001309836804441833
2405, epoch_train_loss=0.0001309836804441833
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0001236680499349636
2406, epoch_train_loss=0.0001236680499349636
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0001050364367591746
2407, epoch_train_loss=0.0001050364367591746
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 8.421333847486152e-05
2408, epoch_train_loss=8.421333847486152e-05
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 6.793552453195279e-05
2409, epoch_train_loss=6.793552453195279e-05
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 5.898431328488813e-05
2410, epoch_train_loss=5.898431328488813e-05
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 6.0904603683711464e-05
2411, epoch_train_loss=6.0904603683711464e-05
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 7.159679372475074e-05
2412, epoch_train_loss=7.159679372475074e-05
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 8.271619968952423e-05
2413, epoch_train_loss=8.271619968952423e-05
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 8.771573710025469e-05
2414, epoch_train_loss=8.771573710025469e-05
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 8.41790027757513e-05
2415, epoch_train_loss=8.41790027757513e-05
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 7.62632184685363e-05
2416, epoch_train_loss=7.62632184685363e-05
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 6.748965299519094e-05
2417, epoch_train_loss=6.748965299519094e-05
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 6.0701445833014035e-05
2418, epoch_train_loss=6.0701445833014035e-05
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 5.623075804515257e-05
2419, epoch_train_loss=5.623075804515257e-05
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 5.461595775486723e-05
2420, epoch_train_loss=5.461595775486723e-05
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 5.648710810513925e-05
2421, epoch_train_loss=5.648710810513925e-05
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 6.063052431263491e-05
2422, epoch_train_loss=6.063052431263491e-05
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 6.43458506194329e-05
2423, epoch_train_loss=6.43458506194329e-05
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 6.57107310164453e-05
2424, epoch_train_loss=6.57107310164453e-05
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 6.497291840972035e-05
2425, epoch_train_loss=6.497291840972035e-05
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 6.280066736992086e-05
2426, epoch_train_loss=6.280066736992086e-05
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 6.014989655039341e-05
2427, epoch_train_loss=6.014989655039341e-05
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 5.7269401235428546e-05
2428, epoch_train_loss=5.7269401235428546e-05
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 5.457911681421798e-05
2429, epoch_train_loss=5.457911681421798e-05
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 5.259426738912513e-05
2430, epoch_train_loss=5.259426738912513e-05
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 5.189173898155943e-05
2431, epoch_train_loss=5.189173898155943e-05
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 5.2345725354090066e-05
2432, epoch_train_loss=5.2345725354090066e-05
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 5.3223392234526504e-05
2433, epoch_train_loss=5.3223392234526504e-05
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 5.4020352727045097e-05
2434, epoch_train_loss=5.4020352727045097e-05
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 5.4663263796808624e-05
2435, epoch_train_loss=5.4663263796808624e-05
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 5.519533100518214e-05
2436, epoch_train_loss=5.519533100518214e-05
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 5.545033759990303e-05
2437, epoch_train_loss=5.545033759990303e-05
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 5.5322988517123886e-05
2438, epoch_train_loss=5.5322988517123886e-05
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 5.474164801567419e-05
2439, epoch_train_loss=5.474164801567419e-05
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 5.391614744658712e-05
2440, epoch_train_loss=5.391614744658712e-05
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 5.307748510905971e-05
2441, epoch_train_loss=5.307748510905971e-05
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 5.236616187994885e-05
2442, epoch_train_loss=5.236616187994885e-05
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 5.1690582471028754e-05
2443, epoch_train_loss=5.1690582471028754e-05
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 5.104146253400998e-05
2444, epoch_train_loss=5.104146253400998e-05
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 5.050459308097746e-05
2445, epoch_train_loss=5.050459308097746e-05
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 5.015497746565886e-05
2446, epoch_train_loss=5.015497746565886e-05
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 4.996716873163786e-05
2447, epoch_train_loss=4.996716873163786e-05
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 4.986888669196208e-05
2448, epoch_train_loss=4.986888669196208e-05
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 4.9798609254534084e-05
2449, epoch_train_loss=4.9798609254534084e-05
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 4.974704745839225e-05
2450, epoch_train_loss=4.974704745839225e-05
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 4.9752626225640124e-05
2451, epoch_train_loss=4.9752626225640124e-05
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 4.9819744822025194e-05
2452, epoch_train_loss=4.9819744822025194e-05
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 4.989814154383681e-05
2453, epoch_train_loss=4.989814154383681e-05
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 4.99498082185532e-05
2454, epoch_train_loss=4.99498082185532e-05
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 4.9992697503771604e-05
2455, epoch_train_loss=4.9992697503771604e-05
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 5.005244961584039e-05
2456, epoch_train_loss=5.005244961584039e-05
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 5.0145977686253925e-05
2457, epoch_train_loss=5.0145977686253925e-05
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 5.026234835455045e-05
2458, epoch_train_loss=5.026234835455045e-05
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 5.040210340530033e-05
2459, epoch_train_loss=5.040210340530033e-05
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 5.0560649109594516e-05
2460, epoch_train_loss=5.0560649109594516e-05
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 5.0785199220138774e-05
2461, epoch_train_loss=5.0785199220138774e-05
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 5.109390894051063e-05
2462, epoch_train_loss=5.109390894051063e-05
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 5.152949985132613e-05
2463, epoch_train_loss=5.152949985132613e-05
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 5.20908805252022e-05
2464, epoch_train_loss=5.20908805252022e-05
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 5.286557352159383e-05
2465, epoch_train_loss=5.286557352159383e-05
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 5.388639965161062e-05
2466, epoch_train_loss=5.388639965161062e-05
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 5.533123903586483e-05
2467, epoch_train_loss=5.533123903586483e-05
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 5.725871117954958e-05
2468, epoch_train_loss=5.725871117954958e-05
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 6.0017483704945115e-05
2469, epoch_train_loss=6.0017483704945115e-05
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 6.371359350170743e-05
2470, epoch_train_loss=6.371359350170743e-05
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 6.910796186004016e-05
2471, epoch_train_loss=6.910796186004016e-05
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 7.6412041418959e-05
2472, epoch_train_loss=7.6412041418959e-05
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 8.733927390582403e-05
2473, epoch_train_loss=8.733927390582403e-05
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.00010221458311877368
2474, epoch_train_loss=0.00010221458311877368
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.00012512209986155113
2475, epoch_train_loss=0.00012512209986155113
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.00015632179722746518
2476, epoch_train_loss=0.00015632179722746518
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.00020609721812007967
2477, epoch_train_loss=0.00020609721812007967
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.0002732100827284364
2478, epoch_train_loss=0.0002732100827284364
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0003848216906272157
2479, epoch_train_loss=0.0003848216906272157
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0005311057237526036
2480, epoch_train_loss=0.0005311057237526036
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007869003613817801
2481, epoch_train_loss=0.0007869003613817801
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.001102825268246508
2482, epoch_train_loss=0.001102825268246508
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.001690001740659852
2483, epoch_train_loss=0.001690001740659852
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.002332225782813019
2484, epoch_train_loss=0.002332225782813019
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.0036161754426329664
2485, epoch_train_loss=0.0036161754426329664
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.004693526329693127
2486, epoch_train_loss=0.004693526329693127
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.007061044779038513
2487, epoch_train_loss=0.007061044779038513
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.007992657115620996
2488, epoch_train_loss=0.007992657115620996
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.010645328310659697
2489, epoch_train_loss=0.010645328310659697
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.009382473012357192
2490, epoch_train_loss=0.009382473012357192
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.009159601757280466
2491, epoch_train_loss=0.009159601757280466
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.005355944157133883
2492, epoch_train_loss=0.005355944157133883
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.00254066630115417
2493, epoch_train_loss=0.00254066630115417
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0005118435207636742
2494, epoch_train_loss=0.0005118435207636742
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0002869182766162603
2495, epoch_train_loss=0.0002869182766162603
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0014576528084283278
2496, epoch_train_loss=0.0014576528084283278
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.0028265021654731845
2497, epoch_train_loss=0.0028265021654731845
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.003972330030470426
2498, epoch_train_loss=0.003972330030470426
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0033517657232878736
2499, epoch_train_loss=0.0033517657232878736
