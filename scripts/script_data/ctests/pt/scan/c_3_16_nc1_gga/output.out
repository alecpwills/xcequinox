/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea950> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea950> in UKS object of <class 'pyscf.dft.uks.UKS'>
<pyscf.gto.mole.Mole object at 0x7ffeac0ea950> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0ea8f0> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0e83d0> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0ea9b0> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0e8670> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0e8fa0> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0e91b0> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0e87c0> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffeac0e9630> [['H', array([0.      , 0.      , 0.371395])], ['H', array([ 0.      ,  0.      , -0.371395])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0e95a0> [['N', array([0.      , 0.      , 0.549396])], ['N', array([ 0.      ,  0.      , -0.549396])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0e9450> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0e9a20> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac0ea050> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac0e9ae0> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0ea4a0> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0ea4d0> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0e9ed0> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac0ea770> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0ea680> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0ea5f0> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0ea920> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0eab30> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac0ea8c0> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffeac0eadd0> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffeac0eaa70> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffeac0eaf20> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffeac0eb250> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992717  <S^2> = 3.7502984  2S+1 = 4.0001492
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea8f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea8f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051022 -0.00019156 -0.00051334 ... -0.02830887 -0.02830887
 -0.02830887] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 3)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046675  <S^2> = 3.7524945  2S+1 = 4.0012471
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e83d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e83d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-3.60081838e-04 -1.08775305e-04 -1.31917160e-05 ... -2.74817476e-02
 -2.74817476e-02 -2.74817476e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 3)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea9b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea9b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.92637310e-09 -1.31700807e-07 -9.61527370e-06 ... -7.49400542e-16
 -7.49400542e-16 -7.49400542e-16] = ,SCAN
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 3)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e8670> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e8670> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.31884219e-04 -2.81911891e-04 -2.81911891e-04 ... -1.27154711e-05
 -2.64861768e-02 -2.64861768e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 3)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033771319123  <S^2> = 2.0027452  2S+1 = 3.0018296
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e8fa0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e8fa0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.04592535e-04 -1.93746627e-05 -1.03530428e-06 ... -2.76158561e-02
 -2.76158561e-02 -2.76158561e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 3)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577120489  <S^2> = 0.7516194  2S+1 = 2.0016187
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e91b0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e91b0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.96840340e-04 -2.41462945e-04 -8.24371181e-05 ... -2.84484387e-02
 -2.84484387e-02 -2.84484387e-02] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 3)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560989222  <S^2> = 0.75226414  2S+1 = 2.0022629
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e87c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e87c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.12430400e-03 -1.34730791e-03 -6.90281808e-04 ... -2.71611201e-05
 -1.90435860e-04 -1.52226957e-05] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 3)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786807705  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e9630> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e9630> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00039854 -0.00017275 -0.00023834 ... -0.02838402 -0.02838402
 -0.02838402] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 3)
mol:  [['H', array([0.      , 0.      , 0.371395])], ['H', array([ 0.      ,  0.      , -0.371395])]]
converged SCF energy = -1.16580491182913  <S^2> = -8.8817842e-16  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e95a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e95a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 14, 14)
ao.shape (10, 4776, 14)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.43725660e-05 -1.02204686e-06 -4.05575842e-05 ... -2.36278434e-02
 -2.36278434e-02 -2.36278434e-02] = ,SCAN
get_data, dm shape = (2, 14, 14)
ao_eval.shape=(4, 4776, 14)
rho shape (4, 4, 2, 4776)
rho_filt shape: (4776,)
get descriptors tdrho.shape=(4776, 3)
mol:  [['N', array([0.      , 0.      , 0.549396])], ['N', array([ 0.      ,  0.      , -0.549396])]]
converged SCF energy = -109.439263799566  <S^2> = 1.0658141e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e9450> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e9450> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9848, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.89629699e-05 -2.76172354e-04 -7.59017288e-05 ... -7.34654212e-06
 -7.34654212e-06 -2.89629699e-05] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9848, 44)
rho shape (4, 4, 2, 9848)
rho_filt shape: (9848,)
get descriptors tdrho.shape=(9848, 3)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 1.7763568e-15  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e9a20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e9a20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00043469 -0.00024024 -0.00035532 ... -0.00047537 -0.03728133
 -0.03728133] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 3)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.337792446513  <S^2> = 4.0072745e-10  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea050> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea050> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-9.02468888e-05 -7.92694658e-06 -9.80568469e-06 ... -4.33714150e-02
 -4.33714150e-02 -4.33714150e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 3)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322843  <S^2> = 1.7763568e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e9ae0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e9ae0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.48187338e-05 -6.19475249e-05 -2.61742784e-04 ... -8.70042314e-07
 -2.73391097e-02 -2.73391097e-02] = ,SCAN
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 3)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888959  <S^2> = 4.9737992e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea4a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea4a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051559 -0.00027432 -0.00088583 ... -0.00027432 -0.04174728
 -0.04174728] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 3)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.1546319e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea4d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea4d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.53951178e-05 -5.93507199e-06 -3.10072916e-04 ... -5.94325581e-02
 -5.94325581e-02 -5.94325581e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 3)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.21489448715  <S^2> = 1.0018599  2S+1 = 2.2377309
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0e9ed0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0e9ed0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.56050702e-04 -2.93826342e-05 -1.60238025e-06 ... -4.22396712e-02
 -4.22396712e-02 -4.22396712e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 3)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346373  <S^2> = 1.3322676e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea770> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea770> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.72190712e-05 -2.72190712e-05 -2.84904833e-04 ... -1.08108260e-05
 -1.03072478e-05 -1.03072478e-05] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 3)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.6346928e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea680> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea680> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00015688 -0.00024669 -0.00068269 ... -0.03791166 -0.03791166
 -0.03791166] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 3)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374078  <S^2> = 6.3948846e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea5f0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea5f0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.28500681e-05 -5.65091132e-06 -7.37932132e-06 ... -4.76689214e-02
 -4.76689214e-02 -4.76689214e-02] = ,SCAN
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 3)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.4384943e-14  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea920> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea920> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003863  -0.00040095 -0.00040095 ... -0.0213199  -0.0213199
 -0.0213199 ] = ,SCAN
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 3)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5859314e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0eab30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0eab30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00088473 -0.00088473 -0.00116894 ... -0.00088473 -0.00088473
 -0.00116894] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 3)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.31335e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0ea8c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0ea8c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.91408540e-05 -1.46971271e-04 -1.08734417e-03 ... -2.81566369e-02
 -2.81566369e-02 -2.81566369e-02] = ,SCAN
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 3)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469574  <S^2> = 2.5389468e-11  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0eadd0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0eadd0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.39373335e-04 -1.31641332e-04 -1.15950750e-05 ... -7.32416564e-02
 -7.32416564e-02 -7.32416564e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 3)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336133527  <S^2> = 1.0034705  2S+1 = 2.2391699
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0eaa70> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0eaa70> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.84683071e-05 -7.80528266e-05 -7.80563243e-05 ... -2.92531360e-02
 -2.92531360e-02 -2.92531360e-02] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 3)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864075  <S^2> = 3.2152059e-13  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0eaf20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0eaf20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.56165538e-04 -7.34744214e-05 -5.30574304e-06 ... -7.93995702e-06
 -7.93995702e-06 -7.93995702e-06] = ,SCAN
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 3)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.202594e-12  2S+1 = 1
Warning: <pyscf.gto.mole.Mole object at 0x7ffeac0eb250> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffeac0eb250> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.28290753e-04 -1.41305449e-05 -6.13700492e-05 ... -2.47993463e-02
 -2.47993463e-02 -2.47993463e-02] = ,SCAN
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 3)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3152146e-11  2S+1 = 1
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.45512011e-04 -7.12775692e-05 -5.48666345e-06 ... -6.02613084e-06
 -6.02613084e-06 -6.02613084e-06] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 3)
PRE NAN FILT: tFxc.shape=(237021,), tdrho.shape=(237021, 3)
nan_filt_rho.shape=(237021,)
nan_filt_fxc.shape=(237021,)
tFxc.shape=(237021,), tdrho.shape=(237021, 3)
inp[0].shape = (237021, 3)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 0.3728621146944484
0, epoch_train_loss=0.3728621146944484
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 0.2855422337871976
1, epoch_train_loss=0.2855422337871976
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 0.2118083009855103
2, epoch_train_loss=0.2118083009855103
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 0.16880768616960695
3, epoch_train_loss=0.16880768616960695
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 0.13646048725186966
4, epoch_train_loss=0.13646048725186966
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 0.09986100284786377
5, epoch_train_loss=0.09986100284786377
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 0.06969580515970862
6, epoch_train_loss=0.06969580515970862
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.04911163452127574
7, epoch_train_loss=0.04911163452127574
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.033884070767576276
8, epoch_train_loss=0.033884070767576276
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.021788526632113503
9, epoch_train_loss=0.021788526632113503
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.012729201799961681
10, epoch_train_loss=0.012729201799961681
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.006791944930947394
11, epoch_train_loss=0.006791944930947394
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.003477952800438089
12, epoch_train_loss=0.003477952800438089
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.0018909198933812284
13, epoch_train_loss=0.0018909198933812284
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.0012103678980823556
14, epoch_train_loss=0.0012103678980823556
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.0009326224415143844
15, epoch_train_loss=0.0009326224415143844
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.0008181355179019865
16, epoch_train_loss=0.0008181355179019865
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.0007697715046912293
17, epoch_train_loss=0.0007697715046912293
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.0007489494181056799
18, epoch_train_loss=0.0007489494181056799
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.0007397423970973714
19, epoch_train_loss=0.0007397423970973714
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.0007355055616904177
20, epoch_train_loss=0.0007355055616904177
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.0007334572793993467
21, epoch_train_loss=0.0007334572793993467
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.0007324132283472668
22, epoch_train_loss=0.0007324132283472668
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.0007318527003148666
23, epoch_train_loss=0.0007318527003148666
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.0007315368730540877
24, epoch_train_loss=0.0007315368730540877
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.0007313509659730517
25, epoch_train_loss=0.0007313509659730517
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.0007312371609434509
26, epoch_train_loss=0.0007312371609434509
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0007311650061778319
27, epoch_train_loss=0.0007311650061778319
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.0007311177929216755
28, epoch_train_loss=0.0007311177929216755
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.0007310860069794465
29, epoch_train_loss=0.0007310860069794465
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0007310640467702071
30, epoch_train_loss=0.0007310640467702071
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.0007310485132530573
31, epoch_train_loss=0.0007310485132530573
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.0007310372866041618
32, epoch_train_loss=0.0007310372866041618
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.000731029011308726
33, epoch_train_loss=0.000731029011308726
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.0007310228004616602
34, epoch_train_loss=0.0007310228004616602
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.0007310180613538694
35, epoch_train_loss=0.0007310180613538694
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.0007310143900483471
36, epoch_train_loss=0.0007310143900483471
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.0007310115062054749
37, epoch_train_loss=0.0007310115062054749
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.0007310092119428843
38, epoch_train_loss=0.0007310092119428843
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.0007310073653592628
39, epoch_train_loss=0.0007310073653592628
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.0007310058631851865
40, epoch_train_loss=0.0007310058631851865
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.0007310046292213193
41, epoch_train_loss=0.0007310046292213193
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.000731003606510685
42, epoch_train_loss=0.000731003606510685
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.0007310027519597913
43, epoch_train_loss=0.0007310027519597913
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.0007310020325905464
44, epoch_train_loss=0.0007310020325905464
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.0007310014228939694
45, epoch_train_loss=0.0007310014228939694
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.0007310009029384985
46, epoch_train_loss=0.0007310009029384985
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.0007310004570017967
47, epoch_train_loss=0.0007310004570017967
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.0007310000725701759
48, epoch_train_loss=0.0007310000725701759
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.0007309997395991658
49, epoch_train_loss=0.0007309997395991658
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.000730999449961627
50, epoch_train_loss=0.000730999449961627
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.000730999197031952
51, epoch_train_loss=0.000730999197031952
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.0007309989753793567
52, epoch_train_loss=0.0007309989753793567
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.0007309987805043147
53, epoch_train_loss=0.0007309987805043147
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.0007309986086638014
54, epoch_train_loss=0.0007309986086638014
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.0007309984567253183
55, epoch_train_loss=0.0007309984567253183
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.0007309983220523378
56, epoch_train_loss=0.0007309983220523378
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.0007309982024138719
57, epoch_train_loss=0.0007309982024138719
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0007309980959125558
58, epoch_train_loss=0.0007309980959125558
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.0007309980009270218
59, epoch_train_loss=0.0007309980009270218
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.0007309979160655722
60, epoch_train_loss=0.0007309979160655722
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.0007309978401286121
61, epoch_train_loss=0.0007309978401286121
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.0007309977720780785
62, epoch_train_loss=0.0007309977720780785
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.0007309977110123488
63, epoch_train_loss=0.0007309977110123488
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.0007309976561456303
64, epoch_train_loss=0.0007309976561456303
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0007309976067908741
65, epoch_train_loss=0.0007309976067908741
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.0007309975623455841
66, epoch_train_loss=0.0007309975623455841
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0007309975222799369
67, epoch_train_loss=0.0007309975222799369
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.0007309974861268218
68, epoch_train_loss=0.0007309974861268218
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0007309974534734386
69, epoch_train_loss=0.0007309974534734386
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0007309974239541807
70, epoch_train_loss=0.0007309974239541807
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0007309973972445908
71, epoch_train_loss=0.0007309973972445908
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0007309973730561877
72, epoch_train_loss=0.0007309973730561877
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0007309973511320389
73, epoch_train_loss=0.0007309973511320389
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0007309973312429574
74, epoch_train_loss=0.0007309973312429574
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0007309973131842076
75, epoch_train_loss=0.0007309973131842076
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0007309972967726577
76, epoch_train_loss=0.0007309972967726577
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0007309972818443072
77, epoch_train_loss=0.0007309972818443072
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.000730997268252128
78, epoch_train_loss=0.000730997268252128
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.000730997255864177
79, epoch_train_loss=0.000730997255864177
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0007309972445619412
80, epoch_train_loss=0.0007309972445619412
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.0007309972342388878
81, epoch_train_loss=0.0007309972342388878
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.00073099722479918
82, epoch_train_loss=0.00073099722479918
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.0007309972161565481
83, epoch_train_loss=0.0007309972161565481
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0007309972082332869
84, epoch_train_loss=0.0007309972082332869
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0007309972009593686
85, epoch_train_loss=0.0007309972009593686
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.0007309971942716546
86, epoch_train_loss=0.0007309971942716546
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.0007309971881131928
87, epoch_train_loss=0.0007309971881131928
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0007309971824325915
88, epoch_train_loss=0.0007309971824325915
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0007309971771834613
89, epoch_train_loss=0.0007309971771834613
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0007309971723239155
90, epoch_train_loss=0.0007309971723239155
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0007309971678161228
91, epoch_train_loss=0.0007309971678161228
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0007309971636259066
92, epoch_train_loss=0.0007309971636259066
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0007309971597223855
93, epoch_train_loss=0.0007309971597223855
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.0007309971560776524
94, epoch_train_loss=0.0007309971560776524
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0007309971526664807
95, epoch_train_loss=0.0007309971526664807
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0007309971494660671
96, epoch_train_loss=0.0007309971494660671
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.0007309971464557948
97, epoch_train_loss=0.0007309971464557948
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0007309971436170224
98, epoch_train_loss=0.0007309971436170224
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0007309971409328941
99, epoch_train_loss=0.0007309971409328941
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0007309971383881665
100, epoch_train_loss=0.0007309971383881665
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.000730997135969055
101, epoch_train_loss=0.000730997135969055
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0007309971336630925
102, epoch_train_loss=0.0007309971336630925
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.0007309971314590046
103, epoch_train_loss=0.0007309971314590046
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0007309971293465944
104, epoch_train_loss=0.0007309971293465944
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0007309971273166398
105, epoch_train_loss=0.0007309971273166398
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0007309971253608009
106, epoch_train_loss=0.0007309971253608009
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.0007309971234715349
107, epoch_train_loss=0.0007309971234715349
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0007309971216420209
108, epoch_train_loss=0.0007309971216420209
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0007309971198660903
109, epoch_train_loss=0.0007309971198660903
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.000730997118138166
110, epoch_train_loss=0.000730997118138166
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0007309971164532039
111, epoch_train_loss=0.0007309971164532039
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0007309971148066446
112, epoch_train_loss=0.0007309971148066446
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0007309971131943652
113, epoch_train_loss=0.0007309971131943652
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0007309971116126389
114, epoch_train_loss=0.0007309971116126389
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0007309971100580969
115, epoch_train_loss=0.0007309971100580969
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0007309971085276942
116, epoch_train_loss=0.0007309971085276942
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007309971070186791
117, epoch_train_loss=0.0007309971070186791
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0007309971055285651
118, epoch_train_loss=0.0007309971055285651
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007309971040551054
119, epoch_train_loss=0.0007309971040551054
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.0007309971025962703
120, epoch_train_loss=0.0007309971025962703
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007309971011502269
121, epoch_train_loss=0.0007309971011502269
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007309970997153194
122, epoch_train_loss=0.0007309970997153194
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.000730997098290053
123, epoch_train_loss=0.000730997098290053
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0007309970968730781
124, epoch_train_loss=0.0007309970968730781
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0007309970954631769
125, epoch_train_loss=0.0007309970954631769
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0007309970940592502
126, epoch_train_loss=0.0007309970940592502
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0007309970926603063
127, epoch_train_loss=0.0007309970926603063
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0007309970912654516
128, epoch_train_loss=0.0007309970912654516
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.0007309970898738794
129, epoch_train_loss=0.0007309970898738794
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0007309970884848633
130, epoch_train_loss=0.0007309970884848633
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0007309970870977485
131, epoch_train_loss=0.0007309970870977485
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007309970857119458
132, epoch_train_loss=0.0007309970857119458
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007309970843269239
133, epoch_train_loss=0.0007309970843269239
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007309970829422059
134, epoch_train_loss=0.0007309970829422059
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0007309970815573619
135, epoch_train_loss=0.0007309970815573619
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007309970801720061
136, epoch_train_loss=0.0007309970801720061
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007309970787857918
137, epoch_train_loss=0.0007309970787857918
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.000730997077398408
138, epoch_train_loss=0.000730997077398408
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007309970760095755
139, epoch_train_loss=0.0007309970760095755
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007309970746190443
140, epoch_train_loss=0.0007309970746190443
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007309970732265904
141, epoch_train_loss=0.0007309970732265904
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0007309970718320142
142, epoch_train_loss=0.0007309970718320142
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0007309970704351366
143, epoch_train_loss=0.0007309970704351366
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0007309970690357984
144, epoch_train_loss=0.0007309970690357984
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.0007309970676338574
145, epoch_train_loss=0.0007309970676338574
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0007309970662291879
146, epoch_train_loss=0.0007309970662291879
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0007309970648216778
147, epoch_train_loss=0.0007309970648216778
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.000730997063411228
148, epoch_train_loss=0.000730997063411228
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0007309970619977515
149, epoch_train_loss=0.0007309970619977515
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0007309970605811711
150, epoch_train_loss=0.0007309970605811711
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.0007309970591614192
151, epoch_train_loss=0.0007309970591614192
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0007309970577384372
152, epoch_train_loss=0.0007309970577384372
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0007309970563121739
153, epoch_train_loss=0.0007309970563121739
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0007309970548825849
154, epoch_train_loss=0.0007309970548825849
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.0007309970534496324
155, epoch_train_loss=0.0007309970534496324
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0007309970520132838
156, epoch_train_loss=0.0007309970520132838
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.0007309970505735122
157, epoch_train_loss=0.0007309970505735122
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0007309970491302947
158, epoch_train_loss=0.0007309970491302947
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0007309970476836131
159, epoch_train_loss=0.0007309970476836131
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.0007309970462334523
160, epoch_train_loss=0.0007309970462334523
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0007309970447798013
161, epoch_train_loss=0.0007309970447798013
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.0007309970433226516
162, epoch_train_loss=0.0007309970433226516
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.000730997041861997
163, epoch_train_loss=0.000730997041861997
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.000730997040397835
164, epoch_train_loss=0.000730997040397835
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0007309970389301642
165, epoch_train_loss=0.0007309970389301642
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0007309970374589856
166, epoch_train_loss=0.0007309970374589856
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.000730997035984302
167, epoch_train_loss=0.000730997035984302
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0007309970345061175
168, epoch_train_loss=0.0007309970345061175
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.000730997033024438
169, epoch_train_loss=0.000730997033024438
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0007309970315392706
170, epoch_train_loss=0.0007309970315392706
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0007309970300506233
171, epoch_train_loss=0.0007309970300506233
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.0007309970285585054
172, epoch_train_loss=0.0007309970285585054
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0007309970270629268
173, epoch_train_loss=0.0007309970270629268
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.0007309970255638985
174, epoch_train_loss=0.0007309970255638985
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0007309970240614323
175, epoch_train_loss=0.0007309970240614323
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0007309970225555402
176, epoch_train_loss=0.0007309970225555402
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.0007309970210462352
177, epoch_train_loss=0.0007309970210462352
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0007309970195335303
178, epoch_train_loss=0.0007309970195335303
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.0007309970180174398
179, epoch_train_loss=0.0007309970180174398
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0007309970164979777
180, epoch_train_loss=0.0007309970164979777
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0007309970149751584
181, epoch_train_loss=0.0007309970149751584
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.0007309970134489968
182, epoch_train_loss=0.0007309970134489968
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0007309970119195083
183, epoch_train_loss=0.0007309970119195083
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0007309970103867078
184, epoch_train_loss=0.0007309970103867078
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0007309970088506109
185, epoch_train_loss=0.0007309970088506109
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0007309970073112336
186, epoch_train_loss=0.0007309970073112336
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0007309970057685916
187, epoch_train_loss=0.0007309970057685916
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0007309970042227007
188, epoch_train_loss=0.0007309970042227007
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.0007309970026735772
189, epoch_train_loss=0.0007309970026735772
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.0007309970011212372
190, epoch_train_loss=0.0007309970011212372
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0007309969995656967
191, epoch_train_loss=0.0007309969995656967
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.0007309969980069723
192, epoch_train_loss=0.0007309969980069723
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0007309969964450802
193, epoch_train_loss=0.0007309969964450802
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.000730996994880037
194, epoch_train_loss=0.000730996994880037
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0007309969933118585
195, epoch_train_loss=0.0007309969933118585
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.0007309969917405613
196, epoch_train_loss=0.0007309969917405613
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.0007309969901661619
197, epoch_train_loss=0.0007309969901661619
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.0007309969885886766
198, epoch_train_loss=0.0007309969885886766
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.0007309969870081216
199, epoch_train_loss=0.0007309969870081216
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0007309969854245133
200, epoch_train_loss=0.0007309969854245133
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.000730996983837868
201, epoch_train_loss=0.000730996983837868
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0007309969822482019
202, epoch_train_loss=0.0007309969822482019
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0007309969806555311
203, epoch_train_loss=0.0007309969806555311
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.0007309969790598718
204, epoch_train_loss=0.0007309969790598718
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0007309969774612401
205, epoch_train_loss=0.0007309969774612401
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0007309969758596521
206, epoch_train_loss=0.0007309969758596521
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0007309969742551241
207, epoch_train_loss=0.0007309969742551241
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.0007309969726476715
208, epoch_train_loss=0.0007309969726476715
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0007309969710373107
209, epoch_train_loss=0.0007309969710373107
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0007309969694240573
210, epoch_train_loss=0.0007309969694240573
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.000730996967807927
211, epoch_train_loss=0.000730996967807927
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.0007309969661889357
212, epoch_train_loss=0.0007309969661889357
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.0007309969645670993
213, epoch_train_loss=0.0007309969645670993
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0007309969629424327
214, epoch_train_loss=0.0007309969629424327
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0007309969613149522
215, epoch_train_loss=0.0007309969613149522
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.0007309969596846726
216, epoch_train_loss=0.0007309969596846726
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.00073099695805161
217, epoch_train_loss=0.00073099695805161
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0007309969564157793
218, epoch_train_loss=0.0007309969564157793
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0007309969547771957
219, epoch_train_loss=0.0007309969547771957
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.0007309969531358745
220, epoch_train_loss=0.0007309969531358745
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0007309969514918313
221, epoch_train_loss=0.0007309969514918313
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.0007309969498450807
222, epoch_train_loss=0.0007309969498450807
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.0007309969481956376
223, epoch_train_loss=0.0007309969481956376
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.0007309969465435174
224, epoch_train_loss=0.0007309969465435174
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.0007309969448887349
225, epoch_train_loss=0.0007309969448887349
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.0007309969432313048
226, epoch_train_loss=0.0007309969432313048
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.0007309969415712418
227, epoch_train_loss=0.0007309969415712418
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.0007309969399085604
228, epoch_train_loss=0.0007309969399085604
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0007309969382432757
229, epoch_train_loss=0.0007309969382432757
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.0007309969365754022
230, epoch_train_loss=0.0007309969365754022
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.0007309969349049543
231, epoch_train_loss=0.0007309969349049543
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.0007309969332319461
232, epoch_train_loss=0.0007309969332319461
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0007309969315563924
233, epoch_train_loss=0.0007309969315563924
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0007309969298783074
234, epoch_train_loss=0.0007309969298783074
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0007309969281977055
235, epoch_train_loss=0.0007309969281977055
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.0007309969265146005
236, epoch_train_loss=0.0007309969265146005
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0007309969248290068
237, epoch_train_loss=0.0007309969248290068
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.0007309969231409383
238, epoch_train_loss=0.0007309969231409383
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.0007309969214504093
239, epoch_train_loss=0.0007309969214504093
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.0007309969197574332
240, epoch_train_loss=0.0007309969197574332
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.0007309969180620245
241, epoch_train_loss=0.0007309969180620245
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0007309969163641967
242, epoch_train_loss=0.0007309969163641967
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.0007309969146639635
243, epoch_train_loss=0.0007309969146639635
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0007309969129613387
244, epoch_train_loss=0.0007309969129613387
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.000730996911256336
245, epoch_train_loss=0.000730996911256336
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.0007309969095489688
246, epoch_train_loss=0.0007309969095489688
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0007309969078392505
247, epoch_train_loss=0.0007309969078392505
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.000730996906127195
248, epoch_train_loss=0.000730996906127195
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.0007309969044128156
249, epoch_train_loss=0.0007309969044128156
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0007309969026961253
250, epoch_train_loss=0.0007309969026961253
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0007309969009771378
251, epoch_train_loss=0.0007309969009771378
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0007309968992558662
252, epoch_train_loss=0.0007309968992558662
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.0007309968975323237
253, epoch_train_loss=0.0007309968975323237
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.0007309968958065233
254, epoch_train_loss=0.0007309968958065233
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0007309968940784782
255, epoch_train_loss=0.0007309968940784782
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.0007309968923482012
256, epoch_train_loss=0.0007309968923482012
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0007309968906157055
257, epoch_train_loss=0.0007309968906157055
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.000730996888881004
258, epoch_train_loss=0.000730996888881004
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0007309968871441094
259, epoch_train_loss=0.0007309968871441094
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.0007309968854050346
260, epoch_train_loss=0.0007309968854050346
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.0007309968836637923
261, epoch_train_loss=0.0007309968836637923
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.0007309968819203953
262, epoch_train_loss=0.0007309968819203953
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.0007309968801748562
263, epoch_train_loss=0.0007309968801748562
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.0007309968784271875
264, epoch_train_loss=0.0007309968784271875
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.0007309968766774018
265, epoch_train_loss=0.0007309968766774018
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0007309968749255115
266, epoch_train_loss=0.0007309968749255115
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.0007309968731715294
267, epoch_train_loss=0.0007309968731715294
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0007309968714154675
268, epoch_train_loss=0.0007309968714154675
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.000730996869657338
269, epoch_train_loss=0.000730996869657338
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.0007309968678971537
270, epoch_train_loss=0.0007309968678971537
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.0007309968661349265
271, epoch_train_loss=0.0007309968661349265
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0007309968643706686
272, epoch_train_loss=0.0007309968643706686
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.0007309968626043925
273, epoch_train_loss=0.0007309968626043925
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0007309968608361096
274, epoch_train_loss=0.0007309968608361096
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0007309968590658325
275, epoch_train_loss=0.0007309968590658325
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.000730996857293573
276, epoch_train_loss=0.000730996857293573
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.0007309968555193429
277, epoch_train_loss=0.0007309968555193429
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0007309968537431547
278, epoch_train_loss=0.0007309968537431547
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.0007309968519650195
279, epoch_train_loss=0.0007309968519650195
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.0007309968501849497
280, epoch_train_loss=0.0007309968501849497
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.0007309968484029565
281, epoch_train_loss=0.0007309968484029565
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.0007309968466190522
282, epoch_train_loss=0.0007309968466190522
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.0007309968448332481
283, epoch_train_loss=0.0007309968448332481
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0007309968430455556
284, epoch_train_loss=0.0007309968430455556
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0007309968412559871
285, epoch_train_loss=0.0007309968412559871
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.0007309968394645532
286, epoch_train_loss=0.0007309968394645532
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.000730996837671266
287, epoch_train_loss=0.000730996837671266
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.0007309968358761368
288, epoch_train_loss=0.0007309968358761368
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0007309968340791767
289, epoch_train_loss=0.0007309968340791767
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.0007309968322803974
290, epoch_train_loss=0.0007309968322803974
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.0007309968304798101
291, epoch_train_loss=0.0007309968304798101
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.0007309968286774263
292, epoch_train_loss=0.0007309968286774263
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.000730996826873257
293, epoch_train_loss=0.000730996826873257
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.0007309968250673131
294, epoch_train_loss=0.0007309968250673131
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.000730996823259606
295, epoch_train_loss=0.000730996823259606
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.000730996821450147
296, epoch_train_loss=0.000730996821450147
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.0007309968196389469
297, epoch_train_loss=0.0007309968196389469
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.000730996817826017
298, epoch_train_loss=0.000730996817826017
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.0007309968160113677
299, epoch_train_loss=0.0007309968160113677
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.0007309968141950104
300, epoch_train_loss=0.0007309968141950104
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0007309968123769558
301, epoch_train_loss=0.0007309968123769558
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.0007309968105572149
302, epoch_train_loss=0.0007309968105572149
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.0007309968087357983
303, epoch_train_loss=0.0007309968087357983
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.000730996806912717
304, epoch_train_loss=0.000730996806912717
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.0007309968050879817
305, epoch_train_loss=0.0007309968050879817
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.0007309968032616028
306, epoch_train_loss=0.0007309968032616028
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.000730996801433591
307, epoch_train_loss=0.000730996801433591
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.0007309967996039574
308, epoch_train_loss=0.0007309967996039574
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.000730996797772712
309, epoch_train_loss=0.000730996797772712
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0007309967959398656
310, epoch_train_loss=0.0007309967959398656
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0007309967941054285
311, epoch_train_loss=0.0007309967941054285
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.0007309967922694114
312, epoch_train_loss=0.0007309967922694114
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.0007309967904318244
313, epoch_train_loss=0.0007309967904318244
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.0007309967885926781
314, epoch_train_loss=0.0007309967885926781
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.000730996786751983
315, epoch_train_loss=0.000730996786751983
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0007309967849097489
316, epoch_train_loss=0.0007309967849097489
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.0007309967830659863
317, epoch_train_loss=0.0007309967830659863
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.0007309967812207055
318, epoch_train_loss=0.0007309967812207055
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.0007309967793739168
319, epoch_train_loss=0.0007309967793739168
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.0007309967775256299
320, epoch_train_loss=0.0007309967775256299
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.0007309967756758553
321, epoch_train_loss=0.0007309967756758553
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.000730996773824603
322, epoch_train_loss=0.000730996773824603
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0007309967719718828
323, epoch_train_loss=0.0007309967719718828
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.000730996770117705
324, epoch_train_loss=0.000730996770117705
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.0007309967682620794
325, epoch_train_loss=0.0007309967682620794
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.000730996766405016
326, epoch_train_loss=0.000730996766405016
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.0007309967645465246
327, epoch_train_loss=0.0007309967645465246
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.000730996762686615
328, epoch_train_loss=0.000730996762686615
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.0007309967608252971
329, epoch_train_loss=0.0007309967608252971
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.0007309967589625809
330, epoch_train_loss=0.0007309967589625809
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0007309967570984756
331, epoch_train_loss=0.0007309967570984756
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0007309967552329914
332, epoch_train_loss=0.0007309967552329914
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0007309967533661378
333, epoch_train_loss=0.0007309967533661378
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.0007309967514979245
334, epoch_train_loss=0.0007309967514979245
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.0007309967496283607
335, epoch_train_loss=0.0007309967496283607
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.0007309967477574567
336, epoch_train_loss=0.0007309967477574567
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0007309967458852215
337, epoch_train_loss=0.0007309967458852215
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.0007309967440116647
338, epoch_train_loss=0.0007309967440116647
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0007309967421367958
339, epoch_train_loss=0.0007309967421367958
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.0007309967402606244
340, epoch_train_loss=0.0007309967402606244
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0007309967383831597
341, epoch_train_loss=0.0007309967383831597
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.0007309967365044112
342, epoch_train_loss=0.0007309967365044112
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.000730996734624388
343, epoch_train_loss=0.000730996734624388
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.0007309967327430996
344, epoch_train_loss=0.0007309967327430996
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.000730996730860555
345, epoch_train_loss=0.000730996730860555
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.0007309967289767641
346, epoch_train_loss=0.0007309967289767641
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0007309967270917353
347, epoch_train_loss=0.0007309967270917353
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0007309967252054782
348, epoch_train_loss=0.0007309967252054782
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.0007309967233180017
349, epoch_train_loss=0.0007309967233180017
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.0007309967214293152
350, epoch_train_loss=0.0007309967214293152
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0007309967195394275
351, epoch_train_loss=0.0007309967195394275
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.0007309967176483479
352, epoch_train_loss=0.0007309967176483479
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.0007309967157560854
353, epoch_train_loss=0.0007309967157560854
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.0007309967138626485
354, epoch_train_loss=0.0007309967138626485
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.0007309967119680465
355, epoch_train_loss=0.0007309967119680465
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.0007309967100722882
356, epoch_train_loss=0.0007309967100722882
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0007309967081753826
357, epoch_train_loss=0.0007309967081753826
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.0007309967062773387
358, epoch_train_loss=0.0007309967062773387
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.0007309967043781649
359, epoch_train_loss=0.0007309967043781649
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.0007309967024778702
360, epoch_train_loss=0.0007309967024778702
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.0007309967005764633
361, epoch_train_loss=0.0007309967005764633
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.0007309966986739531
362, epoch_train_loss=0.0007309966986739531
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0007309966967703483
363, epoch_train_loss=0.0007309966967703483
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.0007309966948656573
364, epoch_train_loss=0.0007309966948656573
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.0007309966929598887
365, epoch_train_loss=0.0007309966929598887
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007309966910530515
366, epoch_train_loss=0.0007309966910530515
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0007309966891451538
367, epoch_train_loss=0.0007309966891451538
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0007309966872362045
368, epoch_train_loss=0.0007309966872362045
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0007309966853262119
369, epoch_train_loss=0.0007309966853262119
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.0007309966834151848
370, epoch_train_loss=0.0007309966834151848
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.0007309966815031312
371, epoch_train_loss=0.0007309966815031312
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.0007309966795900597
372, epoch_train_loss=0.0007309966795900597
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.0007309966776759787
373, epoch_train_loss=0.0007309966776759787
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0007309966757608966
374, epoch_train_loss=0.0007309966757608966
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0007309966738448219
375, epoch_train_loss=0.0007309966738448219
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.0007309966719277624
376, epoch_train_loss=0.0007309966719277624
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.000730996670009727
377, epoch_train_loss=0.000730996670009727
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0007309966680907234
378, epoch_train_loss=0.0007309966680907234
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0007309966661707601
379, epoch_train_loss=0.0007309966661707601
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.0007309966642498453
380, epoch_train_loss=0.0007309966642498453
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.000730996662327987
381, epoch_train_loss=0.000730996662327987
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0007309966604051935
382, epoch_train_loss=0.0007309966604051935
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0007309966584814727
383, epoch_train_loss=0.0007309966584814727
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0007309966565568328
384, epoch_train_loss=0.0007309966565568328
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0007309966546312819
385, epoch_train_loss=0.0007309966546312819
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.0007309966527048279
386, epoch_train_loss=0.0007309966527048279
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0007309966507774789
387, epoch_train_loss=0.0007309966507774789
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.0007309966488492429
388, epoch_train_loss=0.0007309966488492429
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0007309966469201277
389, epoch_train_loss=0.0007309966469201277
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0007309966449901414
390, epoch_train_loss=0.0007309966449901414
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0007309966430592914
391, epoch_train_loss=0.0007309966430592914
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.0007309966411275862
392, epoch_train_loss=0.0007309966411275862
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.000730996639195033
393, epoch_train_loss=0.000730996639195033
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007309966372616402
394, epoch_train_loss=0.0007309966372616402
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0007309966353274152
395, epoch_train_loss=0.0007309966353274152
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.0007309966333923656
396, epoch_train_loss=0.0007309966333923656
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.0007309966314564994
397, epoch_train_loss=0.0007309966314564994
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.0007309966295198241
398, epoch_train_loss=0.0007309966295198241
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0007309966275823477
399, epoch_train_loss=0.0007309966275823477
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0007309966256440775
400, epoch_train_loss=0.0007309966256440775
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0007309966237050213
401, epoch_train_loss=0.0007309966237050213
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0007309966217651866
402, epoch_train_loss=0.0007309966217651866
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.0007309966198245808
403, epoch_train_loss=0.0007309966198245808
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.0007309966178832116
404, epoch_train_loss=0.0007309966178832116
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.0007309966159410866
405, epoch_train_loss=0.0007309966159410866
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0007309966139982132
406, epoch_train_loss=0.0007309966139982132
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.0007309966120545986
407, epoch_train_loss=0.0007309966120545986
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0007309966101102509
408, epoch_train_loss=0.0007309966101102509
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0007309966081651767
409, epoch_train_loss=0.0007309966081651767
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0007309966062193839
410, epoch_train_loss=0.0007309966062193839
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.0007309966042728796
411, epoch_train_loss=0.0007309966042728796
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.000730996602325671
412, epoch_train_loss=0.000730996602325671
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0007309966003777658
413, epoch_train_loss=0.0007309966003777658
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0007309965984291708
414, epoch_train_loss=0.0007309965984291708
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0007309965964798936
415, epoch_train_loss=0.0007309965964798936
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0007309965945299415
416, epoch_train_loss=0.0007309965945299415
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.0007309965925793214
417, epoch_train_loss=0.0007309965925793214
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.0007309965906280406
418, epoch_train_loss=0.0007309965906280406
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.000730996588676106
419, epoch_train_loss=0.000730996588676106
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.0007309965867235254
420, epoch_train_loss=0.0007309965867235254
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.0007309965847703053
421, epoch_train_loss=0.0007309965847703053
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.000730996582816453
422, epoch_train_loss=0.000730996582816453
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0007309965808619754
423, epoch_train_loss=0.0007309965808619754
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.0007309965789068797
424, epoch_train_loss=0.0007309965789068797
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.0007309965769511727
425, epoch_train_loss=0.0007309965769511727
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0007309965749948615
426, epoch_train_loss=0.0007309965749948615
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.0007309965730379532
427, epoch_train_loss=0.0007309965730379532
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.0007309965710804543
428, epoch_train_loss=0.0007309965710804543
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.000730996569122372
429, epoch_train_loss=0.000730996569122372
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.0007309965671637132
430, epoch_train_loss=0.0007309965671637132
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.0007309965652044845
431, epoch_train_loss=0.0007309965652044845
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.000730996563244693
432, epoch_train_loss=0.000730996563244693
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.0007309965612843455
433, epoch_train_loss=0.0007309965612843455
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0007309965593234486
434, epoch_train_loss=0.0007309965593234486
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.0007309965573620091
435, epoch_train_loss=0.0007309965573620091
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.000730996555400034
436, epoch_train_loss=0.000730996555400034
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.0007309965534375298
437, epoch_train_loss=0.0007309965534375298
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0007309965514745031
438, epoch_train_loss=0.0007309965514745031
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0007309965495109609
439, epoch_train_loss=0.0007309965495109609
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.0007309965475469095
440, epoch_train_loss=0.0007309965475469095
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.0007309965455823557
441, epoch_train_loss=0.0007309965455823557
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0007309965436173059
442, epoch_train_loss=0.0007309965436173059
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0007309965416517668
443, epoch_train_loss=0.0007309965416517668
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.0007309965396857448
444, epoch_train_loss=0.0007309965396857448
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.0007309965377192467
445, epoch_train_loss=0.0007309965377192467
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0007309965357522788
446, epoch_train_loss=0.0007309965357522788
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.0007309965337848477
447, epoch_train_loss=0.0007309965337848477
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.0007309965318169599
448, epoch_train_loss=0.0007309965318169599
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.0007309965298486219
449, epoch_train_loss=0.0007309965298486219
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.0007309965278798398
450, epoch_train_loss=0.0007309965278798398
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0007309965259106201
451, epoch_train_loss=0.0007309965259106201
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.0007309965239409693
452, epoch_train_loss=0.0007309965239409693
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0007309965219708936
453, epoch_train_loss=0.0007309965219708936
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0007309965200003994
454, epoch_train_loss=0.0007309965200003994
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0007309965180294932
455, epoch_train_loss=0.0007309965180294932
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.000730996516058181
456, epoch_train_loss=0.000730996516058181
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0007309965140864691
457, epoch_train_loss=0.0007309965140864691
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.0007309965121143638
458, epoch_train_loss=0.0007309965121143638
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.0007309965101418714
459, epoch_train_loss=0.0007309965101418714
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.0007309965081689979
460, epoch_train_loss=0.0007309965081689979
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.0007309965061957494
461, epoch_train_loss=0.0007309965061957494
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0007309965042221324
462, epoch_train_loss=0.0007309965042221324
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0007309965022481527
463, epoch_train_loss=0.0007309965022481527
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.0007309965002738169
464, epoch_train_loss=0.0007309965002738169
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0007309964982991306
465, epoch_train_loss=0.0007309964982991306
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0007309964963240997
466, epoch_train_loss=0.0007309964963240997
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.0007309964943487307
467, epoch_train_loss=0.0007309964943487307
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.0007309964923730296
468, epoch_train_loss=0.0007309964923730296
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0007309964903970021
469, epoch_train_loss=0.0007309964903970021
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.0007309964884206543
470, epoch_train_loss=0.0007309964884206543
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.0007309964864439924
471, epoch_train_loss=0.0007309964864439924
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.000730996484467022
472, epoch_train_loss=0.000730996484467022
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.0007309964824897493
473, epoch_train_loss=0.0007309964824897493
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0007309964805121799
474, epoch_train_loss=0.0007309964805121799
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.00073099647853432
475, epoch_train_loss=0.00073099647853432
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.000730996476556175
476, epoch_train_loss=0.000730996476556175
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.000730996474577751
477, epoch_train_loss=0.000730996474577751
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.0007309964725990541
478, epoch_train_loss=0.0007309964725990541
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.0007309964706200897
479, epoch_train_loss=0.0007309964706200897
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.0007309964686408636
480, epoch_train_loss=0.0007309964686408636
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.0007309964666613817
481, epoch_train_loss=0.0007309964666613817
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.0007309964646816496
482, epoch_train_loss=0.0007309964646816496
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.0007309964627016732
483, epoch_train_loss=0.0007309964627016732
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.000730996460721458
484, epoch_train_loss=0.000730996460721458
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.00073099645874101
485, epoch_train_loss=0.00073099645874101
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.0007309964567603342
486, epoch_train_loss=0.0007309964567603342
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0007309964547794368
487, epoch_train_loss=0.0007309964547794368
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0007309964527983232
488, epoch_train_loss=0.0007309964527983232
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.0007309964508169991
489, epoch_train_loss=0.0007309964508169991
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0007309964488354698
490, epoch_train_loss=0.0007309964488354698
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0007309964468537411
491, epoch_train_loss=0.0007309964468537411
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.0007309964448718187
492, epoch_train_loss=0.0007309964448718187
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0007309964428897077
493, epoch_train_loss=0.0007309964428897077
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0007309964409074138
494, epoch_train_loss=0.0007309964409074138
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.0007309964389249424
495, epoch_train_loss=0.0007309964389249424
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0007309964369422992
496, epoch_train_loss=0.0007309964369422992
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0007309964349594891
497, epoch_train_loss=0.0007309964349594891
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.0007309964329765182
498, epoch_train_loss=0.0007309964329765182
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.0007309964309933914
499, epoch_train_loss=0.0007309964309933914
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.000730996429010114
500, epoch_train_loss=0.000730996429010114
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.0007309964270266918
501, epoch_train_loss=0.0007309964270266918
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.00073099642504313
502, epoch_train_loss=0.00073099642504313
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.0007309964230594335
503, epoch_train_loss=0.0007309964230594335
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0007309964210756081
504, epoch_train_loss=0.0007309964210756081
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.0007309964190916592
505, epoch_train_loss=0.0007309964190916592
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.0007309964171075911
506, epoch_train_loss=0.0007309964171075911
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.0007309964151234104
507, epoch_train_loss=0.0007309964151234104
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.0007309964131391213
508, epoch_train_loss=0.0007309964131391213
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.0007309964111547294
509, epoch_train_loss=0.0007309964111547294
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.0007309964091702397
510, epoch_train_loss=0.0007309964091702397
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.0007309964071856575
511, epoch_train_loss=0.0007309964071856575
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.000730996405200988
512, epoch_train_loss=0.000730996405200988
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.0007309964032162364
513, epoch_train_loss=0.0007309964032162364
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0007309964012314076
514, epoch_train_loss=0.0007309964012314076
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.0007309963992465067
515, epoch_train_loss=0.0007309963992465067
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.000730996397261539
516, epoch_train_loss=0.000730996397261539
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0007309963952765093
517, epoch_train_loss=0.0007309963952765093
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.0007309963932914229
518, epoch_train_loss=0.0007309963932914229
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.0007309963913062842
519, epoch_train_loss=0.0007309963913062842
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.000730996389321099
520, epoch_train_loss=0.000730996389321099
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.0007309963873358719
521, epoch_train_loss=0.0007309963873358719
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.000730996385350608
522, epoch_train_loss=0.000730996385350608
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0007309963833653122
523, epoch_train_loss=0.0007309963833653122
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.0007309963813799893
524, epoch_train_loss=0.0007309963813799893
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0007309963793946441
525, epoch_train_loss=0.0007309963793946441
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.0007309963774092819
526, epoch_train_loss=0.0007309963774092819
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.0007309963754239073
527, epoch_train_loss=0.0007309963754239073
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.0007309963734385253
528, epoch_train_loss=0.0007309963734385253
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0007309963714531405
529, epoch_train_loss=0.0007309963714531405
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.0007309963694677581
530, epoch_train_loss=0.0007309963694677581
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.0007309963674823829
531, epoch_train_loss=0.0007309963674823829
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.000730996365497019
532, epoch_train_loss=0.000730996365497019
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.0007309963635116719
533, epoch_train_loss=0.0007309963635116719
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.0007309963615263463
534, epoch_train_loss=0.0007309963615263463
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.0007309963595410464
535, epoch_train_loss=0.0007309963595410464
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0007309963575557773
536, epoch_train_loss=0.0007309963575557773
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.000730996355570544
537, epoch_train_loss=0.000730996355570544
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.0007309963535853505
538, epoch_train_loss=0.0007309963535853505
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.000730996351600202
539, epoch_train_loss=0.000730996351600202
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.000730996349615103
540, epoch_train_loss=0.000730996349615103
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.000730996347630058
541, epoch_train_loss=0.000730996347630058
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.0007309963456450716
542, epoch_train_loss=0.0007309963456450716
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0007309963436601487
543, epoch_train_loss=0.0007309963436601487
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.0007309963416752937
544, epoch_train_loss=0.0007309963416752937
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.000730996339690511
545, epoch_train_loss=0.000730996339690511
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.0007309963377058054
546, epoch_train_loss=0.0007309963377058054
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.0007309963357211815
547, epoch_train_loss=0.0007309963357211815
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.0007309963337366435
548, epoch_train_loss=0.0007309963337366435
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.000730996331752196
549, epoch_train_loss=0.000730996331752196
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.0007309963297678435
550, epoch_train_loss=0.0007309963297678435
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0007309963277835906
551, epoch_train_loss=0.0007309963277835906
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.0007309963257994418
552, epoch_train_loss=0.0007309963257994418
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0007309963238154012
553, epoch_train_loss=0.0007309963238154012
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.0007309963218314734
554, epoch_train_loss=0.0007309963218314734
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.0007309963198476627
555, epoch_train_loss=0.0007309963198476627
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0007309963178639738
556, epoch_train_loss=0.0007309963178639738
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.0007309963158804108
557, epoch_train_loss=0.0007309963158804108
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.000730996313896978
558, epoch_train_loss=0.000730996313896978
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.0007309963119136798
559, epoch_train_loss=0.0007309963119136798
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.0007309963099305206
560, epoch_train_loss=0.0007309963099305206
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.0007309963079475047
561, epoch_train_loss=0.0007309963079475047
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.0007309963059646363
562, epoch_train_loss=0.0007309963059646363
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.0007309963039819195
563, epoch_train_loss=0.0007309963039819195
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.0007309963019993589
564, epoch_train_loss=0.0007309963019993589
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.0007309963000169586
565, epoch_train_loss=0.0007309963000169586
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.0007309962980347228
566, epoch_train_loss=0.0007309962980347228
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0007309962960526556
567, epoch_train_loss=0.0007309962960526556
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0007309962940707616
568, epoch_train_loss=0.0007309962940707616
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.0007309962920890445
569, epoch_train_loss=0.0007309962920890445
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0007309962901075087
570, epoch_train_loss=0.0007309962901075087
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.0007309962881261582
571, epoch_train_loss=0.0007309962881261582
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.0007309962861449972
572, epoch_train_loss=0.0007309962861449972
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.0007309962841640297
573, epoch_train_loss=0.0007309962841640297
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.0007309962821832601
574, epoch_train_loss=0.0007309962821832601
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.0007309962802026922
575, epoch_train_loss=0.0007309962802026922
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.0007309962782223301
576, epoch_train_loss=0.0007309962782223301
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.0007309962762421781
577, epoch_train_loss=0.0007309962762421781
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.0007309962742622399
578, epoch_train_loss=0.0007309962742622399
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.0007309962722825197
579, epoch_train_loss=0.0007309962722825197
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0007309962703030216
580, epoch_train_loss=0.0007309962703030216
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.0007309962683237494
581, epoch_train_loss=0.0007309962683237494
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.000730996266344707
582, epoch_train_loss=0.000730996266344707
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.0007309962643658987
583, epoch_train_loss=0.0007309962643658987
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.000730996262387328
584, epoch_train_loss=0.000730996262387328
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.0007309962604089993
585, epoch_train_loss=0.0007309962604089993
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.0007309962584309163
586, epoch_train_loss=0.0007309962584309163
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.0007309962564530827
587, epoch_train_loss=0.0007309962564530827
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.0007309962544755026
588, epoch_train_loss=0.0007309962544755026
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.0007309962524981798
589, epoch_train_loss=0.0007309962524981798
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.0007309962505211183
590, epoch_train_loss=0.0007309962505211183
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0007309962485443217
591, epoch_train_loss=0.0007309962485443217
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.0007309962465677939
592, epoch_train_loss=0.0007309962465677939
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.0007309962445915388
593, epoch_train_loss=0.0007309962445915388
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.0007309962426155603
594, epoch_train_loss=0.0007309962426155603
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.0007309962406398617
595, epoch_train_loss=0.0007309962406398617
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.0007309962386644472
596, epoch_train_loss=0.0007309962386644472
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0007309962366893204
597, epoch_train_loss=0.0007309962366893204
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.0007309962347144852
598, epoch_train_loss=0.0007309962347144852
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.000730996232739945
599, epoch_train_loss=0.000730996232739945
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.0007309962307657039
600, epoch_train_loss=0.0007309962307657039
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.0007309962287917653
601, epoch_train_loss=0.0007309962287917653
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0007309962268181329
602, epoch_train_loss=0.0007309962268181329
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.0007309962248448107
603, epoch_train_loss=0.0007309962248448107
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.000730996222871802
604, epoch_train_loss=0.000730996222871802
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.0007309962208991102
605, epoch_train_loss=0.0007309962208991102
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.0007309962189267397
606, epoch_train_loss=0.0007309962189267397
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.0007309962169546936
607, epoch_train_loss=0.0007309962169546936
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.0007309962149829755
608, epoch_train_loss=0.0007309962149829755
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.000730996213011589
609, epoch_train_loss=0.000730996213011589
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.0007309962110405375
610, epoch_train_loss=0.0007309962110405375
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0007309962090698251
611, epoch_train_loss=0.0007309962090698251
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.0007309962070994549
612, epoch_train_loss=0.0007309962070994549
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.0007309962051294303
613, epoch_train_loss=0.0007309962051294303
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.0007309962031597553
614, epoch_train_loss=0.0007309962031597553
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.000730996201190433
615, epoch_train_loss=0.000730996201190433
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.0007309961992214672
616, epoch_train_loss=0.0007309961992214672
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.0007309961972528609
617, epoch_train_loss=0.0007309961972528609
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.0007309961952846178
618, epoch_train_loss=0.0007309961952846178
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.0007309961933167417
619, epoch_train_loss=0.0007309961933167417
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.0007309961913492354
620, epoch_train_loss=0.0007309961913492354
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.0007309961893821027
621, epoch_train_loss=0.0007309961893821027
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.000730996187415347
622, epoch_train_loss=0.000730996187415347
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.0007309961854489715
623, epoch_train_loss=0.0007309961854489715
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.0007309961834829796
624, epoch_train_loss=0.0007309961834829796
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.000730996181517375
625, epoch_train_loss=0.000730996181517375
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.0007309961795521606
626, epoch_train_loss=0.0007309961795521606
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.0007309961775873399
627, epoch_train_loss=0.0007309961775873399
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0007309961756229164
628, epoch_train_loss=0.0007309961756229164
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0007309961736588933
629, epoch_train_loss=0.0007309961736588933
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.0007309961716952737
630, epoch_train_loss=0.0007309961716952737
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.000730996169732061
631, epoch_train_loss=0.000730996169732061
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.0007309961677692586
632, epoch_train_loss=0.0007309961677692586
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.0007309961658068696
633, epoch_train_loss=0.0007309961658068696
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.0007309961638448973
634, epoch_train_loss=0.0007309961638448973
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.0007309961618833449
635, epoch_train_loss=0.0007309961618833449
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.0007309961599222156
636, epoch_train_loss=0.0007309961599222156
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.0007309961579615126
637, epoch_train_loss=0.0007309961579615126
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.0007309961560012393
638, epoch_train_loss=0.0007309961560012393
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.0007309961540413987
639, epoch_train_loss=0.0007309961540413987
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.0007309961520819938
640, epoch_train_loss=0.0007309961520819938
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.0007309961501230282
641, epoch_train_loss=0.0007309961501230282
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.0007309961481645046
642, epoch_train_loss=0.0007309961481645046
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.0007309961462064262
643, epoch_train_loss=0.0007309961462064262
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.0007309961442487962
644, epoch_train_loss=0.0007309961442487962
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0007309961422916179
645, epoch_train_loss=0.0007309961422916179
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0007309961403348939
646, epoch_train_loss=0.0007309961403348939
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.0007309961383786278
647, epoch_train_loss=0.0007309961383786278
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0007309961364228225
648, epoch_train_loss=0.0007309961364228225
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.0007309961344674808
649, epoch_train_loss=0.0007309961344674808
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.0007309961325126061
650, epoch_train_loss=0.0007309961325126061
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.0007309961305582009
651, epoch_train_loss=0.0007309961305582009
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.0007309961286042687
652, epoch_train_loss=0.0007309961286042687
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.0007309961266508124
653, epoch_train_loss=0.0007309961266508124
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.0007309961246978349
654, epoch_train_loss=0.0007309961246978349
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0007309961227453394
655, epoch_train_loss=0.0007309961227453394
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.0007309961207933285
656, epoch_train_loss=0.0007309961207933285
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.0007309961188418055
657, epoch_train_loss=0.0007309961188418055
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.0007309961168907729
658, epoch_train_loss=0.0007309961168907729
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.000730996114940234
659, epoch_train_loss=0.000730996114940234
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.0007309961129901918
660, epoch_train_loss=0.0007309961129901918
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0007309961110406489
661, epoch_train_loss=0.0007309961110406489
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.0007309961090916083
662, epoch_train_loss=0.0007309961090916083
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0007309961071430728
663, epoch_train_loss=0.0007309961071430728
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0007309961051950455
664, epoch_train_loss=0.0007309961051950455
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.000730996103247529
665, epoch_train_loss=0.000730996103247529
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.0007309961013005266
666, epoch_train_loss=0.0007309961013005266
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0007309960993540405
667, epoch_train_loss=0.0007309960993540405
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.0007309960974080739
668, epoch_train_loss=0.0007309960974080739
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.0007309960954626294
669, epoch_train_loss=0.0007309960954626294
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.00073099609351771
670, epoch_train_loss=0.00073099609351771
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.0007309960915733185
671, epoch_train_loss=0.0007309960915733185
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.0007309960896294575
672, epoch_train_loss=0.0007309960896294575
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.0007309960876861298
673, epoch_train_loss=0.0007309960876861298
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.0007309960857433381
674, epoch_train_loss=0.0007309960857433381
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.0007309960838010852
675, epoch_train_loss=0.0007309960838010852
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0007309960818593741
676, epoch_train_loss=0.0007309960818593741
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.0007309960799182069
677, epoch_train_loss=0.0007309960799182069
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.000730996077977587
678, epoch_train_loss=0.000730996077977587
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.0007309960760375165
679, epoch_train_loss=0.0007309960760375165
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0007309960740979986
680, epoch_train_loss=0.0007309960740979986
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0007309960721590354
681, epoch_train_loss=0.0007309960721590354
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0007309960702206301
682, epoch_train_loss=0.0007309960702206301
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.000730996068282785
683, epoch_train_loss=0.000730996068282785
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0007309960663455028
684, epoch_train_loss=0.0007309960663455028
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.0007309960644087863
685, epoch_train_loss=0.0007309960644087863
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.0007309960624726379
686, epoch_train_loss=0.0007309960624726379
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0007309960605370602
687, epoch_train_loss=0.0007309960605370602
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.000730996058602056
688, epoch_train_loss=0.000730996058602056
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.0007309960566676278
689, epoch_train_loss=0.0007309960566676278
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.000730996054733778
690, epoch_train_loss=0.000730996054733778
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0007309960528005093
691, epoch_train_loss=0.0007309960528005093
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.0007309960508678243
692, epoch_train_loss=0.0007309960508678243
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.0007309960489357253
693, epoch_train_loss=0.0007309960489357253
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.000730996047004215
694, epoch_train_loss=0.000730996047004215
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0007309960450732959
695, epoch_train_loss=0.0007309960450732959
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0007309960431429705
696, epoch_train_loss=0.0007309960431429705
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.0007309960412132414
697, epoch_train_loss=0.0007309960412132414
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.0007309960392841107
698, epoch_train_loss=0.0007309960392841107
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0007309960373555813
699, epoch_train_loss=0.0007309960373555813
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.0007309960354276555
700, epoch_train_loss=0.0007309960354276555
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.0007309960335003357
701, epoch_train_loss=0.0007309960335003357
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.0007309960315736244
702, epoch_train_loss=0.0007309960315736244
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0007309960296475239
703, epoch_train_loss=0.0007309960296475239
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.0007309960277220369
704, epoch_train_loss=0.0007309960277220369
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.0007309960257971653
705, epoch_train_loss=0.0007309960257971653
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0007309960238729121
706, epoch_train_loss=0.0007309960238729121
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0007309960219492793
707, epoch_train_loss=0.0007309960219492793
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0007309960200262695
708, epoch_train_loss=0.0007309960200262695
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.0007309960181038849
709, epoch_train_loss=0.0007309960181038849
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.0007309960161821276
710, epoch_train_loss=0.0007309960161821276
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.0007309960142610006
711, epoch_train_loss=0.0007309960142610006
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0007309960123405057
712, epoch_train_loss=0.0007309960123405057
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.0007309960104206453
713, epoch_train_loss=0.0007309960104206453
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.0007309960085014219
714, epoch_train_loss=0.0007309960085014219
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.0007309960065828378
715, epoch_train_loss=0.0007309960065828378
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.0007309960046648952
716, epoch_train_loss=0.0007309960046648952
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0007309960027475962
717, epoch_train_loss=0.0007309960027475962
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.0007309960008309432
718, epoch_train_loss=0.0007309960008309432
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0007309959989149387
719, epoch_train_loss=0.0007309959989149387
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.0007309959969995846
720, epoch_train_loss=0.0007309959969995846
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0007309959950848834
721, epoch_train_loss=0.0007309959950848834
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.0007309959931708369
722, epoch_train_loss=0.0007309959931708369
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.0007309959912574479
723, epoch_train_loss=0.0007309959912574479
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.0007309959893447183
724, epoch_train_loss=0.0007309959893447183
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.0007309959874326504
725, epoch_train_loss=0.0007309959874326504
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0007309959855212463
726, epoch_train_loss=0.0007309959855212463
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.0007309959836105082
727, epoch_train_loss=0.0007309959836105082
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0007309959817004384
728, epoch_train_loss=0.0007309959817004384
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0007309959797910386
729, epoch_train_loss=0.0007309959797910386
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.0007309959778823116
730, epoch_train_loss=0.0007309959778823116
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.000730995975974259
731, epoch_train_loss=0.000730995975974259
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.0007309959740668834
732, epoch_train_loss=0.0007309959740668834
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.0007309959721601868
733, epoch_train_loss=0.0007309959721601868
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.0007309959702541709
734, epoch_train_loss=0.0007309959702541709
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.000730995968348838
735, epoch_train_loss=0.000730995968348838
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.0007309959664441903
736, epoch_train_loss=0.0007309959664441903
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0007309959645402299
737, epoch_train_loss=0.0007309959645402299
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.000730995962636959
738, epoch_train_loss=0.000730995962636959
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.0007309959607343794
739, epoch_train_loss=0.0007309959607343794
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.0007309959588324931
740, epoch_train_loss=0.0007309959588324931
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.0007309959569313027
741, epoch_train_loss=0.0007309959569313027
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.0007309959550308098
742, epoch_train_loss=0.0007309959550308098
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.0007309959531310161
743, epoch_train_loss=0.0007309959531310161
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.0007309959512319242
744, epoch_train_loss=0.0007309959512319242
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.0007309959493335358
745, epoch_train_loss=0.0007309959493335358
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.0007309959474358529
746, epoch_train_loss=0.0007309959474358529
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.0007309959455388776
747, epoch_train_loss=0.0007309959455388776
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.0007309959436426117
748, epoch_train_loss=0.0007309959436426117
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0007309959417470573
749, epoch_train_loss=0.0007309959417470573
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0007309959398522165
750, epoch_train_loss=0.0007309959398522165
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0007309959379580909
751, epoch_train_loss=0.0007309959379580909
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.0007309959360646829
752, epoch_train_loss=0.0007309959360646829
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.0007309959341719941
753, epoch_train_loss=0.0007309959341719941
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.0007309959322800265
754, epoch_train_loss=0.0007309959322800265
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.000730995930388782
755, epoch_train_loss=0.000730995930388782
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.0007309959284982625
756, epoch_train_loss=0.0007309959284982625
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.0007309959266084698
757, epoch_train_loss=0.0007309959266084698
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.0007309959247194061
758, epoch_train_loss=0.0007309959247194061
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.0007309959228310731
759, epoch_train_loss=0.0007309959228310731
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.0007309959209434724
760, epoch_train_loss=0.0007309959209434724
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.0007309959190566061
761, epoch_train_loss=0.0007309959190566061
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.0007309959171704761
762, epoch_train_loss=0.0007309959171704761
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 0.0007309959152850843
763, epoch_train_loss=0.0007309959152850843
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 0.0007309959134004323
764, epoch_train_loss=0.0007309959134004323
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.0007309959115165221
765, epoch_train_loss=0.0007309959115165221
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 0.0007309959096333556
766, epoch_train_loss=0.0007309959096333556
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 0.0007309959077509344
767, epoch_train_loss=0.0007309959077509344
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 0.0007309959058692602
768, epoch_train_loss=0.0007309959058692602
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 0.000730995903988335
769, epoch_train_loss=0.000730995903988335
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 0.0007309959021081605
770, epoch_train_loss=0.0007309959021081605
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 0.0007309959002287388
771, epoch_train_loss=0.0007309959002287388
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 0.0007309958983500709
772, epoch_train_loss=0.0007309958983500709
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 0.0007309958964721591
773, epoch_train_loss=0.0007309958964721591
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 0.0007309958945950051
774, epoch_train_loss=0.0007309958945950051
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 0.0007309958927186106
775, epoch_train_loss=0.0007309958927186106
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 0.0007309958908429775
776, epoch_train_loss=0.0007309958908429775
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 0.0007309958889681072
777, epoch_train_loss=0.0007309958889681072
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 0.0007309958870940014
778, epoch_train_loss=0.0007309958870940014
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 0.000730995885220662
779, epoch_train_loss=0.000730995885220662
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 0.0007309958833480907
780, epoch_train_loss=0.0007309958833480907
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 0.0007309958814762889
781, epoch_train_loss=0.0007309958814762889
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 0.0007309958796052587
782, epoch_train_loss=0.0007309958796052587
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 0.0007309958777350013
783, epoch_train_loss=0.0007309958777350013
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 0.0007309958758655191
784, epoch_train_loss=0.0007309958758655191
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 0.0007309958739968129
785, epoch_train_loss=0.0007309958739968129
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 0.000730995872128885
786, epoch_train_loss=0.000730995872128885
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 0.0007309958702617364
787, epoch_train_loss=0.0007309958702617364
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 0.0007309958683953693
788, epoch_train_loss=0.0007309958683953693
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 0.000730995866529785
789, epoch_train_loss=0.000730995866529785
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 0.0007309958646649854
790, epoch_train_loss=0.0007309958646649854
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 0.0007309958628009715
791, epoch_train_loss=0.0007309958628009715
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 0.0007309958609377456
792, epoch_train_loss=0.0007309958609377456
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 0.0007309958590753088
793, epoch_train_loss=0.0007309958590753088
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 0.0007309958572136629
794, epoch_train_loss=0.0007309958572136629
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 0.0007309958553528095
795, epoch_train_loss=0.0007309958553528095
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 0.0007309958534927501
796, epoch_train_loss=0.0007309958534927501
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 0.0007309958516334861
797, epoch_train_loss=0.0007309958516334861
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 0.0007309958497750191
798, epoch_train_loss=0.0007309958497750191
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 0.0007309958479173508
799, epoch_train_loss=0.0007309958479173508
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 0.0007309958460604829
800, epoch_train_loss=0.0007309958460604829
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 0.0007309958442044165
801, epoch_train_loss=0.0007309958442044165
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 0.0007309958423491533
802, epoch_train_loss=0.0007309958423491533
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 0.0007309958404946946
803, epoch_train_loss=0.0007309958404946946
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 0.0007309958386410423
804, epoch_train_loss=0.0007309958386410423
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 0.0007309958367881975
805, epoch_train_loss=0.0007309958367881975
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 0.0007309958349361621
806, epoch_train_loss=0.0007309958349361621
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 0.0007309958330849371
807, epoch_train_loss=0.0007309958330849371
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 0.0007309958312345244
808, epoch_train_loss=0.0007309958312345244
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 0.0007309958293849249
809, epoch_train_loss=0.0007309958293849249
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 0.0007309958275361407
810, epoch_train_loss=0.0007309958275361407
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 0.0007309958256881727
811, epoch_train_loss=0.0007309958256881727
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 0.0007309958238410228
812, epoch_train_loss=0.0007309958238410228
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 0.0007309958219946921
813, epoch_train_loss=0.0007309958219946921
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 0.0007309958201491821
814, epoch_train_loss=0.0007309958201491821
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 0.0007309958183044942
815, epoch_train_loss=0.0007309958183044942
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 0.00073099581646063
816, epoch_train_loss=0.00073099581646063
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 0.0007309958146175906
817, epoch_train_loss=0.0007309958146175906
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 0.0007309958127753776
818, epoch_train_loss=0.0007309958127753776
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 0.0007309958109339924
819, epoch_train_loss=0.0007309958109339924
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 0.000730995809093436
820, epoch_train_loss=0.000730995809093436
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 0.0007309958072537103
821, epoch_train_loss=0.0007309958072537103
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 0.0007309958054148163
822, epoch_train_loss=0.0007309958054148163
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 0.0007309958035767554
823, epoch_train_loss=0.0007309958035767554
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 0.0007309958017395293
824, epoch_train_loss=0.0007309958017395293
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 0.0007309957999031388
825, epoch_train_loss=0.0007309957999031388
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 0.0007309957980675854
826, epoch_train_loss=0.0007309957980675854
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 0.0007309957962328706
827, epoch_train_loss=0.0007309957962328706
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 0.0007309957943989956
828, epoch_train_loss=0.0007309957943989956
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 0.0007309957925659619
829, epoch_train_loss=0.0007309957925659619
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 0.0007309957907337704
830, epoch_train_loss=0.0007309957907337704
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 0.0007309957889024226
831, epoch_train_loss=0.0007309957889024226
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 0.0007309957870719197
832, epoch_train_loss=0.0007309957870719197
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 0.0007309957852422633
833, epoch_train_loss=0.0007309957852422633
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 0.0007309957834134542
834, epoch_train_loss=0.0007309957834134542
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 0.0007309957815854942
835, epoch_train_loss=0.0007309957815854942
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 0.000730995779758384
836, epoch_train_loss=0.000730995779758384
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 0.0007309957779321252
837, epoch_train_loss=0.0007309957779321252
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 0.0007309957761067191
838, epoch_train_loss=0.0007309957761067191
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 0.0007309957742821667
839, epoch_train_loss=0.0007309957742821667
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 0.0007309957724584694
840, epoch_train_loss=0.0007309957724584694
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 0.0007309957706356284
841, epoch_train_loss=0.0007309957706356284
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 0.0007309957688136447
842, epoch_train_loss=0.0007309957688136447
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 0.0007309957669925198
843, epoch_train_loss=0.0007309957669925198
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 0.0007309957651722547
844, epoch_train_loss=0.0007309957651722547
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 0.0007309957633528506
845, epoch_train_loss=0.0007309957633528506
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 0.000730995761534309
846, epoch_train_loss=0.000730995761534309
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.0007309957597166309
847, epoch_train_loss=0.0007309957597166309
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.0007309957578998175
848, epoch_train_loss=0.0007309957578998175
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0007309957560838695
849, epoch_train_loss=0.0007309957560838695
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.0007309957542687887
850, epoch_train_loss=0.0007309957542687887
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0007309957524545757
851, epoch_train_loss=0.0007309957524545757
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.0007309957506412322
852, epoch_train_loss=0.0007309957506412322
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.0007309957488287591
853, epoch_train_loss=0.0007309957488287591
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.0007309957470171575
854, epoch_train_loss=0.0007309957470171575
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.0007309957452064284
855, epoch_train_loss=0.0007309957452064284
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.0007309957433965733
856, epoch_train_loss=0.0007309957433965733
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.0007309957415875928
857, epoch_train_loss=0.0007309957415875928
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.0007309957397794886
858, epoch_train_loss=0.0007309957397794886
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.0007309957379722613
859, epoch_train_loss=0.0007309957379722613
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.0007309957361659123
860, epoch_train_loss=0.0007309957361659123
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.0007309957343604425
861, epoch_train_loss=0.0007309957343604425
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.000730995732555853
862, epoch_train_loss=0.000730995732555853
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.0007309957307521449
863, epoch_train_loss=0.0007309957307521449
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.0007309957289493194
864, epoch_train_loss=0.0007309957289493194
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.0007309957271473775
865, epoch_train_loss=0.0007309957271473775
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.0007309957253463202
866, epoch_train_loss=0.0007309957253463202
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.0007309957235461484
867, epoch_train_loss=0.0007309957235461484
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.0007309957217468635
868, epoch_train_loss=0.0007309957217468635
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.0007309957199484661
869, epoch_train_loss=0.0007309957199484661
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0007309957181509577
870, epoch_train_loss=0.0007309957181509577
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.0007309957163543389
871, epoch_train_loss=0.0007309957163543389
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.0007309957145586111
872, epoch_train_loss=0.0007309957145586111
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0007309957127637749
873, epoch_train_loss=0.0007309957127637749
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.0007309957109698315
874, epoch_train_loss=0.0007309957109698315
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.000730995709176782
875, epoch_train_loss=0.000730995709176782
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.0007309957073846273
876, epoch_train_loss=0.0007309957073846273
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.0007309957055933685
877, epoch_train_loss=0.0007309957055933685
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.0007309957038030065
878, epoch_train_loss=0.0007309957038030065
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.000730995702013542
879, epoch_train_loss=0.000730995702013542
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.0007309957002249764
880, epoch_train_loss=0.0007309957002249764
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.0007309956984373104
881, epoch_train_loss=0.0007309956984373104
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.000730995696650545
882, epoch_train_loss=0.000730995696650545
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0007309956948646812
883, epoch_train_loss=0.0007309956948646812
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0007309956930797199
884, epoch_train_loss=0.0007309956930797199
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0007309956912956621
885, epoch_train_loss=0.0007309956912956621
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.0007309956895125086
886, epoch_train_loss=0.0007309956895125086
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0007309956877302603
887, epoch_train_loss=0.0007309956877302603
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0007309956859489183
888, epoch_train_loss=0.0007309956859489183
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0007309956841684836
889, epoch_train_loss=0.0007309956841684836
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.0007309956823889569
890, epoch_train_loss=0.0007309956823889569
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0007309956806103389
891, epoch_train_loss=0.0007309956806103389
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0007309956788326309
892, epoch_train_loss=0.0007309956788326309
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.0007309956770558335
893, epoch_train_loss=0.0007309956770558335
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.0007309956752799479
894, epoch_train_loss=0.0007309956752799479
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0007309956735049745
895, epoch_train_loss=0.0007309956735049745
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.0007309956717309147
896, epoch_train_loss=0.0007309956717309147
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.000730995669957769
897, epoch_train_loss=0.000730995669957769
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0007309956681855382
898, epoch_train_loss=0.0007309956681855382
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0007309956664142234
899, epoch_train_loss=0.0007309956664142234
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0007309956646438256
900, epoch_train_loss=0.0007309956646438256
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.0007309956628743451
901, epoch_train_loss=0.0007309956628743451
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0007309956611057833
902, epoch_train_loss=0.0007309956611057833
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.0007309956593381406
903, epoch_train_loss=0.0007309956593381406
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0007309956575714182
904, epoch_train_loss=0.0007309956575714182
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007309956558056165
905, epoch_train_loss=0.0007309956558056165
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.0007309956540407366
906, epoch_train_loss=0.0007309956540407366
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.0007309956522767792
907, epoch_train_loss=0.0007309956522767792
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.000730995650513745
908, epoch_train_loss=0.000730995650513745
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.0007309956487516351
909, epoch_train_loss=0.0007309956487516351
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.0007309956469904502
910, epoch_train_loss=0.0007309956469904502
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0007309956452301908
911, epoch_train_loss=0.0007309956452301908
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.0007309956434708581
912, epoch_train_loss=0.0007309956434708581
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.0007309956417124525
913, epoch_train_loss=0.0007309956417124525
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.0007309956399549751
914, epoch_train_loss=0.0007309956399549751
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0007309956381984265
915, epoch_train_loss=0.0007309956381984265
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.0007309956364428073
916, epoch_train_loss=0.0007309956364428073
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.0007309956346881185
917, epoch_train_loss=0.0007309956346881185
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.0007309956329343606
918, epoch_train_loss=0.0007309956329343606
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0007309956311815348
919, epoch_train_loss=0.0007309956311815348
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.0007309956294296411
920, epoch_train_loss=0.0007309956294296411
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.000730995627678681
921, epoch_train_loss=0.000730995627678681
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.0007309956259286548
922, epoch_train_loss=0.0007309956259286548
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.0007309956241795632
923, epoch_train_loss=0.0007309956241795632
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.0007309956224314069
924, epoch_train_loss=0.0007309956224314069
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.0007309956206841869
925, epoch_train_loss=0.0007309956206841869
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0007309956189379039
926, epoch_train_loss=0.0007309956189379039
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.000730995617192558
927, epoch_train_loss=0.000730995617192558
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.0007309956154481507
928, epoch_train_loss=0.0007309956154481507
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0007309956137046819
929, epoch_train_loss=0.0007309956137046819
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.000730995611962153
930, epoch_train_loss=0.000730995611962153
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.0007309956102205642
931, epoch_train_loss=0.0007309956102205642
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.0007309956084799163
932, epoch_train_loss=0.0007309956084799163
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.00073099560674021
933, epoch_train_loss=0.00073099560674021
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.000730995605001446
934, epoch_train_loss=0.000730995605001446
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.0007309956032636248
935, epoch_train_loss=0.0007309956032636248
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.0007309956015267473
936, epoch_train_loss=0.0007309956015267473
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.000730995599790814
937, epoch_train_loss=0.000730995599790814
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.0007309955980558255
938, epoch_train_loss=0.0007309955980558255
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.0007309955963217827
939, epoch_train_loss=0.0007309955963217827
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.0007309955945886858
940, epoch_train_loss=0.0007309955945886858
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.0007309955928565357
941, epoch_train_loss=0.0007309955928565357
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.0007309955911253329
942, epoch_train_loss=0.0007309955911253329
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.0007309955893950781
943, epoch_train_loss=0.0007309955893950781
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.000730995587665772
944, epoch_train_loss=0.000730995587665772
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.0007309955859374149
945, epoch_train_loss=0.0007309955859374149
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.0007309955842100078
946, epoch_train_loss=0.0007309955842100078
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.000730995582483551
947, epoch_train_loss=0.000730995582483551
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.0007309955807580452
948, epoch_train_loss=0.0007309955807580452
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.000730995579033491
949, epoch_train_loss=0.000730995579033491
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.000730995577309889
950, epoch_train_loss=0.000730995577309889
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0007309955755872396
951, epoch_train_loss=0.0007309955755872396
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.0007309955738655434
952, epoch_train_loss=0.0007309955738655434
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.0007309955721448015
953, epoch_train_loss=0.0007309955721448015
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.0007309955704250138
954, epoch_train_loss=0.0007309955704250138
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.000730995568706181
955, epoch_train_loss=0.000730995568706181
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.0007309955669883038
956, epoch_train_loss=0.0007309955669883038
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.0007309955652713826
957, epoch_train_loss=0.0007309955652713826
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.0007309955635554182
958, epoch_train_loss=0.0007309955635554182
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.0007309955618404108
959, epoch_train_loss=0.0007309955618404108
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0007309955601263612
960, epoch_train_loss=0.0007309955601263612
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0007309955584132696
961, epoch_train_loss=0.0007309955584132696
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.000730995556701137
962, epoch_train_loss=0.000730995556701137
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0007309955549899636
963, epoch_train_loss=0.0007309955549899636
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.00073099555327975
964, epoch_train_loss=0.00073099555327975
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.0007309955515704968
965, epoch_train_loss=0.0007309955515704968
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.0007309955498622043
966, epoch_train_loss=0.0007309955498622043
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.0007309955481548733
967, epoch_train_loss=0.0007309955481548733
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.0007309955464485037
968, epoch_train_loss=0.0007309955464485037
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0007309955447430967
969, epoch_train_loss=0.0007309955447430967
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.0007309955430386523
970, epoch_train_loss=0.0007309955430386523
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.0007309955413351714
971, epoch_train_loss=0.0007309955413351714
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.0007309955396326538
972, epoch_train_loss=0.0007309955396326538
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.0007309955379311009
973, epoch_train_loss=0.0007309955379311009
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.0007309955362305124
974, epoch_train_loss=0.0007309955362305124
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.0007309955345308891
975, epoch_train_loss=0.0007309955345308891
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.0007309955328322313
976, epoch_train_loss=0.0007309955328322313
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0007309955311345396
977, epoch_train_loss=0.0007309955311345396
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.0007309955294378145
978, epoch_train_loss=0.0007309955294378145
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.0007309955277420562
979, epoch_train_loss=0.0007309955277420562
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.0007309955260472654
980, epoch_train_loss=0.0007309955260472654
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0007309955243534426
981, epoch_train_loss=0.0007309955243534426
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.0007309955226605879
982, epoch_train_loss=0.0007309955226605879
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.0007309955209687019
983, epoch_train_loss=0.0007309955209687019
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0007309955192777852
984, epoch_train_loss=0.0007309955192777852
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.0007309955175878378
985, epoch_train_loss=0.0007309955175878378
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.0007309955158988605
986, epoch_train_loss=0.0007309955158988605
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.0007309955142108536
987, epoch_train_loss=0.0007309955142108536
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.0007309955125238172
988, epoch_train_loss=0.0007309955125238172
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.0007309955108377524
989, epoch_train_loss=0.0007309955108377524
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.000730995509152659
990, epoch_train_loss=0.000730995509152659
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0007309955074685374
991, epoch_train_loss=0.0007309955074685374
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0007309955057853884
992, epoch_train_loss=0.0007309955057853884
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0007309955041032121
993, epoch_train_loss=0.0007309955041032121
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.000730995502422009
994, epoch_train_loss=0.000730995502422009
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0007309955007417793
995, epoch_train_loss=0.0007309955007417793
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0007309954990625235
996, epoch_train_loss=0.0007309954990625235
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.000730995497384242
997, epoch_train_loss=0.000730995497384242
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.000730995495706935
998, epoch_train_loss=0.000730995495706935
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.0007309954940306031
999, epoch_train_loss=0.0007309954940306031
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.0007309954923552465
1000, epoch_train_loss=0.0007309954923552465
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.0007309954906808659
1001, epoch_train_loss=0.0007309954906808659
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.0007309954890074607
1002, epoch_train_loss=0.0007309954890074607
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0007309954873350325
1003, epoch_train_loss=0.0007309954873350325
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0007309954856635808
1004, epoch_train_loss=0.0007309954856635808
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.0007309954839931061
1005, epoch_train_loss=0.0007309954839931061
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.0007309954823236088
1006, epoch_train_loss=0.0007309954823236088
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0007309954806550893
1007, epoch_train_loss=0.0007309954806550893
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.000730995478987548
1008, epoch_train_loss=0.000730995478987548
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.0007309954773209847
1009, epoch_train_loss=0.0007309954773209847
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.0007309954756554004
1010, epoch_train_loss=0.0007309954756554004
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.000730995473990795
1011, epoch_train_loss=0.000730995473990795
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.0007309954723271689
1012, epoch_train_loss=0.0007309954723271689
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.0007309954706645225
1013, epoch_train_loss=0.0007309954706645225
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.000730995469002856
1014, epoch_train_loss=0.000730995469002856
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0007309954673421698
1015, epoch_train_loss=0.0007309954673421698
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.000730995465682464
1016, epoch_train_loss=0.000730995465682464
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.0007309954640237388
1017, epoch_train_loss=0.0007309954640237388
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0007309954623659951
1018, epoch_train_loss=0.0007309954623659951
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.0007309954607092326
1019, epoch_train_loss=0.0007309954607092326
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0007309954590534518
1020, epoch_train_loss=0.0007309954590534518
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0007309954573986529
1021, epoch_train_loss=0.0007309954573986529
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0007309954557448362
1022, epoch_train_loss=0.0007309954557448362
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.000730995454092002
1023, epoch_train_loss=0.000730995454092002
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.0007309954524401504
1024, epoch_train_loss=0.0007309954524401504
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.000730995450789282
1025, epoch_train_loss=0.000730995450789282
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.0007309954491393966
1026, epoch_train_loss=0.0007309954491393966
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0007309954474904947
1027, epoch_train_loss=0.0007309954474904947
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.0007309954458425766
1028, epoch_train_loss=0.0007309954458425766
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.0007309954441956426
1029, epoch_train_loss=0.0007309954441956426
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.0007309954425496928
1030, epoch_train_loss=0.0007309954425496928
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.0007309954409047272
1031, epoch_train_loss=0.0007309954409047272
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.0007309954392607466
1032, epoch_train_loss=0.0007309954392607466
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.0007309954376177509
1033, epoch_train_loss=0.0007309954376177509
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0007309954359757401
1034, epoch_train_loss=0.0007309954359757401
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.000730995434334715
1035, epoch_train_loss=0.000730995434334715
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.0007309954326946755
1036, epoch_train_loss=0.0007309954326946755
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.0007309954310556214
1037, epoch_train_loss=0.0007309954310556214
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.0007309954294175539
1038, epoch_train_loss=0.0007309954294175539
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.0007309954277804722
1039, epoch_train_loss=0.0007309954277804722
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.0007309954261443771
1040, epoch_train_loss=0.0007309954261443771
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 0.0007309954245092685
1041, epoch_train_loss=0.0007309954245092685
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.0007309954228751469
1042, epoch_train_loss=0.0007309954228751469
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.0007309954212420122
1043, epoch_train_loss=0.0007309954212420122
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.0007309954196098649
1044, epoch_train_loss=0.0007309954196098649
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 0.0007309954179787049
1045, epoch_train_loss=0.0007309954179787049
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 0.0007309954163485326
1046, epoch_train_loss=0.0007309954163485326
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 0.0007309954147193479
1047, epoch_train_loss=0.0007309954147193479
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 0.0007309954130911511
1048, epoch_train_loss=0.0007309954130911511
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 0.0007309954114639426
1049, epoch_train_loss=0.0007309954114639426
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 0.0007309954098377224
1050, epoch_train_loss=0.0007309954098377224
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 0.0007309954082124905
1051, epoch_train_loss=0.0007309954082124905
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 0.0007309954065882472
1052, epoch_train_loss=0.0007309954065882472
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 0.000730995404964993
1053, epoch_train_loss=0.000730995404964993
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 0.0007309954033427274
1054, epoch_train_loss=0.0007309954033427274
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 0.000730995401721451
1055, epoch_train_loss=0.000730995401721451
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 0.0007309954001011638
1056, epoch_train_loss=0.0007309954001011638
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 0.000730995398481866
1057, epoch_train_loss=0.000730995398481866
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 0.000730995396863558
1058, epoch_train_loss=0.000730995396863558
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 0.0007309953952462394
1059, epoch_train_loss=0.0007309953952462394
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 0.0007309953936299108
1060, epoch_train_loss=0.0007309953936299108
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 0.0007309953920145719
1061, epoch_train_loss=0.0007309953920145719
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 0.0007309953904002231
1062, epoch_train_loss=0.0007309953904002231
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 0.0007309953887868645
1063, epoch_train_loss=0.0007309953887868645
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 0.0007309953871744964
1064, epoch_train_loss=0.0007309953871744964
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 0.0007309953855631188
1065, epoch_train_loss=0.0007309953855631188
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 0.0007309953839527315
1066, epoch_train_loss=0.0007309953839527315
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 0.000730995382343335
1067, epoch_train_loss=0.000730995382343335
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 0.0007309953807349291
1068, epoch_train_loss=0.0007309953807349291
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 0.0007309953791275142
1069, epoch_train_loss=0.0007309953791275142
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 0.0007309953775210903
1070, epoch_train_loss=0.0007309953775210903
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 0.0007309953759156575
1071, epoch_train_loss=0.0007309953759156575
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 0.0007309953743112158
1072, epoch_train_loss=0.0007309953743112158
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 0.0007309953727077656
1073, epoch_train_loss=0.0007309953727077656
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 0.0007309953711053068
1074, epoch_train_loss=0.0007309953711053068
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 0.0007309953695038393
1075, epoch_train_loss=0.0007309953695038393
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 0.0007309953679033633
1076, epoch_train_loss=0.0007309953679033633
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 0.0007309953663038791
1077, epoch_train_loss=0.0007309953663038791
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 0.0007309953647053865
1078, epoch_train_loss=0.0007309953647053865
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 0.0007309953631078857
1079, epoch_train_loss=0.0007309953631078857
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 0.0007309953615113768
1080, epoch_train_loss=0.0007309953615113768
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 0.0007309953599158596
1081, epoch_train_loss=0.0007309953599158596
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 0.0007309953583213345
1082, epoch_train_loss=0.0007309953583213345
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 0.0007309953567278017
1083, epoch_train_loss=0.0007309953567278017
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 0.000730995355135261
1084, epoch_train_loss=0.000730995355135261
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 0.0007309953535437123
1085, epoch_train_loss=0.0007309953535437123
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 0.000730995351953156
1086, epoch_train_loss=0.000730995351953156
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 0.0007309953503635919
1087, epoch_train_loss=0.0007309953503635919
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 0.0007309953487750202
1088, epoch_train_loss=0.0007309953487750202
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 0.0007309953471874407
1089, epoch_train_loss=0.0007309953471874407
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 0.0007309953456008538
1090, epoch_train_loss=0.0007309953456008538
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 0.0007309953440152593
1091, epoch_train_loss=0.0007309953440152593
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 0.0007309953424306573
1092, epoch_train_loss=0.0007309953424306573
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 0.000730995340847048
1093, epoch_train_loss=0.000730995340847048
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 0.0007309953392644312
1094, epoch_train_loss=0.0007309953392644312
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 0.000730995337682807
1095, epoch_train_loss=0.000730995337682807
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 0.0007309953361021753
1096, epoch_train_loss=0.0007309953361021753
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 0.0007309953345225361
1097, epoch_train_loss=0.0007309953345225361
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 0.0007309953329438899
1098, epoch_train_loss=0.0007309953329438899
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 0.0007309953313662363
1099, epoch_train_loss=0.0007309953313662363
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 0.0007309953297895752
1100, epoch_train_loss=0.0007309953297895752
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 0.0007309953282139071
1101, epoch_train_loss=0.0007309953282139071
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 0.0007309953266392316
1102, epoch_train_loss=0.0007309953266392316
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 0.0007309953250655488
1103, epoch_train_loss=0.0007309953250655488
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 0.0007309953234928589
1104, epoch_train_loss=0.0007309953234928589
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 0.0007309953219211615
1105, epoch_train_loss=0.0007309953219211615
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 0.0007309953203504569
1106, epoch_train_loss=0.0007309953203504569
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 0.0007309953187807451
1107, epoch_train_loss=0.0007309953187807451
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 0.0007309953172120261
1108, epoch_train_loss=0.0007309953172120261
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 0.0007309953156442996
1109, epoch_train_loss=0.0007309953156442996
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 0.0007309953140775656
1110, epoch_train_loss=0.0007309953140775656
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 0.0007309953125118245
1111, epoch_train_loss=0.0007309953125118245
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 0.0007309953109470763
1112, epoch_train_loss=0.0007309953109470763
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 0.0007309953093833203
1113, epoch_train_loss=0.0007309953093833203
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 0.0007309953078205571
1114, epoch_train_loss=0.0007309953078205571
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 0.0007309953062587866
1115, epoch_train_loss=0.0007309953062587866
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 0.0007309953046980084
1116, epoch_train_loss=0.0007309953046980084
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 0.0007309953031382228
1117, epoch_train_loss=0.0007309953031382228
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 0.0007309953015794297
1118, epoch_train_loss=0.0007309953015794297
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 0.0007309953000216293
1119, epoch_train_loss=0.0007309953000216293
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 0.0007309952984648212
1120, epoch_train_loss=0.0007309952984648212
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 0.0007309952969090052
1121, epoch_train_loss=0.0007309952969090052
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 0.0007309952953541819
1122, epoch_train_loss=0.0007309952953541819
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 0.0007309952938003506
1123, epoch_train_loss=0.0007309952938003506
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 0.0007309952922475116
1124, epoch_train_loss=0.0007309952922475116
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 0.0007309952906956647
1125, epoch_train_loss=0.0007309952906956647
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 0.00073099528914481
1126, epoch_train_loss=0.00073099528914481
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 0.0007309952875949472
1127, epoch_train_loss=0.0007309952875949472
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 0.0007309952860460765
1128, epoch_train_loss=0.0007309952860460765
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 0.0007309952844981978
1129, epoch_train_loss=0.0007309952844981978
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 0.0007309952829513108
1130, epoch_train_loss=0.0007309952829513108
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 0.0007309952814054157
1131, epoch_train_loss=0.0007309952814054157
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 0.0007309952798605124
1132, epoch_train_loss=0.0007309952798605124
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 0.0007309952783166008
1133, epoch_train_loss=0.0007309952783166008
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 0.0007309952767736805
1134, epoch_train_loss=0.0007309952767736805
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 0.0007309952752317517
1135, epoch_train_loss=0.0007309952752317517
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 0.0007309952736908145
1136, epoch_train_loss=0.0007309952736908145
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 0.0007309952721508687
1137, epoch_train_loss=0.0007309952721508687
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 0.000730995270611914
1138, epoch_train_loss=0.000730995270611914
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 0.0007309952690739504
1139, epoch_train_loss=0.0007309952690739504
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 0.0007309952675369779
1140, epoch_train_loss=0.0007309952675369779
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 0.0007309952660009967
1141, epoch_train_loss=0.0007309952660009967
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 0.000730995264466006
1142, epoch_train_loss=0.000730995264466006
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 0.0007309952629320064
1143, epoch_train_loss=0.0007309952629320064
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 0.0007309952613989972
1144, epoch_train_loss=0.0007309952613989972
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 0.0007309952598669785
1145, epoch_train_loss=0.0007309952598669785
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 0.0007309952583359506
1146, epoch_train_loss=0.0007309952583359506
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 0.0007309952568059129
1147, epoch_train_loss=0.0007309952568059129
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 0.0007309952552768656
1148, epoch_train_loss=0.0007309952552768656
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 0.0007309952537488082
1149, epoch_train_loss=0.0007309952537488082
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 0.0007309952522217411
1150, epoch_train_loss=0.0007309952522217411
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 0.0007309952506956638
1151, epoch_train_loss=0.0007309952506956638
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 0.0007309952491705763
1152, epoch_train_loss=0.0007309952491705763
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 0.0007309952476464784
1153, epoch_train_loss=0.0007309952476464784
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 0.0007309952461233703
1154, epoch_train_loss=0.0007309952461233703
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 0.0007309952446012515
1155, epoch_train_loss=0.0007309952446012515
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 0.0007309952430801218
1156, epoch_train_loss=0.0007309952430801218
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 0.0007309952415599813
1157, epoch_train_loss=0.0007309952415599813
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 0.0007309952400408302
1158, epoch_train_loss=0.0007309952400408302
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 0.0007309952385226678
1159, epoch_train_loss=0.0007309952385226678
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 0.0007309952370054942
1160, epoch_train_loss=0.0007309952370054942
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 0.0007309952354893092
1161, epoch_train_loss=0.0007309952354893092
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 0.0007309952339741127
1162, epoch_train_loss=0.0007309952339741127
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 0.0007309952324599044
1163, epoch_train_loss=0.0007309952324599044
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 0.0007309952309466845
1164, epoch_train_loss=0.0007309952309466845
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 0.0007309952294344525
1165, epoch_train_loss=0.0007309952294344525
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 0.0007309952279232085
1166, epoch_train_loss=0.0007309952279232085
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 0.0007309952264129522
1167, epoch_train_loss=0.0007309952264129522
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 0.0007309952249036836
1168, epoch_train_loss=0.0007309952249036836
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 0.0007309952233954025
1169, epoch_train_loss=0.0007309952233954025
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 0.0007309952218881086
1170, epoch_train_loss=0.0007309952218881086
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 0.0007309952203818016
1171, epoch_train_loss=0.0007309952203818016
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 0.0007309952188764817
1172, epoch_train_loss=0.0007309952188764817
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 0.0007309952173721488
1173, epoch_train_loss=0.0007309952173721488
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 0.0007309952158688023
1174, epoch_train_loss=0.0007309952158688023
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 0.0007309952143664425
1175, epoch_train_loss=0.0007309952143664425
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 0.0007309952128650687
1176, epoch_train_loss=0.0007309952128650687
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 0.0007309952113646812
1177, epoch_train_loss=0.0007309952113646812
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 0.0007309952098652795
1178, epoch_train_loss=0.0007309952098652795
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 0.0007309952083668636
1179, epoch_train_loss=0.0007309952083668636
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 0.0007309952068694335
1180, epoch_train_loss=0.0007309952068694335
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 0.0007309952053729886
1181, epoch_train_loss=0.0007309952053729886
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 0.0007309952038775288
1182, epoch_train_loss=0.0007309952038775288
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 0.0007309952023830542
1183, epoch_train_loss=0.0007309952023830542
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 0.0007309952008895645
1184, epoch_train_loss=0.0007309952008895645
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 0.0007309951993970591
1185, epoch_train_loss=0.0007309951993970591
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 0.0007309951979055385
1186, epoch_train_loss=0.0007309951979055385
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 0.0007309951964150022
1187, epoch_train_loss=0.0007309951964150022
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 0.0007309951949254497
1188, epoch_train_loss=0.0007309951949254497
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 0.0007309951934368813
1189, epoch_train_loss=0.0007309951934368813
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 0.0007309951919492963
1190, epoch_train_loss=0.0007309951919492963
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 0.000730995190462695
1191, epoch_train_loss=0.000730995190462695
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 0.0007309951889770771
1192, epoch_train_loss=0.0007309951889770771
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 0.0007309951874924419
1193, epoch_train_loss=0.0007309951874924419
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 0.0007309951860087899
1194, epoch_train_loss=0.0007309951860087899
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 0.0007309951845261202
1195, epoch_train_loss=0.0007309951845261202
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 0.0007309951830444333
1196, epoch_train_loss=0.0007309951830444333
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 0.0007309951815637286
1197, epoch_train_loss=0.0007309951815637286
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 0.0007309951800840057
1198, epoch_train_loss=0.0007309951800840057
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 0.0007309951786052646
1199, epoch_train_loss=0.0007309951786052646
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 0.0007309951771275053
1200, epoch_train_loss=0.0007309951771275053
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 0.000730995175650727
1201, epoch_train_loss=0.000730995175650727
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 0.0007309951741749302
1202, epoch_train_loss=0.0007309951741749302
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 0.0007309951727001142
1203, epoch_train_loss=0.0007309951727001142
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 0.0007309951712262787
1204, epoch_train_loss=0.0007309951712262787
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 0.0007309951697534238
1205, epoch_train_loss=0.0007309951697534238
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 0.0007309951682815492
1206, epoch_train_loss=0.0007309951682815492
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 0.0007309951668106545
1207, epoch_train_loss=0.0007309951668106545
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 0.0007309951653407395
1208, epoch_train_loss=0.0007309951653407395
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 0.0007309951638718043
1209, epoch_train_loss=0.0007309951638718043
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 0.0007309951624038481
1210, epoch_train_loss=0.0007309951624038481
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 0.0007309951609368709
1211, epoch_train_loss=0.0007309951609368709
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 0.0007309951594708726
1212, epoch_train_loss=0.0007309951594708726
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.0007309951580058529
1213, epoch_train_loss=0.0007309951580058529
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.0007309951565418115
1214, epoch_train_loss=0.0007309951565418115
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.0007309951550787481
1215, epoch_train_loss=0.0007309951550787481
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.0007309951536166627
1216, epoch_train_loss=0.0007309951536166627
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.0007309951521555548
1217, epoch_train_loss=0.0007309951521555548
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.0007309951506954241
1218, epoch_train_loss=0.0007309951506954241
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0007309951492362706
1219, epoch_train_loss=0.0007309951492362706
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.0007309951477780937
1220, epoch_train_loss=0.0007309951477780937
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.0007309951463208937
1221, epoch_train_loss=0.0007309951463208937
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.0007309951448646699
1222, epoch_train_loss=0.0007309951448646699
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.0007309951434094219
1223, epoch_train_loss=0.0007309951434094219
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.0007309951419551498
1224, epoch_train_loss=0.0007309951419551498
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.0007309951405018533
1225, epoch_train_loss=0.0007309951405018533
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.0007309951390495319
1226, epoch_train_loss=0.0007309951390495319
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.0007309951375981857
1227, epoch_train_loss=0.0007309951375981857
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.0007309951361478141
1228, epoch_train_loss=0.0007309951361478141
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.0007309951346984168
1229, epoch_train_loss=0.0007309951346984168
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.000730995133249994
1230, epoch_train_loss=0.000730995133249994
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0007309951318025448
1231, epoch_train_loss=0.0007309951318025448
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0007309951303560695
1232, epoch_train_loss=0.0007309951303560695
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0007309951289105675
1233, epoch_train_loss=0.0007309951289105675
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007309951274660384
1234, epoch_train_loss=0.0007309951274660384
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.0007309951260224822
1235, epoch_train_loss=0.0007309951260224822
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.0007309951245798985
1236, epoch_train_loss=0.0007309951245798985
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.000730995123138287
1237, epoch_train_loss=0.000730995123138287
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0007309951216976474
1238, epoch_train_loss=0.0007309951216976474
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0007309951202579796
1239, epoch_train_loss=0.0007309951202579796
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.0007309951188192831
1240, epoch_train_loss=0.0007309951188192831
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0007309951173815577
1241, epoch_train_loss=0.0007309951173815577
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.000730995115944803
1242, epoch_train_loss=0.000730995115944803
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.0007309951145090188
1243, epoch_train_loss=0.0007309951145090188
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.000730995113074205
1244, epoch_train_loss=0.000730995113074205
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0007309951116403608
1245, epoch_train_loss=0.0007309951116403608
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0007309951102074864
1246, epoch_train_loss=0.0007309951102074864
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0007309951087755812
1247, epoch_train_loss=0.0007309951087755812
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0007309951073446452
1248, epoch_train_loss=0.0007309951073446452
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.0007309951059146778
1249, epoch_train_loss=0.0007309951059146778
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0007309951044856786
1250, epoch_train_loss=0.0007309951044856786
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0007309951030576478
1251, epoch_train_loss=0.0007309951030576478
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.0007309951016305847
1252, epoch_train_loss=0.0007309951016305847
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.0007309951002044893
1253, epoch_train_loss=0.0007309951002044893
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.0007309950987793607
1254, epoch_train_loss=0.0007309950987793607
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.0007309950973551991
1255, epoch_train_loss=0.0007309950973551991
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.000730995095932004
1256, epoch_train_loss=0.000730995095932004
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0007309950945097752
1257, epoch_train_loss=0.0007309950945097752
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0007309950930885123
1258, epoch_train_loss=0.0007309950930885123
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.000730995091668215
1259, epoch_train_loss=0.000730995091668215
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007309950902488831
1260, epoch_train_loss=0.0007309950902488831
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0007309950888305161
1261, epoch_train_loss=0.0007309950888305161
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0007309950874131138
1262, epoch_train_loss=0.0007309950874131138
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0007309950859966758
1263, epoch_train_loss=0.0007309950859966758
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0007309950845812018
1264, epoch_train_loss=0.0007309950845812018
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0007309950831666915
1265, epoch_train_loss=0.0007309950831666915
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0007309950817531445
1266, epoch_train_loss=0.0007309950817531445
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0007309950803405605
1267, epoch_train_loss=0.0007309950803405605
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0007309950789289392
1268, epoch_train_loss=0.0007309950789289392
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0007309950775182804
1269, epoch_train_loss=0.0007309950775182804
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0007309950761085834
1270, epoch_train_loss=0.0007309950761085834
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0007309950746998483
1271, epoch_train_loss=0.0007309950746998483
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.0007309950732920745
1272, epoch_train_loss=0.0007309950732920745
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.0007309950718852616
1273, epoch_train_loss=0.0007309950718852616
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.0007309950704794095
1274, epoch_train_loss=0.0007309950704794095
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.0007309950690745178
1275, epoch_train_loss=0.0007309950690745178
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0007309950676705863
1276, epoch_train_loss=0.0007309950676705863
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007309950662676144
1277, epoch_train_loss=0.0007309950662676144
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0007309950648656016
1278, epoch_train_loss=0.0007309950648656016
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0007309950634645479
1279, epoch_train_loss=0.0007309950634645479
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.0007309950620644528
1280, epoch_train_loss=0.0007309950620644528
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.000730995060665316
1281, epoch_train_loss=0.000730995060665316
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.0007309950592671371
1282, epoch_train_loss=0.0007309950592671371
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0007309950578699159
1283, epoch_train_loss=0.0007309950578699159
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.0007309950564736518
1284, epoch_train_loss=0.0007309950564736518
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0007309950550783448
1285, epoch_train_loss=0.0007309950550783448
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.0007309950536839943
1286, epoch_train_loss=0.0007309950536839943
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.0007309950522905998
1287, epoch_train_loss=0.0007309950522905998
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0007309950508981612
1288, epoch_train_loss=0.0007309950508981612
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0007309950495066782
1289, epoch_train_loss=0.0007309950495066782
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0007309950481161501
1290, epoch_train_loss=0.0007309950481161501
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0007309950467265768
1291, epoch_train_loss=0.0007309950467265768
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.000730995045337958
1292, epoch_train_loss=0.000730995045337958
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.0007309950439502931
1293, epoch_train_loss=0.0007309950439502931
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.0007309950425635821
1294, epoch_train_loss=0.0007309950425635821
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.0007309950411778242
1295, epoch_train_loss=0.0007309950411778242
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.0007309950397930194
1296, epoch_train_loss=0.0007309950397930194
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.0007309950384091669
1297, epoch_train_loss=0.0007309950384091669
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.0007309950370262667
1298, epoch_train_loss=0.0007309950370262667
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.0007309950356443186
1299, epoch_train_loss=0.0007309950356443186
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.0007309950342633218
1300, epoch_train_loss=0.0007309950342633218
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.0007309950328832761
1301, epoch_train_loss=0.0007309950328832761
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.000730995031504181
1302, epoch_train_loss=0.000730995031504181
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.0007309950301260363
1303, epoch_train_loss=0.0007309950301260363
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0007309950287488415
1304, epoch_train_loss=0.0007309950287488415
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.0007309950273725965
1305, epoch_train_loss=0.0007309950273725965
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0007309950259973006
1306, epoch_train_loss=0.0007309950259973006
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.0007309950246229536
1307, epoch_train_loss=0.0007309950246229536
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.000730995023249555
1308, epoch_train_loss=0.000730995023249555
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.0007309950218771045
1309, epoch_train_loss=0.0007309950218771045
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.0007309950205056019
1310, epoch_train_loss=0.0007309950205056019
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 0.0007309950191350462
1311, epoch_train_loss=0.0007309950191350462
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.0007309950177654375
1312, epoch_train_loss=0.0007309950177654375
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.0007309950163967756
1313, epoch_train_loss=0.0007309950163967756
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.0007309950150290597
1314, epoch_train_loss=0.0007309950150290597
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 0.0007309950136622895
1315, epoch_train_loss=0.0007309950136622895
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.0007309950122964649
1316, epoch_train_loss=0.0007309950122964649
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.000730995010931585
1317, epoch_train_loss=0.000730995010931585
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 0.00073099500956765
1318, epoch_train_loss=0.00073099500956765
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 0.0007309950082046591
1319, epoch_train_loss=0.0007309950082046591
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 0.0007309950068426119
1320, epoch_train_loss=0.0007309950068426119
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 0.0007309950054815082
1321, epoch_train_loss=0.0007309950054815082
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 0.0007309950041213474
1322, epoch_train_loss=0.0007309950041213474
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 0.0007309950027621294
1323, epoch_train_loss=0.0007309950027621294
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 0.0007309950014038535
1324, epoch_train_loss=0.0007309950014038535
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 0.0007309950000465196
1325, epoch_train_loss=0.0007309950000465196
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 0.0007309949986901269
1326, epoch_train_loss=0.0007309949986901269
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 0.0007309949973346754
1327, epoch_train_loss=0.0007309949973346754
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 0.0007309949959801644
1328, epoch_train_loss=0.0007309949959801644
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 0.0007309949946265937
1329, epoch_train_loss=0.0007309949946265937
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 0.0007309949932739628
1330, epoch_train_loss=0.0007309949932739628
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 0.0007309949919222714
1331, epoch_train_loss=0.0007309949919222714
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 0.000730994990571519
1332, epoch_train_loss=0.000730994990571519
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 0.0007309949892217052
1333, epoch_train_loss=0.0007309949892217052
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 0.0007309949878728295
1334, epoch_train_loss=0.0007309949878728295
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 0.0007309949865248916
1335, epoch_train_loss=0.0007309949865248916
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 0.0007309949851778913
1336, epoch_train_loss=0.0007309949851778913
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 0.0007309949838318277
1337, epoch_train_loss=0.0007309949838318277
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 0.0007309949824867008
1338, epoch_train_loss=0.0007309949824867008
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 0.0007309949811425101
1339, epoch_train_loss=0.0007309949811425101
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 0.0007309949797992552
1340, epoch_train_loss=0.0007309949797992552
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 0.0007309949784569355
1341, epoch_train_loss=0.0007309949784569355
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 0.0007309949771155506
1342, epoch_train_loss=0.0007309949771155506
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 0.0007309949757751004
1343, epoch_train_loss=0.0007309949757751004
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 0.000730994974435584
1344, epoch_train_loss=0.000730994974435584
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 0.0007309949730970015
1345, epoch_train_loss=0.0007309949730970015
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 0.0007309949717593521
1346, epoch_train_loss=0.0007309949717593521
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 0.0007309949704226356
1347, epoch_train_loss=0.0007309949704226356
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 0.0007309949690868515
1348, epoch_train_loss=0.0007309949690868515
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 0.0007309949677519992
1349, epoch_train_loss=0.0007309949677519992
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 0.0007309949664180786
1350, epoch_train_loss=0.0007309949664180786
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 0.000730994965085089
1351, epoch_train_loss=0.000730994965085089
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 0.0007309949637530303
1352, epoch_train_loss=0.0007309949637530303
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 0.0007309949624219016
1353, epoch_train_loss=0.0007309949624219016
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 0.0007309949610917031
1354, epoch_train_loss=0.0007309949610917031
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 0.0007309949597624337
1355, epoch_train_loss=0.0007309949597624337
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 0.0007309949584340934
1356, epoch_train_loss=0.0007309949584340934
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 0.0007309949571066817
1357, epoch_train_loss=0.0007309949571066817
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 0.000730994955780198
1358, epoch_train_loss=0.000730994955780198
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 0.0007309949544546421
1359, epoch_train_loss=0.0007309949544546421
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 0.0007309949531300135
1360, epoch_train_loss=0.0007309949531300135
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 0.0007309949518063116
1361, epoch_train_loss=0.0007309949518063116
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 0.0007309949504835363
1362, epoch_train_loss=0.0007309949504835363
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 0.0007309949491616867
1363, epoch_train_loss=0.0007309949491616867
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 0.0007309949478407628
1364, epoch_train_loss=0.0007309949478407628
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 0.0007309949465207641
1365, epoch_train_loss=0.0007309949465207641
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 0.0007309949452016899
1366, epoch_train_loss=0.0007309949452016899
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 0.00073099494388354
1367, epoch_train_loss=0.00073099494388354
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 0.0007309949425663137
1368, epoch_train_loss=0.0007309949425663137
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 0.000730994941250011
1369, epoch_train_loss=0.000730994941250011
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 0.0007309949399346311
1370, epoch_train_loss=0.0007309949399346311
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 0.0007309949386201736
1371, epoch_train_loss=0.0007309949386201736
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 0.0007309949373066381
1372, epoch_train_loss=0.0007309949373066381
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 0.0007309949359940244
1373, epoch_train_loss=0.0007309949359940244
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 0.0007309949346823315
1374, epoch_train_loss=0.0007309949346823315
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 0.0007309949333715596
1375, epoch_train_loss=0.0007309949333715596
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 0.0007309949320617077
1376, epoch_train_loss=0.0007309949320617077
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 0.0007309949307527757
1377, epoch_train_loss=0.0007309949307527757
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 0.000730994929444763
1378, epoch_train_loss=0.000730994929444763
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 0.0007309949281376693
1379, epoch_train_loss=0.0007309949281376693
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 0.000730994926831494
1380, epoch_train_loss=0.000730994926831494
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 0.0007309949255262368
1381, epoch_train_loss=0.0007309949255262368
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 0.000730994924221897
1382, epoch_train_loss=0.000730994924221897
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 0.0007309949229184744
1383, epoch_train_loss=0.0007309949229184744
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 0.0007309949216159684
1384, epoch_train_loss=0.0007309949216159684
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 0.0007309949203143785
1385, epoch_train_loss=0.0007309949203143785
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 0.0007309949190137047
1386, epoch_train_loss=0.0007309949190137047
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 0.0007309949177139461
1387, epoch_train_loss=0.0007309949177139461
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 0.0007309949164151021
1388, epoch_train_loss=0.0007309949164151021
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 0.0007309949151171726
1389, epoch_train_loss=0.0007309949151171726
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 0.0007309949138201571
1390, epoch_train_loss=0.0007309949138201571
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 0.0007309949125240549
1391, epoch_train_loss=0.0007309949125240549
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 0.000730994911228866
1392, epoch_train_loss=0.000730994911228866
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 0.0007309949099345894
1393, epoch_train_loss=0.0007309949099345894
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 0.0007309949086412249
1394, epoch_train_loss=0.0007309949086412249
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 0.000730994907348772
1395, epoch_train_loss=0.000730994907348772
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 0.0007309949060572304
1396, epoch_train_loss=0.0007309949060572304
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 0.0007309949047665995
1397, epoch_train_loss=0.0007309949047665995
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 0.0007309949034768789
1398, epoch_train_loss=0.0007309949034768789
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 0.000730994902188068
1399, epoch_train_loss=0.000730994902188068
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 0.0007309949009001666
1400, epoch_train_loss=0.0007309949009001666
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 0.0007309948996131739
1401, epoch_train_loss=0.0007309948996131739
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 0.0007309948983270897
1402, epoch_train_loss=0.0007309948983270897
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 0.0007309948970419134
1403, epoch_train_loss=0.0007309948970419134
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 0.0007309948957576446
1404, epoch_train_loss=0.0007309948957576446
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 0.0007309948944742828
1405, epoch_train_loss=0.0007309948944742828
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 0.0007309948931918275
1406, epoch_train_loss=0.0007309948931918275
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 0.0007309948919102783
1407, epoch_train_loss=0.0007309948919102783
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 0.0007309948906296347
1408, epoch_train_loss=0.0007309948906296347
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 0.0007309948893498961
1409, epoch_train_loss=0.0007309948893498961
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 0.0007309948880710624
1410, epoch_train_loss=0.0007309948880710624
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 0.0007309948867931329
1411, epoch_train_loss=0.0007309948867931329
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 0.000730994885516107
1412, epoch_train_loss=0.000730994885516107
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 0.0007309948842399843
1413, epoch_train_loss=0.0007309948842399843
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 0.0007309948829647643
1414, epoch_train_loss=0.0007309948829647643
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 0.0007309948816904469
1415, epoch_train_loss=0.0007309948816904469
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 0.0007309948804170312
1416, epoch_train_loss=0.0007309948804170312
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 0.0007309948791445167
1417, epoch_train_loss=0.0007309948791445167
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 0.0007309948778729034
1418, epoch_train_loss=0.0007309948778729034
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 0.0007309948766021903
1419, epoch_train_loss=0.0007309948766021903
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 0.0007309948753323771
1420, epoch_train_loss=0.0007309948753323771
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 0.0007309948740634634
1421, epoch_train_loss=0.0007309948740634634
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 0.0007309948727954488
1422, epoch_train_loss=0.0007309948727954488
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 0.0007309948715283326
1423, epoch_train_loss=0.0007309948715283326
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 0.0007309948702621144
1424, epoch_train_loss=0.0007309948702621144
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 0.0007309948689967938
1425, epoch_train_loss=0.0007309948689967938
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 0.0007309948677323702
1426, epoch_train_loss=0.0007309948677323702
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 0.0007309948664688433
1427, epoch_train_loss=0.0007309948664688433
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 0.0007309948652062123
1428, epoch_train_loss=0.0007309948652062123
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 0.0007309948639444772
1429, epoch_train_loss=0.0007309948639444772
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 0.000730994862683637
1430, epoch_train_loss=0.000730994862683637
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 0.0007309948614236915
1431, epoch_train_loss=0.0007309948614236915
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 0.0007309948601646403
1432, epoch_train_loss=0.0007309948601646403
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 0.0007309948589064826
1433, epoch_train_loss=0.0007309948589064826
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 0.0007309948576492184
1434, epoch_train_loss=0.0007309948576492184
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 0.0007309948563928467
1435, epoch_train_loss=0.0007309948563928467
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 0.0007309948551373674
1436, epoch_train_loss=0.0007309948551373674
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 0.0007309948538827797
1437, epoch_train_loss=0.0007309948538827797
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 0.0007309948526290832
1438, epoch_train_loss=0.0007309948526290832
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 0.0007309948513762776
1439, epoch_train_loss=0.0007309948513762776
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 0.0007309948501243622
1440, epoch_train_loss=0.0007309948501243622
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 0.0007309948488733368
1441, epoch_train_loss=0.0007309948488733368
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 0.0007309948476232006
1442, epoch_train_loss=0.0007309948476232006
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 0.0007309948463739531
1443, epoch_train_loss=0.0007309948463739531
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 0.000730994845125594
1444, epoch_train_loss=0.000730994845125594
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 0.0007309948438781227
1445, epoch_train_loss=0.0007309948438781227
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 0.000730994842631539
1446, epoch_train_loss=0.000730994842631539
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 0.0007309948413858421
1447, epoch_train_loss=0.0007309948413858421
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 0.0007309948401410314
1448, epoch_train_loss=0.0007309948401410314
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0007309948388971068
1449, epoch_train_loss=0.0007309948388971068
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.0007309948376540675
1450, epoch_train_loss=0.0007309948376540675
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.0007309948364119131
1451, epoch_train_loss=0.0007309948364119131
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0007309948351706429
1452, epoch_train_loss=0.0007309948351706429
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0007309948339302568
1453, epoch_train_loss=0.0007309948339302568
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.000730994832690754
1454, epoch_train_loss=0.000730994832690754
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.0007309948314521345
1455, epoch_train_loss=0.0007309948314521345
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.000730994830214397
1456, epoch_train_loss=0.000730994830214397
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.0007309948289775413
1457, epoch_train_loss=0.0007309948289775413
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.0007309948277415675
1458, epoch_train_loss=0.0007309948277415675
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.0007309948265064744
1459, epoch_train_loss=0.0007309948265064744
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.0007309948252722619
1460, epoch_train_loss=0.0007309948252722619
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.0007309948240389291
1461, epoch_train_loss=0.0007309948240389291
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.0007309948228064758
1462, epoch_train_loss=0.0007309948228064758
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.0007309948215749015
1463, epoch_train_loss=0.0007309948215749015
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.0007309948203442058
1464, epoch_train_loss=0.0007309948203442058
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0007309948191143879
1465, epoch_train_loss=0.0007309948191143879
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.0007309948178854474
1466, epoch_train_loss=0.0007309948178854474
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.0007309948166573841
1467, epoch_train_loss=0.0007309948166573841
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.0007309948154301969
1468, epoch_train_loss=0.0007309948154301969
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0007309948142038857
1469, epoch_train_loss=0.0007309948142038857
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.00073099481297845
1470, epoch_train_loss=0.00073099481297845
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0007309948117538893
1471, epoch_train_loss=0.0007309948117538893
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.0007309948105302029
1472, epoch_train_loss=0.0007309948105302029
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.0007309948093073905
1473, epoch_train_loss=0.0007309948093073905
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0007309948080854515
1474, epoch_train_loss=0.0007309948080854515
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007309948068643854
1475, epoch_train_loss=0.0007309948068643854
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.0007309948056441919
1476, epoch_train_loss=0.0007309948056441919
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.0007309948044248704
1477, epoch_train_loss=0.0007309948044248704
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.0007309948032064199
1478, epoch_train_loss=0.0007309948032064199
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.0007309948019888406
1479, epoch_train_loss=0.0007309948019888406
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0007309948007721315
1480, epoch_train_loss=0.0007309948007721315
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.0007309947995562925
1481, epoch_train_loss=0.0007309947995562925
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.0007309947983413227
1482, epoch_train_loss=0.0007309947983413227
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0007309947971272218
1483, epoch_train_loss=0.0007309947971272218
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0007309947959139893
1484, epoch_train_loss=0.0007309947959139893
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0007309947947016247
1485, epoch_train_loss=0.0007309947947016247
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0007309947934901274
1486, epoch_train_loss=0.0007309947934901274
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.000730994792279497
1487, epoch_train_loss=0.000730994792279497
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.000730994791069733
1488, epoch_train_loss=0.000730994791069733
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.0007309947898608348
1489, epoch_train_loss=0.0007309947898608348
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.0007309947886528019
1490, epoch_train_loss=0.0007309947886528019
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.0007309947874456339
1491, epoch_train_loss=0.0007309947874456339
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.00073099478623933
1492, epoch_train_loss=0.00073099478623933
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0007309947850338899
1493, epoch_train_loss=0.0007309947850338899
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0007309947838293132
1494, epoch_train_loss=0.0007309947838293132
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0007309947826255992
1495, epoch_train_loss=0.0007309947826255992
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.0007309947814227474
1496, epoch_train_loss=0.0007309947814227474
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0007309947802207575
1497, epoch_train_loss=0.0007309947802207575
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0007309947790196288
1498, epoch_train_loss=0.0007309947790196288
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0007309947778193607
1499, epoch_train_loss=0.0007309947778193607
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.0007309947766199528
1500, epoch_train_loss=0.0007309947766199528
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.0007309947754214046
1501, epoch_train_loss=0.0007309947754214046
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.0007309947742237156
1502, epoch_train_loss=0.0007309947742237156
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.0007309947730268855
1503, epoch_train_loss=0.0007309947730268855
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.0007309947718309133
1504, epoch_train_loss=0.0007309947718309133
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0007309947706357987
1505, epoch_train_loss=0.0007309947706357987
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0007309947694415411
1506, epoch_train_loss=0.0007309947694415411
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.0007309947682481405
1507, epoch_train_loss=0.0007309947682481405
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.0007309947670555958
1508, epoch_train_loss=0.0007309947670555958
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.0007309947658639067
1509, epoch_train_loss=0.0007309947658639067
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.0007309947646730724
1510, epoch_train_loss=0.0007309947646730724
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.0007309947634830928
1511, epoch_train_loss=0.0007309947634830928
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.0007309947622939673
1512, epoch_train_loss=0.0007309947622939673
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.0007309947611056954
1513, epoch_train_loss=0.0007309947611056954
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.0007309947599182762
1514, epoch_train_loss=0.0007309947599182762
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0007309947587317097
1515, epoch_train_loss=0.0007309947587317097
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.000730994757545995
1516, epoch_train_loss=0.000730994757545995
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.0007309947563611318
1517, epoch_train_loss=0.0007309947563611318
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 0.0007309947551771195
1518, epoch_train_loss=0.0007309947551771195
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 0.0007309947539939575
1519, epoch_train_loss=0.0007309947539939575
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0007309947528116456
1520, epoch_train_loss=0.0007309947528116456
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.0007309947516301828
1521, epoch_train_loss=0.0007309947516301828
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.000730994750449569
1522, epoch_train_loss=0.000730994750449569
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 0.0007309947492698034
1523, epoch_train_loss=0.0007309947492698034
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 0.0007309947480908857
1524, epoch_train_loss=0.0007309947480908857
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.0007309947469128152
1525, epoch_train_loss=0.0007309947469128152
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.0007309947457355917
1526, epoch_train_loss=0.0007309947457355917
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.0007309947445592141
1527, epoch_train_loss=0.0007309947445592141
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 0.0007309947433836822
1528, epoch_train_loss=0.0007309947433836822
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 0.0007309947422089955
1529, epoch_train_loss=0.0007309947422089955
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 0.0007309947410351536
1530, epoch_train_loss=0.0007309947410351536
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 0.0007309947398621558
1531, epoch_train_loss=0.0007309947398621558
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 0.0007309947386900014
1532, epoch_train_loss=0.0007309947386900014
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 0.0007309947375186905
1533, epoch_train_loss=0.0007309947375186905
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 0.000730994736348222
1534, epoch_train_loss=0.000730994736348222
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 0.0007309947351785954
1535, epoch_train_loss=0.0007309947351785954
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 0.0007309947340098105
1536, epoch_train_loss=0.0007309947340098105
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.0007309947328418666
1537, epoch_train_loss=0.0007309947328418666
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.0007309947316747632
1538, epoch_train_loss=0.0007309947316747632
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0007309947305084997
1539, epoch_train_loss=0.0007309947305084997
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.0007309947293430756
1540, epoch_train_loss=0.0007309947293430756
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.0007309947281784905
1541, epoch_train_loss=0.0007309947281784905
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.0007309947270147437
1542, epoch_train_loss=0.0007309947270147437
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.0007309947258518347
1543, epoch_train_loss=0.0007309947258518347
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0007309947246897632
1544, epoch_train_loss=0.0007309947246897632
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.0007309947235285283
1545, epoch_train_loss=0.0007309947235285283
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.0007309947223681296
1546, epoch_train_loss=0.0007309947223681296
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.0007309947212085669
1547, epoch_train_loss=0.0007309947212085669
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.0007309947200498395
1548, epoch_train_loss=0.0007309947200498395
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.0007309947188919466
1549, epoch_train_loss=0.0007309947188919466
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.0007309947177348879
1550, epoch_train_loss=0.0007309947177348879
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.000730994716578663
1551, epoch_train_loss=0.000730994716578663
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.0007309947154232712
1552, epoch_train_loss=0.0007309947154232712
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.0007309947142687118
1553, epoch_train_loss=0.0007309947142687118
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0007309947131149846
1554, epoch_train_loss=0.0007309947131149846
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.0007309947119620889
1555, epoch_train_loss=0.0007309947119620889
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.0007309947108100241
1556, epoch_train_loss=0.0007309947108100241
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0007309947096587901
1557, epoch_train_loss=0.0007309947096587901
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.0007309947085083858
1558, epoch_train_loss=0.0007309947085083858
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.000730994707358811
1559, epoch_train_loss=0.000730994707358811
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.000730994706210065
1560, epoch_train_loss=0.000730994706210065
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0007309947050621473
1561, epoch_train_loss=0.0007309947050621473
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.0007309947039150575
1562, epoch_train_loss=0.0007309947039150575
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.0007309947027687953
1563, epoch_train_loss=0.0007309947027687953
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.0007309947016233597
1564, epoch_train_loss=0.0007309947016233597
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.0007309947004787503
1565, epoch_train_loss=0.0007309947004787503
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0007309946993349668
1566, epoch_train_loss=0.0007309946993349668
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.0007309946981920082
1567, epoch_train_loss=0.0007309946981920082
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0007309946970498745
1568, epoch_train_loss=0.0007309946970498745
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.0007309946959085648
1569, epoch_train_loss=0.0007309946959085648
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0007309946947680788
1570, epoch_train_loss=0.0007309946947680788
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.0007309946936284158
1571, epoch_train_loss=0.0007309946936284158
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.0007309946924895753
1572, epoch_train_loss=0.0007309946924895753
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.000730994691351557
1573, epoch_train_loss=0.000730994691351557
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.0007309946902143602
1574, epoch_train_loss=0.0007309946902143602
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0007309946890779841
1575, epoch_train_loss=0.0007309946890779841
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0007309946879424286
1576, epoch_train_loss=0.0007309946879424286
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0007309946868076929
1577, epoch_train_loss=0.0007309946868076929
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.0007309946856737764
1578, epoch_train_loss=0.0007309946856737764
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.0007309946845406789
1579, epoch_train_loss=0.0007309946845406789
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.0007309946834083999
1580, epoch_train_loss=0.0007309946834083999
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.0007309946822769383
1581, epoch_train_loss=0.0007309946822769383
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.0007309946811462943
1582, epoch_train_loss=0.0007309946811462943
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0007309946800164667
1583, epoch_train_loss=0.0007309946800164667
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.0007309946788874553
1584, epoch_train_loss=0.0007309946788874553
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.0007309946777592596
1585, epoch_train_loss=0.0007309946777592596
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.0007309946766318791
1586, epoch_train_loss=0.0007309946766318791
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.0007309946755053129
1587, epoch_train_loss=0.0007309946755053129
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.0007309946743795609
1588, epoch_train_loss=0.0007309946743795609
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0007309946732546226
1589, epoch_train_loss=0.0007309946732546226
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.0007309946721304971
1590, epoch_train_loss=0.0007309946721304971
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.000730994671007184
1591, epoch_train_loss=0.000730994671007184
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.0007309946698846827
1592, epoch_train_loss=0.0007309946698846827
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.0007309946687629929
1593, epoch_train_loss=0.0007309946687629929
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.000730994667642114
1594, epoch_train_loss=0.000730994667642114
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.0007309946665220455
1595, epoch_train_loss=0.0007309946665220455
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.0007309946654027866
1596, epoch_train_loss=0.0007309946654027866
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.0007309946642843368
1597, epoch_train_loss=0.0007309946642843368
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.000730994663166696
1598, epoch_train_loss=0.000730994663166696
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.0007309946620498632
1599, epoch_train_loss=0.0007309946620498632
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.000730994660933838
1600, epoch_train_loss=0.000730994660933838
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.0007309946598186199
1601, epoch_train_loss=0.0007309946598186199
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.0007309946587042085
1602, epoch_train_loss=0.0007309946587042085
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.0007309946575906032
1603, epoch_train_loss=0.0007309946575906032
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.0007309946564778032
1604, epoch_train_loss=0.0007309946564778032
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 0.0007309946553658085
1605, epoch_train_loss=0.0007309946553658085
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.0007309946542546178
1606, epoch_train_loss=0.0007309946542546178
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.0007309946531442313
1607, epoch_train_loss=0.0007309946531442313
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.0007309946520346481
1608, epoch_train_loss=0.0007309946520346481
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 0.0007309946509258677
1609, epoch_train_loss=0.0007309946509258677
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.0007309946498178895
1610, epoch_train_loss=0.0007309946498178895
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.0007309946487107133
1611, epoch_train_loss=0.0007309946487107133
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.0007309946476043381
1612, epoch_train_loss=0.0007309946476043381
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0007309946464987637
1613, epoch_train_loss=0.0007309946464987637
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 0.0007309946453939892
1614, epoch_train_loss=0.0007309946453939892
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 0.0007309946442900146
1615, epoch_train_loss=0.0007309946442900146
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.000730994643186839
1616, epoch_train_loss=0.000730994643186839
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.000730994642084462
1617, epoch_train_loss=0.000730994642084462
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 0.0007309946409828832
1618, epoch_train_loss=0.0007309946409828832
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 0.0007309946398821015
1619, epoch_train_loss=0.0007309946398821015
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 0.0007309946387821169
1620, epoch_train_loss=0.0007309946387821169
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 0.0007309946376829288
1621, epoch_train_loss=0.0007309946376829288
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 0.0007309946365845365
1622, epoch_train_loss=0.0007309946365845365
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 0.0007309946354869395
1623, epoch_train_loss=0.0007309946354869395
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 0.0007309946343901374
1624, epoch_train_loss=0.0007309946343901374
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 0.0007309946332941296
1625, epoch_train_loss=0.0007309946332941296
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 0.0007309946321989154
1626, epoch_train_loss=0.0007309946321989154
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 0.0007309946311044945
1627, epoch_train_loss=0.0007309946311044945
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 0.0007309946300108664
1628, epoch_train_loss=0.0007309946300108664
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 0.0007309946289180301
1629, epoch_train_loss=0.0007309946289180301
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 0.0007309946278259856
1630, epoch_train_loss=0.0007309946278259856
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 0.000730994626734732
1631, epoch_train_loss=0.000730994626734732
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 0.000730994625644269
1632, epoch_train_loss=0.000730994625644269
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 0.0007309946245545962
1633, epoch_train_loss=0.0007309946245545962
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 0.0007309946234657124
1634, epoch_train_loss=0.0007309946234657124
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 0.000730994622377618
1635, epoch_train_loss=0.000730994622377618
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 0.0007309946212903116
1636, epoch_train_loss=0.0007309946212903116
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 0.0007309946202037933
1637, epoch_train_loss=0.0007309946202037933
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 0.0007309946191180622
1638, epoch_train_loss=0.0007309946191180622
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 0.0007309946180331177
1639, epoch_train_loss=0.0007309946180331177
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 0.0007309946169489596
1640, epoch_train_loss=0.0007309946169489596
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 0.0007309946158655873
1641, epoch_train_loss=0.0007309946158655873
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 0.0007309946147830002
1642, epoch_train_loss=0.0007309946147830002
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 0.0007309946137011974
1643, epoch_train_loss=0.0007309946137011974
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 0.0007309946126201789
1644, epoch_train_loss=0.0007309946126201789
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 0.000730994611539944
1645, epoch_train_loss=0.000730994611539944
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 0.000730994610460492
1646, epoch_train_loss=0.000730994610460492
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 0.0007309946093818227
1647, epoch_train_loss=0.0007309946093818227
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 0.000730994608303935
1648, epoch_train_loss=0.000730994608303935
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 0.0007309946072268288
1649, epoch_train_loss=0.0007309946072268288
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 0.0007309946061505037
1650, epoch_train_loss=0.0007309946061505037
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 0.0007309946050749588
1651, epoch_train_loss=0.0007309946050749588
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 0.0007309946040001937
1652, epoch_train_loss=0.0007309946040001937
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 0.0007309946029262079
1653, epoch_train_loss=0.0007309946029262079
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 0.0007309946018530008
1654, epoch_train_loss=0.0007309946018530008
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 0.0007309946007805719
1655, epoch_train_loss=0.0007309946007805719
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 0.0007309945997089208
1656, epoch_train_loss=0.0007309945997089208
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 0.0007309945986380466
1657, epoch_train_loss=0.0007309945986380466
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 0.0007309945975679491
1658, epoch_train_loss=0.0007309945975679491
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 0.0007309945964986277
1659, epoch_train_loss=0.0007309945964986277
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 0.0007309945954300817
1660, epoch_train_loss=0.0007309945954300817
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 0.0007309945943623107
1661, epoch_train_loss=0.0007309945943623107
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 0.0007309945932953141
1662, epoch_train_loss=0.0007309945932953141
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 0.0007309945922290916
1663, epoch_train_loss=0.0007309945922290916
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 0.0007309945911636425
1664, epoch_train_loss=0.0007309945911636425
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 0.000730994590098966
1665, epoch_train_loss=0.000730994590098966
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 0.0007309945890350618
1666, epoch_train_loss=0.0007309945890350618
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 0.0007309945879719295
1667, epoch_train_loss=0.0007309945879719295
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 0.0007309945869095683
1668, epoch_train_loss=0.0007309945869095683
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 0.0007309945858479778
1669, epoch_train_loss=0.0007309945858479778
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 0.0007309945847871577
1670, epoch_train_loss=0.0007309945847871577
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 0.0007309945837271069
1671, epoch_train_loss=0.0007309945837271069
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 0.0007309945826678253
1672, epoch_train_loss=0.0007309945826678253
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 0.0007309945816093123
1673, epoch_train_loss=0.0007309945816093123
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 0.0007309945805515674
1674, epoch_train_loss=0.0007309945805515674
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 0.0007309945794945899
1675, epoch_train_loss=0.0007309945794945899
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.0007309945784383794
1676, epoch_train_loss=0.0007309945784383794
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.0007309945773829352
1677, epoch_train_loss=0.0007309945773829352
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.0007309945763282569
1678, epoch_train_loss=0.0007309945763282569
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.000730994575274344
1679, epoch_train_loss=0.000730994575274344
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0007309945742211958
1680, epoch_train_loss=0.0007309945742211958
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.000730994573168812
1681, epoch_train_loss=0.000730994573168812
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.0007309945721171918
1682, epoch_train_loss=0.0007309945721171918
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.0007309945710663347
1683, epoch_train_loss=0.0007309945710663347
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.0007309945700162406
1684, epoch_train_loss=0.0007309945700162406
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.0007309945689669084
1685, epoch_train_loss=0.0007309945689669084
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0007309945679183378
1686, epoch_train_loss=0.0007309945679183378
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.0007309945668705283
1687, epoch_train_loss=0.0007309945668705283
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.0007309945658234793
1688, epoch_train_loss=0.0007309945658234793
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.0007309945647771903
1689, epoch_train_loss=0.0007309945647771903
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.0007309945637316607
1690, epoch_train_loss=0.0007309945637316607
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.0007309945626868901
1691, epoch_train_loss=0.0007309945626868901
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.0007309945616428779
1692, epoch_train_loss=0.0007309945616428779
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0007309945605996236
1693, epoch_train_loss=0.0007309945605996236
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.0007309945595571265
1694, epoch_train_loss=0.0007309945595571265
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.0007309945585153861
1695, epoch_train_loss=0.0007309945585153861
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.000730994557474402
1696, epoch_train_loss=0.000730994557474402
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.0007309945564341738
1697, epoch_train_loss=0.0007309945564341738
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0007309945553947008
1698, epoch_train_loss=0.0007309945553947008
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.0007309945543559822
1699, epoch_train_loss=0.0007309945543559822
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.0007309945533180179
1700, epoch_train_loss=0.0007309945533180179
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.000730994552280807
1701, epoch_train_loss=0.000730994552280807
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.0007309945512443491
1702, epoch_train_loss=0.0007309945512443491
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.000730994550208644
1703, epoch_train_loss=0.000730994550208644
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.0007309945491736906
1704, epoch_train_loss=0.0007309945491736906
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0007309945481394887
1705, epoch_train_loss=0.0007309945481394887
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.0007309945471060378
1706, epoch_train_loss=0.0007309945471060378
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.0007309945460733373
1707, epoch_train_loss=0.0007309945460733373
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.0007309945450413865
1708, epoch_train_loss=0.0007309945450413865
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.000730994544010185
1709, epoch_train_loss=0.000730994544010185
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.0007309945429797325
1710, epoch_train_loss=0.0007309945429797325
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.000730994541950028
1711, epoch_train_loss=0.000730994541950028
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.0007309945409210714
1712, epoch_train_loss=0.0007309945409210714
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0007309945398928619
1713, epoch_train_loss=0.0007309945398928619
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.0007309945388653988
1714, epoch_train_loss=0.0007309945388653988
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.0007309945378386821
1715, epoch_train_loss=0.0007309945378386821
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.000730994536812711
1716, epoch_train_loss=0.000730994536812711
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.0007309945357874848
1717, epoch_train_loss=0.0007309945357874848
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.0007309945347630032
1718, epoch_train_loss=0.0007309945347630032
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.0007309945337392655
1719, epoch_train_loss=0.0007309945337392655
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.0007309945327162713
1720, epoch_train_loss=0.0007309945327162713
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.00073099453169402
1721, epoch_train_loss=0.00073099453169402
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0007309945306725111
1722, epoch_train_loss=0.0007309945306725111
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.000730994529651744
1723, epoch_train_loss=0.000730994529651744
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.0007309945286317184
1724, epoch_train_loss=0.0007309945286317184
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.0007309945276124335
1725, epoch_train_loss=0.0007309945276124335
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0007309945265938887
1726, epoch_train_loss=0.0007309945265938887
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.0007309945255760837
1727, epoch_train_loss=0.0007309945255760837
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.000730994524559018
1728, epoch_train_loss=0.000730994524559018
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0007309945235426909
1729, epoch_train_loss=0.0007309945235426909
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0007309945225271019
1730, epoch_train_loss=0.0007309945225271019
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.0007309945215122506
1731, epoch_train_loss=0.0007309945215122506
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.0007309945204981363
1732, epoch_train_loss=0.0007309945204981363
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.0007309945194847586
1733, epoch_train_loss=0.0007309945194847586
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.0007309945184721168
1734, epoch_train_loss=0.0007309945184721168
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.0007309945174602105
1735, epoch_train_loss=0.0007309945174602105
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.0007309945164490391
1736, epoch_train_loss=0.0007309945164490391
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.0007309945154386022
1737, epoch_train_loss=0.0007309945154386022
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.000730994514428899
1738, epoch_train_loss=0.000730994514428899
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.0007309945134199294
1739, epoch_train_loss=0.0007309945134199294
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.0007309945124116927
1740, epoch_train_loss=0.0007309945124116927
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 0.0007309945114041881
1741, epoch_train_loss=0.0007309945114041881
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.0007309945103974153
1742, epoch_train_loss=0.0007309945103974153
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.0007309945093913738
1743, epoch_train_loss=0.0007309945093913738
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.000730994508386063
1744, epoch_train_loss=0.000730994508386063
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0007309945073814822
1745, epoch_train_loss=0.0007309945073814822
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 0.0007309945063776312
1746, epoch_train_loss=0.0007309945063776312
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 0.0007309945053745092
1747, epoch_train_loss=0.0007309945053745092
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0007309945043721159
1748, epoch_train_loss=0.0007309945043721159
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.0007309945033704506
1749, epoch_train_loss=0.0007309945033704506
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.000730994502369513
1750, epoch_train_loss=0.000730994502369513
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 0.0007309945013693022
1751, epoch_train_loss=0.0007309945013693022
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 0.0007309945003698181
1752, epoch_train_loss=0.0007309945003698181
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.0007309944993710597
1753, epoch_train_loss=0.0007309944993710597
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.0007309944983730268
1754, epoch_train_loss=0.0007309944983730268
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 0.0007309944973757187
1755, epoch_train_loss=0.0007309944973757187
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 0.0007309944963791351
1756, epoch_train_loss=0.0007309944963791351
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 0.0007309944953832752
1757, epoch_train_loss=0.0007309944953832752
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 0.0007309944943881387
1758, epoch_train_loss=0.0007309944943881387
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 0.000730994493393725
1759, epoch_train_loss=0.000730994493393725
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 0.0007309944924000336
1760, epoch_train_loss=0.0007309944924000336
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 0.0007309944914070638
1761, epoch_train_loss=0.0007309944914070638
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 0.0007309944904148153
1762, epoch_train_loss=0.0007309944904148153
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 0.0007309944894232876
1763, epoch_train_loss=0.0007309944894232876
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 0.0007309944884324797
1764, epoch_train_loss=0.0007309944884324797
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 0.0007309944874423918
1765, epoch_train_loss=0.0007309944874423918
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 0.0007309944864530227
1766, epoch_train_loss=0.0007309944864530227
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 0.0007309944854643724
1767, epoch_train_loss=0.0007309944854643724
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 0.0007309944844764399
1768, epoch_train_loss=0.0007309944844764399
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 0.000730994483489225
1769, epoch_train_loss=0.000730994483489225
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 0.000730994482502727
1770, epoch_train_loss=0.000730994482502727
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 0.0007309944815169457
1771, epoch_train_loss=0.0007309944815169457
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 0.0007309944805318801
1772, epoch_train_loss=0.0007309944805318801
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 0.0007309944795475302
1773, epoch_train_loss=0.0007309944795475302
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 0.0007309944785638949
1774, epoch_train_loss=0.0007309944785638949
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 0.0007309944775809739
1775, epoch_train_loss=0.0007309944775809739
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 0.000730994476598767
1776, epoch_train_loss=0.000730994476598767
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 0.0007309944756172732
1777, epoch_train_loss=0.0007309944756172732
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 0.0007309944746364924
1778, epoch_train_loss=0.0007309944746364924
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 0.0007309944736564237
1779, epoch_train_loss=0.0007309944736564237
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 0.0007309944726770669
1780, epoch_train_loss=0.0007309944726770669
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 0.0007309944716984212
1781, epoch_train_loss=0.0007309944716984212
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 0.0007309944707204862
1782, epoch_train_loss=0.0007309944707204862
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 0.0007309944697432614
1783, epoch_train_loss=0.0007309944697432614
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 0.0007309944687667461
1784, epoch_train_loss=0.0007309944687667461
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 0.0007309944677909401
1785, epoch_train_loss=0.0007309944677909401
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 0.0007309944668158426
1786, epoch_train_loss=0.0007309944668158426
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 0.0007309944658414531
1787, epoch_train_loss=0.0007309944658414531
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.0007309944648677712
1788, epoch_train_loss=0.0007309944648677712
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.0007309944638947964
1789, epoch_train_loss=0.0007309944638947964
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0007309944629225279
1790, epoch_train_loss=0.0007309944629225279
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0007309944619509658
1791, epoch_train_loss=0.0007309944619509658
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0007309944609801088
1792, epoch_train_loss=0.0007309944609801088
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.0007309944600099569
1793, epoch_train_loss=0.0007309944600099569
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.0007309944590405094
1794, epoch_train_loss=0.0007309944590405094
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.0007309944580717656
1795, epoch_train_loss=0.0007309944580717656
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.0007309944571037254
1796, epoch_train_loss=0.0007309944571037254
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.0007309944561363879
1797, epoch_train_loss=0.0007309944561363879
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.0007309944551697529
1798, epoch_train_loss=0.0007309944551697529
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.0007309944542038196
1799, epoch_train_loss=0.0007309944542038196
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.0007309944532385875
1800, epoch_train_loss=0.0007309944532385875
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.0007309944522740564
1801, epoch_train_loss=0.0007309944522740564
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.0007309944513102253
1802, epoch_train_loss=0.0007309944513102253
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.000730994450347094
1803, epoch_train_loss=0.000730994450347094
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.000730994449384662
1804, epoch_train_loss=0.000730994449384662
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.0007309944484229286
1805, epoch_train_loss=0.0007309944484229286
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.0007309944474618935
1806, epoch_train_loss=0.0007309944474618935
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.0007309944465015559
1807, epoch_train_loss=0.0007309944465015559
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0007309944455419155
1808, epoch_train_loss=0.0007309944455419155
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.000730994444582972
1809, epoch_train_loss=0.000730994444582972
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.0007309944436247241
1810, epoch_train_loss=0.0007309944436247241
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.000730994442667172
1811, epoch_train_loss=0.000730994442667172
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.0007309944417103149
1812, epoch_train_loss=0.0007309944417103149
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.0007309944407541523
1813, epoch_train_loss=0.0007309944407541523
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.0007309944397986838
1814, epoch_train_loss=0.0007309944397986838
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.0007309944388439089
1815, epoch_train_loss=0.0007309944388439089
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.0007309944378898267
1816, epoch_train_loss=0.0007309944378898267
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.0007309944369364372
1817, epoch_train_loss=0.0007309944369364372
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0007309944359837396
1818, epoch_train_loss=0.0007309944359837396
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0007309944350317334
1819, epoch_train_loss=0.0007309944350317334
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0007309944340804181
1820, epoch_train_loss=0.0007309944340804181
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0007309944331297932
1821, epoch_train_loss=0.0007309944331297932
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0007309944321798582
1822, epoch_train_loss=0.0007309944321798582
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.0007309944312306125
1823, epoch_train_loss=0.0007309944312306125
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.0007309944302820559
1824, epoch_train_loss=0.0007309944302820559
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0007309944293341875
1825, epoch_train_loss=0.0007309944293341875
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.0007309944283870068
1826, epoch_train_loss=0.0007309944283870068
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.0007309944274405134
1827, epoch_train_loss=0.0007309944274405134
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.0007309944264947068
1828, epoch_train_loss=0.0007309944264947068
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007309944255495868
1829, epoch_train_loss=0.0007309944255495868
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.000730994424605152
1830, epoch_train_loss=0.000730994424605152
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0007309944236614028
1831, epoch_train_loss=0.0007309944236614028
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.0007309944227183383
1832, epoch_train_loss=0.0007309944227183383
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.000730994421775958
1833, epoch_train_loss=0.000730994421775958
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0007309944208342613
1834, epoch_train_loss=0.0007309944208342613
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.000730994419893248
1835, epoch_train_loss=0.000730994419893248
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.0007309944189529171
1836, epoch_train_loss=0.0007309944189529171
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.0007309944180132684
1837, epoch_train_loss=0.0007309944180132684
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.0007309944170743013
1838, epoch_train_loss=0.0007309944170743013
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0007309944161360155
1839, epoch_train_loss=0.0007309944161360155
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.0007309944151984103
1840, epoch_train_loss=0.0007309944151984103
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0007309944142614854
1841, epoch_train_loss=0.0007309944142614854
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.0007309944133252397
1842, epoch_train_loss=0.0007309944133252397
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.0007309944123896735
1843, epoch_train_loss=0.0007309944123896735
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.0007309944114547854
1844, epoch_train_loss=0.0007309944114547854
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.0007309944105205758
1845, epoch_train_loss=0.0007309944105205758
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.0007309944095870433
1846, epoch_train_loss=0.0007309944095870433
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 0.0007309944086541881
1847, epoch_train_loss=0.0007309944086541881
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.0007309944077220094
1848, epoch_train_loss=0.0007309944077220094
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.0007309944067905067
1849, epoch_train_loss=0.0007309944067905067
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.0007309944058596796
1850, epoch_train_loss=0.0007309944058596796
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.0007309944049295274
1851, epoch_train_loss=0.0007309944049295274
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 0.0007309944040000496
1852, epoch_train_loss=0.0007309944040000496
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.000730994403071246
1853, epoch_train_loss=0.000730994403071246
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.0007309944021431156
1854, epoch_train_loss=0.0007309944021431156
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.0007309944012156582
1855, epoch_train_loss=0.0007309944012156582
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.0007309944002888733
1856, epoch_train_loss=0.0007309944002888733
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 0.0007309943993627603
1857, epoch_train_loss=0.0007309943993627603
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 0.0007309943984373187
1858, epoch_train_loss=0.0007309943984373187
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.0007309943975125482
1859, epoch_train_loss=0.0007309943975125482
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.000730994396588448
1860, epoch_train_loss=0.000730994396588448
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.0007309943956650178
1861, epoch_train_loss=0.0007309943956650178
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 0.0007309943947422567
1862, epoch_train_loss=0.0007309943947422567
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 0.0007309943938201647
1863, epoch_train_loss=0.0007309943938201647
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 0.0007309943928987411
1864, epoch_train_loss=0.0007309943928987411
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 0.0007309943919779853
1865, epoch_train_loss=0.0007309943919779853
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 0.0007309943910578968
1866, epoch_train_loss=0.0007309943910578968
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 0.0007309943901384753
1867, epoch_train_loss=0.0007309943901384753
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 0.00073099438921972
1868, epoch_train_loss=0.00073099438921972
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 0.0007309943883016308
1869, epoch_train_loss=0.0007309943883016308
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 0.0007309943873842067
1870, epoch_train_loss=0.0007309943873842067
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 0.0007309943864674475
1871, epoch_train_loss=0.0007309943864674475
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 0.0007309943855513526
1872, epoch_train_loss=0.0007309943855513526
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 0.0007309943846359215
1873, epoch_train_loss=0.0007309943846359215
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 0.0007309943837211538
1874, epoch_train_loss=0.0007309943837211538
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 0.000730994382807049
1875, epoch_train_loss=0.000730994382807049
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 0.0007309943818936063
1876, epoch_train_loss=0.0007309943818936063
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 0.0007309943809808253
1877, epoch_train_loss=0.0007309943809808253
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 0.0007309943800687059
1878, epoch_train_loss=0.0007309943800687059
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 0.000730994379157247
1879, epoch_train_loss=0.000730994379157247
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 0.0007309943782464487
1880, epoch_train_loss=0.0007309943782464487
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 0.00073099437733631
1881, epoch_train_loss=0.00073099437733631
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 0.0007309943764268307
1882, epoch_train_loss=0.0007309943764268307
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 0.0007309943755180101
1883, epoch_train_loss=0.0007309943755180101
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 0.0007309943746098476
1884, epoch_train_loss=0.0007309943746098476
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 0.0007309943737023432
1885, epoch_train_loss=0.0007309943737023432
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 0.0007309943727954959
1886, epoch_train_loss=0.0007309943727954959
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 0.0007309943718893055
1887, epoch_train_loss=0.0007309943718893055
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 0.0007309943709837712
1888, epoch_train_loss=0.0007309943709837712
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 0.0007309943700788927
1889, epoch_train_loss=0.0007309943700788927
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 0.0007309943691746694
1890, epoch_train_loss=0.0007309943691746694
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 0.0007309943682711011
1891, epoch_train_loss=0.0007309943682711011
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 0.0007309943673681869
1892, epoch_train_loss=0.0007309943673681869
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 0.0007309943664659264
1893, epoch_train_loss=0.0007309943664659264
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 0.0007309943655643193
1894, epoch_train_loss=0.0007309943655643193
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 0.000730994364663365
1895, epoch_train_loss=0.000730994364663365
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 0.0007309943637630628
1896, epoch_train_loss=0.0007309943637630628
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 0.0007309943628634124
1897, epoch_train_loss=0.0007309943628634124
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 0.0007309943619644133
1898, epoch_train_loss=0.0007309943619644133
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 0.000730994361066065
1899, epoch_train_loss=0.000730994361066065
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 0.000730994360168367
1900, epoch_train_loss=0.000730994360168367
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 0.0007309943592713186
1901, epoch_train_loss=0.0007309943592713186
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 0.0007309943583749196
1902, epoch_train_loss=0.0007309943583749196
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 0.0007309943574791695
1903, epoch_train_loss=0.0007309943574791695
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 0.0007309943565840674
1904, epoch_train_loss=0.0007309943565840674
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 0.0007309943556896133
1905, epoch_train_loss=0.0007309943556896133
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 0.0007309943547958063
1906, epoch_train_loss=0.0007309943547958063
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 0.0007309943539026461
1907, epoch_train_loss=0.0007309943539026461
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 0.0007309943530101322
1908, epoch_train_loss=0.0007309943530101322
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 0.0007309943521182641
1909, epoch_train_loss=0.0007309943521182641
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.0007309943512270414
1910, epoch_train_loss=0.0007309943512270414
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.0007309943503364633
1911, epoch_train_loss=0.0007309943503364633
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.0007309943494465298
1912, epoch_train_loss=0.0007309943494465298
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.0007309943485572398
1913, epoch_train_loss=0.0007309943485572398
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0007309943476685932
1914, epoch_train_loss=0.0007309943476685932
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0007309943467805896
1915, epoch_train_loss=0.0007309943467805896
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.000730994345893228
1916, epoch_train_loss=0.000730994345893228
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.0007309943450065085
1917, epoch_train_loss=0.0007309943450065085
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.0007309943441204302
1918, epoch_train_loss=0.0007309943441204302
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.0007309943432349926
1919, epoch_train_loss=0.0007309943432349926
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.0007309943423501955
1920, epoch_train_loss=0.0007309943423501955
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.0007309943414660383
1921, epoch_train_loss=0.0007309943414660383
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.0007309943405825204
1922, epoch_train_loss=0.0007309943405825204
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.0007309943396996414
1923, epoch_train_loss=0.0007309943396996414
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.0007309943388174006
1924, epoch_train_loss=0.0007309943388174006
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.0007309943379357978
1925, epoch_train_loss=0.0007309943379357978
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.0007309943370548324
1926, epoch_train_loss=0.0007309943370548324
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.0007309943361745039
1927, epoch_train_loss=0.0007309943361745039
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.0007309943352948118
1928, epoch_train_loss=0.0007309943352948118
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.0007309943344157555
1929, epoch_train_loss=0.0007309943344157555
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.0007309943335373347
1930, epoch_train_loss=0.0007309943335373347
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.0007309943326595489
1931, epoch_train_loss=0.0007309943326595489
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.0007309943317823973
1932, epoch_train_loss=0.0007309943317823973
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.0007309943309058797
1933, epoch_train_loss=0.0007309943309058797
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.0007309943300299957
1934, epoch_train_loss=0.0007309943300299957
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.0007309943291547447
1935, epoch_train_loss=0.0007309943291547447
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0007309943282801261
1936, epoch_train_loss=0.0007309943282801261
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0007309943274061395
1937, epoch_train_loss=0.0007309943274061395
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0007309943265327843
1938, epoch_train_loss=0.0007309943265327843
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.0007309943256600602
1939, epoch_train_loss=0.0007309943256600602
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.0007309943247879668
1940, epoch_train_loss=0.0007309943247879668
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0007309943239165032
1941, epoch_train_loss=0.0007309943239165032
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.0007309943230456692
1942, epoch_train_loss=0.0007309943230456692
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0007309943221754643
1943, epoch_train_loss=0.0007309943221754643
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.0007309943213058879
1944, epoch_train_loss=0.0007309943213058879
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.0007309943204369397
1945, epoch_train_loss=0.0007309943204369397
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.000730994319568619
1946, epoch_train_loss=0.000730994319568619
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0007309943187009252
1947, epoch_train_loss=0.0007309943187009252
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0007309943178338583
1948, epoch_train_loss=0.0007309943178338583
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0007309943169674176
1949, epoch_train_loss=0.0007309943169674176
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.0007309943161016024
1950, epoch_train_loss=0.0007309943161016024
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007309943152364123
1951, epoch_train_loss=0.0007309943152364123
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.000730994314371847
1952, epoch_train_loss=0.000730994314371847
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0007309943135079059
1953, epoch_train_loss=0.0007309943135079059
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0007309943126445885
1954, epoch_train_loss=0.0007309943126445885
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.0007309943117818942
1955, epoch_train_loss=0.0007309943117818942
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007309943109198228
1956, epoch_train_loss=0.0007309943109198228
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007309943100583735
1957, epoch_train_loss=0.0007309943100583735
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.0007309943091975463
1958, epoch_train_loss=0.0007309943091975463
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.00073099430833734
1959, epoch_train_loss=0.00073099430833734
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.0007309943074777546
1960, epoch_train_loss=0.0007309943074777546
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0007309943066187897
1961, epoch_train_loss=0.0007309943066187897
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0007309943057604445
1962, epoch_train_loss=0.0007309943057604445
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.0007309943049027187
1963, epoch_train_loss=0.0007309943049027187
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.0007309943040456118
1964, epoch_train_loss=0.0007309943040456118
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.0007309943031891233
1965, epoch_train_loss=0.0007309943031891233
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.0007309943023332527
1966, epoch_train_loss=0.0007309943023332527
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0007309943014779995
1967, epoch_train_loss=0.0007309943014779995
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.0007309943006233634
1968, epoch_train_loss=0.0007309943006233634
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 0.0007309942997693436
1969, epoch_train_loss=0.0007309942997693436
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.0007309942989159399
1970, epoch_train_loss=0.0007309942989159399
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0007309942980631516
1971, epoch_train_loss=0.0007309942980631516
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.0007309942972109784
1972, epoch_train_loss=0.0007309942972109784
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.0007309942963594196
1973, epoch_train_loss=0.0007309942963594196
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 0.0007309942955084752
1974, epoch_train_loss=0.0007309942955084752
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.0007309942946581442
1975, epoch_train_loss=0.0007309942946581442
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.0007309942938084263
1976, epoch_train_loss=0.0007309942938084263
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0007309942929593211
1977, epoch_train_loss=0.0007309942929593211
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.0007309942921108279
1978, epoch_train_loss=0.0007309942921108279
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 0.0007309942912629466
1979, epoch_train_loss=0.0007309942912629466
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 0.0007309942904156764
1980, epoch_train_loss=0.0007309942904156764
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.000730994289569017
1981, epoch_train_loss=0.000730994289569017
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.0007309942887229677
1982, epoch_train_loss=0.0007309942887229677
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.0007309942878775282
1983, epoch_train_loss=0.0007309942878775282
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 0.0007309942870326982
1984, epoch_train_loss=0.0007309942870326982
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 0.0007309942861884769
1985, epoch_train_loss=0.0007309942861884769
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 0.0007309942853448638
1986, epoch_train_loss=0.0007309942853448638
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.0007309942845018589
1987, epoch_train_loss=0.0007309942845018589
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 0.000730994283659461
1988, epoch_train_loss=0.000730994283659461
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 0.0007309942828176703
1989, epoch_train_loss=0.0007309942828176703
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 0.0007309942819764861
1990, epoch_train_loss=0.0007309942819764861
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 0.0007309942811359076
1991, epoch_train_loss=0.0007309942811359076
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 0.0007309942802959347
1992, epoch_train_loss=0.0007309942802959347
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 0.0007309942794565668
1993, epoch_train_loss=0.0007309942794565668
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 0.0007309942786178036
1994, epoch_train_loss=0.0007309942786178036
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 0.0007309942777796443
1995, epoch_train_loss=0.0007309942777796443
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 0.0007309942769420887
1996, epoch_train_loss=0.0007309942769420887
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 0.0007309942761051362
1997, epoch_train_loss=0.0007309942761051362
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 0.0007309942752687864
1998, epoch_train_loss=0.0007309942752687864
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 0.0007309942744330388
1999, epoch_train_loss=0.0007309942744330388
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 0.0007309942735978927
2000, epoch_train_loss=0.0007309942735978927
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 0.000730994272763348
2001, epoch_train_loss=0.000730994272763348
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 0.000730994271929404
2002, epoch_train_loss=0.000730994271929404
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 0.0007309942710960605
2003, epoch_train_loss=0.0007309942710960605
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 0.0007309942702633167
2004, epoch_train_loss=0.0007309942702633167
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.0007309942694311721
2005, epoch_train_loss=0.0007309942694311721
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.0007309942685996266
2006, epoch_train_loss=0.0007309942685996266
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.0007309942677686794
2007, epoch_train_loss=0.0007309942677686794
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.0007309942669383304
2008, epoch_train_loss=0.0007309942669383304
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0007309942661085784
2009, epoch_train_loss=0.0007309942661085784
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007309942652794239
2010, epoch_train_loss=0.0007309942652794239
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0007309942644508657
2011, epoch_train_loss=0.0007309942644508657
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0007309942636229036
2012, epoch_train_loss=0.0007309942636229036
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.0007309942627955371
2013, epoch_train_loss=0.0007309942627955371
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.0007309942619687657
2014, epoch_train_loss=0.0007309942619687657
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.0007309942611425891
2015, epoch_train_loss=0.0007309942611425891
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.0007309942603170066
2016, epoch_train_loss=0.0007309942603170066
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.0007309942594920178
2017, epoch_train_loss=0.0007309942594920178
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.0007309942586676222
2018, epoch_train_loss=0.0007309942586676222
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.0007309942578438195
2019, epoch_train_loss=0.0007309942578438195
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.0007309942570206091
2020, epoch_train_loss=0.0007309942570206091
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.0007309942561979907
2021, epoch_train_loss=0.0007309942561979907
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0007309942553759636
2022, epoch_train_loss=0.0007309942553759636
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.0007309942545545274
2023, epoch_train_loss=0.0007309942545545274
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.000730994253733682
2024, epoch_train_loss=0.000730994253733682
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.0007309942529134262
2025, epoch_train_loss=0.0007309942529134262
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.0007309942520937603
2026, epoch_train_loss=0.0007309942520937603
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.0007309942512746832
2027, epoch_train_loss=0.0007309942512746832
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.000730994250456195
2028, epoch_train_loss=0.000730994250456195
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.0007309942496382945
2029, epoch_train_loss=0.0007309942496382945
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.0007309942488209819
2030, epoch_train_loss=0.0007309942488209819
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.0007309942480042567
2031, epoch_train_loss=0.0007309942480042567
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0007309942471881182
2032, epoch_train_loss=0.0007309942471881182
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0007309942463725659
2033, epoch_train_loss=0.0007309942463725659
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0007309942455575995
2034, epoch_train_loss=0.0007309942455575995
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.0007309942447432184
2035, epoch_train_loss=0.0007309942447432184
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0007309942439294223
2036, epoch_train_loss=0.0007309942439294223
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0007309942431162108
2037, epoch_train_loss=0.0007309942431162108
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.0007309942423035832
2038, epoch_train_loss=0.0007309942423035832
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.000730994241491539
2039, epoch_train_loss=0.000730994241491539
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0007309942406800778
2040, epoch_train_loss=0.0007309942406800778
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.0007309942398691995
2041, epoch_train_loss=0.0007309942398691995
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.0007309942390589032
2042, epoch_train_loss=0.0007309942390589032
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.0007309942382491886
2043, epoch_train_loss=0.0007309942382491886
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.0007309942374400552
2044, epoch_train_loss=0.0007309942374400552
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.0007309942366315028
2045, epoch_train_loss=0.0007309942366315028
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007309942358235305
2046, epoch_train_loss=0.0007309942358235305
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.0007309942350161383
2047, epoch_train_loss=0.0007309942350161383
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.0007309942342093252
2048, epoch_train_loss=0.0007309942342093252
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.0007309942334030912
2049, epoch_train_loss=0.0007309942334030912
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.0007309942325974357
2050, epoch_train_loss=0.0007309942325974357
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.0007309942317923582
2051, epoch_train_loss=0.0007309942317923582
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0007309942309878584
2052, epoch_train_loss=0.0007309942309878584
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0007309942301839356
2053, epoch_train_loss=0.0007309942301839356
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.0007309942293805895
2054, epoch_train_loss=0.0007309942293805895
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.0007309942285778197
2055, epoch_train_loss=0.0007309942285778197
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0007309942277756255
2056, epoch_train_loss=0.0007309942277756255
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.0007309942269740065
2057, epoch_train_loss=0.0007309942269740065
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.0007309942261729624
2058, epoch_train_loss=0.0007309942261729624
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.0007309942253724929
2059, epoch_train_loss=0.0007309942253724929
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.0007309942245725972
2060, epoch_train_loss=0.0007309942245725972
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 0.000730994223773275
2061, epoch_train_loss=0.000730994223773275
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.0007309942229745258
2062, epoch_train_loss=0.0007309942229745258
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0007309942221763493
2063, epoch_train_loss=0.0007309942221763493
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.0007309942213787447
2064, epoch_train_loss=0.0007309942213787447
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.0007309942205817119
2065, epoch_train_loss=0.0007309942205817119
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 0.0007309942197852502
2066, epoch_train_loss=0.0007309942197852502
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 0.0007309942189893594
2067, epoch_train_loss=0.0007309942189893594
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.0007309942181940389
2068, epoch_train_loss=0.0007309942181940389
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0007309942173992882
2069, epoch_train_loss=0.0007309942173992882
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0007309942166051069
2070, epoch_train_loss=0.0007309942166051069
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.0007309942158114947
2071, epoch_train_loss=0.0007309942158114947
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 0.000730994215018451
2072, epoch_train_loss=0.000730994215018451
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 0.0007309942142259753
2073, epoch_train_loss=0.0007309942142259753
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 0.0007309942134340671
2074, epoch_train_loss=0.0007309942134340671
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.000730994212642726
2075, epoch_train_loss=0.000730994212642726
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.0007309942118519519
2076, epoch_train_loss=0.0007309942118519519
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 0.0007309942110617437
2077, epoch_train_loss=0.0007309942110617437
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 0.0007309942102721015
2078, epoch_train_loss=0.0007309942102721015
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 0.0007309942094830247
2079, epoch_train_loss=0.0007309942094830247
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 0.0007309942086945127
2080, epoch_train_loss=0.0007309942086945127
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 0.0007309942079065652
2081, epoch_train_loss=0.0007309942079065652
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 0.0007309942071191818
2082, epoch_train_loss=0.0007309942071191818
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 0.0007309942063323619
2083, epoch_train_loss=0.0007309942063323619
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 0.0007309942055461051
2084, epoch_train_loss=0.0007309942055461051
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 0.000730994204760411
2085, epoch_train_loss=0.000730994204760411
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 0.0007309942039752792
2086, epoch_train_loss=0.0007309942039752792
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 0.0007309942031907092
2087, epoch_train_loss=0.0007309942031907092
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 0.0007309942024067005
2088, epoch_train_loss=0.0007309942024067005
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 0.0007309942016232525
2089, epoch_train_loss=0.0007309942016232525
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 0.0007309942008403652
2090, epoch_train_loss=0.0007309942008403652
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 0.0007309942000580377
2091, epoch_train_loss=0.0007309942000580377
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 0.0007309941992762697
2092, epoch_train_loss=0.0007309941992762697
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 0.0007309941984950612
2093, epoch_train_loss=0.0007309941984950612
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 0.000730994197714411
2094, epoch_train_loss=0.000730994197714411
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 0.0007309941969343192
2095, epoch_train_loss=0.0007309941969343192
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 0.0007309941961547851
2096, epoch_train_loss=0.0007309941961547851
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 0.0007309941953758084
2097, epoch_train_loss=0.0007309941953758084
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 0.0007309941945973886
2098, epoch_train_loss=0.0007309941945973886
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 0.0007309941938195252
2099, epoch_train_loss=0.0007309941938195252
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 0.0007309941930422178
2100, epoch_train_loss=0.0007309941930422178
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 0.000730994192265466
2101, epoch_train_loss=0.000730994192265466
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 0.0007309941914892694
2102, epoch_train_loss=0.0007309941914892694
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 0.0007309941907136274
2103, epoch_train_loss=0.0007309941907136274
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 0.0007309941899385397
2104, epoch_train_loss=0.0007309941899385397
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 0.0007309941891640059
2105, epoch_train_loss=0.0007309941891640059
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 0.0007309941883900253
2106, epoch_train_loss=0.0007309941883900253
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 0.0007309941876165977
2107, epoch_train_loss=0.0007309941876165977
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 0.0007309941868437225
2108, epoch_train_loss=0.0007309941868437225
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 0.0007309941860713994
2109, epoch_train_loss=0.0007309941860713994
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 0.0007309941852996277
2110, epoch_train_loss=0.0007309941852996277
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 0.0007309941845284075
2111, epoch_train_loss=0.0007309941845284075
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 0.000730994183757738
2112, epoch_train_loss=0.000730994183757738
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 0.0007309941829876185
2113, epoch_train_loss=0.0007309941829876185
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 0.000730994182218049
2114, epoch_train_loss=0.000730994182218049
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 0.0007309941814490289
2115, epoch_train_loss=0.0007309941814490289
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 0.0007309941806805579
2116, epoch_train_loss=0.0007309941806805579
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 0.0007309941799126354
2117, epoch_train_loss=0.0007309941799126354
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 0.0007309941791452608
2118, epoch_train_loss=0.0007309941791452608
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 0.000730994178378434
2119, epoch_train_loss=0.000730994178378434
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 0.0007309941776121544
2120, epoch_train_loss=0.0007309941776121544
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 0.0007309941768464216
2121, epoch_train_loss=0.0007309941768464216
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 0.0007309941760812352
2122, epoch_train_loss=0.0007309941760812352
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 0.0007309941753165947
2123, epoch_train_loss=0.0007309941753165947
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 0.0007309941745524996
2124, epoch_train_loss=0.0007309941745524996
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 0.0007309941737889496
2125, epoch_train_loss=0.0007309941737889496
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 0.0007309941730259444
2126, epoch_train_loss=0.0007309941730259444
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 0.0007309941722634832
2127, epoch_train_loss=0.0007309941722634832
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 0.0007309941715015659
2128, epoch_train_loss=0.0007309941715015659
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 0.000730994170740192
2129, epoch_train_loss=0.000730994170740192
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 0.0007309941699793606
2130, epoch_train_loss=0.0007309941699793606
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 0.0007309941692190718
2131, epoch_train_loss=0.0007309941692190718
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 0.0007309941684593252
2132, epoch_train_loss=0.0007309941684593252
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 0.0007309941677001201
2133, epoch_train_loss=0.0007309941677001201
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 0.0007309941669414559
2134, epoch_train_loss=0.0007309941669414559
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 0.0007309941661833328
2135, epoch_train_loss=0.0007309941661833328
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 0.0007309941654257499
2136, epoch_train_loss=0.0007309941654257499
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.0007309941646687067
2137, epoch_train_loss=0.0007309941646687067
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.0007309941639122033
2138, epoch_train_loss=0.0007309941639122033
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0007309941631562386
2139, epoch_train_loss=0.0007309941631562386
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0007309941624008126
2140, epoch_train_loss=0.0007309941624008126
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0007309941616459247
2141, epoch_train_loss=0.0007309941616459247
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0007309941608915744
2142, epoch_train_loss=0.0007309941608915744
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.0007309941601377615
2143, epoch_train_loss=0.0007309941601377615
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0007309941593844853
2144, epoch_train_loss=0.0007309941593844853
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0007309941586317458
2145, epoch_train_loss=0.0007309941586317458
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.0007309941578795421
2146, epoch_train_loss=0.0007309941578795421
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.0007309941571278742
2147, epoch_train_loss=0.0007309941571278742
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.0007309941563767412
2148, epoch_train_loss=0.0007309941563767412
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.0007309941556261429
2149, epoch_train_loss=0.0007309941556261429
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.000730994154876079
2150, epoch_train_loss=0.000730994154876079
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.0007309941541265488
2151, epoch_train_loss=0.0007309941541265488
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.0007309941533775522
2152, epoch_train_loss=0.0007309941533775522
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.0007309941526290886
2153, epoch_train_loss=0.0007309941526290886
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0007309941518811575
2154, epoch_train_loss=0.0007309941518811575
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.0007309941511337585
2155, epoch_train_loss=0.0007309941511337585
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.0007309941503868914
2156, epoch_train_loss=0.0007309941503868914
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.0007309941496405557
2157, epoch_train_loss=0.0007309941496405557
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0007309941488947506
2158, epoch_train_loss=0.0007309941488947506
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0007309941481494762
2159, epoch_train_loss=0.0007309941481494762
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.0007309941474047317
2160, epoch_train_loss=0.0007309941474047317
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.0007309941466605168
2161, epoch_train_loss=0.0007309941466605168
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0007309941459168311
2162, epoch_train_loss=0.0007309941459168311
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.0007309941451736743
2163, epoch_train_loss=0.0007309941451736743
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.0007309941444310457
2164, epoch_train_loss=0.0007309941444310457
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.0007309941436889451
2165, epoch_train_loss=0.0007309941436889451
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.0007309941429473718
2166, epoch_train_loss=0.0007309941429473718
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.0007309941422063259
2167, epoch_train_loss=0.0007309941422063259
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0007309941414658065
2168, epoch_train_loss=0.0007309941414658065
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0007309941407258133
2169, epoch_train_loss=0.0007309941407258133
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.000730994139986346
2170, epoch_train_loss=0.000730994139986346
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.000730994139247404
2171, epoch_train_loss=0.000730994139247404
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.000730994138508987
2172, epoch_train_loss=0.000730994138508987
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.0007309941377710946
2173, epoch_train_loss=0.0007309941377710946
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0007309941370337262
2174, epoch_train_loss=0.0007309941370337262
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.0007309941362968817
2175, epoch_train_loss=0.0007309941362968817
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0007309941355605604
2176, epoch_train_loss=0.0007309941355605604
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.0007309941348247619
2177, epoch_train_loss=0.0007309941348247619
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.000730994134089486
2178, epoch_train_loss=0.000730994134089486
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.0007309941333547321
2179, epoch_train_loss=0.0007309941333547321
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.0007309941326204998
2180, epoch_train_loss=0.0007309941326204998
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.0007309941318867887
2181, epoch_train_loss=0.0007309941318867887
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.0007309941311535984
2182, epoch_train_loss=0.0007309941311535984
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007309941304209284
2183, epoch_train_loss=0.0007309941304209284
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007309941296887785
2184, epoch_train_loss=0.0007309941296887785
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.000730994128957148
2185, epoch_train_loss=0.000730994128957148
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.0007309941282260368
2186, epoch_train_loss=0.0007309941282260368
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0007309941274954441
2187, epoch_train_loss=0.0007309941274954441
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0007309941267653698
2188, epoch_train_loss=0.0007309941267653698
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0007309941260358133
2189, epoch_train_loss=0.0007309941260358133
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0007309941253067745
2190, epoch_train_loss=0.0007309941253067745
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0007309941245782524
2191, epoch_train_loss=0.0007309941245782524
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.000730994123850247
2192, epoch_train_loss=0.000730994123850247
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.0007309941231227581
2193, epoch_train_loss=0.0007309941231227581
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.0007309941223957847
2194, epoch_train_loss=0.0007309941223957847
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.0007309941216693269
2195, epoch_train_loss=0.0007309941216693269
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.0007309941209433841
2196, epoch_train_loss=0.0007309941209433841
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0007309941202179557
2197, epoch_train_loss=0.0007309941202179557
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.0007309941194930415
2198, epoch_train_loss=0.0007309941194930415
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.0007309941187686411
2199, epoch_train_loss=0.0007309941187686411
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.000730994118044754
2200, epoch_train_loss=0.000730994118044754
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.0007309941173213798
2201, epoch_train_loss=0.0007309941173213798
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.0007309941165985182
2202, epoch_train_loss=0.0007309941165985182
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.0007309941158761685
2203, epoch_train_loss=0.0007309941158761685
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0007309941151543306
2204, epoch_train_loss=0.0007309941151543306
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.000730994114433004
2205, epoch_train_loss=0.000730994114433004
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.0007309941137121882
2206, epoch_train_loss=0.0007309941137121882
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.000730994112991883
2207, epoch_train_loss=0.000730994112991883
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0007309941122720877
2208, epoch_train_loss=0.0007309941122720877
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.000730994111552802
2209, epoch_train_loss=0.000730994111552802
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.0007309941108340258
2210, epoch_train_loss=0.0007309941108340258
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0007309941101157582
2211, epoch_train_loss=0.0007309941101157582
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.000730994109397999
2212, epoch_train_loss=0.000730994109397999
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.000730994108680748
2213, epoch_train_loss=0.000730994108680748
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0007309941079640045
2214, epoch_train_loss=0.0007309941079640045
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.0007309941072477682
2215, epoch_train_loss=0.0007309941072477682
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.0007309941065320387
2216, epoch_train_loss=0.0007309941065320387
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0007309941058168154
2217, epoch_train_loss=0.0007309941058168154
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0007309941051020981
2218, epoch_train_loss=0.0007309941051020981
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0007309941043878866
2219, epoch_train_loss=0.0007309941043878866
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007309941036741802
2220, epoch_train_loss=0.0007309941036741802
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.0007309941029609785
2221, epoch_train_loss=0.0007309941029609785
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.0007309941022482812
2222, epoch_train_loss=0.0007309941022482812
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.0007309941015360878
2223, epoch_train_loss=0.0007309941015360878
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.0007309941008243979
2224, epoch_train_loss=0.0007309941008243979
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.0007309941001132112
2225, epoch_train_loss=0.0007309941001132112
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.0007309940994025272
2226, epoch_train_loss=0.0007309940994025272
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0007309940986923456
2227, epoch_train_loss=0.0007309940986923456
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.000730994097982666
2228, epoch_train_loss=0.000730994097982666
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.0007309940972734878
2229, epoch_train_loss=0.0007309940972734878
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0007309940965648107
2230, epoch_train_loss=0.0007309940965648107
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0007309940958566345
2231, epoch_train_loss=0.0007309940958566345
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.0007309940951489585
2232, epoch_train_loss=0.0007309940951489585
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.0007309940944417824
2233, epoch_train_loss=0.0007309940944417824
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.0007309940937351058
2234, epoch_train_loss=0.0007309940937351058
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.0007309940930289284
2235, epoch_train_loss=0.0007309940930289284
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.0007309940923232497
2236, epoch_train_loss=0.0007309940923232497
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0007309940916180691
2237, epoch_train_loss=0.0007309940916180691
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.0007309940909133867
2238, epoch_train_loss=0.0007309940909133867
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.0007309940902092018
2239, epoch_train_loss=0.0007309940902092018
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 0.0007309940895055139
2240, epoch_train_loss=0.0007309940895055139
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.0007309940888023228
2241, epoch_train_loss=0.0007309940888023228
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.000730994088099628
2242, epoch_train_loss=0.000730994088099628
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.0007309940873974291
2243, epoch_train_loss=0.0007309940873974291
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0007309940866957257
2244, epoch_train_loss=0.0007309940866957257
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.0007309940859945175
2245, epoch_train_loss=0.0007309940859945175
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 0.000730994085293804
2246, epoch_train_loss=0.000730994085293804
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 0.0007309940845935847
2247, epoch_train_loss=0.0007309940845935847
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 0.0007309940838938595
2248, epoch_train_loss=0.0007309940838938595
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.0007309940831946278
2249, epoch_train_loss=0.0007309940831946278
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.0007309940824958891
2250, epoch_train_loss=0.0007309940824958891
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.0007309940817976433
2251, epoch_train_loss=0.0007309940817976433
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 0.0007309940810998899
2252, epoch_train_loss=0.0007309940810998899
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 0.0007309940804026282
2253, epoch_train_loss=0.0007309940804026282
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 0.0007309940797058585
2254, epoch_train_loss=0.0007309940797058585
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 0.0007309940790095796
2255, epoch_train_loss=0.0007309940790095796
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 0.0007309940783137915
2256, epoch_train_loss=0.0007309940783137915
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 0.0007309940776184938
2257, epoch_train_loss=0.0007309940776184938
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 0.0007309940769236862
2258, epoch_train_loss=0.0007309940769236862
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 0.000730994076229368
2259, epoch_train_loss=0.000730994076229368
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 0.0007309940755355391
2260, epoch_train_loss=0.0007309940755355391
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 0.0007309940748421992
2261, epoch_train_loss=0.0007309940748421992
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 0.0007309940741493474
2262, epoch_train_loss=0.0007309940741493474
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 0.0007309940734569837
2263, epoch_train_loss=0.0007309940734569837
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 0.0007309940727651077
2264, epoch_train_loss=0.0007309940727651077
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 0.0007309940720737188
2265, epoch_train_loss=0.0007309940720737188
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 0.000730994071382817
2266, epoch_train_loss=0.000730994071382817
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 0.0007309940706924014
2267, epoch_train_loss=0.0007309940706924014
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 0.000730994070002472
2268, epoch_train_loss=0.000730994070002472
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 0.0007309940693130282
2269, epoch_train_loss=0.0007309940693130282
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 0.0007309940686240696
2270, epoch_train_loss=0.0007309940686240696
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 0.000730994067935596
2271, epoch_train_loss=0.000730994067935596
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 0.0007309940672476069
2272, epoch_train_loss=0.0007309940672476069
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 0.0007309940665601017
2273, epoch_train_loss=0.0007309940665601017
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 0.0007309940658730805
2274, epoch_train_loss=0.0007309940658730805
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 0.0007309940651865426
2275, epoch_train_loss=0.0007309940651865426
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 0.0007309940645004874
2276, epoch_train_loss=0.0007309940645004874
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 0.000730994063814915
2277, epoch_train_loss=0.000730994063814915
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 0.0007309940631298247
2278, epoch_train_loss=0.0007309940631298247
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 0.0007309940624452163
2279, epoch_train_loss=0.0007309940624452163
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 0.0007309940617610889
2280, epoch_train_loss=0.0007309940617610889
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 0.0007309940610774428
2281, epoch_train_loss=0.0007309940610774428
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 0.0007309940603942774
2282, epoch_train_loss=0.0007309940603942774
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 0.000730994059711592
2283, epoch_train_loss=0.000730994059711592
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 0.0007309940590293866
2284, epoch_train_loss=0.0007309940590293866
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 0.0007309940583476606
2285, epoch_train_loss=0.0007309940583476606
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 0.0007309940576664137
2286, epoch_train_loss=0.0007309940576664137
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 0.0007309940569856455
2287, epoch_train_loss=0.0007309940569856455
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 0.0007309940563053556
2288, epoch_train_loss=0.0007309940563053556
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 0.0007309940556255436
2289, epoch_train_loss=0.0007309940556255436
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 0.0007309940549462092
2290, epoch_train_loss=0.0007309940549462092
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 0.0007309940542673518
2291, epoch_train_loss=0.0007309940542673518
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 0.0007309940535889714
2292, epoch_train_loss=0.0007309940535889714
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 0.0007309940529110671
2293, epoch_train_loss=0.0007309940529110671
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 0.000730994052233639
2294, epoch_train_loss=0.000730994052233639
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 0.0007309940515566864
2295, epoch_train_loss=0.0007309940515566864
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 0.0007309940508802091
2296, epoch_train_loss=0.0007309940508802091
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 0.0007309940502042067
2297, epoch_train_loss=0.0007309940502042067
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 0.0007309940495286786
2298, epoch_train_loss=0.0007309940495286786
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 0.0007309940488536246
2299, epoch_train_loss=0.0007309940488536246
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 0.0007309940481790446
2300, epoch_train_loss=0.0007309940481790446
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 0.0007309940475049376
2301, epoch_train_loss=0.0007309940475049376
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 0.0007309940468313037
2302, epoch_train_loss=0.0007309940468313037
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 0.0007309940461581424
2303, epoch_train_loss=0.0007309940461581424
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 0.0007309940454854532
2304, epoch_train_loss=0.0007309940454854532
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 0.0007309940448132358
2305, epoch_train_loss=0.0007309940448132358
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 0.00073099404414149
2306, epoch_train_loss=0.00073099404414149
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 0.0007309940434702152
2307, epoch_train_loss=0.0007309940434702152
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 0.0007309940427994109
2308, epoch_train_loss=0.0007309940427994109
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 0.0007309940421290771
2309, epoch_train_loss=0.0007309940421290771
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 0.0007309940414592132
2310, epoch_train_loss=0.0007309940414592132
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 0.0007309940407898187
2311, epoch_train_loss=0.0007309940407898187
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 0.0007309940401208936
2312, epoch_train_loss=0.0007309940401208936
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 0.0007309940394524371
2313, epoch_train_loss=0.0007309940394524371
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 0.000730994038784449
2314, epoch_train_loss=0.000730994038784449
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 0.000730994038116929
2315, epoch_train_loss=0.000730994038116929
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 0.0007309940374498765
2316, epoch_train_loss=0.0007309940374498765
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 0.0007309940367832915
2317, epoch_train_loss=0.0007309940367832915
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 0.0007309940361171731
2318, epoch_train_loss=0.0007309940361171731
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 0.0007309940354515214
2319, epoch_train_loss=0.0007309940354515214
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 0.0007309940347863358
2320, epoch_train_loss=0.0007309940347863358
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 0.0007309940341216161
2321, epoch_train_loss=0.0007309940341216161
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 0.0007309940334573618
2322, epoch_train_loss=0.0007309940334573618
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 0.0007309940327935722
2323, epoch_train_loss=0.0007309940327935722
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 0.0007309940321302477
2324, epoch_train_loss=0.0007309940321302477
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 0.0007309940314673872
2325, epoch_train_loss=0.0007309940314673872
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 0.0007309940308049908
2326, epoch_train_loss=0.0007309940308049908
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 0.0007309940301430576
2327, epoch_train_loss=0.0007309940301430576
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 0.0007309940294815879
2328, epoch_train_loss=0.0007309940294815879
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 0.0007309940288205808
2329, epoch_train_loss=0.0007309940288205808
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 0.0007309940281600362
2330, epoch_train_loss=0.0007309940281600362
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 0.0007309940274999537
2331, epoch_train_loss=0.0007309940274999537
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 0.0007309940268403327
2332, epoch_train_loss=0.0007309940268403327
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 0.000730994026181173
2333, epoch_train_loss=0.000730994026181173
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 0.0007309940255224743
2334, epoch_train_loss=0.0007309940255224743
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 0.0007309940248642361
2335, epoch_train_loss=0.0007309940248642361
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 0.0007309940242064582
2336, epoch_train_loss=0.0007309940242064582
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 0.0007309940235491401
2337, epoch_train_loss=0.0007309940235491401
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 0.0007309940228922813
2338, epoch_train_loss=0.0007309940228922813
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 0.0007309940222358816
2339, epoch_train_loss=0.0007309940222358816
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.0007309940215799409
2340, epoch_train_loss=0.0007309940215799409
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.0007309940209244581
2341, epoch_train_loss=0.0007309940209244581
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.0007309940202694336
2342, epoch_train_loss=0.0007309940202694336
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.0007309940196148666
2343, epoch_train_loss=0.0007309940196148666
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.0007309940189607568
2344, epoch_train_loss=0.0007309940189607568
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0007309940183071039
2345, epoch_train_loss=0.0007309940183071039
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0007309940176539074
2346, epoch_train_loss=0.0007309940176539074
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.000730994017001167
2347, epoch_train_loss=0.000730994017001167
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0007309940163488826
2348, epoch_train_loss=0.0007309940163488826
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.0007309940156970535
2349, epoch_train_loss=0.0007309940156970535
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0007309940150456793
2350, epoch_train_loss=0.0007309940150456793
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.00073099401439476
2351, epoch_train_loss=0.00073099401439476
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.0007309940137442948
2352, epoch_train_loss=0.0007309940137442948
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.0007309940130942837
2353, epoch_train_loss=0.0007309940130942837
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.000730994012444726
2354, epoch_train_loss=0.000730994012444726
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.0007309940117956216
2355, epoch_train_loss=0.0007309940117956216
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.00073099401114697
2356, epoch_train_loss=0.00073099401114697
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.0007309940104987709
2357, epoch_train_loss=0.0007309940104987709
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.0007309940098510239
2358, epoch_train_loss=0.0007309940098510239
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007309940092037286
2359, epoch_train_loss=0.0007309940092037286
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.0007309940085568847
2360, epoch_train_loss=0.0007309940085568847
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.0007309940079104919
2361, epoch_train_loss=0.0007309940079104919
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.0007309940072645496
2362, epoch_train_loss=0.0007309940072645496
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0007309940066190577
2363, epoch_train_loss=0.0007309940066190577
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.0007309940059740157
2364, epoch_train_loss=0.0007309940059740157
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0007309940053294233
2365, epoch_train_loss=0.0007309940053294233
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0007309940046852802
2366, epoch_train_loss=0.0007309940046852802
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.0007309940040415858
2367, epoch_train_loss=0.0007309940040415858
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.00073099400339834
2368, epoch_train_loss=0.00073099400339834
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.0007309940027555423
2369, epoch_train_loss=0.0007309940027555423
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0007309940021131923
2370, epoch_train_loss=0.0007309940021131923
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0007309940014712897
2371, epoch_train_loss=0.0007309940014712897
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0007309940008298344
2372, epoch_train_loss=0.0007309940008298344
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.0007309940001888254
2373, epoch_train_loss=0.0007309940001888254
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0007309939995482629
2374, epoch_train_loss=0.0007309939995482629
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0007309939989081464
2375, epoch_train_loss=0.0007309939989081464
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0007309939982684756
2376, epoch_train_loss=0.0007309939982684756
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0007309939976292497
2377, epoch_train_loss=0.0007309939976292497
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.000730993996990469
2378, epoch_train_loss=0.000730993996990469
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.0007309939963521326
2379, epoch_train_loss=0.0007309939963521326
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0007309939957142406
2380, epoch_train_loss=0.0007309939957142406
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.0007309939950767924
2381, epoch_train_loss=0.0007309939950767924
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0007309939944397877
2382, epoch_train_loss=0.0007309939944397877
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.0007309939938032259
2383, epoch_train_loss=0.0007309939938032259
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.0007309939931671069
2384, epoch_train_loss=0.0007309939931671069
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.0007309939925314305
2385, epoch_train_loss=0.0007309939925314305
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.0007309939918961959
2386, epoch_train_loss=0.0007309939918961959
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.000730993991261403
2387, epoch_train_loss=0.000730993991261403
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.0007309939906270516
2388, epoch_train_loss=0.0007309939906270516
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.000730993989993141
2389, epoch_train_loss=0.000730993989993141
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0007309939893596711
2390, epoch_train_loss=0.0007309939893596711
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0007309939887266416
2391, epoch_train_loss=0.0007309939887266416
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.0007309939880940518
2392, epoch_train_loss=0.0007309939880940518
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.0007309939874619015
2393, epoch_train_loss=0.0007309939874619015
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.0007309939868301907
2394, epoch_train_loss=0.0007309939868301907
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0007309939861989186
2395, epoch_train_loss=0.0007309939861989186
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0007309939855680849
2396, epoch_train_loss=0.0007309939855680849
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.0007309939849376896
2397, epoch_train_loss=0.0007309939849376896
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0007309939843077318
2398, epoch_train_loss=0.0007309939843077318
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0007309939836782115
2399, epoch_train_loss=0.0007309939836782115
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.0007309939830491283
2400, epoch_train_loss=0.0007309939830491283
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.0007309939824204819
2401, epoch_train_loss=0.0007309939824204819
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0007309939817922717
2402, epoch_train_loss=0.0007309939817922717
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.0007309939811644977
2403, epoch_train_loss=0.0007309939811644977
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.0007309939805371595
2404, epoch_train_loss=0.0007309939805371595
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0007309939799102565
2405, epoch_train_loss=0.0007309939799102565
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0007309939792837883
2406, epoch_train_loss=0.0007309939792837883
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.000730993978657755
2407, epoch_train_loss=0.000730993978657755
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.0007309939780321559
2408, epoch_train_loss=0.0007309939780321559
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.0007309939774069907
2409, epoch_train_loss=0.0007309939774069907
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.0007309939767822591
2410, epoch_train_loss=0.0007309939767822591
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.0007309939761579608
2411, epoch_train_loss=0.0007309939761579608
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.0007309939755340952
2412, epoch_train_loss=0.0007309939755340952
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.0007309939749106624
2413, epoch_train_loss=0.0007309939749106624
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.0007309939742876616
2414, epoch_train_loss=0.0007309939742876616
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 0.0007309939736650929
2415, epoch_train_loss=0.0007309939736650929
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0007309939730429552
2416, epoch_train_loss=0.0007309939730429552
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.0007309939724212491
2417, epoch_train_loss=0.0007309939724212491
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0007309939717999737
2418, epoch_train_loss=0.0007309939717999737
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.0007309939711791287
2419, epoch_train_loss=0.0007309939711791287
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 0.0007309939705587138
2420, epoch_train_loss=0.0007309939705587138
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0007309939699387288
2421, epoch_train_loss=0.0007309939699387288
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0007309939693191733
2422, epoch_train_loss=0.0007309939693191733
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.0007309939687000465
2423, epoch_train_loss=0.0007309939687000465
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.0007309939680813487
2424, epoch_train_loss=0.0007309939680813487
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.0007309939674630793
2425, epoch_train_loss=0.0007309939674630793
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 0.0007309939668452378
2426, epoch_train_loss=0.0007309939668452378
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.0007309939662278241
2427, epoch_train_loss=0.0007309939662278241
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.0007309939656108377
2428, epoch_train_loss=0.0007309939656108377
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.0007309939649942782
2429, epoch_train_loss=0.0007309939649942782
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.0007309939643781454
2430, epoch_train_loss=0.0007309939643781454
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 0.0007309939637624391
2431, epoch_train_loss=0.0007309939637624391
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 0.0007309939631471588
2432, epoch_train_loss=0.0007309939631471588
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.000730993962532304
2433, epoch_train_loss=0.000730993962532304
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0007309939619178744
2434, epoch_train_loss=0.0007309939619178744
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.0007309939613038699
2435, epoch_train_loss=0.0007309939613038699
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 0.00073099396069029
2436, epoch_train_loss=0.00073099396069029
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 0.0007309939600771345
2437, epoch_train_loss=0.0007309939600771345
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 0.0007309939594644028
2438, epoch_train_loss=0.0007309939594644028
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.0007309939588520946
2439, epoch_train_loss=0.0007309939588520946
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.0007309939582402097
2440, epoch_train_loss=0.0007309939582402097
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 0.0007309939576287478
2441, epoch_train_loss=0.0007309939576287478
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 0.0007309939570177084
2442, epoch_train_loss=0.0007309939570177084
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 0.0007309939564070914
2443, epoch_train_loss=0.0007309939564070914
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 0.0007309939557968962
2444, epoch_train_loss=0.0007309939557968962
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 0.0007309939551871224
2445, epoch_train_loss=0.0007309939551871224
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 0.0007309939545777699
2446, epoch_train_loss=0.0007309939545777699
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 0.0007309939539688384
2447, epoch_train_loss=0.0007309939539688384
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 0.0007309939533603274
2448, epoch_train_loss=0.0007309939533603274
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 0.0007309939527522365
2449, epoch_train_loss=0.0007309939527522365
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 0.0007309939521445654
2450, epoch_train_loss=0.0007309939521445654
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 0.000730993951537314
2451, epoch_train_loss=0.000730993951537314
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 0.0007309939509304817
2452, epoch_train_loss=0.0007309939509304817
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 0.0007309939503240683
2453, epoch_train_loss=0.0007309939503240683
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 0.0007309939497180734
2454, epoch_train_loss=0.0007309939497180734
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 0.0007309939491124968
2455, epoch_train_loss=0.0007309939491124968
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 0.0007309939485073379
2456, epoch_train_loss=0.0007309939485073379
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 0.0007309939479025964
2457, epoch_train_loss=0.0007309939479025964
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 0.0007309939472982723
2458, epoch_train_loss=0.0007309939472982723
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 0.0007309939466943649
2459, epoch_train_loss=0.0007309939466943649
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 0.000730993946090874
2460, epoch_train_loss=0.000730993946090874
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 0.0007309939454877994
2461, epoch_train_loss=0.0007309939454877994
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 0.0007309939448851405
2462, epoch_train_loss=0.0007309939448851405
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 0.0007309939442828973
2463, epoch_train_loss=0.0007309939442828973
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 0.0007309939436810689
2464, epoch_train_loss=0.0007309939436810689
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 0.0007309939430796557
2465, epoch_train_loss=0.0007309939430796557
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 0.0007309939424786568
2466, epoch_train_loss=0.0007309939424786568
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 0.0007309939418780723
2467, epoch_train_loss=0.0007309939418780723
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 0.0007309939412779011
2468, epoch_train_loss=0.0007309939412779011
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 0.000730993940678144
2469, epoch_train_loss=0.000730993940678144
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 0.0007309939400787997
2470, epoch_train_loss=0.0007309939400787997
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 0.0007309939394798683
2471, epoch_train_loss=0.0007309939394798683
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 0.0007309939388813496
2472, epoch_train_loss=0.0007309939388813496
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 0.0007309939382832429
2473, epoch_train_loss=0.0007309939382832429
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.0007309939376855482
2474, epoch_train_loss=0.0007309939376855482
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.0007309939370882648
2475, epoch_train_loss=0.0007309939370882648
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.0007309939364913929
2476, epoch_train_loss=0.0007309939364913929
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.0007309939358949315
2477, epoch_train_loss=0.0007309939358949315
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.000730993935298881
2478, epoch_train_loss=0.000730993935298881
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0007309939347032405
2479, epoch_train_loss=0.0007309939347032405
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0007309939341080098
2480, epoch_train_loss=0.0007309939341080098
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007309939335131888
2481, epoch_train_loss=0.0007309939335131888
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.0007309939329187767
2482, epoch_train_loss=0.0007309939329187767
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.0007309939323247738
2483, epoch_train_loss=0.0007309939323247738
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.0007309939317311794
2484, epoch_train_loss=0.0007309939317311794
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.0007309939311379932
2485, epoch_train_loss=0.0007309939311379932
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.0007309939305452149
2486, epoch_train_loss=0.0007309939305452149
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.0007309939299528441
2487, epoch_train_loss=0.0007309939299528441
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.0007309939293608804
2488, epoch_train_loss=0.0007309939293608804
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.0007309939287693238
2489, epoch_train_loss=0.0007309939287693238
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.0007309939281781738
2490, epoch_train_loss=0.0007309939281781738
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.0007309939275874301
2491, epoch_train_loss=0.0007309939275874301
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.0007309939269970922
2492, epoch_train_loss=0.0007309939269970922
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.0007309939264071603
2493, epoch_train_loss=0.0007309939264071603
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0007309939258176333
2494, epoch_train_loss=0.0007309939258176333
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0007309939252285113
2495, epoch_train_loss=0.0007309939252285113
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0007309939246397941
2496, epoch_train_loss=0.0007309939246397941
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.0007309939240514812
2497, epoch_train_loss=0.0007309939240514812
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.0007309939234635721
2498, epoch_train_loss=0.0007309939234635721
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0007309939228760667
2499, epoch_train_loss=0.0007309939228760667
