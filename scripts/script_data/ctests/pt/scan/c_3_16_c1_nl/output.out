/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/pyscf/dft/libxc.py:772: UserWarning: Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, the same to the B3LYP functional in Gaussian and ORCA (issue 1480). To restore the VWN5 definition, you can put the setting "B3LYP_WITH_VWN5 = True" in pyscf_conf.py
  warnings.warn('Since PySCF-2.3, B3LYP (and B3P86) are changed to the VWN-RPA variant, '
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430b940> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430b940> in UKS object of <class 'pyscf.dft.uks.UKS'>
WARNING: External module "mldftdat" required for non-local descriptor use.
<pyscf.gto.mole.Mole object at 0x7ffec430b940> [['P', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec430b160> [['N', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec430b400> [['H', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec430ac80> [['Li', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec430a0e0> [['O', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec430b670> [['Cl', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec4309a20> [['Al', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec430b340> [['S', array([0., 0., 0.])]] 1
<pyscf.gto.mole.Mole object at 0x7ffec43088e0> [['H', array([0.      , 0.      , 0.371395])], ['H', array([ 0.      ,  0.      , -0.371395])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec4308b20> [['N', array([0.      , 0.      , 0.549396])], ['N', array([ 0.      ,  0.      , -0.549396])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec4308910> [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec4309f30> [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]] 3
<pyscf.gto.mole.Mole object at 0x7ffec430ba00> [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]] 3
<pyscf.gto.mole.Mole object at 0x7ffec43089d0> [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec4308790> [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec4308670> [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec425a560> [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]] 4
<pyscf.gto.mole.Mole object at 0x7ffec4259de0> [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec425a5c0> [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec4259b70> [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec41b0f70> [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec41b3d30> [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]] 4
<pyscf.gto.mole.Mole object at 0x7ffec41b3340> [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]] 4
<pyscf.gto.mole.Mole object at 0x7ffec41b1d20> [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]] 2
<pyscf.gto.mole.Mole object at 0x7ffec41b09a0> [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]] 5
<pyscf.gto.mole.Mole object at 0x7ffec41b0160> [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]] 3
<pyscf.gto.mole.Mole object at 0x7ffec41b3550> [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]] 5
mol:  [['P', array([0., 0., 0.])]]
converged SCF energy = -341.104145992718  <S^2> = 3.7502984  2S+1 = 4.0001492
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430b160> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430b160> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051022 -0.00019156 -0.00051334 ... -0.02830887 -0.02830887
 -0.02830887] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 16)
mol:  [['N', array([0., 0., 0.])]]
converged SCF energy = -54.5289742046674  <S^2> = 3.7524945  2S+1 = 4.0012471
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430b400> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430b400> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5016, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-3.60081838e-04 -1.08775305e-04 -1.31917160e-05 ... -2.74817476e-02
 -2.74817476e-02 -2.74817476e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5016, 22)
rho shape (4, 4, 2, 5016)
rho_filt shape: (5016,)
get descriptors tdrho.shape=(5016, 16)
mol:  [['H', array([0., 0., 0.])]]
converged SCF energy = -0.499812984008539  <S^2> = 0.75  2S+1 = 2
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430ac80> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430ac80> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 7, 7)
ao.shape (10, 2440, 7)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.92637355e-09 -1.31700807e-07 -9.61527370e-06 ... -7.42461648e-16
 -7.42461648e-16 -7.42461648e-16] = ,SCAN
get_data, dm shape = (2, 7, 7)
ao_eval.shape=(4, 2440, 7)
rho shape (4, 4, 2, 2440)
rho_filt shape: (2440,)
get descriptors tdrho.shape=(2440, 16)
mol:  [['Li', array([0., 0., 0.])]]
converged SCF energy = -7.46006188627842  <S^2> = 0.75000049  2S+1 = 2.0000005
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430a0e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430a0e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 4592, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.31884219e-04 -2.81911891e-04 -2.81911891e-04 ... -1.27154711e-05
 -2.64861768e-02 -2.64861768e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 4592, 22)
rho shape (4, 4, 2, 4592)
rho_filt shape: (4592,)
get descriptors tdrho.shape=(4592, 16)
mol:  [['O', array([0., 0., 0.])]]
converged SCF energy = -75.0033802931119  <S^2> = 2.0027444  2S+1 = 3.0018291
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430b670> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430b670> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 22, 22)
ao.shape (10, 5040, 22)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.15858504e-04 -4.01258773e-05 -2.14117748e-06 ... -2.76158580e-02
 -2.76158580e-02 -2.76158580e-02] = ,SCAN
get_data, dm shape = (2, 22, 22)
ao_eval.shape=(4, 5040, 22)
rho shape (4, 4, 2, 5040)
rho_filt shape: (5040,)
get descriptors tdrho.shape=(5040, 16)
mol:  [['Cl', array([0., 0., 0.])]]
converged SCF energy = -459.957577121377  <S^2> = 0.7516194  2S+1 = 2.0016187
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4309a20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4309a20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6152, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.99669571e-04 -2.40563119e-04 -8.22178014e-05 ... -2.84484386e-02
 -2.84484386e-02 -2.84484386e-02] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6152, 30)
rho shape (4, 4, 2, 6152)
rho_filt shape: (6152,)
get descriptors tdrho.shape=(6152, 16)
mol:  [['Al', array([0., 0., 0.])]]
converged SCF energy = -242.226560974222  <S^2> = 0.75226419  2S+1 = 2.0022629
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430b340> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430b340> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6088, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.43603673e-03 -1.51421506e-03 -7.66133644e-04 ... -2.92106789e-05
 -3.16140742e-04 -3.60148424e-05] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6088, 30)
rho shape (4, 4, 2, 6088)
rho_filt shape: (6088,)
get descriptors tdrho.shape=(6088, 16)
mol:  [['S', array([0., 0., 0.])]]
converged SCF energy = -397.938786807113  <S^2> = 2.0022329  2S+1 = 3.0014882
Warning: <pyscf.gto.mole.Mole object at 0x7ffec43088e0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec43088e0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 30, 30)
ao.shape (10, 6320, 30)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00038745 -0.00017488 -0.00023373 ... -0.02838402 -0.02838402
 -0.02838402] = ,SCAN
get_data, dm shape = (2, 30, 30)
ao_eval.shape=(4, 6320, 30)
rho shape (4, 4, 2, 6320)
rho_filt shape: (6320,)
get descriptors tdrho.shape=(6320, 16)
mol:  [['H', array([0.      , 0.      , 0.371395])], ['H', array([ 0.      ,  0.      , -0.371395])]]
converged SCF energy = -1.16580491182912  <S^2> = 8.8817842e-16  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4308b20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4308b20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 14, 14)
ao.shape (10, 4776, 14)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.43725660e-05 -1.02204687e-06 -4.05575842e-05 ... -2.36278434e-02
 -2.36278434e-02 -2.36278434e-02] = ,SCAN
get_data, dm shape = (2, 14, 14)
ao_eval.shape=(4, 4776, 14)
rho shape (4, 4, 2, 4776)
rho_filt shape: (4776,)
get descriptors tdrho.shape=(4776, 16)
mol:  [['N', array([0.      , 0.      , 0.549396])], ['N', array([ 0.      ,  0.      , -0.549396])]]
converged SCF energy = -109.439263799566  <S^2> = 1.4210855e-14  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4308910> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4308910> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9848, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.89629699e-05 -2.76172354e-04 -7.59017288e-05 ... -7.34654212e-06
 -7.34654212e-06 -2.89629699e-05] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9848, 44)
rho shape (4, 4, 2, 9848)
rho_filt shape: (9848,)
get descriptors tdrho.shape=(9848, 16)
mol:  [['Li', array([ 0.      ,  0.      , -1.172697])], ['F', array([0.      , 0.      , 0.390899])]]
converged SCF energy = -107.339357395734  <S^2> = 1.7763568e-15  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4309f30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4309f30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9752, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00043469 -0.00024024 -0.00035532 ... -0.00047537 -0.03728133
 -0.03728133] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9752, 44)
rho shape (4, 4, 2, 9752)
rho_filt shape: (9752,)
get descriptors tdrho.shape=(9752, 16)
mol:  [['C', array([ 0.      ,  0.      , -0.499686])], ['N', array([0.      , 0.      , 0.652056])], ['H', array([ 0.        ,  0.        , -1.56627401])]]
converged SCF energy = -93.3377924465131  <S^2> = 4.0072123e-10  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec430ba00> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec430ba00> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 12256, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-9.02468888e-05 -7.92694658e-06 -9.80568469e-06 ... -4.33714150e-02
 -4.33714150e-02 -4.33714150e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 12256, 51)
rho shape (4, 4, 2, 12256)
rho_filt shape: (12256,)
get descriptors tdrho.shape=(12256, 16)
mol:  [['C', array([0., 0., 0.])], ['O', array([0.      , 0.      , 1.162879])], ['O', array([ 0.      ,  0.      , -1.162879])]]
converged SCF energy = -188.456965322843  <S^2> = 1.5987212e-14  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec43089d0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec43089d0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 66, 66)
ao.shape (10, 14920, 66)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.48187338e-05 -6.19475249e-05 -2.61742784e-04 ... -8.70042314e-07
 -2.73391097e-02 -2.73391097e-02] = ,SCAN
get_data, dm shape = (2, 66, 66)
ao_eval.shape=(4, 14920, 66)
rho shape (4, 4, 2, 14920)
rho_filt shape: (14920,)
get descriptors tdrho.shape=(14920, 16)
mol:  [['Cl', array([0.      , 0.      , 1.008241])], ['Cl', array([ 0.      ,  0.      , -1.008241])]]
converged SCF energy = -920.005608888959  <S^2> = 4.938272e-13  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4308790> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4308790> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12208, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00051559 -0.00027432 -0.00088583 ... -0.00027432 -0.04174728
 -0.04174728] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12208, 60)
rho shape (4, 4, 2, 12208)
rho_filt shape: (12208,)
get descriptors tdrho.shape=(12208, 16)
mol:  [['F', array([0.      , 0.      , 0.693963])], ['F', array([ 0.      ,  0.      , -0.693963])]]
converged SCF energy = -199.394370591172  <S^2> = 1.2256862e-13  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4308670> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4308670> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9824, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-5.53951178e-05 -5.93507199e-06 -3.10072916e-04 ... -5.94325581e-02
 -5.94325581e-02 -5.94325581e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9824, 44)
rho shape (4, 4, 2, 9824)
rho_filt shape: (9824,)
get descriptors tdrho.shape=(9824, 16)
mol:  [['O', array([0.      , 0.      , 0.603195])], ['O', array([ 0.      ,  0.      , -0.603195])]]
converged SCF energy = -150.21489456173  <S^2> = 1.0018599  2S+1 = 2.2377309
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec425a560> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec425a560> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 9912, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-1.74564232e-04 -3.26401427e-05 -1.76686070e-06 ... -4.22396849e-02
 -4.22396849e-02 -4.22396849e-02] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 9912, 44)
rho shape (4, 4, 2, 9912)
rho_filt shape: (9912,)
get descriptors tdrho.shape=(9912, 16)
mol:  [['C', array([0.      , 0.      , 0.599454])], ['C', array([ 0.      ,  0.      , -0.599454])], ['H', array([ 0.        ,  0.        , -1.66162301])], ['H', array([0.        , 0.        , 1.66162301])]]
converged SCF energy = -77.2435048346374  <S^2> = 1.0658141e-14  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4259de0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4259de0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 58, 58)
ao.shape (10, 15208, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.72190712e-05 -2.72190712e-05 -2.84904833e-04 ... -1.08108260e-05
 -1.03072478e-05 -1.03072478e-05] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15208, 58)
rho shape (4, 4, 2, 15208)
rho_filt shape: (15208,)
get descriptors tdrho.shape=(15208, 16)
mol:  [['O', array([0.      , 0.      , 0.484676])], ['C', array([ 0.      ,  0.      , -0.646235])]]
converged SCF energy = -113.221335689652  <S^2> = 6.5547567e-13  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec425a5c0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec425a5c0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 44, 44)
ao.shape (10, 10040, 44)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00015688 -0.00024669 -0.00068269 ... -0.03791166 -0.03791166
 -0.03791166] = ,SCAN
get_data, dm shape = (2, 44, 44)
ao_eval.shape=(4, 10040, 44)
rho shape (4, 4, 2, 10040)
rho_filt shape: (10040,)
get descriptors tdrho.shape=(10040, 16)
mol:  [['Cl', array([0.      , 0.      , 0.071315])], ['H', array([ 0.      ,  0.      , -1.212358])]]
converged SCF energy = -460.624592374078  <S^2> = 7.8159701e-14  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec4259b70> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec4259b70> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 37, 37)
ao.shape (10, 8552, 37)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-7.28500681e-05 -5.65091132e-06 -7.37932132e-06 ... -4.76689214e-02
 -4.76689214e-02 -4.76689214e-02] = ,SCAN
get_data, dm shape = (2, 37, 37)
ao_eval.shape=(4, 8552, 37)
rho shape (4, 4, 2, 8552)
rho_filt shape: (8552,)
get descriptors tdrho.shape=(8552, 16)
mol:  [['Li', array([0.      , 0.      , 0.403632])], ['H', array([ 0.      ,  0.      , -1.210897])]]
converged SCF energy = -8.04458854018922  <S^2> = 7.8381746e-14  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b0f70> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b0f70> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 29, 29)
ao.shape (10, 6936, 29)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.0003863  -0.00040095 -0.00040095 ... -0.0213199  -0.0213199
 -0.0213199 ] = ,SCAN
get_data, dm shape = (2, 29, 29)
ao_eval.shape=(4, 6936, 29)
rho shape (4, 4, 2, 6936)
rho_filt shape: (6936,)
get descriptors tdrho.shape=(6936, 16)
mol:  [['Na', array([0.        , 0.        , 1.50747901])], ['Na', array([ 0.        ,  0.        , -1.50747901])]]
converged SCF energy = -324.340512506578  <S^2> = 1.5869972e-11  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b3d30> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b3d30> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 11536, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-0.00088473 -0.00088473 -0.00116894 ... -0.00088473 -0.00088473
 -0.00116894] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 11536, 60)
rho shape (4, 4, 2, 11536)
rho_filt shape: (11536,)
get descriptors tdrho.shape=(11536, 16)
mol:  [['Al', array([0., 0., 0.])], ['Cl', array([0.        , 2.08019101, 0.        ])], ['Cl', array([ 1.80149801, -1.040095  ,  0.        ])], ['Cl', array([-1.80149801, -1.040095  ,  0.        ])]]
converged SCF energy = -1622.57507845814  <S^2> = 8.0646601e-13  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b3340> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b3340> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 120, 120)
ao.shape (10, 24512, 120)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.91408540e-05 -1.46971271e-04 -1.08734417e-03 ... -2.81566369e-02
 -2.81566369e-02 -2.81566369e-02] = ,SCAN
get_data, dm shape = (2, 120, 120)
ao_eval.shape=(4, 24512, 120)
rho shape (4, 4, 2, 24512)
rho_filt shape: (24512,)
get descriptors tdrho.shape=(24512, 16)
mol:  [['P', array([0.      , 0.      , 0.128906])], ['H', array([ 0.      ,  1.19333 , -0.644531])], ['H', array([ 1.033455, -0.596665, -0.644531])], ['H', array([-1.033455, -0.596665, -0.644531])]]
converged SCF energy = -342.979728469575  <S^2> = 2.5389468e-11  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b1d20> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b1d20> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 51, 51)
ao.shape (10, 13096, 51)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.39373335e-04 -1.31641332e-04 -1.15950750e-05 ... -7.32416564e-02
 -7.32416564e-02 -7.32416564e-02] = ,SCAN
get_data, dm shape = (2, 51, 51)
ao_eval.shape=(4, 13096, 51)
rho shape (4, 4, 2, 13096)
rho_filt shape: (13096,)
get descriptors tdrho.shape=(13096, 16)
mol:  [['Si', array([0.      , 0.      , 1.135214])], ['Si', array([ 0.      ,  0.      , -1.135214])]]
converged SCF energy = -578.565336179611  <S^2> = 1.0034705  2S+1 = 2.2391699
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b09a0> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b09a0> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 60, 60)
ao.shape (10, 12384, 60)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-4.84683816e-05 -7.80525601e-05 -7.80561012e-05 ... -2.92531391e-02
 -2.92531391e-02 -2.92531391e-02] = ,SCAN
get_data, dm shape = (2, 60, 60)
ao_eval.shape=(4, 12384, 60)
rho shape (4, 4, 2, 12384)
rho_filt shape: (12384,)
get descriptors tdrho.shape=(12384, 16)
mol:  [['C', array([0., 0., 0.])], ['H', array([0.630382, 0.630382, 0.630382])], ['H', array([-0.630382, -0.630382,  0.630382])], ['H', array([ 0.630382, -0.630382, -0.630382])], ['H', array([-0.630382,  0.630382, -0.630382])]]
converged SCF energy = -40.4598214864075  <S^2> = 3.250733e-13  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b0160> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b0160> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 50, 50)
ao.shape (10, 13936, 50)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.56165538e-04 -7.34744214e-05 -5.30574304e-06 ... -7.93995702e-06
 -7.93995702e-06 -7.93995702e-06] = ,SCAN
get_data, dm shape = (2, 50, 50)
ao_eval.shape=(4, 13936, 50)
rho shape (4, 4, 2, 13936)
rho_filt shape: (13936,)
get descriptors tdrho.shape=(13936, 16)
mol:  [['C', array([0.      , 0.      , 0.179918])], ['H', array([ 0.      ,  0.855475, -0.539754])], ['H', array([ 0.      , -0.855475, -0.539754])]]
converged SCF energy = -39.0756147483504  <S^2> = 6.2043704e-12  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
Warning: <pyscf.gto.mole.Mole object at 0x7ffec41b3550> must be initialized before calling SCF.
Initialize <pyscf.gto.mole.Mole object at 0x7ffec41b3550> in UKS object of <class 'pyscf.dft.uks.UKS'>
New DM shape: (2, 36, 36)
ao.shape (10, 9656, 36)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.28290753e-04 -1.41305449e-05 -6.13700492e-05 ... -2.47993463e-02
 -2.47993463e-02 -2.47993463e-02] = ,SCAN
get_data, dm shape = (2, 36, 36)
ao_eval.shape=(4, 9656, 36)
rho shape (4, 4, 2, 9656)
rho_filt shape: (9656,)
get descriptors tdrho.shape=(9656, 16)
mol:  [['Si', array([0., 0., 0.])], ['H', array([0.855876, 0.855876, 0.855876])], ['H', array([-0.855876, -0.855876,  0.855876])], ['H', array([-0.855876,  0.855876, -0.855876])], ['H', array([ 0.855876, -0.855876, -0.855876])]]
converged SCF energy = -291.719272437819  <S^2> = 1.3155699e-11  2S+1 = 1
/gpfs/home/jofranklin/.conda/envs/pyscfad/lib/python3.10/site-packages/jax/_src/ops/scatter.py:96: FutureWarning: scatter inputs have incompatible types: cannot safely cast value from dtype=int64 to dtype=int32 with jax_numpy_dtype_promotion='standard'. In future JAX releases this will result in an error.
  warnings.warn(
New DM shape: (2, 58, 58)
ao.shape (10, 15256, 58)
Correlation contribution only
,SCAN
no spin scaling
exc with xc_func = [-2.45512011e-04 -7.12775692e-05 -5.48666345e-06 ... -6.02613084e-06
 -6.02613084e-06 -6.02613084e-06] = ,SCAN
get_data, dm shape = (2, 58, 58)
ao_eval.shape=(4, 15256, 58)
rho shape (4, 4, 2, 15256)
rho_filt shape: (15256,)
get descriptors tdrho.shape=(15256, 16)
PRE NAN FILT: tFxc.shape=(237019,), tdrho.shape=(237019, 16)
nan_filt_rho.shape=(237019,)
nan_filt_fxc.shape=(237019,)
tFxc.shape=(237019,), tdrho.shape=(237019, 16)
inp[0].shape = (237019, 16)
Epoch 0
Epoch 0 :: Batch 0/1
Batch Loss = 8137902.219844131
0, epoch_train_loss=8137902.219844131
Epoch 1
Epoch 1 :: Batch 0/1
Batch Loss = 0.2588562610498327
1, epoch_train_loss=0.2588562610498327
Epoch 2
Epoch 2 :: Batch 0/1
Batch Loss = 0.20424770785823015
2, epoch_train_loss=0.20424770785823015
Epoch 3
Epoch 3 :: Batch 0/1
Batch Loss = 0.12121796401483195
3, epoch_train_loss=0.12121796401483195
Epoch 4
Epoch 4 :: Batch 0/1
Batch Loss = 0.05901488940597297
4, epoch_train_loss=0.05901488940597297
Epoch 5
Epoch 5 :: Batch 0/1
Batch Loss = 0.028979680349016004
5, epoch_train_loss=0.028979680349016004
Epoch 6
Epoch 6 :: Batch 0/1
Batch Loss = 0.014443061141216362
6, epoch_train_loss=0.014443061141216362
Epoch 7
Epoch 7 :: Batch 0/1
Batch Loss = 0.0069289161156723495
7, epoch_train_loss=0.0069289161156723495
Epoch 8
Epoch 8 :: Batch 0/1
Batch Loss = 0.0032800507312211145
8, epoch_train_loss=0.0032800507312211145
Epoch 9
Epoch 9 :: Batch 0/1
Batch Loss = 0.0017105469229856288
9, epoch_train_loss=0.0017105469229856288
Epoch 10
Epoch 10 :: Batch 0/1
Batch Loss = 0.0010986450148674578
10, epoch_train_loss=0.0010986450148674578
Epoch 11
Epoch 11 :: Batch 0/1
Batch Loss = 0.0008708330472866597
11, epoch_train_loss=0.0008708330472866597
Epoch 12
Epoch 12 :: Batch 0/1
Batch Loss = 0.0007859738099594423
12, epoch_train_loss=0.0007859738099594423
Epoch 13
Epoch 13 :: Batch 0/1
Batch Loss = 0.000753440668563172
13, epoch_train_loss=0.000753440668563172
Epoch 14
Epoch 14 :: Batch 0/1
Batch Loss = 0.0007404697705117318
14, epoch_train_loss=0.0007404697705117318
Epoch 15
Epoch 15 :: Batch 0/1
Batch Loss = 0.000735101702904073
15, epoch_train_loss=0.000735101702904073
Epoch 16
Epoch 16 :: Batch 0/1
Batch Loss = 0.0007328099649781783
16, epoch_train_loss=0.0007328099649781783
Epoch 17
Epoch 17 :: Batch 0/1
Batch Loss = 0.0007318054960108508
17, epoch_train_loss=0.0007318054960108508
Epoch 18
Epoch 18 :: Batch 0/1
Batch Loss = 0.0007313542794690047
18, epoch_train_loss=0.0007313542794690047
Epoch 19
Epoch 19 :: Batch 0/1
Batch Loss = 0.0007311464413161955
19, epoch_train_loss=0.0007311464413161955
Epoch 20
Epoch 20 :: Batch 0/1
Batch Loss = 0.0007310481317869393
20, epoch_train_loss=0.0007310481317869393
Epoch 21
Epoch 21 :: Batch 0/1
Batch Loss = 0.0007310003027044655
21, epoch_train_loss=0.0007310003027044655
Epoch 22
Epoch 22 :: Batch 0/1
Batch Loss = 0.0007309763370545175
22, epoch_train_loss=0.0007309763370545175
Epoch 23
Epoch 23 :: Batch 0/1
Batch Loss = 0.0007309639583166886
23, epoch_train_loss=0.0007309639583166886
Epoch 24
Epoch 24 :: Batch 0/1
Batch Loss = 0.0007309573643032436
24, epoch_train_loss=0.0007309573643032436
Epoch 25
Epoch 25 :: Batch 0/1
Batch Loss = 0.0007309537416290633
25, epoch_train_loss=0.0007309537416290633
Epoch 26
Epoch 26 :: Batch 0/1
Batch Loss = 0.0007309516896050161
26, epoch_train_loss=0.0007309516896050161
Epoch 27
Epoch 27 :: Batch 0/1
Batch Loss = 0.0007309504918957007
27, epoch_train_loss=0.0007309504918957007
Epoch 28
Epoch 28 :: Batch 0/1
Batch Loss = 0.0007309497721523718
28, epoch_train_loss=0.0007309497721523718
Epoch 29
Epoch 29 :: Batch 0/1
Batch Loss = 0.0007309493272912562
29, epoch_train_loss=0.0007309493272912562
Epoch 30
Epoch 30 :: Batch 0/1
Batch Loss = 0.0007309490448052835
30, epoch_train_loss=0.0007309490448052835
Epoch 31
Epoch 31 :: Batch 0/1
Batch Loss = 0.0007309488607455358
31, epoch_train_loss=0.0007309488607455358
Epoch 32
Epoch 32 :: Batch 0/1
Batch Loss = 0.0007309487378468129
32, epoch_train_loss=0.0007309487378468129
Epoch 33
Epoch 33 :: Batch 0/1
Batch Loss = 0.0007309486538650457
33, epoch_train_loss=0.0007309486538650457
Epoch 34
Epoch 34 :: Batch 0/1
Batch Loss = 0.0007309485952121347
34, epoch_train_loss=0.0007309485952121347
Epoch 35
Epoch 35 :: Batch 0/1
Batch Loss = 0.0007309485534019265
35, epoch_train_loss=0.0007309485534019265
Epoch 36
Epoch 36 :: Batch 0/1
Batch Loss = 0.0007309485230214562
36, epoch_train_loss=0.0007309485230214562
Epoch 37
Epoch 37 :: Batch 0/1
Batch Loss = 0.0007309485005478785
37, epoch_train_loss=0.0007309485005478785
Epoch 38
Epoch 38 :: Batch 0/1
Batch Loss = 0.0007309484836442281
38, epoch_train_loss=0.0007309484836442281
Epoch 39
Epoch 39 :: Batch 0/1
Batch Loss = 0.0007309484707318582
39, epoch_train_loss=0.0007309484707318582
Epoch 40
Epoch 40 :: Batch 0/1
Batch Loss = 0.0007309484607258968
40, epoch_train_loss=0.0007309484607258968
Epoch 41
Epoch 41 :: Batch 0/1
Batch Loss = 0.000730948452868582
41, epoch_train_loss=0.000730948452868582
Epoch 42
Epoch 42 :: Batch 0/1
Batch Loss = 0.0007309484466224295
42, epoch_train_loss=0.0007309484466224295
Epoch 43
Epoch 43 :: Batch 0/1
Batch Loss = 0.0007309484416006179
43, epoch_train_loss=0.0007309484416006179
Epoch 44
Epoch 44 :: Batch 0/1
Batch Loss = 0.0007309484375209053
44, epoch_train_loss=0.0007309484375209053
Epoch 45
Epoch 45 :: Batch 0/1
Batch Loss = 0.000730948434174666
45, epoch_train_loss=0.000730948434174666
Epoch 46
Epoch 46 :: Batch 0/1
Batch Loss = 0.0007309484314057868
46, epoch_train_loss=0.0007309484314057868
Epoch 47
Epoch 47 :: Batch 0/1
Batch Loss = 0.0007309484290960868
47, epoch_train_loss=0.0007309484290960868
Epoch 48
Epoch 48 :: Batch 0/1
Batch Loss = 0.0007309484271551164
48, epoch_train_loss=0.0007309484271551164
Epoch 49
Epoch 49 :: Batch 0/1
Batch Loss = 0.0007309484255129281
49, epoch_train_loss=0.0007309484255129281
Epoch 50
Epoch 50 :: Batch 0/1
Batch Loss = 0.0007309484241148962
50, epoch_train_loss=0.0007309484241148962
Epoch 51
Epoch 51 :: Batch 0/1
Batch Loss = 0.0007309484229179647
51, epoch_train_loss=0.0007309484229179647
Epoch 52
Epoch 52 :: Batch 0/1
Batch Loss = 0.0007309484218879387
52, epoch_train_loss=0.0007309484218879387
Epoch 53
Epoch 53 :: Batch 0/1
Batch Loss = 0.0007309484209973526
53, epoch_train_loss=0.0007309484209973526
Epoch 54
Epoch 54 :: Batch 0/1
Batch Loss = 0.0007309484202240108
54, epoch_train_loss=0.0007309484202240108
Epoch 55
Epoch 55 :: Batch 0/1
Batch Loss = 0.0007309484195498416
55, epoch_train_loss=0.0007309484195498416
Epoch 56
Epoch 56 :: Batch 0/1
Batch Loss = 0.0007309484189600277
56, epoch_train_loss=0.0007309484189600277
Epoch 57
Epoch 57 :: Batch 0/1
Batch Loss = 0.0007309484184423367
57, epoch_train_loss=0.0007309484184423367
Epoch 58
Epoch 58 :: Batch 0/1
Batch Loss = 0.0007309484179866075
58, epoch_train_loss=0.0007309484179866075
Epoch 59
Epoch 59 :: Batch 0/1
Batch Loss = 0.0007309484175843471
59, epoch_train_loss=0.0007309484175843471
Epoch 60
Epoch 60 :: Batch 0/1
Batch Loss = 0.0007309484172284176
60, epoch_train_loss=0.0007309484172284176
Epoch 61
Epoch 61 :: Batch 0/1
Batch Loss = 0.0007309484169127863
61, epoch_train_loss=0.0007309484169127863
Epoch 62
Epoch 62 :: Batch 0/1
Batch Loss = 0.0007309484166323307
62, epoch_train_loss=0.0007309484166323307
Epoch 63
Epoch 63 :: Batch 0/1
Batch Loss = 0.0007309484163826775
63, epoch_train_loss=0.0007309484163826775
Epoch 64
Epoch 64 :: Batch 0/1
Batch Loss = 0.0007309484161600789
64, epoch_train_loss=0.0007309484161600789
Epoch 65
Epoch 65 :: Batch 0/1
Batch Loss = 0.0007309484159613074
65, epoch_train_loss=0.0007309484159613074
Epoch 66
Epoch 66 :: Batch 0/1
Batch Loss = 0.0007309484157835742
66, epoch_train_loss=0.0007309484157835742
Epoch 67
Epoch 67 :: Batch 0/1
Batch Loss = 0.0007309484156244594
67, epoch_train_loss=0.0007309484156244594
Epoch 68
Epoch 68 :: Batch 0/1
Batch Loss = 0.000730948415481856
68, epoch_train_loss=0.000730948415481856
Epoch 69
Epoch 69 :: Batch 0/1
Batch Loss = 0.0007309484153539245
69, epoch_train_loss=0.0007309484153539245
Epoch 70
Epoch 70 :: Batch 0/1
Batch Loss = 0.0007309484152390528
70, epoch_train_loss=0.0007309484152390528
Epoch 71
Epoch 71 :: Batch 0/1
Batch Loss = 0.0007309484151358248
71, epoch_train_loss=0.0007309484151358248
Epoch 72
Epoch 72 :: Batch 0/1
Batch Loss = 0.0007309484150429931
72, epoch_train_loss=0.0007309484150429931
Epoch 73
Epoch 73 :: Batch 0/1
Batch Loss = 0.0007309484149594565
73, epoch_train_loss=0.0007309484149594565
Epoch 74
Epoch 74 :: Batch 0/1
Batch Loss = 0.0007309484148842403
74, epoch_train_loss=0.0007309484148842403
Epoch 75
Epoch 75 :: Batch 0/1
Batch Loss = 0.0007309484148164804
75, epoch_train_loss=0.0007309484148164804
Epoch 76
Epoch 76 :: Batch 0/1
Batch Loss = 0.0007309484147554089
76, epoch_train_loss=0.0007309484147554089
Epoch 77
Epoch 77 :: Batch 0/1
Batch Loss = 0.0007309484147003426
77, epoch_train_loss=0.0007309484147003426
Epoch 78
Epoch 78 :: Batch 0/1
Batch Loss = 0.0007309484146506723
78, epoch_train_loss=0.0007309484146506723
Epoch 79
Epoch 79 :: Batch 0/1
Batch Loss = 0.0007309484146058541
79, epoch_train_loss=0.0007309484146058541
Epoch 80
Epoch 80 :: Batch 0/1
Batch Loss = 0.0007309484145654022
80, epoch_train_loss=0.0007309484145654022
Epoch 81
Epoch 81 :: Batch 0/1
Batch Loss = 0.0007309484145288817
81, epoch_train_loss=0.0007309484145288817
Epoch 82
Epoch 82 :: Batch 0/1
Batch Loss = 0.0007309484144959025
82, epoch_train_loss=0.0007309484144959025
Epoch 83
Epoch 83 :: Batch 0/1
Batch Loss = 0.0007309484144661151
83, epoch_train_loss=0.0007309484144661151
Epoch 84
Epoch 84 :: Batch 0/1
Batch Loss = 0.0007309484144392056
84, epoch_train_loss=0.0007309484144392056
Epoch 85
Epoch 85 :: Batch 0/1
Batch Loss = 0.0007309484144148924
85, epoch_train_loss=0.0007309484144148924
Epoch 86
Epoch 86 :: Batch 0/1
Batch Loss = 0.0007309484143929214
86, epoch_train_loss=0.0007309484143929214
Epoch 87
Epoch 87 :: Batch 0/1
Batch Loss = 0.0007309484143730649
87, epoch_train_loss=0.0007309484143730649
Epoch 88
Epoch 88 :: Batch 0/1
Batch Loss = 0.0007309484143551174
88, epoch_train_loss=0.0007309484143551174
Epoch 89
Epoch 89 :: Batch 0/1
Batch Loss = 0.0007309484143388936
89, epoch_train_loss=0.0007309484143388936
Epoch 90
Epoch 90 :: Batch 0/1
Batch Loss = 0.0007309484143242274
90, epoch_train_loss=0.0007309484143242274
Epoch 91
Epoch 91 :: Batch 0/1
Batch Loss = 0.0007309484143109677
91, epoch_train_loss=0.0007309484143109677
Epoch 92
Epoch 92 :: Batch 0/1
Batch Loss = 0.0007309484142989796
92, epoch_train_loss=0.0007309484142989796
Epoch 93
Epoch 93 :: Batch 0/1
Batch Loss = 0.0007309484142881402
93, epoch_train_loss=0.0007309484142881402
Epoch 94
Epoch 94 :: Batch 0/1
Batch Loss = 0.0007309484142783392
94, epoch_train_loss=0.0007309484142783392
Epoch 95
Epoch 95 :: Batch 0/1
Batch Loss = 0.0007309484142694766
95, epoch_train_loss=0.0007309484142694766
Epoch 96
Epoch 96 :: Batch 0/1
Batch Loss = 0.0007309484142614628
96, epoch_train_loss=0.0007309484142614628
Epoch 97
Epoch 97 :: Batch 0/1
Batch Loss = 0.0007309484142542163
97, epoch_train_loss=0.0007309484142542163
Epoch 98
Epoch 98 :: Batch 0/1
Batch Loss = 0.0007309484142476632
98, epoch_train_loss=0.0007309484142476632
Epoch 99
Epoch 99 :: Batch 0/1
Batch Loss = 0.0007309484142417375
99, epoch_train_loss=0.0007309484142417375
Epoch 100
Epoch 100 :: Batch 0/1
Batch Loss = 0.0007309484142363788
100, epoch_train_loss=0.0007309484142363788
Epoch 101
Epoch 101 :: Batch 0/1
Batch Loss = 0.0007309484142315332
101, epoch_train_loss=0.0007309484142315332
Epoch 102
Epoch 102 :: Batch 0/1
Batch Loss = 0.0007309484142271513
102, epoch_train_loss=0.0007309484142271513
Epoch 103
Epoch 103 :: Batch 0/1
Batch Loss = 0.0007309484142231889
103, epoch_train_loss=0.0007309484142231889
Epoch 104
Epoch 104 :: Batch 0/1
Batch Loss = 0.0007309484142196059
104, epoch_train_loss=0.0007309484142196059
Epoch 105
Epoch 105 :: Batch 0/1
Batch Loss = 0.0007309484142163659
105, epoch_train_loss=0.0007309484142163659
Epoch 106
Epoch 106 :: Batch 0/1
Batch Loss = 0.0007309484142134362
106, epoch_train_loss=0.0007309484142134362
Epoch 107
Epoch 107 :: Batch 0/1
Batch Loss = 0.000730948414210787
107, epoch_train_loss=0.000730948414210787
Epoch 108
Epoch 108 :: Batch 0/1
Batch Loss = 0.0007309484142083916
108, epoch_train_loss=0.0007309484142083916
Epoch 109
Epoch 109 :: Batch 0/1
Batch Loss = 0.0007309484142062257
109, epoch_train_loss=0.0007309484142062257
Epoch 110
Epoch 110 :: Batch 0/1
Batch Loss = 0.0007309484142042673
110, epoch_train_loss=0.0007309484142042673
Epoch 111
Epoch 111 :: Batch 0/1
Batch Loss = 0.0007309484142024967
111, epoch_train_loss=0.0007309484142024967
Epoch 112
Epoch 112 :: Batch 0/1
Batch Loss = 0.0007309484142008957
112, epoch_train_loss=0.0007309484142008957
Epoch 113
Epoch 113 :: Batch 0/1
Batch Loss = 0.0007309484141994482
113, epoch_train_loss=0.0007309484141994482
Epoch 114
Epoch 114 :: Batch 0/1
Batch Loss = 0.0007309484141981395
114, epoch_train_loss=0.0007309484141981395
Epoch 115
Epoch 115 :: Batch 0/1
Batch Loss = 0.0007309484141969565
115, epoch_train_loss=0.0007309484141969565
Epoch 116
Epoch 116 :: Batch 0/1
Batch Loss = 0.0007309484141958869
116, epoch_train_loss=0.0007309484141958869
Epoch 117
Epoch 117 :: Batch 0/1
Batch Loss = 0.0007309484141949198
117, epoch_train_loss=0.0007309484141949198
Epoch 118
Epoch 118 :: Batch 0/1
Batch Loss = 0.0007309484141940456
118, epoch_train_loss=0.0007309484141940456
Epoch 119
Epoch 119 :: Batch 0/1
Batch Loss = 0.0007309484141932555
119, epoch_train_loss=0.0007309484141932555
Epoch 120
Epoch 120 :: Batch 0/1
Batch Loss = 0.000730948414192541
120, epoch_train_loss=0.000730948414192541
Epoch 121
Epoch 121 :: Batch 0/1
Batch Loss = 0.0007309484141918952
121, epoch_train_loss=0.0007309484141918952
Epoch 122
Epoch 122 :: Batch 0/1
Batch Loss = 0.0007309484141913114
122, epoch_train_loss=0.0007309484141913114
Epoch 123
Epoch 123 :: Batch 0/1
Batch Loss = 0.0007309484141907838
123, epoch_train_loss=0.0007309484141907838
Epoch 124
Epoch 124 :: Batch 0/1
Batch Loss = 0.0007309484141903068
124, epoch_train_loss=0.0007309484141903068
Epoch 125
Epoch 125 :: Batch 0/1
Batch Loss = 0.0007309484141898756
125, epoch_train_loss=0.0007309484141898756
Epoch 126
Epoch 126 :: Batch 0/1
Batch Loss = 0.0007309484141894857
126, epoch_train_loss=0.0007309484141894857
Epoch 127
Epoch 127 :: Batch 0/1
Batch Loss = 0.0007309484141891334
127, epoch_train_loss=0.0007309484141891334
Epoch 128
Epoch 128 :: Batch 0/1
Batch Loss = 0.0007309484141888149
128, epoch_train_loss=0.0007309484141888149
Epoch 129
Epoch 129 :: Batch 0/1
Batch Loss = 0.000730948414188527
129, epoch_train_loss=0.000730948414188527
Epoch 130
Epoch 130 :: Batch 0/1
Batch Loss = 0.0007309484141882668
130, epoch_train_loss=0.0007309484141882668
Epoch 131
Epoch 131 :: Batch 0/1
Batch Loss = 0.0007309484141880317
131, epoch_train_loss=0.0007309484141880317
Epoch 132
Epoch 132 :: Batch 0/1
Batch Loss = 0.0007309484141878191
132, epoch_train_loss=0.0007309484141878191
Epoch 133
Epoch 133 :: Batch 0/1
Batch Loss = 0.0007309484141876269
133, epoch_train_loss=0.0007309484141876269
Epoch 134
Epoch 134 :: Batch 0/1
Batch Loss = 0.0007309484141874531
134, epoch_train_loss=0.0007309484141874531
Epoch 135
Epoch 135 :: Batch 0/1
Batch Loss = 0.0007309484141872962
135, epoch_train_loss=0.0007309484141872962
Epoch 136
Epoch 136 :: Batch 0/1
Batch Loss = 0.0007309484141871542
136, epoch_train_loss=0.0007309484141871542
Epoch 137
Epoch 137 :: Batch 0/1
Batch Loss = 0.0007309484141870259
137, epoch_train_loss=0.0007309484141870259
Epoch 138
Epoch 138 :: Batch 0/1
Batch Loss = 0.0007309484141869097
138, epoch_train_loss=0.0007309484141869097
Epoch 139
Epoch 139 :: Batch 0/1
Batch Loss = 0.0007309484141868049
139, epoch_train_loss=0.0007309484141868049
Epoch 140
Epoch 140 :: Batch 0/1
Batch Loss = 0.0007309484141867101
140, epoch_train_loss=0.0007309484141867101
Epoch 141
Epoch 141 :: Batch 0/1
Batch Loss = 0.0007309484141866243
141, epoch_train_loss=0.0007309484141866243
Epoch 142
Epoch 142 :: Batch 0/1
Batch Loss = 0.0007309484141865467
142, epoch_train_loss=0.0007309484141865467
Epoch 143
Epoch 143 :: Batch 0/1
Batch Loss = 0.0007309484141864765
143, epoch_train_loss=0.0007309484141864765
Epoch 144
Epoch 144 :: Batch 0/1
Batch Loss = 0.0007309484141864132
144, epoch_train_loss=0.0007309484141864132
Epoch 145
Epoch 145 :: Batch 0/1
Batch Loss = 0.0007309484141863559
145, epoch_train_loss=0.0007309484141863559
Epoch 146
Epoch 146 :: Batch 0/1
Batch Loss = 0.0007309484141863039
146, epoch_train_loss=0.0007309484141863039
Epoch 147
Epoch 147 :: Batch 0/1
Batch Loss = 0.0007309484141862568
147, epoch_train_loss=0.0007309484141862568
Epoch 148
Epoch 148 :: Batch 0/1
Batch Loss = 0.0007309484141862144
148, epoch_train_loss=0.0007309484141862144
Epoch 149
Epoch 149 :: Batch 0/1
Batch Loss = 0.0007309484141861761
149, epoch_train_loss=0.0007309484141861761
Epoch 150
Epoch 150 :: Batch 0/1
Batch Loss = 0.0007309484141861411
150, epoch_train_loss=0.0007309484141861411
Epoch 151
Epoch 151 :: Batch 0/1
Batch Loss = 0.0007309484141861096
151, epoch_train_loss=0.0007309484141861096
Epoch 152
Epoch 152 :: Batch 0/1
Batch Loss = 0.0007309484141860811
152, epoch_train_loss=0.0007309484141860811
Epoch 153
Epoch 153 :: Batch 0/1
Batch Loss = 0.0007309484141860552
153, epoch_train_loss=0.0007309484141860552
Epoch 154
Epoch 154 :: Batch 0/1
Batch Loss = 0.0007309484141860316
154, epoch_train_loss=0.0007309484141860316
Epoch 155
Epoch 155 :: Batch 0/1
Batch Loss = 0.0007309484141860103
155, epoch_train_loss=0.0007309484141860103
Epoch 156
Epoch 156 :: Batch 0/1
Batch Loss = 0.0007309484141859911
156, epoch_train_loss=0.0007309484141859911
Epoch 157
Epoch 157 :: Batch 0/1
Batch Loss = 0.0007309484141859736
157, epoch_train_loss=0.0007309484141859736
Epoch 158
Epoch 158 :: Batch 0/1
Batch Loss = 0.0007309484141859577
158, epoch_train_loss=0.0007309484141859577
Epoch 159
Epoch 159 :: Batch 0/1
Batch Loss = 0.0007309484141859434
159, epoch_train_loss=0.0007309484141859434
Epoch 160
Epoch 160 :: Batch 0/1
Batch Loss = 0.0007309484141859302
160, epoch_train_loss=0.0007309484141859302
Epoch 161
Epoch 161 :: Batch 0/1
Batch Loss = 0.0007309484141859182
161, epoch_train_loss=0.0007309484141859182
Epoch 162
Epoch 162 :: Batch 0/1
Batch Loss = 0.0007309484141859074
162, epoch_train_loss=0.0007309484141859074
Epoch 163
Epoch 163 :: Batch 0/1
Batch Loss = 0.0007309484141858975
163, epoch_train_loss=0.0007309484141858975
Epoch 164
Epoch 164 :: Batch 0/1
Batch Loss = 0.0007309484141858884
164, epoch_train_loss=0.0007309484141858884
Epoch 165
Epoch 165 :: Batch 0/1
Batch Loss = 0.0007309484141858803
165, epoch_train_loss=0.0007309484141858803
Epoch 166
Epoch 166 :: Batch 0/1
Batch Loss = 0.0007309484141858728
166, epoch_train_loss=0.0007309484141858728
Epoch 167
Epoch 167 :: Batch 0/1
Batch Loss = 0.0007309484141858659
167, epoch_train_loss=0.0007309484141858659
Epoch 168
Epoch 168 :: Batch 0/1
Batch Loss = 0.0007309484141858596
168, epoch_train_loss=0.0007309484141858596
Epoch 169
Epoch 169 :: Batch 0/1
Batch Loss = 0.0007309484141858538
169, epoch_train_loss=0.0007309484141858538
Epoch 170
Epoch 170 :: Batch 0/1
Batch Loss = 0.0007309484141858486
170, epoch_train_loss=0.0007309484141858486
Epoch 171
Epoch 171 :: Batch 0/1
Batch Loss = 0.0007309484141858436
171, epoch_train_loss=0.0007309484141858436
Epoch 172
Epoch 172 :: Batch 0/1
Batch Loss = 0.0007309484141858392
172, epoch_train_loss=0.0007309484141858392
Epoch 173
Epoch 173 :: Batch 0/1
Batch Loss = 0.0007309484141858351
173, epoch_train_loss=0.0007309484141858351
Epoch 174
Epoch 174 :: Batch 0/1
Batch Loss = 0.0007309484141858313
174, epoch_train_loss=0.0007309484141858313
Epoch 175
Epoch 175 :: Batch 0/1
Batch Loss = 0.0007309484141858278
175, epoch_train_loss=0.0007309484141858278
Epoch 176
Epoch 176 :: Batch 0/1
Batch Loss = 0.0007309484141858245
176, epoch_train_loss=0.0007309484141858245
Epoch 177
Epoch 177 :: Batch 0/1
Batch Loss = 0.0007309484141858214
177, epoch_train_loss=0.0007309484141858214
Epoch 178
Epoch 178 :: Batch 0/1
Batch Loss = 0.0007309484141858187
178, epoch_train_loss=0.0007309484141858187
Epoch 179
Epoch 179 :: Batch 0/1
Batch Loss = 0.0007309484141858159
179, epoch_train_loss=0.0007309484141858159
Epoch 180
Epoch 180 :: Batch 0/1
Batch Loss = 0.0007309484141858134
180, epoch_train_loss=0.0007309484141858134
Epoch 181
Epoch 181 :: Batch 0/1
Batch Loss = 0.0007309484141858111
181, epoch_train_loss=0.0007309484141858111
Epoch 182
Epoch 182 :: Batch 0/1
Batch Loss = 0.0007309484141858088
182, epoch_train_loss=0.0007309484141858088
Epoch 183
Epoch 183 :: Batch 0/1
Batch Loss = 0.0007309484141858069
183, epoch_train_loss=0.0007309484141858069
Epoch 184
Epoch 184 :: Batch 0/1
Batch Loss = 0.0007309484141858049
184, epoch_train_loss=0.0007309484141858049
Epoch 185
Epoch 185 :: Batch 0/1
Batch Loss = 0.0007309484141858031
185, epoch_train_loss=0.0007309484141858031
Epoch 186
Epoch 186 :: Batch 0/1
Batch Loss = 0.0007309484141858011
186, epoch_train_loss=0.0007309484141858011
Epoch 187
Epoch 187 :: Batch 0/1
Batch Loss = 0.0007309484141857996
187, epoch_train_loss=0.0007309484141857996
Epoch 188
Epoch 188 :: Batch 0/1
Batch Loss = 0.0007309484141857979
188, epoch_train_loss=0.0007309484141857979
Epoch 189
Epoch 189 :: Batch 0/1
Batch Loss = 0.0007309484141857964
189, epoch_train_loss=0.0007309484141857964
Epoch 190
Epoch 190 :: Batch 0/1
Batch Loss = 0.000730948414185795
190, epoch_train_loss=0.000730948414185795
Epoch 191
Epoch 191 :: Batch 0/1
Batch Loss = 0.0007309484141857934
191, epoch_train_loss=0.0007309484141857934
Epoch 192
Epoch 192 :: Batch 0/1
Batch Loss = 0.000730948414185792
192, epoch_train_loss=0.000730948414185792
Epoch 193
Epoch 193 :: Batch 0/1
Batch Loss = 0.0007309484141857908
193, epoch_train_loss=0.0007309484141857908
Epoch 194
Epoch 194 :: Batch 0/1
Batch Loss = 0.0007309484141857895
194, epoch_train_loss=0.0007309484141857895
Epoch 195
Epoch 195 :: Batch 0/1
Batch Loss = 0.0007309484141857882
195, epoch_train_loss=0.0007309484141857882
Epoch 196
Epoch 196 :: Batch 0/1
Batch Loss = 0.0007309484141857869
196, epoch_train_loss=0.0007309484141857869
Epoch 197
Epoch 197 :: Batch 0/1
Batch Loss = 0.0007309484141857859
197, epoch_train_loss=0.0007309484141857859
Epoch 198
Epoch 198 :: Batch 0/1
Batch Loss = 0.0007309484141857846
198, epoch_train_loss=0.0007309484141857846
Epoch 199
Epoch 199 :: Batch 0/1
Batch Loss = 0.0007309484141857835
199, epoch_train_loss=0.0007309484141857835
Epoch 200
Epoch 200 :: Batch 0/1
Batch Loss = 0.0007309484141857822
200, epoch_train_loss=0.0007309484141857822
Epoch 201
Epoch 201 :: Batch 0/1
Batch Loss = 0.000730948414185781
201, epoch_train_loss=0.000730948414185781
Epoch 202
Epoch 202 :: Batch 0/1
Batch Loss = 0.0007309484141857799
202, epoch_train_loss=0.0007309484141857799
Epoch 203
Epoch 203 :: Batch 0/1
Batch Loss = 0.0007309484141857789
203, epoch_train_loss=0.0007309484141857789
Epoch 204
Epoch 204 :: Batch 0/1
Batch Loss = 0.0007309484141857778
204, epoch_train_loss=0.0007309484141857778
Epoch 205
Epoch 205 :: Batch 0/1
Batch Loss = 0.0007309484141857767
205, epoch_train_loss=0.0007309484141857767
Epoch 206
Epoch 206 :: Batch 0/1
Batch Loss = 0.0007309484141857758
206, epoch_train_loss=0.0007309484141857758
Epoch 207
Epoch 207 :: Batch 0/1
Batch Loss = 0.0007309484141857746
207, epoch_train_loss=0.0007309484141857746
Epoch 208
Epoch 208 :: Batch 0/1
Batch Loss = 0.0007309484141857736
208, epoch_train_loss=0.0007309484141857736
Epoch 209
Epoch 209 :: Batch 0/1
Batch Loss = 0.0007309484141857724
209, epoch_train_loss=0.0007309484141857724
Epoch 210
Epoch 210 :: Batch 0/1
Batch Loss = 0.0007309484141857714
210, epoch_train_loss=0.0007309484141857714
Epoch 211
Epoch 211 :: Batch 0/1
Batch Loss = 0.0007309484141857704
211, epoch_train_loss=0.0007309484141857704
Epoch 212
Epoch 212 :: Batch 0/1
Batch Loss = 0.0007309484141857693
212, epoch_train_loss=0.0007309484141857693
Epoch 213
Epoch 213 :: Batch 0/1
Batch Loss = 0.0007309484141857683
213, epoch_train_loss=0.0007309484141857683
Epoch 214
Epoch 214 :: Batch 0/1
Batch Loss = 0.0007309484141857673
214, epoch_train_loss=0.0007309484141857673
Epoch 215
Epoch 215 :: Batch 0/1
Batch Loss = 0.0007309484141857662
215, epoch_train_loss=0.0007309484141857662
Epoch 216
Epoch 216 :: Batch 0/1
Batch Loss = 0.0007309484141857651
216, epoch_train_loss=0.0007309484141857651
Epoch 217
Epoch 217 :: Batch 0/1
Batch Loss = 0.0007309484141857643
217, epoch_train_loss=0.0007309484141857643
Epoch 218
Epoch 218 :: Batch 0/1
Batch Loss = 0.0007309484141857631
218, epoch_train_loss=0.0007309484141857631
Epoch 219
Epoch 219 :: Batch 0/1
Batch Loss = 0.0007309484141857621
219, epoch_train_loss=0.0007309484141857621
Epoch 220
Epoch 220 :: Batch 0/1
Batch Loss = 0.0007309484141857611
220, epoch_train_loss=0.0007309484141857611
Epoch 221
Epoch 221 :: Batch 0/1
Batch Loss = 0.0007309484141857602
221, epoch_train_loss=0.0007309484141857602
Epoch 222
Epoch 222 :: Batch 0/1
Batch Loss = 0.0007309484141857591
222, epoch_train_loss=0.0007309484141857591
Epoch 223
Epoch 223 :: Batch 0/1
Batch Loss = 0.000730948414185758
223, epoch_train_loss=0.000730948414185758
Epoch 224
Epoch 224 :: Batch 0/1
Batch Loss = 0.000730948414185757
224, epoch_train_loss=0.000730948414185757
Epoch 225
Epoch 225 :: Batch 0/1
Batch Loss = 0.000730948414185756
225, epoch_train_loss=0.000730948414185756
Epoch 226
Epoch 226 :: Batch 0/1
Batch Loss = 0.0007309484141857548
226, epoch_train_loss=0.0007309484141857548
Epoch 227
Epoch 227 :: Batch 0/1
Batch Loss = 0.0007309484141857539
227, epoch_train_loss=0.0007309484141857539
Epoch 228
Epoch 228 :: Batch 0/1
Batch Loss = 0.000730948414185753
228, epoch_train_loss=0.000730948414185753
Epoch 229
Epoch 229 :: Batch 0/1
Batch Loss = 0.0007309484141857519
229, epoch_train_loss=0.0007309484141857519
Epoch 230
Epoch 230 :: Batch 0/1
Batch Loss = 0.0007309484141857508
230, epoch_train_loss=0.0007309484141857508
Epoch 231
Epoch 231 :: Batch 0/1
Batch Loss = 0.0007309484141857499
231, epoch_train_loss=0.0007309484141857499
Epoch 232
Epoch 232 :: Batch 0/1
Batch Loss = 0.0007309484141857489
232, epoch_train_loss=0.0007309484141857489
Epoch 233
Epoch 233 :: Batch 0/1
Batch Loss = 0.0007309484141857478
233, epoch_train_loss=0.0007309484141857478
Epoch 234
Epoch 234 :: Batch 0/1
Batch Loss = 0.0007309484141857468
234, epoch_train_loss=0.0007309484141857468
Epoch 235
Epoch 235 :: Batch 0/1
Batch Loss = 0.0007309484141857457
235, epoch_train_loss=0.0007309484141857457
Epoch 236
Epoch 236 :: Batch 0/1
Batch Loss = 0.0007309484141857447
236, epoch_train_loss=0.0007309484141857447
Epoch 237
Epoch 237 :: Batch 0/1
Batch Loss = 0.0007309484141857436
237, epoch_train_loss=0.0007309484141857436
Epoch 238
Epoch 238 :: Batch 0/1
Batch Loss = 0.0007309484141857427
238, epoch_train_loss=0.0007309484141857427
Epoch 239
Epoch 239 :: Batch 0/1
Batch Loss = 0.0007309484141857416
239, epoch_train_loss=0.0007309484141857416
Epoch 240
Epoch 240 :: Batch 0/1
Batch Loss = 0.0007309484141857405
240, epoch_train_loss=0.0007309484141857405
Epoch 241
Epoch 241 :: Batch 0/1
Batch Loss = 0.0007309484141857395
241, epoch_train_loss=0.0007309484141857395
Epoch 242
Epoch 242 :: Batch 0/1
Batch Loss = 0.0007309484141857385
242, epoch_train_loss=0.0007309484141857385
Epoch 243
Epoch 243 :: Batch 0/1
Batch Loss = 0.0007309484141857374
243, epoch_train_loss=0.0007309484141857374
Epoch 244
Epoch 244 :: Batch 0/1
Batch Loss = 0.0007309484141857364
244, epoch_train_loss=0.0007309484141857364
Epoch 245
Epoch 245 :: Batch 0/1
Batch Loss = 0.0007309484141857352
245, epoch_train_loss=0.0007309484141857352
Epoch 246
Epoch 246 :: Batch 0/1
Batch Loss = 0.0007309484141857342
246, epoch_train_loss=0.0007309484141857342
Epoch 247
Epoch 247 :: Batch 0/1
Batch Loss = 0.0007309484141857332
247, epoch_train_loss=0.0007309484141857332
Epoch 248
Epoch 248 :: Batch 0/1
Batch Loss = 0.0007309484141857321
248, epoch_train_loss=0.0007309484141857321
Epoch 249
Epoch 249 :: Batch 0/1
Batch Loss = 0.000730948414185731
249, epoch_train_loss=0.000730948414185731
Epoch 250
Epoch 250 :: Batch 0/1
Batch Loss = 0.0007309484141857299
250, epoch_train_loss=0.0007309484141857299
Epoch 251
Epoch 251 :: Batch 0/1
Batch Loss = 0.0007309484141857288
251, epoch_train_loss=0.0007309484141857288
Epoch 252
Epoch 252 :: Batch 0/1
Batch Loss = 0.0007309484141857277
252, epoch_train_loss=0.0007309484141857277
Epoch 253
Epoch 253 :: Batch 0/1
Batch Loss = 0.0007309484141857267
253, epoch_train_loss=0.0007309484141857267
Epoch 254
Epoch 254 :: Batch 0/1
Batch Loss = 0.0007309484141857256
254, epoch_train_loss=0.0007309484141857256
Epoch 255
Epoch 255 :: Batch 0/1
Batch Loss = 0.0007309484141857246
255, epoch_train_loss=0.0007309484141857246
Epoch 256
Epoch 256 :: Batch 0/1
Batch Loss = 0.0007309484141857235
256, epoch_train_loss=0.0007309484141857235
Epoch 257
Epoch 257 :: Batch 0/1
Batch Loss = 0.0007309484141857224
257, epoch_train_loss=0.0007309484141857224
Epoch 258
Epoch 258 :: Batch 0/1
Batch Loss = 0.0007309484141857213
258, epoch_train_loss=0.0007309484141857213
Epoch 259
Epoch 259 :: Batch 0/1
Batch Loss = 0.0007309484141857203
259, epoch_train_loss=0.0007309484141857203
Epoch 260
Epoch 260 :: Batch 0/1
Batch Loss = 0.0007309484141857192
260, epoch_train_loss=0.0007309484141857192
Epoch 261
Epoch 261 :: Batch 0/1
Batch Loss = 0.000730948414185718
261, epoch_train_loss=0.000730948414185718
Epoch 262
Epoch 262 :: Batch 0/1
Batch Loss = 0.000730948414185717
262, epoch_train_loss=0.000730948414185717
Epoch 263
Epoch 263 :: Batch 0/1
Batch Loss = 0.0007309484141857158
263, epoch_train_loss=0.0007309484141857158
Epoch 264
Epoch 264 :: Batch 0/1
Batch Loss = 0.0007309484141857147
264, epoch_train_loss=0.0007309484141857147
Epoch 265
Epoch 265 :: Batch 0/1
Batch Loss = 0.0007309484141857136
265, epoch_train_loss=0.0007309484141857136
Epoch 266
Epoch 266 :: Batch 0/1
Batch Loss = 0.0007309484141857125
266, epoch_train_loss=0.0007309484141857125
Epoch 267
Epoch 267 :: Batch 0/1
Batch Loss = 0.0007309484141857114
267, epoch_train_loss=0.0007309484141857114
Epoch 268
Epoch 268 :: Batch 0/1
Batch Loss = 0.0007309484141857103
268, epoch_train_loss=0.0007309484141857103
Epoch 269
Epoch 269 :: Batch 0/1
Batch Loss = 0.0007309484141857092
269, epoch_train_loss=0.0007309484141857092
Epoch 270
Epoch 270 :: Batch 0/1
Batch Loss = 0.0007309484141857081
270, epoch_train_loss=0.0007309484141857081
Epoch 271
Epoch 271 :: Batch 0/1
Batch Loss = 0.0007309484141857069
271, epoch_train_loss=0.0007309484141857069
Epoch 272
Epoch 272 :: Batch 0/1
Batch Loss = 0.0007309484141857058
272, epoch_train_loss=0.0007309484141857058
Epoch 273
Epoch 273 :: Batch 0/1
Batch Loss = 0.0007309484141857048
273, epoch_train_loss=0.0007309484141857048
Epoch 274
Epoch 274 :: Batch 0/1
Batch Loss = 0.0007309484141857036
274, epoch_train_loss=0.0007309484141857036
Epoch 275
Epoch 275 :: Batch 0/1
Batch Loss = 0.0007309484141857025
275, epoch_train_loss=0.0007309484141857025
Epoch 276
Epoch 276 :: Batch 0/1
Batch Loss = 0.0007309484141857014
276, epoch_train_loss=0.0007309484141857014
Epoch 277
Epoch 277 :: Batch 0/1
Batch Loss = 0.0007309484141857002
277, epoch_train_loss=0.0007309484141857002
Epoch 278
Epoch 278 :: Batch 0/1
Batch Loss = 0.0007309484141856991
278, epoch_train_loss=0.0007309484141856991
Epoch 279
Epoch 279 :: Batch 0/1
Batch Loss = 0.000730948414185698
279, epoch_train_loss=0.000730948414185698
Epoch 280
Epoch 280 :: Batch 0/1
Batch Loss = 0.0007309484141856968
280, epoch_train_loss=0.0007309484141856968
Epoch 281
Epoch 281 :: Batch 0/1
Batch Loss = 0.0007309484141856957
281, epoch_train_loss=0.0007309484141856957
Epoch 282
Epoch 282 :: Batch 0/1
Batch Loss = 0.0007309484141856945
282, epoch_train_loss=0.0007309484141856945
Epoch 283
Epoch 283 :: Batch 0/1
Batch Loss = 0.0007309484141856934
283, epoch_train_loss=0.0007309484141856934
Epoch 284
Epoch 284 :: Batch 0/1
Batch Loss = 0.0007309484141856923
284, epoch_train_loss=0.0007309484141856923
Epoch 285
Epoch 285 :: Batch 0/1
Batch Loss = 0.0007309484141856911
285, epoch_train_loss=0.0007309484141856911
Epoch 286
Epoch 286 :: Batch 0/1
Batch Loss = 0.0007309484141856899
286, epoch_train_loss=0.0007309484141856899
Epoch 287
Epoch 287 :: Batch 0/1
Batch Loss = 0.0007309484141856888
287, epoch_train_loss=0.0007309484141856888
Epoch 288
Epoch 288 :: Batch 0/1
Batch Loss = 0.0007309484141856876
288, epoch_train_loss=0.0007309484141856876
Epoch 289
Epoch 289 :: Batch 0/1
Batch Loss = 0.0007309484141856865
289, epoch_train_loss=0.0007309484141856865
Epoch 290
Epoch 290 :: Batch 0/1
Batch Loss = 0.0007309484141856854
290, epoch_train_loss=0.0007309484141856854
Epoch 291
Epoch 291 :: Batch 0/1
Batch Loss = 0.0007309484141856842
291, epoch_train_loss=0.0007309484141856842
Epoch 292
Epoch 292 :: Batch 0/1
Batch Loss = 0.000730948414185683
292, epoch_train_loss=0.000730948414185683
Epoch 293
Epoch 293 :: Batch 0/1
Batch Loss = 0.0007309484141856819
293, epoch_train_loss=0.0007309484141856819
Epoch 294
Epoch 294 :: Batch 0/1
Batch Loss = 0.0007309484141856806
294, epoch_train_loss=0.0007309484141856806
Epoch 295
Epoch 295 :: Batch 0/1
Batch Loss = 0.0007309484141856795
295, epoch_train_loss=0.0007309484141856795
Epoch 296
Epoch 296 :: Batch 0/1
Batch Loss = 0.0007309484141856784
296, epoch_train_loss=0.0007309484141856784
Epoch 297
Epoch 297 :: Batch 0/1
Batch Loss = 0.0007309484141856772
297, epoch_train_loss=0.0007309484141856772
Epoch 298
Epoch 298 :: Batch 0/1
Batch Loss = 0.000730948414185676
298, epoch_train_loss=0.000730948414185676
Epoch 299
Epoch 299 :: Batch 0/1
Batch Loss = 0.0007309484141856748
299, epoch_train_loss=0.0007309484141856748
Epoch 300
Epoch 300 :: Batch 0/1
Batch Loss = 0.0007309484141856735
300, epoch_train_loss=0.0007309484141856735
Epoch 301
Epoch 301 :: Batch 0/1
Batch Loss = 0.0007309484141856723
301, epoch_train_loss=0.0007309484141856723
Epoch 302
Epoch 302 :: Batch 0/1
Batch Loss = 0.0007309484141856711
302, epoch_train_loss=0.0007309484141856711
Epoch 303
Epoch 303 :: Batch 0/1
Batch Loss = 0.00073094841418567
303, epoch_train_loss=0.00073094841418567
Epoch 304
Epoch 304 :: Batch 0/1
Batch Loss = 0.0007309484141856688
304, epoch_train_loss=0.0007309484141856688
Epoch 305
Epoch 305 :: Batch 0/1
Batch Loss = 0.0007309484141856676
305, epoch_train_loss=0.0007309484141856676
Epoch 306
Epoch 306 :: Batch 0/1
Batch Loss = 0.0007309484141856664
306, epoch_train_loss=0.0007309484141856664
Epoch 307
Epoch 307 :: Batch 0/1
Batch Loss = 0.0007309484141856653
307, epoch_train_loss=0.0007309484141856653
Epoch 308
Epoch 308 :: Batch 0/1
Batch Loss = 0.0007309484141856641
308, epoch_train_loss=0.0007309484141856641
Epoch 309
Epoch 309 :: Batch 0/1
Batch Loss = 0.0007309484141856628
309, epoch_train_loss=0.0007309484141856628
Epoch 310
Epoch 310 :: Batch 0/1
Batch Loss = 0.0007309484141856617
310, epoch_train_loss=0.0007309484141856617
Epoch 311
Epoch 311 :: Batch 0/1
Batch Loss = 0.0007309484141856604
311, epoch_train_loss=0.0007309484141856604
Epoch 312
Epoch 312 :: Batch 0/1
Batch Loss = 0.0007309484141856592
312, epoch_train_loss=0.0007309484141856592
Epoch 313
Epoch 313 :: Batch 0/1
Batch Loss = 0.000730948414185658
313, epoch_train_loss=0.000730948414185658
Epoch 314
Epoch 314 :: Batch 0/1
Batch Loss = 0.0007309484141856568
314, epoch_train_loss=0.0007309484141856568
Epoch 315
Epoch 315 :: Batch 0/1
Batch Loss = 0.0007309484141856556
315, epoch_train_loss=0.0007309484141856556
Epoch 316
Epoch 316 :: Batch 0/1
Batch Loss = 0.0007309484141856543
316, epoch_train_loss=0.0007309484141856543
Epoch 317
Epoch 317 :: Batch 0/1
Batch Loss = 0.0007309484141856532
317, epoch_train_loss=0.0007309484141856532
Epoch 318
Epoch 318 :: Batch 0/1
Batch Loss = 0.0007309484141856518
318, epoch_train_loss=0.0007309484141856518
Epoch 319
Epoch 319 :: Batch 0/1
Batch Loss = 0.0007309484141856508
319, epoch_train_loss=0.0007309484141856508
Epoch 320
Epoch 320 :: Batch 0/1
Batch Loss = 0.0007309484141856495
320, epoch_train_loss=0.0007309484141856495
Epoch 321
Epoch 321 :: Batch 0/1
Batch Loss = 0.0007309484141856482
321, epoch_train_loss=0.0007309484141856482
Epoch 322
Epoch 322 :: Batch 0/1
Batch Loss = 0.000730948414185647
322, epoch_train_loss=0.000730948414185647
Epoch 323
Epoch 323 :: Batch 0/1
Batch Loss = 0.0007309484141856458
323, epoch_train_loss=0.0007309484141856458
Epoch 324
Epoch 324 :: Batch 0/1
Batch Loss = 0.0007309484141856446
324, epoch_train_loss=0.0007309484141856446
Epoch 325
Epoch 325 :: Batch 0/1
Batch Loss = 0.0007309484141856434
325, epoch_train_loss=0.0007309484141856434
Epoch 326
Epoch 326 :: Batch 0/1
Batch Loss = 0.0007309484141856422
326, epoch_train_loss=0.0007309484141856422
Epoch 327
Epoch 327 :: Batch 0/1
Batch Loss = 0.0007309484141856407
327, epoch_train_loss=0.0007309484141856407
Epoch 328
Epoch 328 :: Batch 0/1
Batch Loss = 0.0007309484141856396
328, epoch_train_loss=0.0007309484141856396
Epoch 329
Epoch 329 :: Batch 0/1
Batch Loss = 0.0007309484141856383
329, epoch_train_loss=0.0007309484141856383
Epoch 330
Epoch 330 :: Batch 0/1
Batch Loss = 0.0007309484141856371
330, epoch_train_loss=0.0007309484141856371
Epoch 331
Epoch 331 :: Batch 0/1
Batch Loss = 0.0007309484141856359
331, epoch_train_loss=0.0007309484141856359
Epoch 332
Epoch 332 :: Batch 0/1
Batch Loss = 0.0007309484141856345
332, epoch_train_loss=0.0007309484141856345
Epoch 333
Epoch 333 :: Batch 0/1
Batch Loss = 0.0007309484141856334
333, epoch_train_loss=0.0007309484141856334
Epoch 334
Epoch 334 :: Batch 0/1
Batch Loss = 0.0007309484141856321
334, epoch_train_loss=0.0007309484141856321
Epoch 335
Epoch 335 :: Batch 0/1
Batch Loss = 0.0007309484141856309
335, epoch_train_loss=0.0007309484141856309
Epoch 336
Epoch 336 :: Batch 0/1
Batch Loss = 0.0007309484141856296
336, epoch_train_loss=0.0007309484141856296
Epoch 337
Epoch 337 :: Batch 0/1
Batch Loss = 0.0007309484141856283
337, epoch_train_loss=0.0007309484141856283
Epoch 338
Epoch 338 :: Batch 0/1
Batch Loss = 0.000730948414185627
338, epoch_train_loss=0.000730948414185627
Epoch 339
Epoch 339 :: Batch 0/1
Batch Loss = 0.0007309484141856258
339, epoch_train_loss=0.0007309484141856258
Epoch 340
Epoch 340 :: Batch 0/1
Batch Loss = 0.0007309484141856245
340, epoch_train_loss=0.0007309484141856245
Epoch 341
Epoch 341 :: Batch 0/1
Batch Loss = 0.0007309484141856232
341, epoch_train_loss=0.0007309484141856232
Epoch 342
Epoch 342 :: Batch 0/1
Batch Loss = 0.000730948414185622
342, epoch_train_loss=0.000730948414185622
Epoch 343
Epoch 343 :: Batch 0/1
Batch Loss = 0.0007309484141856206
343, epoch_train_loss=0.0007309484141856206
Epoch 344
Epoch 344 :: Batch 0/1
Batch Loss = 0.0007309484141856195
344, epoch_train_loss=0.0007309484141856195
Epoch 345
Epoch 345 :: Batch 0/1
Batch Loss = 0.0007309484141856181
345, epoch_train_loss=0.0007309484141856181
Epoch 346
Epoch 346 :: Batch 0/1
Batch Loss = 0.0007309484141856167
346, epoch_train_loss=0.0007309484141856167
Epoch 347
Epoch 347 :: Batch 0/1
Batch Loss = 0.0007309484141856155
347, epoch_train_loss=0.0007309484141856155
Epoch 348
Epoch 348 :: Batch 0/1
Batch Loss = 0.0007309484141856143
348, epoch_train_loss=0.0007309484141856143
Epoch 349
Epoch 349 :: Batch 0/1
Batch Loss = 0.0007309484141856129
349, epoch_train_loss=0.0007309484141856129
Epoch 350
Epoch 350 :: Batch 0/1
Batch Loss = 0.0007309484141856117
350, epoch_train_loss=0.0007309484141856117
Epoch 351
Epoch 351 :: Batch 0/1
Batch Loss = 0.0007309484141856105
351, epoch_train_loss=0.0007309484141856105
Epoch 352
Epoch 352 :: Batch 0/1
Batch Loss = 0.000730948414185609
352, epoch_train_loss=0.000730948414185609
Epoch 353
Epoch 353 :: Batch 0/1
Batch Loss = 0.0007309484141856078
353, epoch_train_loss=0.0007309484141856078
Epoch 354
Epoch 354 :: Batch 0/1
Batch Loss = 0.0007309484141856065
354, epoch_train_loss=0.0007309484141856065
Epoch 355
Epoch 355 :: Batch 0/1
Batch Loss = 0.0007309484141856052
355, epoch_train_loss=0.0007309484141856052
Epoch 356
Epoch 356 :: Batch 0/1
Batch Loss = 0.0007309484141856039
356, epoch_train_loss=0.0007309484141856039
Epoch 357
Epoch 357 :: Batch 0/1
Batch Loss = 0.0007309484141856026
357, epoch_train_loss=0.0007309484141856026
Epoch 358
Epoch 358 :: Batch 0/1
Batch Loss = 0.0007309484141856013
358, epoch_train_loss=0.0007309484141856013
Epoch 359
Epoch 359 :: Batch 0/1
Batch Loss = 0.0007309484141855999
359, epoch_train_loss=0.0007309484141855999
Epoch 360
Epoch 360 :: Batch 0/1
Batch Loss = 0.0007309484141855987
360, epoch_train_loss=0.0007309484141855987
Epoch 361
Epoch 361 :: Batch 0/1
Batch Loss = 0.0007309484141855973
361, epoch_train_loss=0.0007309484141855973
Epoch 362
Epoch 362 :: Batch 0/1
Batch Loss = 0.000730948414185596
362, epoch_train_loss=0.000730948414185596
Epoch 363
Epoch 363 :: Batch 0/1
Batch Loss = 0.0007309484141855947
363, epoch_train_loss=0.0007309484141855947
Epoch 364
Epoch 364 :: Batch 0/1
Batch Loss = 0.0007309484141855935
364, epoch_train_loss=0.0007309484141855935
Epoch 365
Epoch 365 :: Batch 0/1
Batch Loss = 0.000730948414185592
365, epoch_train_loss=0.000730948414185592
Epoch 366
Epoch 366 :: Batch 0/1
Batch Loss = 0.0007309484141855908
366, epoch_train_loss=0.0007309484141855908
Epoch 367
Epoch 367 :: Batch 0/1
Batch Loss = 0.0007309484141855894
367, epoch_train_loss=0.0007309484141855894
Epoch 368
Epoch 368 :: Batch 0/1
Batch Loss = 0.0007309484141855881
368, epoch_train_loss=0.0007309484141855881
Epoch 369
Epoch 369 :: Batch 0/1
Batch Loss = 0.0007309484141855868
369, epoch_train_loss=0.0007309484141855868
Epoch 370
Epoch 370 :: Batch 0/1
Batch Loss = 0.0007309484141855853
370, epoch_train_loss=0.0007309484141855853
Epoch 371
Epoch 371 :: Batch 0/1
Batch Loss = 0.0007309484141855841
371, epoch_train_loss=0.0007309484141855841
Epoch 372
Epoch 372 :: Batch 0/1
Batch Loss = 0.0007309484141855827
372, epoch_train_loss=0.0007309484141855827
Epoch 373
Epoch 373 :: Batch 0/1
Batch Loss = 0.0007309484141855815
373, epoch_train_loss=0.0007309484141855815
Epoch 374
Epoch 374 :: Batch 0/1
Batch Loss = 0.0007309484141855801
374, epoch_train_loss=0.0007309484141855801
Epoch 375
Epoch 375 :: Batch 0/1
Batch Loss = 0.0007309484141855788
375, epoch_train_loss=0.0007309484141855788
Epoch 376
Epoch 376 :: Batch 0/1
Batch Loss = 0.0007309484141855774
376, epoch_train_loss=0.0007309484141855774
Epoch 377
Epoch 377 :: Batch 0/1
Batch Loss = 0.000730948414185576
377, epoch_train_loss=0.000730948414185576
Epoch 378
Epoch 378 :: Batch 0/1
Batch Loss = 0.0007309484141855747
378, epoch_train_loss=0.0007309484141855747
Epoch 379
Epoch 379 :: Batch 0/1
Batch Loss = 0.0007309484141855734
379, epoch_train_loss=0.0007309484141855734
Epoch 380
Epoch 380 :: Batch 0/1
Batch Loss = 0.000730948414185572
380, epoch_train_loss=0.000730948414185572
Epoch 381
Epoch 381 :: Batch 0/1
Batch Loss = 0.0007309484141855708
381, epoch_train_loss=0.0007309484141855708
Epoch 382
Epoch 382 :: Batch 0/1
Batch Loss = 0.0007309484141855692
382, epoch_train_loss=0.0007309484141855692
Epoch 383
Epoch 383 :: Batch 0/1
Batch Loss = 0.0007309484141855679
383, epoch_train_loss=0.0007309484141855679
Epoch 384
Epoch 384 :: Batch 0/1
Batch Loss = 0.0007309484141855666
384, epoch_train_loss=0.0007309484141855666
Epoch 385
Epoch 385 :: Batch 0/1
Batch Loss = 0.0007309484141855652
385, epoch_train_loss=0.0007309484141855652
Epoch 386
Epoch 386 :: Batch 0/1
Batch Loss = 0.0007309484141855637
386, epoch_train_loss=0.0007309484141855637
Epoch 387
Epoch 387 :: Batch 0/1
Batch Loss = 0.0007309484141855625
387, epoch_train_loss=0.0007309484141855625
Epoch 388
Epoch 388 :: Batch 0/1
Batch Loss = 0.000730948414185561
388, epoch_train_loss=0.000730948414185561
Epoch 389
Epoch 389 :: Batch 0/1
Batch Loss = 0.0007309484141855597
389, epoch_train_loss=0.0007309484141855597
Epoch 390
Epoch 390 :: Batch 0/1
Batch Loss = 0.0007309484141855582
390, epoch_train_loss=0.0007309484141855582
Epoch 391
Epoch 391 :: Batch 0/1
Batch Loss = 0.0007309484141855569
391, epoch_train_loss=0.0007309484141855569
Epoch 392
Epoch 392 :: Batch 0/1
Batch Loss = 0.0007309484141855556
392, epoch_train_loss=0.0007309484141855556
Epoch 393
Epoch 393 :: Batch 0/1
Batch Loss = 0.0007309484141855542
393, epoch_train_loss=0.0007309484141855542
Epoch 394
Epoch 394 :: Batch 0/1
Batch Loss = 0.0007309484141855529
394, epoch_train_loss=0.0007309484141855529
Epoch 395
Epoch 395 :: Batch 0/1
Batch Loss = 0.0007309484141855513
395, epoch_train_loss=0.0007309484141855513
Epoch 396
Epoch 396 :: Batch 0/1
Batch Loss = 0.00073094841418555
396, epoch_train_loss=0.00073094841418555
Epoch 397
Epoch 397 :: Batch 0/1
Batch Loss = 0.0007309484141855486
397, epoch_train_loss=0.0007309484141855486
Epoch 398
Epoch 398 :: Batch 0/1
Batch Loss = 0.0007309484141855473
398, epoch_train_loss=0.0007309484141855473
Epoch 399
Epoch 399 :: Batch 0/1
Batch Loss = 0.0007309484141855459
399, epoch_train_loss=0.0007309484141855459
Epoch 400
Epoch 400 :: Batch 0/1
Batch Loss = 0.0007309484141855444
400, epoch_train_loss=0.0007309484141855444
Epoch 401
Epoch 401 :: Batch 0/1
Batch Loss = 0.0007309484141855431
401, epoch_train_loss=0.0007309484141855431
Epoch 402
Epoch 402 :: Batch 0/1
Batch Loss = 0.0007309484141855417
402, epoch_train_loss=0.0007309484141855417
Epoch 403
Epoch 403 :: Batch 0/1
Batch Loss = 0.0007309484141855403
403, epoch_train_loss=0.0007309484141855403
Epoch 404
Epoch 404 :: Batch 0/1
Batch Loss = 0.0007309484141855389
404, epoch_train_loss=0.0007309484141855389
Epoch 405
Epoch 405 :: Batch 0/1
Batch Loss = 0.0007309484141855375
405, epoch_train_loss=0.0007309484141855375
Epoch 406
Epoch 406 :: Batch 0/1
Batch Loss = 0.0007309484141855361
406, epoch_train_loss=0.0007309484141855361
Epoch 407
Epoch 407 :: Batch 0/1
Batch Loss = 0.0007309484141855348
407, epoch_train_loss=0.0007309484141855348
Epoch 408
Epoch 408 :: Batch 0/1
Batch Loss = 0.0007309484141855331
408, epoch_train_loss=0.0007309484141855331
Epoch 409
Epoch 409 :: Batch 0/1
Batch Loss = 0.0007309484141855318
409, epoch_train_loss=0.0007309484141855318
Epoch 410
Epoch 410 :: Batch 0/1
Batch Loss = 0.0007309484141855304
410, epoch_train_loss=0.0007309484141855304
Epoch 411
Epoch 411 :: Batch 0/1
Batch Loss = 0.000730948414185529
411, epoch_train_loss=0.000730948414185529
Epoch 412
Epoch 412 :: Batch 0/1
Batch Loss = 0.0007309484141855275
412, epoch_train_loss=0.0007309484141855275
Epoch 413
Epoch 413 :: Batch 0/1
Batch Loss = 0.0007309484141855261
413, epoch_train_loss=0.0007309484141855261
Epoch 414
Epoch 414 :: Batch 0/1
Batch Loss = 0.0007309484141855247
414, epoch_train_loss=0.0007309484141855247
Epoch 415
Epoch 415 :: Batch 0/1
Batch Loss = 0.0007309484141855233
415, epoch_train_loss=0.0007309484141855233
Epoch 416
Epoch 416 :: Batch 0/1
Batch Loss = 0.0007309484141855217
416, epoch_train_loss=0.0007309484141855217
Epoch 417
Epoch 417 :: Batch 0/1
Batch Loss = 0.0007309484141855204
417, epoch_train_loss=0.0007309484141855204
Epoch 418
Epoch 418 :: Batch 0/1
Batch Loss = 0.000730948414185519
418, epoch_train_loss=0.000730948414185519
Epoch 419
Epoch 419 :: Batch 0/1
Batch Loss = 0.0007309484141855176
419, epoch_train_loss=0.0007309484141855176
Epoch 420
Epoch 420 :: Batch 0/1
Batch Loss = 0.0007309484141855161
420, epoch_train_loss=0.0007309484141855161
Epoch 421
Epoch 421 :: Batch 0/1
Batch Loss = 0.0007309484141855147
421, epoch_train_loss=0.0007309484141855147
Epoch 422
Epoch 422 :: Batch 0/1
Batch Loss = 0.0007309484141855132
422, epoch_train_loss=0.0007309484141855132
Epoch 423
Epoch 423 :: Batch 0/1
Batch Loss = 0.0007309484141855118
423, epoch_train_loss=0.0007309484141855118
Epoch 424
Epoch 424 :: Batch 0/1
Batch Loss = 0.0007309484141855104
424, epoch_train_loss=0.0007309484141855104
Epoch 425
Epoch 425 :: Batch 0/1
Batch Loss = 0.0007309484141855088
425, epoch_train_loss=0.0007309484141855088
Epoch 426
Epoch 426 :: Batch 0/1
Batch Loss = 0.0007309484141855074
426, epoch_train_loss=0.0007309484141855074
Epoch 427
Epoch 427 :: Batch 0/1
Batch Loss = 0.000730948414185506
427, epoch_train_loss=0.000730948414185506
Epoch 428
Epoch 428 :: Batch 0/1
Batch Loss = 0.0007309484141855045
428, epoch_train_loss=0.0007309484141855045
Epoch 429
Epoch 429 :: Batch 0/1
Batch Loss = 0.0007309484141855031
429, epoch_train_loss=0.0007309484141855031
Epoch 430
Epoch 430 :: Batch 0/1
Batch Loss = 0.0007309484141855016
430, epoch_train_loss=0.0007309484141855016
Epoch 431
Epoch 431 :: Batch 0/1
Batch Loss = 0.0007309484141855002
431, epoch_train_loss=0.0007309484141855002
Epoch 432
Epoch 432 :: Batch 0/1
Batch Loss = 0.0007309484141854988
432, epoch_train_loss=0.0007309484141854988
Epoch 433
Epoch 433 :: Batch 0/1
Batch Loss = 0.0007309484141854974
433, epoch_train_loss=0.0007309484141854974
Epoch 434
Epoch 434 :: Batch 0/1
Batch Loss = 0.0007309484141854958
434, epoch_train_loss=0.0007309484141854958
Epoch 435
Epoch 435 :: Batch 0/1
Batch Loss = 0.0007309484141854943
435, epoch_train_loss=0.0007309484141854943
Epoch 436
Epoch 436 :: Batch 0/1
Batch Loss = 0.0007309484141854929
436, epoch_train_loss=0.0007309484141854929
Epoch 437
Epoch 437 :: Batch 0/1
Batch Loss = 0.0007309484141854913
437, epoch_train_loss=0.0007309484141854913
Epoch 438
Epoch 438 :: Batch 0/1
Batch Loss = 0.0007309484141854899
438, epoch_train_loss=0.0007309484141854899
Epoch 439
Epoch 439 :: Batch 0/1
Batch Loss = 0.0007309484141854885
439, epoch_train_loss=0.0007309484141854885
Epoch 440
Epoch 440 :: Batch 0/1
Batch Loss = 0.000730948414185487
440, epoch_train_loss=0.000730948414185487
Epoch 441
Epoch 441 :: Batch 0/1
Batch Loss = 0.0007309484141854855
441, epoch_train_loss=0.0007309484141854855
Epoch 442
Epoch 442 :: Batch 0/1
Batch Loss = 0.0007309484141854841
442, epoch_train_loss=0.0007309484141854841
Epoch 443
Epoch 443 :: Batch 0/1
Batch Loss = 0.0007309484141854824
443, epoch_train_loss=0.0007309484141854824
Epoch 444
Epoch 444 :: Batch 0/1
Batch Loss = 0.000730948414185481
444, epoch_train_loss=0.000730948414185481
Epoch 445
Epoch 445 :: Batch 0/1
Batch Loss = 0.0007309484141854796
445, epoch_train_loss=0.0007309484141854796
Epoch 446
Epoch 446 :: Batch 0/1
Batch Loss = 0.0007309484141854782
446, epoch_train_loss=0.0007309484141854782
Epoch 447
Epoch 447 :: Batch 0/1
Batch Loss = 0.0007309484141854765
447, epoch_train_loss=0.0007309484141854765
Epoch 448
Epoch 448 :: Batch 0/1
Batch Loss = 0.000730948414185475
448, epoch_train_loss=0.000730948414185475
Epoch 449
Epoch 449 :: Batch 0/1
Batch Loss = 0.0007309484141854736
449, epoch_train_loss=0.0007309484141854736
Epoch 450
Epoch 450 :: Batch 0/1
Batch Loss = 0.0007309484141854721
450, epoch_train_loss=0.0007309484141854721
Epoch 451
Epoch 451 :: Batch 0/1
Batch Loss = 0.0007309484141854706
451, epoch_train_loss=0.0007309484141854706
Epoch 452
Epoch 452 :: Batch 0/1
Batch Loss = 0.000730948414185469
452, epoch_train_loss=0.000730948414185469
Epoch 453
Epoch 453 :: Batch 0/1
Batch Loss = 0.0007309484141854675
453, epoch_train_loss=0.0007309484141854675
Epoch 454
Epoch 454 :: Batch 0/1
Batch Loss = 0.0007309484141854661
454, epoch_train_loss=0.0007309484141854661
Epoch 455
Epoch 455 :: Batch 0/1
Batch Loss = 0.0007309484141854646
455, epoch_train_loss=0.0007309484141854646
Epoch 456
Epoch 456 :: Batch 0/1
Batch Loss = 0.000730948414185463
456, epoch_train_loss=0.000730948414185463
Epoch 457
Epoch 457 :: Batch 0/1
Batch Loss = 0.0007309484141854616
457, epoch_train_loss=0.0007309484141854616
Epoch 458
Epoch 458 :: Batch 0/1
Batch Loss = 0.00073094841418546
458, epoch_train_loss=0.00073094841418546
Epoch 459
Epoch 459 :: Batch 0/1
Batch Loss = 0.0007309484141854584
459, epoch_train_loss=0.0007309484141854584
Epoch 460
Epoch 460 :: Batch 0/1
Batch Loss = 0.000730948414185457
460, epoch_train_loss=0.000730948414185457
Epoch 461
Epoch 461 :: Batch 0/1
Batch Loss = 0.0007309484141854555
461, epoch_train_loss=0.0007309484141854555
Epoch 462
Epoch 462 :: Batch 0/1
Batch Loss = 0.0007309484141854539
462, epoch_train_loss=0.0007309484141854539
Epoch 463
Epoch 463 :: Batch 0/1
Batch Loss = 0.0007309484141854525
463, epoch_train_loss=0.0007309484141854525
Epoch 464
Epoch 464 :: Batch 0/1
Batch Loss = 0.000730948414185451
464, epoch_train_loss=0.000730948414185451
Epoch 465
Epoch 465 :: Batch 0/1
Batch Loss = 0.0007309484141854493
465, epoch_train_loss=0.0007309484141854493
Epoch 466
Epoch 466 :: Batch 0/1
Batch Loss = 0.0007309484141854479
466, epoch_train_loss=0.0007309484141854479
Epoch 467
Epoch 467 :: Batch 0/1
Batch Loss = 0.0007309484141854465
467, epoch_train_loss=0.0007309484141854465
Epoch 468
Epoch 468 :: Batch 0/1
Batch Loss = 0.0007309484141854448
468, epoch_train_loss=0.0007309484141854448
Epoch 469
Epoch 469 :: Batch 0/1
Batch Loss = 0.0007309484141854434
469, epoch_train_loss=0.0007309484141854434
Epoch 470
Epoch 470 :: Batch 0/1
Batch Loss = 0.0007309484141854418
470, epoch_train_loss=0.0007309484141854418
Epoch 471
Epoch 471 :: Batch 0/1
Batch Loss = 0.0007309484141854402
471, epoch_train_loss=0.0007309484141854402
Epoch 472
Epoch 472 :: Batch 0/1
Batch Loss = 0.0007309484141854386
472, epoch_train_loss=0.0007309484141854386
Epoch 473
Epoch 473 :: Batch 0/1
Batch Loss = 0.0007309484141854371
473, epoch_train_loss=0.0007309484141854371
Epoch 474
Epoch 474 :: Batch 0/1
Batch Loss = 0.0007309484141854356
474, epoch_train_loss=0.0007309484141854356
Epoch 475
Epoch 475 :: Batch 0/1
Batch Loss = 0.000730948414185434
475, epoch_train_loss=0.000730948414185434
Epoch 476
Epoch 476 :: Batch 0/1
Batch Loss = 0.0007309484141854325
476, epoch_train_loss=0.0007309484141854325
Epoch 477
Epoch 477 :: Batch 0/1
Batch Loss = 0.0007309484141854309
477, epoch_train_loss=0.0007309484141854309
Epoch 478
Epoch 478 :: Batch 0/1
Batch Loss = 0.0007309484141854294
478, epoch_train_loss=0.0007309484141854294
Epoch 479
Epoch 479 :: Batch 0/1
Batch Loss = 0.0007309484141854277
479, epoch_train_loss=0.0007309484141854277
Epoch 480
Epoch 480 :: Batch 0/1
Batch Loss = 0.0007309484141854263
480, epoch_train_loss=0.0007309484141854263
Epoch 481
Epoch 481 :: Batch 0/1
Batch Loss = 0.0007309484141854247
481, epoch_train_loss=0.0007309484141854247
Epoch 482
Epoch 482 :: Batch 0/1
Batch Loss = 0.0007309484141854232
482, epoch_train_loss=0.0007309484141854232
Epoch 483
Epoch 483 :: Batch 0/1
Batch Loss = 0.0007309484141854216
483, epoch_train_loss=0.0007309484141854216
Epoch 484
Epoch 484 :: Batch 0/1
Batch Loss = 0.0007309484141854199
484, epoch_train_loss=0.0007309484141854199
Epoch 485
Epoch 485 :: Batch 0/1
Batch Loss = 0.0007309484141854184
485, epoch_train_loss=0.0007309484141854184
Epoch 486
Epoch 486 :: Batch 0/1
Batch Loss = 0.000730948414185417
486, epoch_train_loss=0.000730948414185417
Epoch 487
Epoch 487 :: Batch 0/1
Batch Loss = 0.0007309484141854153
487, epoch_train_loss=0.0007309484141854153
Epoch 488
Epoch 488 :: Batch 0/1
Batch Loss = 0.0007309484141854137
488, epoch_train_loss=0.0007309484141854137
Epoch 489
Epoch 489 :: Batch 0/1
Batch Loss = 0.0007309484141854121
489, epoch_train_loss=0.0007309484141854121
Epoch 490
Epoch 490 :: Batch 0/1
Batch Loss = 0.0007309484141854106
490, epoch_train_loss=0.0007309484141854106
Epoch 491
Epoch 491 :: Batch 0/1
Batch Loss = 0.0007309484141854091
491, epoch_train_loss=0.0007309484141854091
Epoch 492
Epoch 492 :: Batch 0/1
Batch Loss = 0.0007309484141854074
492, epoch_train_loss=0.0007309484141854074
Epoch 493
Epoch 493 :: Batch 0/1
Batch Loss = 0.0007309484141854058
493, epoch_train_loss=0.0007309484141854058
Epoch 494
Epoch 494 :: Batch 0/1
Batch Loss = 0.0007309484141854042
494, epoch_train_loss=0.0007309484141854042
Epoch 495
Epoch 495 :: Batch 0/1
Batch Loss = 0.0007309484141854026
495, epoch_train_loss=0.0007309484141854026
Epoch 496
Epoch 496 :: Batch 0/1
Batch Loss = 0.0007309484141854011
496, epoch_train_loss=0.0007309484141854011
Epoch 497
Epoch 497 :: Batch 0/1
Batch Loss = 0.0007309484141853994
497, epoch_train_loss=0.0007309484141853994
Epoch 498
Epoch 498 :: Batch 0/1
Batch Loss = 0.0007309484141853979
498, epoch_train_loss=0.0007309484141853979
Epoch 499
Epoch 499 :: Batch 0/1
Batch Loss = 0.0007309484141853962
499, epoch_train_loss=0.0007309484141853962
Epoch 500
Epoch 500 :: Batch 0/1
Batch Loss = 0.0007309484141853947
500, epoch_train_loss=0.0007309484141853947
Epoch 501
Epoch 501 :: Batch 0/1
Batch Loss = 0.0007309484141853932
501, epoch_train_loss=0.0007309484141853932
Epoch 502
Epoch 502 :: Batch 0/1
Batch Loss = 0.0007309484141853915
502, epoch_train_loss=0.0007309484141853915
Epoch 503
Epoch 503 :: Batch 0/1
Batch Loss = 0.0007309484141853899
503, epoch_train_loss=0.0007309484141853899
Epoch 504
Epoch 504 :: Batch 0/1
Batch Loss = 0.0007309484141853883
504, epoch_train_loss=0.0007309484141853883
Epoch 505
Epoch 505 :: Batch 0/1
Batch Loss = 0.0007309484141853868
505, epoch_train_loss=0.0007309484141853868
Epoch 506
Epoch 506 :: Batch 0/1
Batch Loss = 0.000730948414185385
506, epoch_train_loss=0.000730948414185385
Epoch 507
Epoch 507 :: Batch 0/1
Batch Loss = 0.0007309484141853835
507, epoch_train_loss=0.0007309484141853835
Epoch 508
Epoch 508 :: Batch 0/1
Batch Loss = 0.000730948414185382
508, epoch_train_loss=0.000730948414185382
Epoch 509
Epoch 509 :: Batch 0/1
Batch Loss = 0.0007309484141853803
509, epoch_train_loss=0.0007309484141853803
Epoch 510
Epoch 510 :: Batch 0/1
Batch Loss = 0.0007309484141853787
510, epoch_train_loss=0.0007309484141853787
Epoch 511
Epoch 511 :: Batch 0/1
Batch Loss = 0.000730948414185377
511, epoch_train_loss=0.000730948414185377
Epoch 512
Epoch 512 :: Batch 0/1
Batch Loss = 0.0007309484141853755
512, epoch_train_loss=0.0007309484141853755
Epoch 513
Epoch 513 :: Batch 0/1
Batch Loss = 0.0007309484141853738
513, epoch_train_loss=0.0007309484141853738
Epoch 514
Epoch 514 :: Batch 0/1
Batch Loss = 0.0007309484141853721
514, epoch_train_loss=0.0007309484141853721
Epoch 515
Epoch 515 :: Batch 0/1
Batch Loss = 0.0007309484141853704
515, epoch_train_loss=0.0007309484141853704
Epoch 516
Epoch 516 :: Batch 0/1
Batch Loss = 0.000730948414185369
516, epoch_train_loss=0.000730948414185369
Epoch 517
Epoch 517 :: Batch 0/1
Batch Loss = 0.0007309484141853674
517, epoch_train_loss=0.0007309484141853674
Epoch 518
Epoch 518 :: Batch 0/1
Batch Loss = 0.0007309484141853656
518, epoch_train_loss=0.0007309484141853656
Epoch 519
Epoch 519 :: Batch 0/1
Batch Loss = 0.000730948414185364
519, epoch_train_loss=0.000730948414185364
Epoch 520
Epoch 520 :: Batch 0/1
Batch Loss = 0.0007309484141853623
520, epoch_train_loss=0.0007309484141853623
Epoch 521
Epoch 521 :: Batch 0/1
Batch Loss = 0.0007309484141853607
521, epoch_train_loss=0.0007309484141853607
Epoch 522
Epoch 522 :: Batch 0/1
Batch Loss = 0.0007309484141853592
522, epoch_train_loss=0.0007309484141853592
Epoch 523
Epoch 523 :: Batch 0/1
Batch Loss = 0.0007309484141853575
523, epoch_train_loss=0.0007309484141853575
Epoch 524
Epoch 524 :: Batch 0/1
Batch Loss = 0.0007309484141853559
524, epoch_train_loss=0.0007309484141853559
Epoch 525
Epoch 525 :: Batch 0/1
Batch Loss = 0.0007309484141853541
525, epoch_train_loss=0.0007309484141853541
Epoch 526
Epoch 526 :: Batch 0/1
Batch Loss = 0.0007309484141853525
526, epoch_train_loss=0.0007309484141853525
Epoch 527
Epoch 527 :: Batch 0/1
Batch Loss = 0.0007309484141853509
527, epoch_train_loss=0.0007309484141853509
Epoch 528
Epoch 528 :: Batch 0/1
Batch Loss = 0.0007309484141853494
528, epoch_train_loss=0.0007309484141853494
Epoch 529
Epoch 529 :: Batch 0/1
Batch Loss = 0.0007309484141853476
529, epoch_train_loss=0.0007309484141853476
Epoch 530
Epoch 530 :: Batch 0/1
Batch Loss = 0.000730948414185346
530, epoch_train_loss=0.000730948414185346
Epoch 531
Epoch 531 :: Batch 0/1
Batch Loss = 0.0007309484141853443
531, epoch_train_loss=0.0007309484141853443
Epoch 532
Epoch 532 :: Batch 0/1
Batch Loss = 0.0007309484141853426
532, epoch_train_loss=0.0007309484141853426
Epoch 533
Epoch 533 :: Batch 0/1
Batch Loss = 0.0007309484141853409
533, epoch_train_loss=0.0007309484141853409
Epoch 534
Epoch 534 :: Batch 0/1
Batch Loss = 0.0007309484141853393
534, epoch_train_loss=0.0007309484141853393
Epoch 535
Epoch 535 :: Batch 0/1
Batch Loss = 0.0007309484141853375
535, epoch_train_loss=0.0007309484141853375
Epoch 536
Epoch 536 :: Batch 0/1
Batch Loss = 0.0007309484141853359
536, epoch_train_loss=0.0007309484141853359
Epoch 537
Epoch 537 :: Batch 0/1
Batch Loss = 0.0007309484141853342
537, epoch_train_loss=0.0007309484141853342
Epoch 538
Epoch 538 :: Batch 0/1
Batch Loss = 0.0007309484141853327
538, epoch_train_loss=0.0007309484141853327
Epoch 539
Epoch 539 :: Batch 0/1
Batch Loss = 0.000730948414185331
539, epoch_train_loss=0.000730948414185331
Epoch 540
Epoch 540 :: Batch 0/1
Batch Loss = 0.0007309484141853292
540, epoch_train_loss=0.0007309484141853292
Epoch 541
Epoch 541 :: Batch 0/1
Batch Loss = 0.0007309484141853276
541, epoch_train_loss=0.0007309484141853276
Epoch 542
Epoch 542 :: Batch 0/1
Batch Loss = 0.0007309484141853259
542, epoch_train_loss=0.0007309484141853259
Epoch 543
Epoch 543 :: Batch 0/1
Batch Loss = 0.0007309484141853243
543, epoch_train_loss=0.0007309484141853243
Epoch 544
Epoch 544 :: Batch 0/1
Batch Loss = 0.0007309484141853225
544, epoch_train_loss=0.0007309484141853225
Epoch 545
Epoch 545 :: Batch 0/1
Batch Loss = 0.000730948414185321
545, epoch_train_loss=0.000730948414185321
Epoch 546
Epoch 546 :: Batch 0/1
Batch Loss = 0.0007309484141853192
546, epoch_train_loss=0.0007309484141853192
Epoch 547
Epoch 547 :: Batch 0/1
Batch Loss = 0.0007309484141853175
547, epoch_train_loss=0.0007309484141853175
Epoch 548
Epoch 548 :: Batch 0/1
Batch Loss = 0.0007309484141853159
548, epoch_train_loss=0.0007309484141853159
Epoch 549
Epoch 549 :: Batch 0/1
Batch Loss = 0.0007309484141853141
549, epoch_train_loss=0.0007309484141853141
Epoch 550
Epoch 550 :: Batch 0/1
Batch Loss = 0.0007309484141853124
550, epoch_train_loss=0.0007309484141853124
Epoch 551
Epoch 551 :: Batch 0/1
Batch Loss = 0.0007309484141853108
551, epoch_train_loss=0.0007309484141853108
Epoch 552
Epoch 552 :: Batch 0/1
Batch Loss = 0.000730948414185309
552, epoch_train_loss=0.000730948414185309
Epoch 553
Epoch 553 :: Batch 0/1
Batch Loss = 0.0007309484141853074
553, epoch_train_loss=0.0007309484141853074
Epoch 554
Epoch 554 :: Batch 0/1
Batch Loss = 0.0007309484141853057
554, epoch_train_loss=0.0007309484141853057
Epoch 555
Epoch 555 :: Batch 0/1
Batch Loss = 0.000730948414185304
555, epoch_train_loss=0.000730948414185304
Epoch 556
Epoch 556 :: Batch 0/1
Batch Loss = 0.0007309484141853022
556, epoch_train_loss=0.0007309484141853022
Epoch 557
Epoch 557 :: Batch 0/1
Batch Loss = 0.0007309484141853007
557, epoch_train_loss=0.0007309484141853007
Epoch 558
Epoch 558 :: Batch 0/1
Batch Loss = 0.0007309484141852987
558, epoch_train_loss=0.0007309484141852987
Epoch 559
Epoch 559 :: Batch 0/1
Batch Loss = 0.0007309484141852971
559, epoch_train_loss=0.0007309484141852971
Epoch 560
Epoch 560 :: Batch 0/1
Batch Loss = 0.0007309484141852954
560, epoch_train_loss=0.0007309484141852954
Epoch 561
Epoch 561 :: Batch 0/1
Batch Loss = 0.0007309484141852937
561, epoch_train_loss=0.0007309484141852937
Epoch 562
Epoch 562 :: Batch 0/1
Batch Loss = 0.0007309484141852919
562, epoch_train_loss=0.0007309484141852919
Epoch 563
Epoch 563 :: Batch 0/1
Batch Loss = 0.0007309484141852903
563, epoch_train_loss=0.0007309484141852903
Epoch 564
Epoch 564 :: Batch 0/1
Batch Loss = 0.0007309484141852884
564, epoch_train_loss=0.0007309484141852884
Epoch 565
Epoch 565 :: Batch 0/1
Batch Loss = 0.0007309484141852867
565, epoch_train_loss=0.0007309484141852867
Epoch 566
Epoch 566 :: Batch 0/1
Batch Loss = 0.0007309484141852851
566, epoch_train_loss=0.0007309484141852851
Epoch 567
Epoch 567 :: Batch 0/1
Batch Loss = 0.0007309484141852834
567, epoch_train_loss=0.0007309484141852834
Epoch 568
Epoch 568 :: Batch 0/1
Batch Loss = 0.0007309484141852817
568, epoch_train_loss=0.0007309484141852817
Epoch 569
Epoch 569 :: Batch 0/1
Batch Loss = 0.0007309484141852799
569, epoch_train_loss=0.0007309484141852799
Epoch 570
Epoch 570 :: Batch 0/1
Batch Loss = 0.0007309484141852782
570, epoch_train_loss=0.0007309484141852782
Epoch 571
Epoch 571 :: Batch 0/1
Batch Loss = 0.0007309484141852764
571, epoch_train_loss=0.0007309484141852764
Epoch 572
Epoch 572 :: Batch 0/1
Batch Loss = 0.0007309484141852748
572, epoch_train_loss=0.0007309484141852748
Epoch 573
Epoch 573 :: Batch 0/1
Batch Loss = 0.000730948414185273
573, epoch_train_loss=0.000730948414185273
Epoch 574
Epoch 574 :: Batch 0/1
Batch Loss = 0.0007309484141852712
574, epoch_train_loss=0.0007309484141852712
Epoch 575
Epoch 575 :: Batch 0/1
Batch Loss = 0.0007309484141852695
575, epoch_train_loss=0.0007309484141852695
Epoch 576
Epoch 576 :: Batch 0/1
Batch Loss = 0.0007309484141852678
576, epoch_train_loss=0.0007309484141852678
Epoch 577
Epoch 577 :: Batch 0/1
Batch Loss = 0.000730948414185266
577, epoch_train_loss=0.000730948414185266
Epoch 578
Epoch 578 :: Batch 0/1
Batch Loss = 0.0007309484141852644
578, epoch_train_loss=0.0007309484141852644
Epoch 579
Epoch 579 :: Batch 0/1
Batch Loss = 0.0007309484141852625
579, epoch_train_loss=0.0007309484141852625
Epoch 580
Epoch 580 :: Batch 0/1
Batch Loss = 0.0007309484141852607
580, epoch_train_loss=0.0007309484141852607
Epoch 581
Epoch 581 :: Batch 0/1
Batch Loss = 0.000730948414185259
581, epoch_train_loss=0.000730948414185259
Epoch 582
Epoch 582 :: Batch 0/1
Batch Loss = 0.0007309484141852572
582, epoch_train_loss=0.0007309484141852572
Epoch 583
Epoch 583 :: Batch 0/1
Batch Loss = 0.0007309484141852555
583, epoch_train_loss=0.0007309484141852555
Epoch 584
Epoch 584 :: Batch 0/1
Batch Loss = 0.0007309484141852536
584, epoch_train_loss=0.0007309484141852536
Epoch 585
Epoch 585 :: Batch 0/1
Batch Loss = 0.000730948414185252
585, epoch_train_loss=0.000730948414185252
Epoch 586
Epoch 586 :: Batch 0/1
Batch Loss = 0.0007309484141852503
586, epoch_train_loss=0.0007309484141852503
Epoch 587
Epoch 587 :: Batch 0/1
Batch Loss = 0.0007309484141852484
587, epoch_train_loss=0.0007309484141852484
Epoch 588
Epoch 588 :: Batch 0/1
Batch Loss = 0.0007309484141852467
588, epoch_train_loss=0.0007309484141852467
Epoch 589
Epoch 589 :: Batch 0/1
Batch Loss = 0.0007309484141852451
589, epoch_train_loss=0.0007309484141852451
Epoch 590
Epoch 590 :: Batch 0/1
Batch Loss = 0.0007309484141852431
590, epoch_train_loss=0.0007309484141852431
Epoch 591
Epoch 591 :: Batch 0/1
Batch Loss = 0.0007309484141852414
591, epoch_train_loss=0.0007309484141852414
Epoch 592
Epoch 592 :: Batch 0/1
Batch Loss = 0.0007309484141852396
592, epoch_train_loss=0.0007309484141852396
Epoch 593
Epoch 593 :: Batch 0/1
Batch Loss = 0.0007309484141852378
593, epoch_train_loss=0.0007309484141852378
Epoch 594
Epoch 594 :: Batch 0/1
Batch Loss = 0.0007309484141852361
594, epoch_train_loss=0.0007309484141852361
Epoch 595
Epoch 595 :: Batch 0/1
Batch Loss = 0.0007309484141852342
595, epoch_train_loss=0.0007309484141852342
Epoch 596
Epoch 596 :: Batch 0/1
Batch Loss = 0.0007309484141852324
596, epoch_train_loss=0.0007309484141852324
Epoch 597
Epoch 597 :: Batch 0/1
Batch Loss = 0.0007309484141852306
597, epoch_train_loss=0.0007309484141852306
Epoch 598
Epoch 598 :: Batch 0/1
Batch Loss = 0.0007309484141852289
598, epoch_train_loss=0.0007309484141852289
Epoch 599
Epoch 599 :: Batch 0/1
Batch Loss = 0.0007309484141852272
599, epoch_train_loss=0.0007309484141852272
Epoch 600
Epoch 600 :: Batch 0/1
Batch Loss = 0.0007309484141852253
600, epoch_train_loss=0.0007309484141852253
Epoch 601
Epoch 601 :: Batch 0/1
Batch Loss = 0.0007309484141852236
601, epoch_train_loss=0.0007309484141852236
Epoch 602
Epoch 602 :: Batch 0/1
Batch Loss = 0.0007309484141852217
602, epoch_train_loss=0.0007309484141852217
Epoch 603
Epoch 603 :: Batch 0/1
Batch Loss = 0.0007309484141852199
603, epoch_train_loss=0.0007309484141852199
Epoch 604
Epoch 604 :: Batch 0/1
Batch Loss = 0.0007309484141852182
604, epoch_train_loss=0.0007309484141852182
Epoch 605
Epoch 605 :: Batch 0/1
Batch Loss = 0.0007309484141852164
605, epoch_train_loss=0.0007309484141852164
Epoch 606
Epoch 606 :: Batch 0/1
Batch Loss = 0.0007309484141852146
606, epoch_train_loss=0.0007309484141852146
Epoch 607
Epoch 607 :: Batch 0/1
Batch Loss = 0.0007309484141852127
607, epoch_train_loss=0.0007309484141852127
Epoch 608
Epoch 608 :: Batch 0/1
Batch Loss = 0.0007309484141852109
608, epoch_train_loss=0.0007309484141852109
Epoch 609
Epoch 609 :: Batch 0/1
Batch Loss = 0.0007309484141852093
609, epoch_train_loss=0.0007309484141852093
Epoch 610
Epoch 610 :: Batch 0/1
Batch Loss = 0.0007309484141852073
610, epoch_train_loss=0.0007309484141852073
Epoch 611
Epoch 611 :: Batch 0/1
Batch Loss = 0.0007309484141852056
611, epoch_train_loss=0.0007309484141852056
Epoch 612
Epoch 612 :: Batch 0/1
Batch Loss = 0.0007309484141852037
612, epoch_train_loss=0.0007309484141852037
Epoch 613
Epoch 613 :: Batch 0/1
Batch Loss = 0.0007309484141852018
613, epoch_train_loss=0.0007309484141852018
Epoch 614
Epoch 614 :: Batch 0/1
Batch Loss = 0.0007309484141852002
614, epoch_train_loss=0.0007309484141852002
Epoch 615
Epoch 615 :: Batch 0/1
Batch Loss = 0.0007309484141851982
615, epoch_train_loss=0.0007309484141851982
Epoch 616
Epoch 616 :: Batch 0/1
Batch Loss = 0.0007309484141851965
616, epoch_train_loss=0.0007309484141851965
Epoch 617
Epoch 617 :: Batch 0/1
Batch Loss = 0.0007309484141851946
617, epoch_train_loss=0.0007309484141851946
Epoch 618
Epoch 618 :: Batch 0/1
Batch Loss = 0.0007309484141851927
618, epoch_train_loss=0.0007309484141851927
Epoch 619
Epoch 619 :: Batch 0/1
Batch Loss = 0.0007309484141851911
619, epoch_train_loss=0.0007309484141851911
Epoch 620
Epoch 620 :: Batch 0/1
Batch Loss = 0.0007309484141851891
620, epoch_train_loss=0.0007309484141851891
Epoch 621
Epoch 621 :: Batch 0/1
Batch Loss = 0.0007309484141851874
621, epoch_train_loss=0.0007309484141851874
Epoch 622
Epoch 622 :: Batch 0/1
Batch Loss = 0.0007309484141851855
622, epoch_train_loss=0.0007309484141851855
Epoch 623
Epoch 623 :: Batch 0/1
Batch Loss = 0.0007309484141851837
623, epoch_train_loss=0.0007309484141851837
Epoch 624
Epoch 624 :: Batch 0/1
Batch Loss = 0.0007309484141851818
624, epoch_train_loss=0.0007309484141851818
Epoch 625
Epoch 625 :: Batch 0/1
Batch Loss = 0.00073094841418518
625, epoch_train_loss=0.00073094841418518
Epoch 626
Epoch 626 :: Batch 0/1
Batch Loss = 0.0007309484141851783
626, epoch_train_loss=0.0007309484141851783
Epoch 627
Epoch 627 :: Batch 0/1
Batch Loss = 0.0007309484141851764
627, epoch_train_loss=0.0007309484141851764
Epoch 628
Epoch 628 :: Batch 0/1
Batch Loss = 0.0007309484141851745
628, epoch_train_loss=0.0007309484141851745
Epoch 629
Epoch 629 :: Batch 0/1
Batch Loss = 0.0007309484141851726
629, epoch_train_loss=0.0007309484141851726
Epoch 630
Epoch 630 :: Batch 0/1
Batch Loss = 0.0007309484141851709
630, epoch_train_loss=0.0007309484141851709
Epoch 631
Epoch 631 :: Batch 0/1
Batch Loss = 0.0007309484141851689
631, epoch_train_loss=0.0007309484141851689
Epoch 632
Epoch 632 :: Batch 0/1
Batch Loss = 0.0007309484141851671
632, epoch_train_loss=0.0007309484141851671
Epoch 633
Epoch 633 :: Batch 0/1
Batch Loss = 0.0007309484141851653
633, epoch_train_loss=0.0007309484141851653
Epoch 634
Epoch 634 :: Batch 0/1
Batch Loss = 0.0007309484141851635
634, epoch_train_loss=0.0007309484141851635
Epoch 635
Epoch 635 :: Batch 0/1
Batch Loss = 0.0007309484141851616
635, epoch_train_loss=0.0007309484141851616
Epoch 636
Epoch 636 :: Batch 0/1
Batch Loss = 0.0007309484141851596
636, epoch_train_loss=0.0007309484141851596
Epoch 637
Epoch 637 :: Batch 0/1
Batch Loss = 0.0007309484141851579
637, epoch_train_loss=0.0007309484141851579
Epoch 638
Epoch 638 :: Batch 0/1
Batch Loss = 0.0007309484141851559
638, epoch_train_loss=0.0007309484141851559
Epoch 639
Epoch 639 :: Batch 0/1
Batch Loss = 0.0007309484141851541
639, epoch_train_loss=0.0007309484141851541
Epoch 640
Epoch 640 :: Batch 0/1
Batch Loss = 0.0007309484141851522
640, epoch_train_loss=0.0007309484141851522
Epoch 641
Epoch 641 :: Batch 0/1
Batch Loss = 0.0007309484141851504
641, epoch_train_loss=0.0007309484141851504
Epoch 642
Epoch 642 :: Batch 0/1
Batch Loss = 0.0007309484141851485
642, epoch_train_loss=0.0007309484141851485
Epoch 643
Epoch 643 :: Batch 0/1
Batch Loss = 0.0007309484141851466
643, epoch_train_loss=0.0007309484141851466
Epoch 644
Epoch 644 :: Batch 0/1
Batch Loss = 0.0007309484141851448
644, epoch_train_loss=0.0007309484141851448
Epoch 645
Epoch 645 :: Batch 0/1
Batch Loss = 0.0007309484141851428
645, epoch_train_loss=0.0007309484141851428
Epoch 646
Epoch 646 :: Batch 0/1
Batch Loss = 0.0007309484141851411
646, epoch_train_loss=0.0007309484141851411
Epoch 647
Epoch 647 :: Batch 0/1
Batch Loss = 0.000730948414185139
647, epoch_train_loss=0.000730948414185139
Epoch 648
Epoch 648 :: Batch 0/1
Batch Loss = 0.0007309484141851372
648, epoch_train_loss=0.0007309484141851372
Epoch 649
Epoch 649 :: Batch 0/1
Batch Loss = 0.0007309484141851354
649, epoch_train_loss=0.0007309484141851354
Epoch 650
Epoch 650 :: Batch 0/1
Batch Loss = 0.0007309484141851335
650, epoch_train_loss=0.0007309484141851335
Epoch 651
Epoch 651 :: Batch 0/1
Batch Loss = 0.0007309484141851315
651, epoch_train_loss=0.0007309484141851315
Epoch 652
Epoch 652 :: Batch 0/1
Batch Loss = 0.0007309484141851297
652, epoch_train_loss=0.0007309484141851297
Epoch 653
Epoch 653 :: Batch 0/1
Batch Loss = 0.0007309484141851279
653, epoch_train_loss=0.0007309484141851279
Epoch 654
Epoch 654 :: Batch 0/1
Batch Loss = 0.0007309484141851258
654, epoch_train_loss=0.0007309484141851258
Epoch 655
Epoch 655 :: Batch 0/1
Batch Loss = 0.0007309484141851241
655, epoch_train_loss=0.0007309484141851241
Epoch 656
Epoch 656 :: Batch 0/1
Batch Loss = 0.0007309484141851222
656, epoch_train_loss=0.0007309484141851222
Epoch 657
Epoch 657 :: Batch 0/1
Batch Loss = 0.0007309484141851203
657, epoch_train_loss=0.0007309484141851203
Epoch 658
Epoch 658 :: Batch 0/1
Batch Loss = 0.0007309484141851184
658, epoch_train_loss=0.0007309484141851184
Epoch 659
Epoch 659 :: Batch 0/1
Batch Loss = 0.0007309484141851165
659, epoch_train_loss=0.0007309484141851165
Epoch 660
Epoch 660 :: Batch 0/1
Batch Loss = 0.0007309484141851145
660, epoch_train_loss=0.0007309484141851145
Epoch 661
Epoch 661 :: Batch 0/1
Batch Loss = 0.0007309484141851127
661, epoch_train_loss=0.0007309484141851127
Epoch 662
Epoch 662 :: Batch 0/1
Batch Loss = 0.0007309484141851107
662, epoch_train_loss=0.0007309484141851107
Epoch 663
Epoch 663 :: Batch 0/1
Batch Loss = 0.0007309484141851088
663, epoch_train_loss=0.0007309484141851088
Epoch 664
Epoch 664 :: Batch 0/1
Batch Loss = 0.0007309484141851068
664, epoch_train_loss=0.0007309484141851068
Epoch 665
Epoch 665 :: Batch 0/1
Batch Loss = 0.000730948414185105
665, epoch_train_loss=0.000730948414185105
Epoch 666
Epoch 666 :: Batch 0/1
Batch Loss = 0.000730948414185103
666, epoch_train_loss=0.000730948414185103
Epoch 667
Epoch 667 :: Batch 0/1
Batch Loss = 0.0007309484141851011
667, epoch_train_loss=0.0007309484141851011
Epoch 668
Epoch 668 :: Batch 0/1
Batch Loss = 0.0007309484141850992
668, epoch_train_loss=0.0007309484141850992
Epoch 669
Epoch 669 :: Batch 0/1
Batch Loss = 0.0007309484141850973
669, epoch_train_loss=0.0007309484141850973
Epoch 670
Epoch 670 :: Batch 0/1
Batch Loss = 0.0007309484141850953
670, epoch_train_loss=0.0007309484141850953
Epoch 671
Epoch 671 :: Batch 0/1
Batch Loss = 0.0007309484141850935
671, epoch_train_loss=0.0007309484141850935
Epoch 672
Epoch 672 :: Batch 0/1
Batch Loss = 0.0007309484141850915
672, epoch_train_loss=0.0007309484141850915
Epoch 673
Epoch 673 :: Batch 0/1
Batch Loss = 0.0007309484141850896
673, epoch_train_loss=0.0007309484141850896
Epoch 674
Epoch 674 :: Batch 0/1
Batch Loss = 0.0007309484141850877
674, epoch_train_loss=0.0007309484141850877
Epoch 675
Epoch 675 :: Batch 0/1
Batch Loss = 0.0007309484141850858
675, epoch_train_loss=0.0007309484141850858
Epoch 676
Epoch 676 :: Batch 0/1
Batch Loss = 0.0007309484141850838
676, epoch_train_loss=0.0007309484141850838
Epoch 677
Epoch 677 :: Batch 0/1
Batch Loss = 0.0007309484141850818
677, epoch_train_loss=0.0007309484141850818
Epoch 678
Epoch 678 :: Batch 0/1
Batch Loss = 0.00073094841418508
678, epoch_train_loss=0.00073094841418508
Epoch 679
Epoch 679 :: Batch 0/1
Batch Loss = 0.000730948414185078
679, epoch_train_loss=0.000730948414185078
Epoch 680
Epoch 680 :: Batch 0/1
Batch Loss = 0.0007309484141850761
680, epoch_train_loss=0.0007309484141850761
Epoch 681
Epoch 681 :: Batch 0/1
Batch Loss = 0.0007309484141850743
681, epoch_train_loss=0.0007309484141850743
Epoch 682
Epoch 682 :: Batch 0/1
Batch Loss = 0.0007309484141850722
682, epoch_train_loss=0.0007309484141850722
Epoch 683
Epoch 683 :: Batch 0/1
Batch Loss = 0.0007309484141850703
683, epoch_train_loss=0.0007309484141850703
Epoch 684
Epoch 684 :: Batch 0/1
Batch Loss = 0.0007309484141850682
684, epoch_train_loss=0.0007309484141850682
Epoch 685
Epoch 685 :: Batch 0/1
Batch Loss = 0.0007309484141850664
685, epoch_train_loss=0.0007309484141850664
Epoch 686
Epoch 686 :: Batch 0/1
Batch Loss = 0.0007309484141850644
686, epoch_train_loss=0.0007309484141850644
Epoch 687
Epoch 687 :: Batch 0/1
Batch Loss = 0.0007309484141850625
687, epoch_train_loss=0.0007309484141850625
Epoch 688
Epoch 688 :: Batch 0/1
Batch Loss = 0.0007309484141850604
688, epoch_train_loss=0.0007309484141850604
Epoch 689
Epoch 689 :: Batch 0/1
Batch Loss = 0.0007309484141850585
689, epoch_train_loss=0.0007309484141850585
Epoch 690
Epoch 690 :: Batch 0/1
Batch Loss = 0.0007309484141850565
690, epoch_train_loss=0.0007309484141850565
Epoch 691
Epoch 691 :: Batch 0/1
Batch Loss = 0.0007309484141850546
691, epoch_train_loss=0.0007309484141850546
Epoch 692
Epoch 692 :: Batch 0/1
Batch Loss = 0.0007309484141850527
692, epoch_train_loss=0.0007309484141850527
Epoch 693
Epoch 693 :: Batch 0/1
Batch Loss = 0.0007309484141850507
693, epoch_train_loss=0.0007309484141850507
Epoch 694
Epoch 694 :: Batch 0/1
Batch Loss = 0.0007309484141850488
694, epoch_train_loss=0.0007309484141850488
Epoch 695
Epoch 695 :: Batch 0/1
Batch Loss = 0.0007309484141850468
695, epoch_train_loss=0.0007309484141850468
Epoch 696
Epoch 696 :: Batch 0/1
Batch Loss = 0.0007309484141850448
696, epoch_train_loss=0.0007309484141850448
Epoch 697
Epoch 697 :: Batch 0/1
Batch Loss = 0.0007309484141850429
697, epoch_train_loss=0.0007309484141850429
Epoch 698
Epoch 698 :: Batch 0/1
Batch Loss = 0.0007309484141850408
698, epoch_train_loss=0.0007309484141850408
Epoch 699
Epoch 699 :: Batch 0/1
Batch Loss = 0.0007309484141850387
699, epoch_train_loss=0.0007309484141850387
Epoch 700
Epoch 700 :: Batch 0/1
Batch Loss = 0.000730948414185037
700, epoch_train_loss=0.000730948414185037
Epoch 701
Epoch 701 :: Batch 0/1
Batch Loss = 0.0007309484141850349
701, epoch_train_loss=0.0007309484141850349
Epoch 702
Epoch 702 :: Batch 0/1
Batch Loss = 0.000730948414185033
702, epoch_train_loss=0.000730948414185033
Epoch 703
Epoch 703 :: Batch 0/1
Batch Loss = 0.0007309484141850309
703, epoch_train_loss=0.0007309484141850309
Epoch 704
Epoch 704 :: Batch 0/1
Batch Loss = 0.000730948414185029
704, epoch_train_loss=0.000730948414185029
Epoch 705
Epoch 705 :: Batch 0/1
Batch Loss = 0.000730948414185027
705, epoch_train_loss=0.000730948414185027
Epoch 706
Epoch 706 :: Batch 0/1
Batch Loss = 0.0007309484141850249
706, epoch_train_loss=0.0007309484141850249
Epoch 707
Epoch 707 :: Batch 0/1
Batch Loss = 0.0007309484141850229
707, epoch_train_loss=0.0007309484141850229
Epoch 708
Epoch 708 :: Batch 0/1
Batch Loss = 0.0007309484141850211
708, epoch_train_loss=0.0007309484141850211
Epoch 709
Epoch 709 :: Batch 0/1
Batch Loss = 0.000730948414185019
709, epoch_train_loss=0.000730948414185019
Epoch 710
Epoch 710 :: Batch 0/1
Batch Loss = 0.000730948414185017
710, epoch_train_loss=0.000730948414185017
Epoch 711
Epoch 711 :: Batch 0/1
Batch Loss = 0.000730948414185015
711, epoch_train_loss=0.000730948414185015
Epoch 712
Epoch 712 :: Batch 0/1
Batch Loss = 0.0007309484141850131
712, epoch_train_loss=0.0007309484141850131
Epoch 713
Epoch 713 :: Batch 0/1
Batch Loss = 0.000730948414185011
713, epoch_train_loss=0.000730948414185011
Epoch 714
Epoch 714 :: Batch 0/1
Batch Loss = 0.000730948414185009
714, epoch_train_loss=0.000730948414185009
Epoch 715
Epoch 715 :: Batch 0/1
Batch Loss = 0.0007309484141850071
715, epoch_train_loss=0.0007309484141850071
Epoch 716
Epoch 716 :: Batch 0/1
Batch Loss = 0.000730948414185005
716, epoch_train_loss=0.000730948414185005
Epoch 717
Epoch 717 :: Batch 0/1
Batch Loss = 0.0007309484141850031
717, epoch_train_loss=0.0007309484141850031
Epoch 718
Epoch 718 :: Batch 0/1
Batch Loss = 0.000730948414185001
718, epoch_train_loss=0.000730948414185001
Epoch 719
Epoch 719 :: Batch 0/1
Batch Loss = 0.0007309484141849989
719, epoch_train_loss=0.0007309484141849989
Epoch 720
Epoch 720 :: Batch 0/1
Batch Loss = 0.0007309484141849969
720, epoch_train_loss=0.0007309484141849969
Epoch 721
Epoch 721 :: Batch 0/1
Batch Loss = 0.0007309484141849948
721, epoch_train_loss=0.0007309484141849948
Epoch 722
Epoch 722 :: Batch 0/1
Batch Loss = 0.000730948414184993
722, epoch_train_loss=0.000730948414184993
Epoch 723
Epoch 723 :: Batch 0/1
Batch Loss = 0.0007309484141849909
723, epoch_train_loss=0.0007309484141849909
Epoch 724
Epoch 724 :: Batch 0/1
Batch Loss = 0.0007309484141849889
724, epoch_train_loss=0.0007309484141849889
Epoch 725
Epoch 725 :: Batch 0/1
Batch Loss = 0.0007309484141849868
725, epoch_train_loss=0.0007309484141849868
Epoch 726
Epoch 726 :: Batch 0/1
Batch Loss = 0.0007309484141849848
726, epoch_train_loss=0.0007309484141849848
Epoch 727
Epoch 727 :: Batch 0/1
Batch Loss = 0.0007309484141849828
727, epoch_train_loss=0.0007309484141849828
Epoch 728
Epoch 728 :: Batch 0/1
Batch Loss = 0.0007309484141849807
728, epoch_train_loss=0.0007309484141849807
Epoch 729
Epoch 729 :: Batch 0/1
Batch Loss = 0.0007309484141849788
729, epoch_train_loss=0.0007309484141849788
Epoch 730
Epoch 730 :: Batch 0/1
Batch Loss = 0.0007309484141849766
730, epoch_train_loss=0.0007309484141849766
Epoch 731
Epoch 731 :: Batch 0/1
Batch Loss = 0.0007309484141849748
731, epoch_train_loss=0.0007309484141849748
Epoch 732
Epoch 732 :: Batch 0/1
Batch Loss = 0.0007309484141849727
732, epoch_train_loss=0.0007309484141849727
Epoch 733
Epoch 733 :: Batch 0/1
Batch Loss = 0.0007309484141849706
733, epoch_train_loss=0.0007309484141849706
Epoch 734
Epoch 734 :: Batch 0/1
Batch Loss = 0.0007309484141849686
734, epoch_train_loss=0.0007309484141849686
Epoch 735
Epoch 735 :: Batch 0/1
Batch Loss = 0.0007309484141849665
735, epoch_train_loss=0.0007309484141849665
Epoch 736
Epoch 736 :: Batch 0/1
Batch Loss = 0.0007309484141849645
736, epoch_train_loss=0.0007309484141849645
Epoch 737
Epoch 737 :: Batch 0/1
Batch Loss = 0.0007309484141849625
737, epoch_train_loss=0.0007309484141849625
Epoch 738
Epoch 738 :: Batch 0/1
Batch Loss = 0.0007309484141849603
738, epoch_train_loss=0.0007309484141849603
Epoch 739
Epoch 739 :: Batch 0/1
Batch Loss = 0.0007309484141849583
739, epoch_train_loss=0.0007309484141849583
Epoch 740
Epoch 740 :: Batch 0/1
Batch Loss = 0.0007309484141849562
740, epoch_train_loss=0.0007309484141849562
Epoch 741
Epoch 741 :: Batch 0/1
Batch Loss = 0.0007309484141849541
741, epoch_train_loss=0.0007309484141849541
Epoch 742
Epoch 742 :: Batch 0/1
Batch Loss = 0.0007309484141849522
742, epoch_train_loss=0.0007309484141849522
Epoch 743
Epoch 743 :: Batch 0/1
Batch Loss = 0.00073094841418495
743, epoch_train_loss=0.00073094841418495
Epoch 744
Epoch 744 :: Batch 0/1
Batch Loss = 0.000730948414184948
744, epoch_train_loss=0.000730948414184948
Epoch 745
Epoch 745 :: Batch 0/1
Batch Loss = 0.0007309484141849459
745, epoch_train_loss=0.0007309484141849459
Epoch 746
Epoch 746 :: Batch 0/1
Batch Loss = 0.0007309484141849438
746, epoch_train_loss=0.0007309484141849438
Epoch 747
Epoch 747 :: Batch 0/1
Batch Loss = 0.0007309484141849418
747, epoch_train_loss=0.0007309484141849418
Epoch 748
Epoch 748 :: Batch 0/1
Batch Loss = 0.0007309484141849397
748, epoch_train_loss=0.0007309484141849397
Epoch 749
Epoch 749 :: Batch 0/1
Batch Loss = 0.0007309484141849378
749, epoch_train_loss=0.0007309484141849378
Epoch 750
Epoch 750 :: Batch 0/1
Batch Loss = 0.0007309484141849356
750, epoch_train_loss=0.0007309484141849356
Epoch 751
Epoch 751 :: Batch 0/1
Batch Loss = 0.0007309484141849335
751, epoch_train_loss=0.0007309484141849335
Epoch 752
Epoch 752 :: Batch 0/1
Batch Loss = 0.0007309484141849316
752, epoch_train_loss=0.0007309484141849316
Epoch 753
Epoch 753 :: Batch 0/1
Batch Loss = 0.0007309484141849294
753, epoch_train_loss=0.0007309484141849294
Epoch 754
Epoch 754 :: Batch 0/1
Batch Loss = 0.0007309484141849273
754, epoch_train_loss=0.0007309484141849273
Epoch 755
Epoch 755 :: Batch 0/1
Batch Loss = 0.0007309484141849253
755, epoch_train_loss=0.0007309484141849253
Epoch 756
Epoch 756 :: Batch 0/1
Batch Loss = 0.0007309484141849232
756, epoch_train_loss=0.0007309484141849232
Epoch 757
Epoch 757 :: Batch 0/1
Batch Loss = 0.000730948414184921
757, epoch_train_loss=0.000730948414184921
Epoch 758
Epoch 758 :: Batch 0/1
Batch Loss = 0.0007309484141849189
758, epoch_train_loss=0.0007309484141849189
Epoch 759
Epoch 759 :: Batch 0/1
Batch Loss = 0.000730948414184917
759, epoch_train_loss=0.000730948414184917
Epoch 760
Epoch 760 :: Batch 0/1
Batch Loss = 0.0007309484141849148
760, epoch_train_loss=0.0007309484141849148
Epoch 761
Epoch 761 :: Batch 0/1
Batch Loss = 0.0007309484141849126
761, epoch_train_loss=0.0007309484141849126
Epoch 762
Epoch 762 :: Batch 0/1
Batch Loss = 0.0007309484141849106
762, epoch_train_loss=0.0007309484141849106
Epoch 763
Epoch 763 :: Batch 0/1
Batch Loss = 0.0007309484141849085
763, epoch_train_loss=0.0007309484141849085
Epoch 764
Epoch 764 :: Batch 0/1
Batch Loss = 0.0007309484141849064
764, epoch_train_loss=0.0007309484141849064
Epoch 765
Epoch 765 :: Batch 0/1
Batch Loss = 0.0007309484141849043
765, epoch_train_loss=0.0007309484141849043
Epoch 766
Epoch 766 :: Batch 0/1
Batch Loss = 0.0007309484141849023
766, epoch_train_loss=0.0007309484141849023
Epoch 767
Epoch 767 :: Batch 0/1
Batch Loss = 0.0007309484141849001
767, epoch_train_loss=0.0007309484141849001
Epoch 768
Epoch 768 :: Batch 0/1
Batch Loss = 0.000730948414184898
768, epoch_train_loss=0.000730948414184898
Epoch 769
Epoch 769 :: Batch 0/1
Batch Loss = 0.0007309484141848959
769, epoch_train_loss=0.0007309484141848959
Epoch 770
Epoch 770 :: Batch 0/1
Batch Loss = 0.0007309484141848939
770, epoch_train_loss=0.0007309484141848939
Epoch 771
Epoch 771 :: Batch 0/1
Batch Loss = 0.0007309484141848917
771, epoch_train_loss=0.0007309484141848917
Epoch 772
Epoch 772 :: Batch 0/1
Batch Loss = 0.0007309484141848895
772, epoch_train_loss=0.0007309484141848895
Epoch 773
Epoch 773 :: Batch 0/1
Batch Loss = 0.0007309484141848874
773, epoch_train_loss=0.0007309484141848874
Epoch 774
Epoch 774 :: Batch 0/1
Batch Loss = 0.0007309484141848853
774, epoch_train_loss=0.0007309484141848853
Epoch 775
Epoch 775 :: Batch 0/1
Batch Loss = 0.0007309484141848833
775, epoch_train_loss=0.0007309484141848833
Epoch 776
Epoch 776 :: Batch 0/1
Batch Loss = 0.0007309484141848812
776, epoch_train_loss=0.0007309484141848812
Epoch 777
Epoch 777 :: Batch 0/1
Batch Loss = 0.000730948414184879
777, epoch_train_loss=0.000730948414184879
Epoch 778
Epoch 778 :: Batch 0/1
Batch Loss = 0.0007309484141848769
778, epoch_train_loss=0.0007309484141848769
Epoch 779
Epoch 779 :: Batch 0/1
Batch Loss = 0.0007309484141848747
779, epoch_train_loss=0.0007309484141848747
Epoch 780
Epoch 780 :: Batch 0/1
Batch Loss = 0.0007309484141848725
780, epoch_train_loss=0.0007309484141848725
Epoch 781
Epoch 781 :: Batch 0/1
Batch Loss = 0.0007309484141848704
781, epoch_train_loss=0.0007309484141848704
Epoch 782
Epoch 782 :: Batch 0/1
Batch Loss = 0.0007309484141848684
782, epoch_train_loss=0.0007309484141848684
Epoch 783
Epoch 783 :: Batch 0/1
Batch Loss = 0.0007309484141848662
783, epoch_train_loss=0.0007309484141848662
Epoch 784
Epoch 784 :: Batch 0/1
Batch Loss = 0.0007309484141848641
784, epoch_train_loss=0.0007309484141848641
Epoch 785
Epoch 785 :: Batch 0/1
Batch Loss = 0.000730948414184862
785, epoch_train_loss=0.000730948414184862
Epoch 786
Epoch 786 :: Batch 0/1
Batch Loss = 0.0007309484141848598
786, epoch_train_loss=0.0007309484141848598
Epoch 787
Epoch 787 :: Batch 0/1
Batch Loss = 0.0007309484141848577
787, epoch_train_loss=0.0007309484141848577
Epoch 788
Epoch 788 :: Batch 0/1
Batch Loss = 0.0007309484141848555
788, epoch_train_loss=0.0007309484141848555
Epoch 789
Epoch 789 :: Batch 0/1
Batch Loss = 0.0007309484141848533
789, epoch_train_loss=0.0007309484141848533
Epoch 790
Epoch 790 :: Batch 0/1
Batch Loss = 0.0007309484141848512
790, epoch_train_loss=0.0007309484141848512
Epoch 791
Epoch 791 :: Batch 0/1
Batch Loss = 0.0007309484141848491
791, epoch_train_loss=0.0007309484141848491
Epoch 792
Epoch 792 :: Batch 0/1
Batch Loss = 0.0007309484141848469
792, epoch_train_loss=0.0007309484141848469
Epoch 793
Epoch 793 :: Batch 0/1
Batch Loss = 0.0007309484141848448
793, epoch_train_loss=0.0007309484141848448
Epoch 794
Epoch 794 :: Batch 0/1
Batch Loss = 0.0007309484141848426
794, epoch_train_loss=0.0007309484141848426
Epoch 795
Epoch 795 :: Batch 0/1
Batch Loss = 0.0007309484141848404
795, epoch_train_loss=0.0007309484141848404
Epoch 796
Epoch 796 :: Batch 0/1
Batch Loss = 0.0007309484141848383
796, epoch_train_loss=0.0007309484141848383
Epoch 797
Epoch 797 :: Batch 0/1
Batch Loss = 0.0007309484141848362
797, epoch_train_loss=0.0007309484141848362
Epoch 798
Epoch 798 :: Batch 0/1
Batch Loss = 0.0007309484141848339
798, epoch_train_loss=0.0007309484141848339
Epoch 799
Epoch 799 :: Batch 0/1
Batch Loss = 0.0007309484141848318
799, epoch_train_loss=0.0007309484141848318
Epoch 800
Epoch 800 :: Batch 0/1
Batch Loss = 0.0007309484141848296
800, epoch_train_loss=0.0007309484141848296
Epoch 801
Epoch 801 :: Batch 0/1
Batch Loss = 0.0007309484141848274
801, epoch_train_loss=0.0007309484141848274
Epoch 802
Epoch 802 :: Batch 0/1
Batch Loss = 0.0007309484141848254
802, epoch_train_loss=0.0007309484141848254
Epoch 803
Epoch 803 :: Batch 0/1
Batch Loss = 0.0007309484141848232
803, epoch_train_loss=0.0007309484141848232
Epoch 804
Epoch 804 :: Batch 0/1
Batch Loss = 0.000730948414184821
804, epoch_train_loss=0.000730948414184821
Epoch 805
Epoch 805 :: Batch 0/1
Batch Loss = 0.0007309484141848189
805, epoch_train_loss=0.0007309484141848189
Epoch 806
Epoch 806 :: Batch 0/1
Batch Loss = 0.0007309484141848166
806, epoch_train_loss=0.0007309484141848166
Epoch 807
Epoch 807 :: Batch 0/1
Batch Loss = 0.0007309484141848144
807, epoch_train_loss=0.0007309484141848144
Epoch 808
Epoch 808 :: Batch 0/1
Batch Loss = 0.0007309484141848122
808, epoch_train_loss=0.0007309484141848122
Epoch 809
Epoch 809 :: Batch 0/1
Batch Loss = 0.0007309484141848102
809, epoch_train_loss=0.0007309484141848102
Epoch 810
Epoch 810 :: Batch 0/1
Batch Loss = 0.0007309484141848078
810, epoch_train_loss=0.0007309484141848078
Epoch 811
Epoch 811 :: Batch 0/1
Batch Loss = 0.0007309484141848057
811, epoch_train_loss=0.0007309484141848057
Epoch 812
Epoch 812 :: Batch 0/1
Batch Loss = 0.0007309484141848035
812, epoch_train_loss=0.0007309484141848035
Epoch 813
Epoch 813 :: Batch 0/1
Batch Loss = 0.0007309484141848013
813, epoch_train_loss=0.0007309484141848013
Epoch 814
Epoch 814 :: Batch 0/1
Batch Loss = 0.0007309484141847991
814, epoch_train_loss=0.0007309484141847991
Epoch 815
Epoch 815 :: Batch 0/1
Batch Loss = 0.0007309484141847971
815, epoch_train_loss=0.0007309484141847971
Epoch 816
Epoch 816 :: Batch 0/1
Batch Loss = 0.0007309484141847948
816, epoch_train_loss=0.0007309484141847948
Epoch 817
Epoch 817 :: Batch 0/1
Batch Loss = 0.0007309484141847926
817, epoch_train_loss=0.0007309484141847926
Epoch 818
Epoch 818 :: Batch 0/1
Batch Loss = 0.0007309484141847905
818, epoch_train_loss=0.0007309484141847905
Epoch 819
Epoch 819 :: Batch 0/1
Batch Loss = 0.0007309484141847882
819, epoch_train_loss=0.0007309484141847882
Epoch 820
Epoch 820 :: Batch 0/1
Batch Loss = 0.000730948414184786
820, epoch_train_loss=0.000730948414184786
Epoch 821
Epoch 821 :: Batch 0/1
Batch Loss = 0.0007309484141847837
821, epoch_train_loss=0.0007309484141847837
Epoch 822
Epoch 822 :: Batch 0/1
Batch Loss = 0.0007309484141847816
822, epoch_train_loss=0.0007309484141847816
Epoch 823
Epoch 823 :: Batch 0/1
Batch Loss = 0.0007309484141847793
823, epoch_train_loss=0.0007309484141847793
Epoch 824
Epoch 824 :: Batch 0/1
Batch Loss = 0.0007309484141847771
824, epoch_train_loss=0.0007309484141847771
Epoch 825
Epoch 825 :: Batch 0/1
Batch Loss = 0.000730948414184775
825, epoch_train_loss=0.000730948414184775
Epoch 826
Epoch 826 :: Batch 0/1
Batch Loss = 0.0007309484141847727
826, epoch_train_loss=0.0007309484141847727
Epoch 827
Epoch 827 :: Batch 0/1
Batch Loss = 0.0007309484141847704
827, epoch_train_loss=0.0007309484141847704
Epoch 828
Epoch 828 :: Batch 0/1
Batch Loss = 0.0007309484141847682
828, epoch_train_loss=0.0007309484141847682
Epoch 829
Epoch 829 :: Batch 0/1
Batch Loss = 0.0007309484141847661
829, epoch_train_loss=0.0007309484141847661
Epoch 830
Epoch 830 :: Batch 0/1
Batch Loss = 0.0007309484141847638
830, epoch_train_loss=0.0007309484141847638
Epoch 831
Epoch 831 :: Batch 0/1
Batch Loss = 0.0007309484141847616
831, epoch_train_loss=0.0007309484141847616
Epoch 832
Epoch 832 :: Batch 0/1
Batch Loss = 0.0007309484141847593
832, epoch_train_loss=0.0007309484141847593
Epoch 833
Epoch 833 :: Batch 0/1
Batch Loss = 0.0007309484141847572
833, epoch_train_loss=0.0007309484141847572
Epoch 834
Epoch 834 :: Batch 0/1
Batch Loss = 0.0007309484141847549
834, epoch_train_loss=0.0007309484141847549
Epoch 835
Epoch 835 :: Batch 0/1
Batch Loss = 0.0007309484141847526
835, epoch_train_loss=0.0007309484141847526
Epoch 836
Epoch 836 :: Batch 0/1
Batch Loss = 0.0007309484141847504
836, epoch_train_loss=0.0007309484141847504
Epoch 837
Epoch 837 :: Batch 0/1
Batch Loss = 0.0007309484141847484
837, epoch_train_loss=0.0007309484141847484
Epoch 838
Epoch 838 :: Batch 0/1
Batch Loss = 0.0007309484141847459
838, epoch_train_loss=0.0007309484141847459
Epoch 839
Epoch 839 :: Batch 0/1
Batch Loss = 0.0007309484141847438
839, epoch_train_loss=0.0007309484141847438
Epoch 840
Epoch 840 :: Batch 0/1
Batch Loss = 0.0007309484141847414
840, epoch_train_loss=0.0007309484141847414
Epoch 841
Epoch 841 :: Batch 0/1
Batch Loss = 0.0007309484141847392
841, epoch_train_loss=0.0007309484141847392
Epoch 842
Epoch 842 :: Batch 0/1
Batch Loss = 0.0007309484141847369
842, epoch_train_loss=0.0007309484141847369
Epoch 843
Epoch 843 :: Batch 0/1
Batch Loss = 0.0007309484141847346
843, epoch_train_loss=0.0007309484141847346
Epoch 844
Epoch 844 :: Batch 0/1
Batch Loss = 0.0007309484141847326
844, epoch_train_loss=0.0007309484141847326
Epoch 845
Epoch 845 :: Batch 0/1
Batch Loss = 0.0007309484141847304
845, epoch_train_loss=0.0007309484141847304
Epoch 846
Epoch 846 :: Batch 0/1
Batch Loss = 0.000730948414184728
846, epoch_train_loss=0.000730948414184728
Epoch 847
Epoch 847 :: Batch 0/1
Batch Loss = 0.0007309484141847258
847, epoch_train_loss=0.0007309484141847258
Epoch 848
Epoch 848 :: Batch 0/1
Batch Loss = 0.0007309484141847237
848, epoch_train_loss=0.0007309484141847237
Epoch 849
Epoch 849 :: Batch 0/1
Batch Loss = 0.0007309484141847213
849, epoch_train_loss=0.0007309484141847213
Epoch 850
Epoch 850 :: Batch 0/1
Batch Loss = 0.0007309484141847191
850, epoch_train_loss=0.0007309484141847191
Epoch 851
Epoch 851 :: Batch 0/1
Batch Loss = 0.0007309484141847167
851, epoch_train_loss=0.0007309484141847167
Epoch 852
Epoch 852 :: Batch 0/1
Batch Loss = 0.0007309484141847144
852, epoch_train_loss=0.0007309484141847144
Epoch 853
Epoch 853 :: Batch 0/1
Batch Loss = 0.0007309484141847122
853, epoch_train_loss=0.0007309484141847122
Epoch 854
Epoch 854 :: Batch 0/1
Batch Loss = 0.00073094841418471
854, epoch_train_loss=0.00073094841418471
Epoch 855
Epoch 855 :: Batch 0/1
Batch Loss = 0.0007309484141847078
855, epoch_train_loss=0.0007309484141847078
Epoch 856
Epoch 856 :: Batch 0/1
Batch Loss = 0.0007309484141847054
856, epoch_train_loss=0.0007309484141847054
Epoch 857
Epoch 857 :: Batch 0/1
Batch Loss = 0.0007309484141847033
857, epoch_train_loss=0.0007309484141847033
Epoch 858
Epoch 858 :: Batch 0/1
Batch Loss = 0.0007309484141847009
858, epoch_train_loss=0.0007309484141847009
Epoch 859
Epoch 859 :: Batch 0/1
Batch Loss = 0.0007309484141846987
859, epoch_train_loss=0.0007309484141846987
Epoch 860
Epoch 860 :: Batch 0/1
Batch Loss = 0.0007309484141846963
860, epoch_train_loss=0.0007309484141846963
Epoch 861
Epoch 861 :: Batch 0/1
Batch Loss = 0.0007309484141846942
861, epoch_train_loss=0.0007309484141846942
Epoch 862
Epoch 862 :: Batch 0/1
Batch Loss = 0.0007309484141846917
862, epoch_train_loss=0.0007309484141846917
Epoch 863
Epoch 863 :: Batch 0/1
Batch Loss = 0.0007309484141846896
863, epoch_train_loss=0.0007309484141846896
Epoch 864
Epoch 864 :: Batch 0/1
Batch Loss = 0.0007309484141846871
864, epoch_train_loss=0.0007309484141846871
Epoch 865
Epoch 865 :: Batch 0/1
Batch Loss = 0.0007309484141846848
865, epoch_train_loss=0.0007309484141846848
Epoch 866
Epoch 866 :: Batch 0/1
Batch Loss = 0.0007309484141846826
866, epoch_train_loss=0.0007309484141846826
Epoch 867
Epoch 867 :: Batch 0/1
Batch Loss = 0.0007309484141846802
867, epoch_train_loss=0.0007309484141846802
Epoch 868
Epoch 868 :: Batch 0/1
Batch Loss = 0.000730948414184678
868, epoch_train_loss=0.000730948414184678
Epoch 869
Epoch 869 :: Batch 0/1
Batch Loss = 0.0007309484141846757
869, epoch_train_loss=0.0007309484141846757
Epoch 870
Epoch 870 :: Batch 0/1
Batch Loss = 0.0007309484141846734
870, epoch_train_loss=0.0007309484141846734
Epoch 871
Epoch 871 :: Batch 0/1
Batch Loss = 0.0007309484141846711
871, epoch_train_loss=0.0007309484141846711
Epoch 872
Epoch 872 :: Batch 0/1
Batch Loss = 0.0007309484141846688
872, epoch_train_loss=0.0007309484141846688
Epoch 873
Epoch 873 :: Batch 0/1
Batch Loss = 0.0007309484141846665
873, epoch_train_loss=0.0007309484141846665
Epoch 874
Epoch 874 :: Batch 0/1
Batch Loss = 0.0007309484141846642
874, epoch_train_loss=0.0007309484141846642
Epoch 875
Epoch 875 :: Batch 0/1
Batch Loss = 0.000730948414184662
875, epoch_train_loss=0.000730948414184662
Epoch 876
Epoch 876 :: Batch 0/1
Batch Loss = 0.0007309484141846596
876, epoch_train_loss=0.0007309484141846596
Epoch 877
Epoch 877 :: Batch 0/1
Batch Loss = 0.0007309484141846574
877, epoch_train_loss=0.0007309484141846574
Epoch 878
Epoch 878 :: Batch 0/1
Batch Loss = 0.000730948414184655
878, epoch_train_loss=0.000730948414184655
Epoch 879
Epoch 879 :: Batch 0/1
Batch Loss = 0.0007309484141846526
879, epoch_train_loss=0.0007309484141846526
Epoch 880
Epoch 880 :: Batch 0/1
Batch Loss = 0.0007309484141846504
880, epoch_train_loss=0.0007309484141846504
Epoch 881
Epoch 881 :: Batch 0/1
Batch Loss = 0.0007309484141846481
881, epoch_train_loss=0.0007309484141846481
Epoch 882
Epoch 882 :: Batch 0/1
Batch Loss = 0.0007309484141846457
882, epoch_train_loss=0.0007309484141846457
Epoch 883
Epoch 883 :: Batch 0/1
Batch Loss = 0.0007309484141846434
883, epoch_train_loss=0.0007309484141846434
Epoch 884
Epoch 884 :: Batch 0/1
Batch Loss = 0.0007309484141846412
884, epoch_train_loss=0.0007309484141846412
Epoch 885
Epoch 885 :: Batch 0/1
Batch Loss = 0.0007309484141846388
885, epoch_train_loss=0.0007309484141846388
Epoch 886
Epoch 886 :: Batch 0/1
Batch Loss = 0.0007309484141846365
886, epoch_train_loss=0.0007309484141846365
Epoch 887
Epoch 887 :: Batch 0/1
Batch Loss = 0.0007309484141846342
887, epoch_train_loss=0.0007309484141846342
Epoch 888
Epoch 888 :: Batch 0/1
Batch Loss = 0.0007309484141846317
888, epoch_train_loss=0.0007309484141846317
Epoch 889
Epoch 889 :: Batch 0/1
Batch Loss = 0.0007309484141846293
889, epoch_train_loss=0.0007309484141846293
Epoch 890
Epoch 890 :: Batch 0/1
Batch Loss = 0.0007309484141846271
890, epoch_train_loss=0.0007309484141846271
Epoch 891
Epoch 891 :: Batch 0/1
Batch Loss = 0.0007309484141846248
891, epoch_train_loss=0.0007309484141846248
Epoch 892
Epoch 892 :: Batch 0/1
Batch Loss = 0.0007309484141846224
892, epoch_train_loss=0.0007309484141846224
Epoch 893
Epoch 893 :: Batch 0/1
Batch Loss = 0.0007309484141846201
893, epoch_train_loss=0.0007309484141846201
Epoch 894
Epoch 894 :: Batch 0/1
Batch Loss = 0.0007309484141846177
894, epoch_train_loss=0.0007309484141846177
Epoch 895
Epoch 895 :: Batch 0/1
Batch Loss = 0.0007309484141846155
895, epoch_train_loss=0.0007309484141846155
Epoch 896
Epoch 896 :: Batch 0/1
Batch Loss = 0.0007309484141846131
896, epoch_train_loss=0.0007309484141846131
Epoch 897
Epoch 897 :: Batch 0/1
Batch Loss = 0.0007309484141846107
897, epoch_train_loss=0.0007309484141846107
Epoch 898
Epoch 898 :: Batch 0/1
Batch Loss = 0.0007309484141846084
898, epoch_train_loss=0.0007309484141846084
Epoch 899
Epoch 899 :: Batch 0/1
Batch Loss = 0.0007309484141846061
899, epoch_train_loss=0.0007309484141846061
Epoch 900
Epoch 900 :: Batch 0/1
Batch Loss = 0.0007309484141846038
900, epoch_train_loss=0.0007309484141846038
Epoch 901
Epoch 901 :: Batch 0/1
Batch Loss = 0.0007309484141846014
901, epoch_train_loss=0.0007309484141846014
Epoch 902
Epoch 902 :: Batch 0/1
Batch Loss = 0.0007309484141845989
902, epoch_train_loss=0.0007309484141845989
Epoch 903
Epoch 903 :: Batch 0/1
Batch Loss = 0.0007309484141845965
903, epoch_train_loss=0.0007309484141845965
Epoch 904
Epoch 904 :: Batch 0/1
Batch Loss = 0.0007309484141845942
904, epoch_train_loss=0.0007309484141845942
Epoch 905
Epoch 905 :: Batch 0/1
Batch Loss = 0.0007309484141845919
905, epoch_train_loss=0.0007309484141845919
Epoch 906
Epoch 906 :: Batch 0/1
Batch Loss = 0.0007309484141845895
906, epoch_train_loss=0.0007309484141845895
Epoch 907
Epoch 907 :: Batch 0/1
Batch Loss = 0.0007309484141845872
907, epoch_train_loss=0.0007309484141845872
Epoch 908
Epoch 908 :: Batch 0/1
Batch Loss = 0.0007309484141845848
908, epoch_train_loss=0.0007309484141845848
Epoch 909
Epoch 909 :: Batch 0/1
Batch Loss = 0.0007309484141845824
909, epoch_train_loss=0.0007309484141845824
Epoch 910
Epoch 910 :: Batch 0/1
Batch Loss = 0.00073094841418458
910, epoch_train_loss=0.00073094841418458
Epoch 911
Epoch 911 :: Batch 0/1
Batch Loss = 0.0007309484141845777
911, epoch_train_loss=0.0007309484141845777
Epoch 912
Epoch 912 :: Batch 0/1
Batch Loss = 0.0007309484141845753
912, epoch_train_loss=0.0007309484141845753
Epoch 913
Epoch 913 :: Batch 0/1
Batch Loss = 0.0007309484141845729
913, epoch_train_loss=0.0007309484141845729
Epoch 914
Epoch 914 :: Batch 0/1
Batch Loss = 0.0007309484141845705
914, epoch_train_loss=0.0007309484141845705
Epoch 915
Epoch 915 :: Batch 0/1
Batch Loss = 0.0007309484141845681
915, epoch_train_loss=0.0007309484141845681
Epoch 916
Epoch 916 :: Batch 0/1
Batch Loss = 0.0007309484141845658
916, epoch_train_loss=0.0007309484141845658
Epoch 917
Epoch 917 :: Batch 0/1
Batch Loss = 0.0007309484141845634
917, epoch_train_loss=0.0007309484141845634
Epoch 918
Epoch 918 :: Batch 0/1
Batch Loss = 0.000730948414184561
918, epoch_train_loss=0.000730948414184561
Epoch 919
Epoch 919 :: Batch 0/1
Batch Loss = 0.0007309484141845586
919, epoch_train_loss=0.0007309484141845586
Epoch 920
Epoch 920 :: Batch 0/1
Batch Loss = 0.0007309484141845563
920, epoch_train_loss=0.0007309484141845563
Epoch 921
Epoch 921 :: Batch 0/1
Batch Loss = 0.0007309484141845539
921, epoch_train_loss=0.0007309484141845539
Epoch 922
Epoch 922 :: Batch 0/1
Batch Loss = 0.0007309484141845514
922, epoch_train_loss=0.0007309484141845514
Epoch 923
Epoch 923 :: Batch 0/1
Batch Loss = 0.000730948414184549
923, epoch_train_loss=0.000730948414184549
Epoch 924
Epoch 924 :: Batch 0/1
Batch Loss = 0.0007309484141845466
924, epoch_train_loss=0.0007309484141845466
Epoch 925
Epoch 925 :: Batch 0/1
Batch Loss = 0.0007309484141845442
925, epoch_train_loss=0.0007309484141845442
Epoch 926
Epoch 926 :: Batch 0/1
Batch Loss = 0.0007309484141845418
926, epoch_train_loss=0.0007309484141845418
Epoch 927
Epoch 927 :: Batch 0/1
Batch Loss = 0.0007309484141845395
927, epoch_train_loss=0.0007309484141845395
Epoch 928
Epoch 928 :: Batch 0/1
Batch Loss = 0.0007309484141845371
928, epoch_train_loss=0.0007309484141845371
Epoch 929
Epoch 929 :: Batch 0/1
Batch Loss = 0.0007309484141845347
929, epoch_train_loss=0.0007309484141845347
Epoch 930
Epoch 930 :: Batch 0/1
Batch Loss = 0.0007309484141845323
930, epoch_train_loss=0.0007309484141845323
Epoch 931
Epoch 931 :: Batch 0/1
Batch Loss = 0.0007309484141845298
931, epoch_train_loss=0.0007309484141845298
Epoch 932
Epoch 932 :: Batch 0/1
Batch Loss = 0.0007309484141845273
932, epoch_train_loss=0.0007309484141845273
Epoch 933
Epoch 933 :: Batch 0/1
Batch Loss = 0.000730948414184525
933, epoch_train_loss=0.000730948414184525
Epoch 934
Epoch 934 :: Batch 0/1
Batch Loss = 0.0007309484141845225
934, epoch_train_loss=0.0007309484141845225
Epoch 935
Epoch 935 :: Batch 0/1
Batch Loss = 0.0007309484141845203
935, epoch_train_loss=0.0007309484141845203
Epoch 936
Epoch 936 :: Batch 0/1
Batch Loss = 0.0007309484141845178
936, epoch_train_loss=0.0007309484141845178
Epoch 937
Epoch 937 :: Batch 0/1
Batch Loss = 0.0007309484141845154
937, epoch_train_loss=0.0007309484141845154
Epoch 938
Epoch 938 :: Batch 0/1
Batch Loss = 0.0007309484141845128
938, epoch_train_loss=0.0007309484141845128
Epoch 939
Epoch 939 :: Batch 0/1
Batch Loss = 0.0007309484141845104
939, epoch_train_loss=0.0007309484141845104
Epoch 940
Epoch 940 :: Batch 0/1
Batch Loss = 0.000730948414184508
940, epoch_train_loss=0.000730948414184508
Epoch 941
Epoch 941 :: Batch 0/1
Batch Loss = 0.0007309484141845056
941, epoch_train_loss=0.0007309484141845056
Epoch 942
Epoch 942 :: Batch 0/1
Batch Loss = 0.0007309484141845032
942, epoch_train_loss=0.0007309484141845032
Epoch 943
Epoch 943 :: Batch 0/1
Batch Loss = 0.0007309484141845009
943, epoch_train_loss=0.0007309484141845009
Epoch 944
Epoch 944 :: Batch 0/1
Batch Loss = 0.0007309484141844981
944, epoch_train_loss=0.0007309484141844981
Epoch 945
Epoch 945 :: Batch 0/1
Batch Loss = 0.0007309484141844958
945, epoch_train_loss=0.0007309484141844958
Epoch 946
Epoch 946 :: Batch 0/1
Batch Loss = 0.0007309484141844934
946, epoch_train_loss=0.0007309484141844934
Epoch 947
Epoch 947 :: Batch 0/1
Batch Loss = 0.000730948414184491
947, epoch_train_loss=0.000730948414184491
Epoch 948
Epoch 948 :: Batch 0/1
Batch Loss = 0.0007309484141844886
948, epoch_train_loss=0.0007309484141844886
Epoch 949
Epoch 949 :: Batch 0/1
Batch Loss = 0.0007309484141844861
949, epoch_train_loss=0.0007309484141844861
Epoch 950
Epoch 950 :: Batch 0/1
Batch Loss = 0.0007309484141844835
950, epoch_train_loss=0.0007309484141844835
Epoch 951
Epoch 951 :: Batch 0/1
Batch Loss = 0.0007309484141844811
951, epoch_train_loss=0.0007309484141844811
Epoch 952
Epoch 952 :: Batch 0/1
Batch Loss = 0.0007309484141844787
952, epoch_train_loss=0.0007309484141844787
Epoch 953
Epoch 953 :: Batch 0/1
Batch Loss = 0.0007309484141844764
953, epoch_train_loss=0.0007309484141844764
Epoch 954
Epoch 954 :: Batch 0/1
Batch Loss = 0.0007309484141844738
954, epoch_train_loss=0.0007309484141844738
Epoch 955
Epoch 955 :: Batch 0/1
Batch Loss = 0.0007309484141844714
955, epoch_train_loss=0.0007309484141844714
Epoch 956
Epoch 956 :: Batch 0/1
Batch Loss = 0.000730948414184469
956, epoch_train_loss=0.000730948414184469
Epoch 957
Epoch 957 :: Batch 0/1
Batch Loss = 0.0007309484141844665
957, epoch_train_loss=0.0007309484141844665
Epoch 958
Epoch 958 :: Batch 0/1
Batch Loss = 0.0007309484141844639
958, epoch_train_loss=0.0007309484141844639
Epoch 959
Epoch 959 :: Batch 0/1
Batch Loss = 0.0007309484141844615
959, epoch_train_loss=0.0007309484141844615
Epoch 960
Epoch 960 :: Batch 0/1
Batch Loss = 0.0007309484141844591
960, epoch_train_loss=0.0007309484141844591
Epoch 961
Epoch 961 :: Batch 0/1
Batch Loss = 0.0007309484141844567
961, epoch_train_loss=0.0007309484141844567
Epoch 962
Epoch 962 :: Batch 0/1
Batch Loss = 0.0007309484141844542
962, epoch_train_loss=0.0007309484141844542
Epoch 963
Epoch 963 :: Batch 0/1
Batch Loss = 0.0007309484141844516
963, epoch_train_loss=0.0007309484141844516
Epoch 964
Epoch 964 :: Batch 0/1
Batch Loss = 0.0007309484141844491
964, epoch_train_loss=0.0007309484141844491
Epoch 965
Epoch 965 :: Batch 0/1
Batch Loss = 0.0007309484141844467
965, epoch_train_loss=0.0007309484141844467
Epoch 966
Epoch 966 :: Batch 0/1
Batch Loss = 0.0007309484141844443
966, epoch_train_loss=0.0007309484141844443
Epoch 967
Epoch 967 :: Batch 0/1
Batch Loss = 0.0007309484141844419
967, epoch_train_loss=0.0007309484141844419
Epoch 968
Epoch 968 :: Batch 0/1
Batch Loss = 0.0007309484141844393
968, epoch_train_loss=0.0007309484141844393
Epoch 969
Epoch 969 :: Batch 0/1
Batch Loss = 0.0007309484141844368
969, epoch_train_loss=0.0007309484141844368
Epoch 970
Epoch 970 :: Batch 0/1
Batch Loss = 0.0007309484141844344
970, epoch_train_loss=0.0007309484141844344
Epoch 971
Epoch 971 :: Batch 0/1
Batch Loss = 0.0007309484141844319
971, epoch_train_loss=0.0007309484141844319
Epoch 972
Epoch 972 :: Batch 0/1
Batch Loss = 0.0007309484141844294
972, epoch_train_loss=0.0007309484141844294
Epoch 973
Epoch 973 :: Batch 0/1
Batch Loss = 0.0007309484141844268
973, epoch_train_loss=0.0007309484141844268
Epoch 974
Epoch 974 :: Batch 0/1
Batch Loss = 0.0007309484141844243
974, epoch_train_loss=0.0007309484141844243
Epoch 975
Epoch 975 :: Batch 0/1
Batch Loss = 0.0007309484141844219
975, epoch_train_loss=0.0007309484141844219
Epoch 976
Epoch 976 :: Batch 0/1
Batch Loss = 0.0007309484141844195
976, epoch_train_loss=0.0007309484141844195
Epoch 977
Epoch 977 :: Batch 0/1
Batch Loss = 0.0007309484141844169
977, epoch_train_loss=0.0007309484141844169
Epoch 978
Epoch 978 :: Batch 0/1
Batch Loss = 0.0007309484141844142
978, epoch_train_loss=0.0007309484141844142
Epoch 979
Epoch 979 :: Batch 0/1
Batch Loss = 0.0007309484141844118
979, epoch_train_loss=0.0007309484141844118
Epoch 980
Epoch 980 :: Batch 0/1
Batch Loss = 0.0007309484141844095
980, epoch_train_loss=0.0007309484141844095
Epoch 981
Epoch 981 :: Batch 0/1
Batch Loss = 0.0007309484141844069
981, epoch_train_loss=0.0007309484141844069
Epoch 982
Epoch 982 :: Batch 0/1
Batch Loss = 0.0007309484141844043
982, epoch_train_loss=0.0007309484141844043
Epoch 983
Epoch 983 :: Batch 0/1
Batch Loss = 0.0007309484141844018
983, epoch_train_loss=0.0007309484141844018
Epoch 984
Epoch 984 :: Batch 0/1
Batch Loss = 0.0007309484141843993
984, epoch_train_loss=0.0007309484141843993
Epoch 985
Epoch 985 :: Batch 0/1
Batch Loss = 0.0007309484141843968
985, epoch_train_loss=0.0007309484141843968
Epoch 986
Epoch 986 :: Batch 0/1
Batch Loss = 0.0007309484141843944
986, epoch_train_loss=0.0007309484141843944
Epoch 987
Epoch 987 :: Batch 0/1
Batch Loss = 0.0007309484141843917
987, epoch_train_loss=0.0007309484141843917
Epoch 988
Epoch 988 :: Batch 0/1
Batch Loss = 0.0007309484141843893
988, epoch_train_loss=0.0007309484141843893
Epoch 989
Epoch 989 :: Batch 0/1
Batch Loss = 0.0007309484141843867
989, epoch_train_loss=0.0007309484141843867
Epoch 990
Epoch 990 :: Batch 0/1
Batch Loss = 0.0007309484141843843
990, epoch_train_loss=0.0007309484141843843
Epoch 991
Epoch 991 :: Batch 0/1
Batch Loss = 0.0007309484141843816
991, epoch_train_loss=0.0007309484141843816
Epoch 992
Epoch 992 :: Batch 0/1
Batch Loss = 0.0007309484141843792
992, epoch_train_loss=0.0007309484141843792
Epoch 993
Epoch 993 :: Batch 0/1
Batch Loss = 0.0007309484141843767
993, epoch_train_loss=0.0007309484141843767
Epoch 994
Epoch 994 :: Batch 0/1
Batch Loss = 0.0007309484141843742
994, epoch_train_loss=0.0007309484141843742
Epoch 995
Epoch 995 :: Batch 0/1
Batch Loss = 0.0007309484141843715
995, epoch_train_loss=0.0007309484141843715
Epoch 996
Epoch 996 :: Batch 0/1
Batch Loss = 0.0007309484141843689
996, epoch_train_loss=0.0007309484141843689
Epoch 997
Epoch 997 :: Batch 0/1
Batch Loss = 0.0007309484141843665
997, epoch_train_loss=0.0007309484141843665
Epoch 998
Epoch 998 :: Batch 0/1
Batch Loss = 0.0007309484141843639
998, epoch_train_loss=0.0007309484141843639
Epoch 999
Epoch 999 :: Batch 0/1
Batch Loss = 0.0007309484141843615
999, epoch_train_loss=0.0007309484141843615
Epoch 1000
Epoch 1000 :: Batch 0/1
Batch Loss = 0.0007309484141843588
1000, epoch_train_loss=0.0007309484141843588
Epoch 1001
Epoch 1001 :: Batch 0/1
Batch Loss = 0.0007309484141843563
1001, epoch_train_loss=0.0007309484141843563
Epoch 1002
Epoch 1002 :: Batch 0/1
Batch Loss = 0.0007309484141843538
1002, epoch_train_loss=0.0007309484141843538
Epoch 1003
Epoch 1003 :: Batch 0/1
Batch Loss = 0.0007309484141843511
1003, epoch_train_loss=0.0007309484141843511
Epoch 1004
Epoch 1004 :: Batch 0/1
Batch Loss = 0.0007309484141843486
1004, epoch_train_loss=0.0007309484141843486
Epoch 1005
Epoch 1005 :: Batch 0/1
Batch Loss = 0.0007309484141843461
1005, epoch_train_loss=0.0007309484141843461
Epoch 1006
Epoch 1006 :: Batch 0/1
Batch Loss = 0.0007309484141843437
1006, epoch_train_loss=0.0007309484141843437
Epoch 1007
Epoch 1007 :: Batch 0/1
Batch Loss = 0.0007309484141843412
1007, epoch_train_loss=0.0007309484141843412
Epoch 1008
Epoch 1008 :: Batch 0/1
Batch Loss = 0.0007309484141843384
1008, epoch_train_loss=0.0007309484141843384
Epoch 1009
Epoch 1009 :: Batch 0/1
Batch Loss = 0.000730948414184336
1009, epoch_train_loss=0.000730948414184336
Epoch 1010
Epoch 1010 :: Batch 0/1
Batch Loss = 0.0007309484141843335
1010, epoch_train_loss=0.0007309484141843335
Epoch 1011
Epoch 1011 :: Batch 0/1
Batch Loss = 0.0007309484141843307
1011, epoch_train_loss=0.0007309484141843307
Epoch 1012
Epoch 1012 :: Batch 0/1
Batch Loss = 0.0007309484141843281
1012, epoch_train_loss=0.0007309484141843281
Epoch 1013
Epoch 1013 :: Batch 0/1
Batch Loss = 0.0007309484141843258
1013, epoch_train_loss=0.0007309484141843258
Epoch 1014
Epoch 1014 :: Batch 0/1
Batch Loss = 0.0007309484141843232
1014, epoch_train_loss=0.0007309484141843232
Epoch 1015
Epoch 1015 :: Batch 0/1
Batch Loss = 0.0007309484141843204
1015, epoch_train_loss=0.0007309484141843204
Epoch 1016
Epoch 1016 :: Batch 0/1
Batch Loss = 0.000730948414184318
1016, epoch_train_loss=0.000730948414184318
Epoch 1017
Epoch 1017 :: Batch 0/1
Batch Loss = 0.0007309484141843155
1017, epoch_train_loss=0.0007309484141843155
Epoch 1018
Epoch 1018 :: Batch 0/1
Batch Loss = 0.0007309484141843129
1018, epoch_train_loss=0.0007309484141843129
Epoch 1019
Epoch 1019 :: Batch 0/1
Batch Loss = 0.0007309484141843101
1019, epoch_train_loss=0.0007309484141843101
Epoch 1020
Epoch 1020 :: Batch 0/1
Batch Loss = 0.0007309484141843077
1020, epoch_train_loss=0.0007309484141843077
Epoch 1021
Epoch 1021 :: Batch 0/1
Batch Loss = 0.0007309484141843052
1021, epoch_train_loss=0.0007309484141843052
Epoch 1022
Epoch 1022 :: Batch 0/1
Batch Loss = 0.0007309484141843025
1022, epoch_train_loss=0.0007309484141843025
Epoch 1023
Epoch 1023 :: Batch 0/1
Batch Loss = 0.0007309484141842998
1023, epoch_train_loss=0.0007309484141842998
Epoch 1024
Epoch 1024 :: Batch 0/1
Batch Loss = 0.0007309484141842974
1024, epoch_train_loss=0.0007309484141842974
Epoch 1025
Epoch 1025 :: Batch 0/1
Batch Loss = 0.0007309484141842948
1025, epoch_train_loss=0.0007309484141842948
Epoch 1026
Epoch 1026 :: Batch 0/1
Batch Loss = 0.0007309484141842922
1026, epoch_train_loss=0.0007309484141842922
Epoch 1027
Epoch 1027 :: Batch 0/1
Batch Loss = 0.0007309484141842895
1027, epoch_train_loss=0.0007309484141842895
Epoch 1028
Epoch 1028 :: Batch 0/1
Batch Loss = 0.000730948414184287
1028, epoch_train_loss=0.000730948414184287
Epoch 1029
Epoch 1029 :: Batch 0/1
Batch Loss = 0.0007309484141842842
1029, epoch_train_loss=0.0007309484141842842
Epoch 1030
Epoch 1030 :: Batch 0/1
Batch Loss = 0.0007309484141842819
1030, epoch_train_loss=0.0007309484141842819
Epoch 1031
Epoch 1031 :: Batch 0/1
Batch Loss = 0.0007309484141842792
1031, epoch_train_loss=0.0007309484141842792
Epoch 1032
Epoch 1032 :: Batch 0/1
Batch Loss = 0.0007309484141842766
1032, epoch_train_loss=0.0007309484141842766
Epoch 1033
Epoch 1033 :: Batch 0/1
Batch Loss = 0.0007309484141842739
1033, epoch_train_loss=0.0007309484141842739
Epoch 1034
Epoch 1034 :: Batch 0/1
Batch Loss = 0.0007309484141842713
1034, epoch_train_loss=0.0007309484141842713
Epoch 1035
Epoch 1035 :: Batch 0/1
Batch Loss = 0.0007309484141842687
1035, epoch_train_loss=0.0007309484141842687
Epoch 1036
Epoch 1036 :: Batch 0/1
Batch Loss = 0.0007309484141842661
1036, epoch_train_loss=0.0007309484141842661
Epoch 1037
Epoch 1037 :: Batch 0/1
Batch Loss = 0.0007309484141842635
1037, epoch_train_loss=0.0007309484141842635
Epoch 1038
Epoch 1038 :: Batch 0/1
Batch Loss = 0.0007309484141842609
1038, epoch_train_loss=0.0007309484141842609
Epoch 1039
Epoch 1039 :: Batch 0/1
Batch Loss = 0.0007309484141842582
1039, epoch_train_loss=0.0007309484141842582
Epoch 1040
Epoch 1040 :: Batch 0/1
Batch Loss = 0.0007309484141842557
1040, epoch_train_loss=0.0007309484141842557
Epoch 1041
Epoch 1041 :: Batch 0/1
Batch Loss = 0.000730948414184253
1041, epoch_train_loss=0.000730948414184253
Epoch 1042
Epoch 1042 :: Batch 0/1
Batch Loss = 0.0007309484141842504
1042, epoch_train_loss=0.0007309484141842504
Epoch 1043
Epoch 1043 :: Batch 0/1
Batch Loss = 0.0007309484141842478
1043, epoch_train_loss=0.0007309484141842478
Epoch 1044
Epoch 1044 :: Batch 0/1
Batch Loss = 0.0007309484141842452
1044, epoch_train_loss=0.0007309484141842452
Epoch 1045
Epoch 1045 :: Batch 0/1
Batch Loss = 0.0007309484141842425
1045, epoch_train_loss=0.0007309484141842425
Epoch 1046
Epoch 1046 :: Batch 0/1
Batch Loss = 0.0007309484141842399
1046, epoch_train_loss=0.0007309484141842399
Epoch 1047
Epoch 1047 :: Batch 0/1
Batch Loss = 0.0007309484141842373
1047, epoch_train_loss=0.0007309484141842373
Epoch 1048
Epoch 1048 :: Batch 0/1
Batch Loss = 0.0007309484141842346
1048, epoch_train_loss=0.0007309484141842346
Epoch 1049
Epoch 1049 :: Batch 0/1
Batch Loss = 0.000730948414184232
1049, epoch_train_loss=0.000730948414184232
Epoch 1050
Epoch 1050 :: Batch 0/1
Batch Loss = 0.0007309484141842294
1050, epoch_train_loss=0.0007309484141842294
Epoch 1051
Epoch 1051 :: Batch 0/1
Batch Loss = 0.0007309484141842267
1051, epoch_train_loss=0.0007309484141842267
Epoch 1052
Epoch 1052 :: Batch 0/1
Batch Loss = 0.0007309484141842241
1052, epoch_train_loss=0.0007309484141842241
Epoch 1053
Epoch 1053 :: Batch 0/1
Batch Loss = 0.0007309484141842216
1053, epoch_train_loss=0.0007309484141842216
Epoch 1054
Epoch 1054 :: Batch 0/1
Batch Loss = 0.0007309484141842188
1054, epoch_train_loss=0.0007309484141842188
Epoch 1055
Epoch 1055 :: Batch 0/1
Batch Loss = 0.0007309484141842161
1055, epoch_train_loss=0.0007309484141842161
Epoch 1056
Epoch 1056 :: Batch 0/1
Batch Loss = 0.0007309484141842135
1056, epoch_train_loss=0.0007309484141842135
Epoch 1057
Epoch 1057 :: Batch 0/1
Batch Loss = 0.0007309484141842108
1057, epoch_train_loss=0.0007309484141842108
Epoch 1058
Epoch 1058 :: Batch 0/1
Batch Loss = 0.0007309484141842082
1058, epoch_train_loss=0.0007309484141842082
Epoch 1059
Epoch 1059 :: Batch 0/1
Batch Loss = 0.0007309484141842056
1059, epoch_train_loss=0.0007309484141842056
Epoch 1060
Epoch 1060 :: Batch 0/1
Batch Loss = 0.0007309484141842029
1060, epoch_train_loss=0.0007309484141842029
Epoch 1061
Epoch 1061 :: Batch 0/1
Batch Loss = 0.0007309484141842003
1061, epoch_train_loss=0.0007309484141842003
Epoch 1062
Epoch 1062 :: Batch 0/1
Batch Loss = 0.0007309484141841977
1062, epoch_train_loss=0.0007309484141841977
Epoch 1063
Epoch 1063 :: Batch 0/1
Batch Loss = 0.0007309484141841949
1063, epoch_train_loss=0.0007309484141841949
Epoch 1064
Epoch 1064 :: Batch 0/1
Batch Loss = 0.0007309484141841922
1064, epoch_train_loss=0.0007309484141841922
Epoch 1065
Epoch 1065 :: Batch 0/1
Batch Loss = 0.0007309484141841897
1065, epoch_train_loss=0.0007309484141841897
Epoch 1066
Epoch 1066 :: Batch 0/1
Batch Loss = 0.0007309484141841869
1066, epoch_train_loss=0.0007309484141841869
Epoch 1067
Epoch 1067 :: Batch 0/1
Batch Loss = 0.0007309484141841843
1067, epoch_train_loss=0.0007309484141841843
Epoch 1068
Epoch 1068 :: Batch 0/1
Batch Loss = 0.0007309484141841817
1068, epoch_train_loss=0.0007309484141841817
Epoch 1069
Epoch 1069 :: Batch 0/1
Batch Loss = 0.000730948414184179
1069, epoch_train_loss=0.000730948414184179
Epoch 1070
Epoch 1070 :: Batch 0/1
Batch Loss = 0.0007309484141841763
1070, epoch_train_loss=0.0007309484141841763
Epoch 1071
Epoch 1071 :: Batch 0/1
Batch Loss = 0.0007309484141841735
1071, epoch_train_loss=0.0007309484141841735
Epoch 1072
Epoch 1072 :: Batch 0/1
Batch Loss = 0.0007309484141841708
1072, epoch_train_loss=0.0007309484141841708
Epoch 1073
Epoch 1073 :: Batch 0/1
Batch Loss = 0.0007309484141841682
1073, epoch_train_loss=0.0007309484141841682
Epoch 1074
Epoch 1074 :: Batch 0/1
Batch Loss = 0.0007309484141841655
1074, epoch_train_loss=0.0007309484141841655
Epoch 1075
Epoch 1075 :: Batch 0/1
Batch Loss = 0.0007309484141841628
1075, epoch_train_loss=0.0007309484141841628
Epoch 1076
Epoch 1076 :: Batch 0/1
Batch Loss = 0.0007309484141841603
1076, epoch_train_loss=0.0007309484141841603
Epoch 1077
Epoch 1077 :: Batch 0/1
Batch Loss = 0.0007309484141841574
1077, epoch_train_loss=0.0007309484141841574
Epoch 1078
Epoch 1078 :: Batch 0/1
Batch Loss = 0.0007309484141841548
1078, epoch_train_loss=0.0007309484141841548
Epoch 1079
Epoch 1079 :: Batch 0/1
Batch Loss = 0.0007309484141841521
1079, epoch_train_loss=0.0007309484141841521
Epoch 1080
Epoch 1080 :: Batch 0/1
Batch Loss = 0.0007309484141841495
1080, epoch_train_loss=0.0007309484141841495
Epoch 1081
Epoch 1081 :: Batch 0/1
Batch Loss = 0.0007309484141841467
1081, epoch_train_loss=0.0007309484141841467
Epoch 1082
Epoch 1082 :: Batch 0/1
Batch Loss = 0.0007309484141841439
1082, epoch_train_loss=0.0007309484141841439
Epoch 1083
Epoch 1083 :: Batch 0/1
Batch Loss = 0.0007309484141841413
1083, epoch_train_loss=0.0007309484141841413
Epoch 1084
Epoch 1084 :: Batch 0/1
Batch Loss = 0.0007309484141841385
1084, epoch_train_loss=0.0007309484141841385
Epoch 1085
Epoch 1085 :: Batch 0/1
Batch Loss = 0.0007309484141841359
1085, epoch_train_loss=0.0007309484141841359
Epoch 1086
Epoch 1086 :: Batch 0/1
Batch Loss = 0.0007309484141841332
1086, epoch_train_loss=0.0007309484141841332
Epoch 1087
Epoch 1087 :: Batch 0/1
Batch Loss = 0.0007309484141841304
1087, epoch_train_loss=0.0007309484141841304
Epoch 1088
Epoch 1088 :: Batch 0/1
Batch Loss = 0.0007309484141841279
1088, epoch_train_loss=0.0007309484141841279
Epoch 1089
Epoch 1089 :: Batch 0/1
Batch Loss = 0.0007309484141841251
1089, epoch_train_loss=0.0007309484141841251
Epoch 1090
Epoch 1090 :: Batch 0/1
Batch Loss = 0.0007309484141841224
1090, epoch_train_loss=0.0007309484141841224
Epoch 1091
Epoch 1091 :: Batch 0/1
Batch Loss = 0.0007309484141841195
1091, epoch_train_loss=0.0007309484141841195
Epoch 1092
Epoch 1092 :: Batch 0/1
Batch Loss = 0.0007309484141841168
1092, epoch_train_loss=0.0007309484141841168
Epoch 1093
Epoch 1093 :: Batch 0/1
Batch Loss = 0.0007309484141841142
1093, epoch_train_loss=0.0007309484141841142
Epoch 1094
Epoch 1094 :: Batch 0/1
Batch Loss = 0.0007309484141841115
1094, epoch_train_loss=0.0007309484141841115
Epoch 1095
Epoch 1095 :: Batch 0/1
Batch Loss = 0.0007309484141841087
1095, epoch_train_loss=0.0007309484141841087
Epoch 1096
Epoch 1096 :: Batch 0/1
Batch Loss = 0.0007309484141841061
1096, epoch_train_loss=0.0007309484141841061
Epoch 1097
Epoch 1097 :: Batch 0/1
Batch Loss = 0.0007309484141841033
1097, epoch_train_loss=0.0007309484141841033
Epoch 1098
Epoch 1098 :: Batch 0/1
Batch Loss = 0.0007309484141841006
1098, epoch_train_loss=0.0007309484141841006
Epoch 1099
Epoch 1099 :: Batch 0/1
Batch Loss = 0.0007309484141840978
1099, epoch_train_loss=0.0007309484141840978
Epoch 1100
Epoch 1100 :: Batch 0/1
Batch Loss = 0.000730948414184095
1100, epoch_train_loss=0.000730948414184095
Epoch 1101
Epoch 1101 :: Batch 0/1
Batch Loss = 0.0007309484141840924
1101, epoch_train_loss=0.0007309484141840924
Epoch 1102
Epoch 1102 :: Batch 0/1
Batch Loss = 0.0007309484141840896
1102, epoch_train_loss=0.0007309484141840896
Epoch 1103
Epoch 1103 :: Batch 0/1
Batch Loss = 0.0007309484141840869
1103, epoch_train_loss=0.0007309484141840869
Epoch 1104
Epoch 1104 :: Batch 0/1
Batch Loss = 0.0007309484141840841
1104, epoch_train_loss=0.0007309484141840841
Epoch 1105
Epoch 1105 :: Batch 0/1
Batch Loss = 0.0007309484141840814
1105, epoch_train_loss=0.0007309484141840814
Epoch 1106
Epoch 1106 :: Batch 0/1
Batch Loss = 0.0007309484141840788
1106, epoch_train_loss=0.0007309484141840788
Epoch 1107
Epoch 1107 :: Batch 0/1
Batch Loss = 0.000730948414184076
1107, epoch_train_loss=0.000730948414184076
Epoch 1108
Epoch 1108 :: Batch 0/1
Batch Loss = 0.0007309484141840733
1108, epoch_train_loss=0.0007309484141840733
Epoch 1109
Epoch 1109 :: Batch 0/1
Batch Loss = 0.0007309484141840703
1109, epoch_train_loss=0.0007309484141840703
Epoch 1110
Epoch 1110 :: Batch 0/1
Batch Loss = 0.0007309484141840677
1110, epoch_train_loss=0.0007309484141840677
Epoch 1111
Epoch 1111 :: Batch 0/1
Batch Loss = 0.0007309484141840648
1111, epoch_train_loss=0.0007309484141840648
Epoch 1112
Epoch 1112 :: Batch 0/1
Batch Loss = 0.0007309484141840622
1112, epoch_train_loss=0.0007309484141840622
Epoch 1113
Epoch 1113 :: Batch 0/1
Batch Loss = 0.0007309484141840593
1113, epoch_train_loss=0.0007309484141840593
Epoch 1114
Epoch 1114 :: Batch 0/1
Batch Loss = 0.0007309484141840567
1114, epoch_train_loss=0.0007309484141840567
Epoch 1115
Epoch 1115 :: Batch 0/1
Batch Loss = 0.0007309484141840538
1115, epoch_train_loss=0.0007309484141840538
Epoch 1116
Epoch 1116 :: Batch 0/1
Batch Loss = 0.0007309484141840511
1116, epoch_train_loss=0.0007309484141840511
Epoch 1117
Epoch 1117 :: Batch 0/1
Batch Loss = 0.0007309484141840484
1117, epoch_train_loss=0.0007309484141840484
Epoch 1118
Epoch 1118 :: Batch 0/1
Batch Loss = 0.0007309484141840456
1118, epoch_train_loss=0.0007309484141840456
Epoch 1119
Epoch 1119 :: Batch 0/1
Batch Loss = 0.0007309484141840428
1119, epoch_train_loss=0.0007309484141840428
Epoch 1120
Epoch 1120 :: Batch 0/1
Batch Loss = 0.00073094841418404
1120, epoch_train_loss=0.00073094841418404
Epoch 1121
Epoch 1121 :: Batch 0/1
Batch Loss = 0.0007309484141840373
1121, epoch_train_loss=0.0007309484141840373
Epoch 1122
Epoch 1122 :: Batch 0/1
Batch Loss = 0.0007309484141840344
1122, epoch_train_loss=0.0007309484141840344
Epoch 1123
Epoch 1123 :: Batch 0/1
Batch Loss = 0.0007309484141840317
1123, epoch_train_loss=0.0007309484141840317
Epoch 1124
Epoch 1124 :: Batch 0/1
Batch Loss = 0.0007309484141840289
1124, epoch_train_loss=0.0007309484141840289
Epoch 1125
Epoch 1125 :: Batch 0/1
Batch Loss = 0.0007309484141840261
1125, epoch_train_loss=0.0007309484141840261
Epoch 1126
Epoch 1126 :: Batch 0/1
Batch Loss = 0.0007309484141840234
1126, epoch_train_loss=0.0007309484141840234
Epoch 1127
Epoch 1127 :: Batch 0/1
Batch Loss = 0.0007309484141840206
1127, epoch_train_loss=0.0007309484141840206
Epoch 1128
Epoch 1128 :: Batch 0/1
Batch Loss = 0.0007309484141840178
1128, epoch_train_loss=0.0007309484141840178
Epoch 1129
Epoch 1129 :: Batch 0/1
Batch Loss = 0.0007309484141840149
1129, epoch_train_loss=0.0007309484141840149
Epoch 1130
Epoch 1130 :: Batch 0/1
Batch Loss = 0.0007309484141840122
1130, epoch_train_loss=0.0007309484141840122
Epoch 1131
Epoch 1131 :: Batch 0/1
Batch Loss = 0.0007309484141840094
1131, epoch_train_loss=0.0007309484141840094
Epoch 1132
Epoch 1132 :: Batch 0/1
Batch Loss = 0.0007309484141840067
1132, epoch_train_loss=0.0007309484141840067
Epoch 1133
Epoch 1133 :: Batch 0/1
Batch Loss = 0.0007309484141840038
1133, epoch_train_loss=0.0007309484141840038
Epoch 1134
Epoch 1134 :: Batch 0/1
Batch Loss = 0.000730948414184001
1134, epoch_train_loss=0.000730948414184001
Epoch 1135
Epoch 1135 :: Batch 0/1
Batch Loss = 0.0007309484141839982
1135, epoch_train_loss=0.0007309484141839982
Epoch 1136
Epoch 1136 :: Batch 0/1
Batch Loss = 0.0007309484141839955
1136, epoch_train_loss=0.0007309484141839955
Epoch 1137
Epoch 1137 :: Batch 0/1
Batch Loss = 0.0007309484141839926
1137, epoch_train_loss=0.0007309484141839926
Epoch 1138
Epoch 1138 :: Batch 0/1
Batch Loss = 0.0007309484141839899
1138, epoch_train_loss=0.0007309484141839899
Epoch 1139
Epoch 1139 :: Batch 0/1
Batch Loss = 0.0007309484141839871
1139, epoch_train_loss=0.0007309484141839871
Epoch 1140
Epoch 1140 :: Batch 0/1
Batch Loss = 0.0007309484141839841
1140, epoch_train_loss=0.0007309484141839841
Epoch 1141
Epoch 1141 :: Batch 0/1
Batch Loss = 0.0007309484141839814
1141, epoch_train_loss=0.0007309484141839814
Epoch 1142
Epoch 1142 :: Batch 0/1
Batch Loss = 0.0007309484141839785
1142, epoch_train_loss=0.0007309484141839785
Epoch 1143
Epoch 1143 :: Batch 0/1
Batch Loss = 0.0007309484141839758
1143, epoch_train_loss=0.0007309484141839758
Epoch 1144
Epoch 1144 :: Batch 0/1
Batch Loss = 0.000730948414183973
1144, epoch_train_loss=0.000730948414183973
Epoch 1145
Epoch 1145 :: Batch 0/1
Batch Loss = 0.0007309484141839701
1145, epoch_train_loss=0.0007309484141839701
Epoch 1146
Epoch 1146 :: Batch 0/1
Batch Loss = 0.0007309484141839672
1146, epoch_train_loss=0.0007309484141839672
Epoch 1147
Epoch 1147 :: Batch 0/1
Batch Loss = 0.0007309484141839645
1147, epoch_train_loss=0.0007309484141839645
Epoch 1148
Epoch 1148 :: Batch 0/1
Batch Loss = 0.0007309484141839616
1148, epoch_train_loss=0.0007309484141839616
Epoch 1149
Epoch 1149 :: Batch 0/1
Batch Loss = 0.0007309484141839589
1149, epoch_train_loss=0.0007309484141839589
Epoch 1150
Epoch 1150 :: Batch 0/1
Batch Loss = 0.0007309484141839559
1150, epoch_train_loss=0.0007309484141839559
Epoch 1151
Epoch 1151 :: Batch 0/1
Batch Loss = 0.0007309484141839532
1151, epoch_train_loss=0.0007309484141839532
Epoch 1152
Epoch 1152 :: Batch 0/1
Batch Loss = 0.0007309484141839502
1152, epoch_train_loss=0.0007309484141839502
Epoch 1153
Epoch 1153 :: Batch 0/1
Batch Loss = 0.0007309484141839475
1153, epoch_train_loss=0.0007309484141839475
Epoch 1154
Epoch 1154 :: Batch 0/1
Batch Loss = 0.0007309484141839447
1154, epoch_train_loss=0.0007309484141839447
Epoch 1155
Epoch 1155 :: Batch 0/1
Batch Loss = 0.0007309484141839418
1155, epoch_train_loss=0.0007309484141839418
Epoch 1156
Epoch 1156 :: Batch 0/1
Batch Loss = 0.0007309484141839389
1156, epoch_train_loss=0.0007309484141839389
Epoch 1157
Epoch 1157 :: Batch 0/1
Batch Loss = 0.0007309484141839362
1157, epoch_train_loss=0.0007309484141839362
Epoch 1158
Epoch 1158 :: Batch 0/1
Batch Loss = 0.0007309484141839333
1158, epoch_train_loss=0.0007309484141839333
Epoch 1159
Epoch 1159 :: Batch 0/1
Batch Loss = 0.0007309484141839304
1159, epoch_train_loss=0.0007309484141839304
Epoch 1160
Epoch 1160 :: Batch 0/1
Batch Loss = 0.0007309484141839276
1160, epoch_train_loss=0.0007309484141839276
Epoch 1161
Epoch 1161 :: Batch 0/1
Batch Loss = 0.0007309484141839247
1161, epoch_train_loss=0.0007309484141839247
Epoch 1162
Epoch 1162 :: Batch 0/1
Batch Loss = 0.0007309484141839219
1162, epoch_train_loss=0.0007309484141839219
Epoch 1163
Epoch 1163 :: Batch 0/1
Batch Loss = 0.000730948414183919
1163, epoch_train_loss=0.000730948414183919
Epoch 1164
Epoch 1164 :: Batch 0/1
Batch Loss = 0.0007309484141839161
1164, epoch_train_loss=0.0007309484141839161
Epoch 1165
Epoch 1165 :: Batch 0/1
Batch Loss = 0.0007309484141839132
1165, epoch_train_loss=0.0007309484141839132
Epoch 1166
Epoch 1166 :: Batch 0/1
Batch Loss = 0.0007309484141839104
1166, epoch_train_loss=0.0007309484141839104
Epoch 1167
Epoch 1167 :: Batch 0/1
Batch Loss = 0.0007309484141839075
1167, epoch_train_loss=0.0007309484141839075
Epoch 1168
Epoch 1168 :: Batch 0/1
Batch Loss = 0.0007309484141839047
1168, epoch_train_loss=0.0007309484141839047
Epoch 1169
Epoch 1169 :: Batch 0/1
Batch Loss = 0.0007309484141839018
1169, epoch_train_loss=0.0007309484141839018
Epoch 1170
Epoch 1170 :: Batch 0/1
Batch Loss = 0.0007309484141838989
1170, epoch_train_loss=0.0007309484141838989
Epoch 1171
Epoch 1171 :: Batch 0/1
Batch Loss = 0.0007309484141838962
1171, epoch_train_loss=0.0007309484141838962
Epoch 1172
Epoch 1172 :: Batch 0/1
Batch Loss = 0.0007309484141838933
1172, epoch_train_loss=0.0007309484141838933
Epoch 1173
Epoch 1173 :: Batch 0/1
Batch Loss = 0.0007309484141838903
1173, epoch_train_loss=0.0007309484141838903
Epoch 1174
Epoch 1174 :: Batch 0/1
Batch Loss = 0.0007309484141838876
1174, epoch_train_loss=0.0007309484141838876
Epoch 1175
Epoch 1175 :: Batch 0/1
Batch Loss = 0.0007309484141838846
1175, epoch_train_loss=0.0007309484141838846
Epoch 1176
Epoch 1176 :: Batch 0/1
Batch Loss = 0.0007309484141838817
1176, epoch_train_loss=0.0007309484141838817
Epoch 1177
Epoch 1177 :: Batch 0/1
Batch Loss = 0.0007309484141838789
1177, epoch_train_loss=0.0007309484141838789
Epoch 1178
Epoch 1178 :: Batch 0/1
Batch Loss = 0.0007309484141838759
1178, epoch_train_loss=0.0007309484141838759
Epoch 1179
Epoch 1179 :: Batch 0/1
Batch Loss = 0.000730948414183873
1179, epoch_train_loss=0.000730948414183873
Epoch 1180
Epoch 1180 :: Batch 0/1
Batch Loss = 0.0007309484141838701
1180, epoch_train_loss=0.0007309484141838701
Epoch 1181
Epoch 1181 :: Batch 0/1
Batch Loss = 0.0007309484141838673
1181, epoch_train_loss=0.0007309484141838673
Epoch 1182
Epoch 1182 :: Batch 0/1
Batch Loss = 0.0007309484141838643
1182, epoch_train_loss=0.0007309484141838643
Epoch 1183
Epoch 1183 :: Batch 0/1
Batch Loss = 0.0007309484141838615
1183, epoch_train_loss=0.0007309484141838615
Epoch 1184
Epoch 1184 :: Batch 0/1
Batch Loss = 0.0007309484141838586
1184, epoch_train_loss=0.0007309484141838586
Epoch 1185
Epoch 1185 :: Batch 0/1
Batch Loss = 0.0007309484141838557
1185, epoch_train_loss=0.0007309484141838557
Epoch 1186
Epoch 1186 :: Batch 0/1
Batch Loss = 0.0007309484141838528
1186, epoch_train_loss=0.0007309484141838528
Epoch 1187
Epoch 1187 :: Batch 0/1
Batch Loss = 0.0007309484141838499
1187, epoch_train_loss=0.0007309484141838499
Epoch 1188
Epoch 1188 :: Batch 0/1
Batch Loss = 0.0007309484141838471
1188, epoch_train_loss=0.0007309484141838471
Epoch 1189
Epoch 1189 :: Batch 0/1
Batch Loss = 0.000730948414183844
1189, epoch_train_loss=0.000730948414183844
Epoch 1190
Epoch 1190 :: Batch 0/1
Batch Loss = 0.0007309484141838412
1190, epoch_train_loss=0.0007309484141838412
Epoch 1191
Epoch 1191 :: Batch 0/1
Batch Loss = 0.0007309484141838383
1191, epoch_train_loss=0.0007309484141838383
Epoch 1192
Epoch 1192 :: Batch 0/1
Batch Loss = 0.0007309484141838353
1192, epoch_train_loss=0.0007309484141838353
Epoch 1193
Epoch 1193 :: Batch 0/1
Batch Loss = 0.0007309484141838324
1193, epoch_train_loss=0.0007309484141838324
Epoch 1194
Epoch 1194 :: Batch 0/1
Batch Loss = 0.0007309484141838295
1194, epoch_train_loss=0.0007309484141838295
Epoch 1195
Epoch 1195 :: Batch 0/1
Batch Loss = 0.0007309484141838267
1195, epoch_train_loss=0.0007309484141838267
Epoch 1196
Epoch 1196 :: Batch 0/1
Batch Loss = 0.0007309484141838237
1196, epoch_train_loss=0.0007309484141838237
Epoch 1197
Epoch 1197 :: Batch 0/1
Batch Loss = 0.0007309484141838208
1197, epoch_train_loss=0.0007309484141838208
Epoch 1198
Epoch 1198 :: Batch 0/1
Batch Loss = 0.0007309484141838178
1198, epoch_train_loss=0.0007309484141838178
Epoch 1199
Epoch 1199 :: Batch 0/1
Batch Loss = 0.0007309484141838149
1199, epoch_train_loss=0.0007309484141838149
Epoch 1200
Epoch 1200 :: Batch 0/1
Batch Loss = 0.0007309484141838121
1200, epoch_train_loss=0.0007309484141838121
Epoch 1201
Epoch 1201 :: Batch 0/1
Batch Loss = 0.000730948414183809
1201, epoch_train_loss=0.000730948414183809
Epoch 1202
Epoch 1202 :: Batch 0/1
Batch Loss = 0.0007309484141838062
1202, epoch_train_loss=0.0007309484141838062
Epoch 1203
Epoch 1203 :: Batch 0/1
Batch Loss = 0.0007309484141838032
1203, epoch_train_loss=0.0007309484141838032
Epoch 1204
Epoch 1204 :: Batch 0/1
Batch Loss = 0.0007309484141838002
1204, epoch_train_loss=0.0007309484141838002
Epoch 1205
Epoch 1205 :: Batch 0/1
Batch Loss = 0.0007309484141837973
1205, epoch_train_loss=0.0007309484141837973
Epoch 1206
Epoch 1206 :: Batch 0/1
Batch Loss = 0.0007309484141837944
1206, epoch_train_loss=0.0007309484141837944
Epoch 1207
Epoch 1207 :: Batch 0/1
Batch Loss = 0.0007309484141837915
1207, epoch_train_loss=0.0007309484141837915
Epoch 1208
Epoch 1208 :: Batch 0/1
Batch Loss = 0.0007309484141837884
1208, epoch_train_loss=0.0007309484141837884
Epoch 1209
Epoch 1209 :: Batch 0/1
Batch Loss = 0.0007309484141837855
1209, epoch_train_loss=0.0007309484141837855
Epoch 1210
Epoch 1210 :: Batch 0/1
Batch Loss = 0.0007309484141837826
1210, epoch_train_loss=0.0007309484141837826
Epoch 1211
Epoch 1211 :: Batch 0/1
Batch Loss = 0.0007309484141837796
1211, epoch_train_loss=0.0007309484141837796
Epoch 1212
Epoch 1212 :: Batch 0/1
Batch Loss = 0.0007309484141837768
1212, epoch_train_loss=0.0007309484141837768
Epoch 1213
Epoch 1213 :: Batch 0/1
Batch Loss = 0.0007309484141837737
1213, epoch_train_loss=0.0007309484141837737
Epoch 1214
Epoch 1214 :: Batch 0/1
Batch Loss = 0.0007309484141837708
1214, epoch_train_loss=0.0007309484141837708
Epoch 1215
Epoch 1215 :: Batch 0/1
Batch Loss = 0.0007309484141837679
1215, epoch_train_loss=0.0007309484141837679
Epoch 1216
Epoch 1216 :: Batch 0/1
Batch Loss = 0.0007309484141837648
1216, epoch_train_loss=0.0007309484141837648
Epoch 1217
Epoch 1217 :: Batch 0/1
Batch Loss = 0.000730948414183762
1217, epoch_train_loss=0.000730948414183762
Epoch 1218
Epoch 1218 :: Batch 0/1
Batch Loss = 0.000730948414183759
1218, epoch_train_loss=0.000730948414183759
Epoch 1219
Epoch 1219 :: Batch 0/1
Batch Loss = 0.0007309484141837559
1219, epoch_train_loss=0.0007309484141837559
Epoch 1220
Epoch 1220 :: Batch 0/1
Batch Loss = 0.0007309484141837531
1220, epoch_train_loss=0.0007309484141837531
Epoch 1221
Epoch 1221 :: Batch 0/1
Batch Loss = 0.00073094841418375
1221, epoch_train_loss=0.00073094841418375
Epoch 1222
Epoch 1222 :: Batch 0/1
Batch Loss = 0.000730948414183747
1222, epoch_train_loss=0.000730948414183747
Epoch 1223
Epoch 1223 :: Batch 0/1
Batch Loss = 0.0007309484141837442
1223, epoch_train_loss=0.0007309484141837442
Epoch 1224
Epoch 1224 :: Batch 0/1
Batch Loss = 0.000730948414183741
1224, epoch_train_loss=0.000730948414183741
Epoch 1225
Epoch 1225 :: Batch 0/1
Batch Loss = 0.0007309484141837382
1225, epoch_train_loss=0.0007309484141837382
Epoch 1226
Epoch 1226 :: Batch 0/1
Batch Loss = 0.0007309484141837352
1226, epoch_train_loss=0.0007309484141837352
Epoch 1227
Epoch 1227 :: Batch 0/1
Batch Loss = 0.0007309484141837322
1227, epoch_train_loss=0.0007309484141837322
Epoch 1228
Epoch 1228 :: Batch 0/1
Batch Loss = 0.0007309484141837292
1228, epoch_train_loss=0.0007309484141837292
Epoch 1229
Epoch 1229 :: Batch 0/1
Batch Loss = 0.0007309484141837263
1229, epoch_train_loss=0.0007309484141837263
Epoch 1230
Epoch 1230 :: Batch 0/1
Batch Loss = 0.0007309484141837233
1230, epoch_train_loss=0.0007309484141837233
Epoch 1231
Epoch 1231 :: Batch 0/1
Batch Loss = 0.0007309484141837202
1231, epoch_train_loss=0.0007309484141837202
Epoch 1232
Epoch 1232 :: Batch 0/1
Batch Loss = 0.0007309484141837173
1232, epoch_train_loss=0.0007309484141837173
Epoch 1233
Epoch 1233 :: Batch 0/1
Batch Loss = 0.0007309484141837142
1233, epoch_train_loss=0.0007309484141837142
Epoch 1234
Epoch 1234 :: Batch 0/1
Batch Loss = 0.0007309484141837113
1234, epoch_train_loss=0.0007309484141837113
Epoch 1235
Epoch 1235 :: Batch 0/1
Batch Loss = 0.0007309484141837082
1235, epoch_train_loss=0.0007309484141837082
Epoch 1236
Epoch 1236 :: Batch 0/1
Batch Loss = 0.0007309484141837054
1236, epoch_train_loss=0.0007309484141837054
Epoch 1237
Epoch 1237 :: Batch 0/1
Batch Loss = 0.0007309484141837023
1237, epoch_train_loss=0.0007309484141837023
Epoch 1238
Epoch 1238 :: Batch 0/1
Batch Loss = 0.0007309484141836993
1238, epoch_train_loss=0.0007309484141836993
Epoch 1239
Epoch 1239 :: Batch 0/1
Batch Loss = 0.0007309484141836962
1239, epoch_train_loss=0.0007309484141836962
Epoch 1240
Epoch 1240 :: Batch 0/1
Batch Loss = 0.0007309484141836933
1240, epoch_train_loss=0.0007309484141836933
Epoch 1241
Epoch 1241 :: Batch 0/1
Batch Loss = 0.0007309484141836902
1241, epoch_train_loss=0.0007309484141836902
Epoch 1242
Epoch 1242 :: Batch 0/1
Batch Loss = 0.0007309484141836874
1242, epoch_train_loss=0.0007309484141836874
Epoch 1243
Epoch 1243 :: Batch 0/1
Batch Loss = 0.0007309484141836843
1243, epoch_train_loss=0.0007309484141836843
Epoch 1244
Epoch 1244 :: Batch 0/1
Batch Loss = 0.0007309484141836811
1244, epoch_train_loss=0.0007309484141836811
Epoch 1245
Epoch 1245 :: Batch 0/1
Batch Loss = 0.0007309484141836783
1245, epoch_train_loss=0.0007309484141836783
Epoch 1246
Epoch 1246 :: Batch 0/1
Batch Loss = 0.0007309484141836752
1246, epoch_train_loss=0.0007309484141836752
Epoch 1247
Epoch 1247 :: Batch 0/1
Batch Loss = 0.0007309484141836722
1247, epoch_train_loss=0.0007309484141836722
Epoch 1248
Epoch 1248 :: Batch 0/1
Batch Loss = 0.0007309484141836691
1248, epoch_train_loss=0.0007309484141836691
Epoch 1249
Epoch 1249 :: Batch 0/1
Batch Loss = 0.0007309484141836661
1249, epoch_train_loss=0.0007309484141836661
Epoch 1250
Epoch 1250 :: Batch 0/1
Batch Loss = 0.0007309484141836631
1250, epoch_train_loss=0.0007309484141836631
Epoch 1251
Epoch 1251 :: Batch 0/1
Batch Loss = 0.0007309484141836602
1251, epoch_train_loss=0.0007309484141836602
Epoch 1252
Epoch 1252 :: Batch 0/1
Batch Loss = 0.000730948414183657
1252, epoch_train_loss=0.000730948414183657
Epoch 1253
Epoch 1253 :: Batch 0/1
Batch Loss = 0.000730948414183654
1253, epoch_train_loss=0.000730948414183654
Epoch 1254
Epoch 1254 :: Batch 0/1
Batch Loss = 0.000730948414183651
1254, epoch_train_loss=0.000730948414183651
Epoch 1255
Epoch 1255 :: Batch 0/1
Batch Loss = 0.000730948414183648
1255, epoch_train_loss=0.000730948414183648
Epoch 1256
Epoch 1256 :: Batch 0/1
Batch Loss = 0.0007309484141836449
1256, epoch_train_loss=0.0007309484141836449
Epoch 1257
Epoch 1257 :: Batch 0/1
Batch Loss = 0.0007309484141836418
1257, epoch_train_loss=0.0007309484141836418
Epoch 1258
Epoch 1258 :: Batch 0/1
Batch Loss = 0.0007309484141836389
1258, epoch_train_loss=0.0007309484141836389
Epoch 1259
Epoch 1259 :: Batch 0/1
Batch Loss = 0.0007309484141836358
1259, epoch_train_loss=0.0007309484141836358
Epoch 1260
Epoch 1260 :: Batch 0/1
Batch Loss = 0.0007309484141836326
1260, epoch_train_loss=0.0007309484141836326
Epoch 1261
Epoch 1261 :: Batch 0/1
Batch Loss = 0.0007309484141836297
1261, epoch_train_loss=0.0007309484141836297
Epoch 1262
Epoch 1262 :: Batch 0/1
Batch Loss = 0.0007309484141836267
1262, epoch_train_loss=0.0007309484141836267
Epoch 1263
Epoch 1263 :: Batch 0/1
Batch Loss = 0.0007309484141836235
1263, epoch_train_loss=0.0007309484141836235
Epoch 1264
Epoch 1264 :: Batch 0/1
Batch Loss = 0.0007309484141836204
1264, epoch_train_loss=0.0007309484141836204
Epoch 1265
Epoch 1265 :: Batch 0/1
Batch Loss = 0.0007309484141836176
1265, epoch_train_loss=0.0007309484141836176
Epoch 1266
Epoch 1266 :: Batch 0/1
Batch Loss = 0.0007309484141836144
1266, epoch_train_loss=0.0007309484141836144
Epoch 1267
Epoch 1267 :: Batch 0/1
Batch Loss = 0.0007309484141836113
1267, epoch_train_loss=0.0007309484141836113
Epoch 1268
Epoch 1268 :: Batch 0/1
Batch Loss = 0.0007309484141836082
1268, epoch_train_loss=0.0007309484141836082
Epoch 1269
Epoch 1269 :: Batch 0/1
Batch Loss = 0.0007309484141836052
1269, epoch_train_loss=0.0007309484141836052
Epoch 1270
Epoch 1270 :: Batch 0/1
Batch Loss = 0.0007309484141836021
1270, epoch_train_loss=0.0007309484141836021
Epoch 1271
Epoch 1271 :: Batch 0/1
Batch Loss = 0.0007309484141835991
1271, epoch_train_loss=0.0007309484141835991
Epoch 1272
Epoch 1272 :: Batch 0/1
Batch Loss = 0.000730948414183596
1272, epoch_train_loss=0.000730948414183596
Epoch 1273
Epoch 1273 :: Batch 0/1
Batch Loss = 0.000730948414183593
1273, epoch_train_loss=0.000730948414183593
Epoch 1274
Epoch 1274 :: Batch 0/1
Batch Loss = 0.0007309484141835898
1274, epoch_train_loss=0.0007309484141835898
Epoch 1275
Epoch 1275 :: Batch 0/1
Batch Loss = 0.0007309484141835869
1275, epoch_train_loss=0.0007309484141835869
Epoch 1276
Epoch 1276 :: Batch 0/1
Batch Loss = 0.0007309484141835836
1276, epoch_train_loss=0.0007309484141835836
Epoch 1277
Epoch 1277 :: Batch 0/1
Batch Loss = 0.0007309484141835806
1277, epoch_train_loss=0.0007309484141835806
Epoch 1278
Epoch 1278 :: Batch 0/1
Batch Loss = 0.0007309484141835776
1278, epoch_train_loss=0.0007309484141835776
Epoch 1279
Epoch 1279 :: Batch 0/1
Batch Loss = 0.0007309484141835745
1279, epoch_train_loss=0.0007309484141835745
Epoch 1280
Epoch 1280 :: Batch 0/1
Batch Loss = 0.0007309484141835715
1280, epoch_train_loss=0.0007309484141835715
Epoch 1281
Epoch 1281 :: Batch 0/1
Batch Loss = 0.0007309484141835683
1281, epoch_train_loss=0.0007309484141835683
Epoch 1282
Epoch 1282 :: Batch 0/1
Batch Loss = 0.0007309484141835653
1282, epoch_train_loss=0.0007309484141835653
Epoch 1283
Epoch 1283 :: Batch 0/1
Batch Loss = 0.0007309484141835622
1283, epoch_train_loss=0.0007309484141835622
Epoch 1284
Epoch 1284 :: Batch 0/1
Batch Loss = 0.000730948414183559
1284, epoch_train_loss=0.000730948414183559
Epoch 1285
Epoch 1285 :: Batch 0/1
Batch Loss = 0.0007309484141835559
1285, epoch_train_loss=0.0007309484141835559
Epoch 1286
Epoch 1286 :: Batch 0/1
Batch Loss = 0.0007309484141835528
1286, epoch_train_loss=0.0007309484141835528
Epoch 1287
Epoch 1287 :: Batch 0/1
Batch Loss = 0.0007309484141835497
1287, epoch_train_loss=0.0007309484141835497
Epoch 1288
Epoch 1288 :: Batch 0/1
Batch Loss = 0.0007309484141835465
1288, epoch_train_loss=0.0007309484141835465
Epoch 1289
Epoch 1289 :: Batch 0/1
Batch Loss = 0.0007309484141835434
1289, epoch_train_loss=0.0007309484141835434
Epoch 1290
Epoch 1290 :: Batch 0/1
Batch Loss = 0.0007309484141835404
1290, epoch_train_loss=0.0007309484141835404
Epoch 1291
Epoch 1291 :: Batch 0/1
Batch Loss = 0.0007309484141835373
1291, epoch_train_loss=0.0007309484141835373
Epoch 1292
Epoch 1292 :: Batch 0/1
Batch Loss = 0.0007309484141835342
1292, epoch_train_loss=0.0007309484141835342
Epoch 1293
Epoch 1293 :: Batch 0/1
Batch Loss = 0.000730948414183531
1293, epoch_train_loss=0.000730948414183531
Epoch 1294
Epoch 1294 :: Batch 0/1
Batch Loss = 0.0007309484141835279
1294, epoch_train_loss=0.0007309484141835279
Epoch 1295
Epoch 1295 :: Batch 0/1
Batch Loss = 0.0007309484141835249
1295, epoch_train_loss=0.0007309484141835249
Epoch 1296
Epoch 1296 :: Batch 0/1
Batch Loss = 0.0007309484141835217
1296, epoch_train_loss=0.0007309484141835217
Epoch 1297
Epoch 1297 :: Batch 0/1
Batch Loss = 0.0007309484141835186
1297, epoch_train_loss=0.0007309484141835186
Epoch 1298
Epoch 1298 :: Batch 0/1
Batch Loss = 0.0007309484141835155
1298, epoch_train_loss=0.0007309484141835155
Epoch 1299
Epoch 1299 :: Batch 0/1
Batch Loss = 0.0007309484141835123
1299, epoch_train_loss=0.0007309484141835123
Epoch 1300
Epoch 1300 :: Batch 0/1
Batch Loss = 0.0007309484141835091
1300, epoch_train_loss=0.0007309484141835091
Epoch 1301
Epoch 1301 :: Batch 0/1
Batch Loss = 0.000730948414183506
1301, epoch_train_loss=0.000730948414183506
Epoch 1302
Epoch 1302 :: Batch 0/1
Batch Loss = 0.000730948414183503
1302, epoch_train_loss=0.000730948414183503
Epoch 1303
Epoch 1303 :: Batch 0/1
Batch Loss = 0.0007309484141834998
1303, epoch_train_loss=0.0007309484141834998
Epoch 1304
Epoch 1304 :: Batch 0/1
Batch Loss = 0.0007309484141834968
1304, epoch_train_loss=0.0007309484141834968
Epoch 1305
Epoch 1305 :: Batch 0/1
Batch Loss = 0.0007309484141834935
1305, epoch_train_loss=0.0007309484141834935
Epoch 1306
Epoch 1306 :: Batch 0/1
Batch Loss = 0.0007309484141834905
1306, epoch_train_loss=0.0007309484141834905
Epoch 1307
Epoch 1307 :: Batch 0/1
Batch Loss = 0.0007309484141834873
1307, epoch_train_loss=0.0007309484141834873
Epoch 1308
Epoch 1308 :: Batch 0/1
Batch Loss = 0.0007309484141834841
1308, epoch_train_loss=0.0007309484141834841
Epoch 1309
Epoch 1309 :: Batch 0/1
Batch Loss = 0.0007309484141834811
1309, epoch_train_loss=0.0007309484141834811
Epoch 1310
Epoch 1310 :: Batch 0/1
Batch Loss = 0.0007309484141834778
1310, epoch_train_loss=0.0007309484141834778
Epoch 1311
Epoch 1311 :: Batch 0/1
Batch Loss = 0.0007309484141834748
1311, epoch_train_loss=0.0007309484141834748
Epoch 1312
Epoch 1312 :: Batch 0/1
Batch Loss = 0.0007309484141834715
1312, epoch_train_loss=0.0007309484141834715
Epoch 1313
Epoch 1313 :: Batch 0/1
Batch Loss = 0.0007309484141834684
1313, epoch_train_loss=0.0007309484141834684
Epoch 1314
Epoch 1314 :: Batch 0/1
Batch Loss = 0.0007309484141834652
1314, epoch_train_loss=0.0007309484141834652
Epoch 1315
Epoch 1315 :: Batch 0/1
Batch Loss = 0.0007309484141834622
1315, epoch_train_loss=0.0007309484141834622
Epoch 1316
Epoch 1316 :: Batch 0/1
Batch Loss = 0.0007309484141834589
1316, epoch_train_loss=0.0007309484141834589
Epoch 1317
Epoch 1317 :: Batch 0/1
Batch Loss = 0.0007309484141834558
1317, epoch_train_loss=0.0007309484141834558
Epoch 1318
Epoch 1318 :: Batch 0/1
Batch Loss = 0.0007309484141834527
1318, epoch_train_loss=0.0007309484141834527
Epoch 1319
Epoch 1319 :: Batch 0/1
Batch Loss = 0.0007309484141834494
1319, epoch_train_loss=0.0007309484141834494
Epoch 1320
Epoch 1320 :: Batch 0/1
Batch Loss = 0.0007309484141834464
1320, epoch_train_loss=0.0007309484141834464
Epoch 1321
Epoch 1321 :: Batch 0/1
Batch Loss = 0.0007309484141834431
1321, epoch_train_loss=0.0007309484141834431
Epoch 1322
Epoch 1322 :: Batch 0/1
Batch Loss = 0.0007309484141834399
1322, epoch_train_loss=0.0007309484141834399
Epoch 1323
Epoch 1323 :: Batch 0/1
Batch Loss = 0.0007309484141834367
1323, epoch_train_loss=0.0007309484141834367
Epoch 1324
Epoch 1324 :: Batch 0/1
Batch Loss = 0.0007309484141834336
1324, epoch_train_loss=0.0007309484141834336
Epoch 1325
Epoch 1325 :: Batch 0/1
Batch Loss = 0.0007309484141834305
1325, epoch_train_loss=0.0007309484141834305
Epoch 1326
Epoch 1326 :: Batch 0/1
Batch Loss = 0.0007309484141834272
1326, epoch_train_loss=0.0007309484141834272
Epoch 1327
Epoch 1327 :: Batch 0/1
Batch Loss = 0.0007309484141834241
1327, epoch_train_loss=0.0007309484141834241
Epoch 1328
Epoch 1328 :: Batch 0/1
Batch Loss = 0.0007309484141834209
1328, epoch_train_loss=0.0007309484141834209
Epoch 1329
Epoch 1329 :: Batch 0/1
Batch Loss = 0.0007309484141834176
1329, epoch_train_loss=0.0007309484141834176
Epoch 1330
Epoch 1330 :: Batch 0/1
Batch Loss = 0.0007309484141834144
1330, epoch_train_loss=0.0007309484141834144
Epoch 1331
Epoch 1331 :: Batch 0/1
Batch Loss = 0.0007309484141834113
1331, epoch_train_loss=0.0007309484141834113
Epoch 1332
Epoch 1332 :: Batch 0/1
Batch Loss = 0.0007309484141834081
1332, epoch_train_loss=0.0007309484141834081
Epoch 1333
Epoch 1333 :: Batch 0/1
Batch Loss = 0.000730948414183405
1333, epoch_train_loss=0.000730948414183405
Epoch 1334
Epoch 1334 :: Batch 0/1
Batch Loss = 0.0007309484141834017
1334, epoch_train_loss=0.0007309484141834017
Epoch 1335
Epoch 1335 :: Batch 0/1
Batch Loss = 0.0007309484141833986
1335, epoch_train_loss=0.0007309484141833986
Epoch 1336
Epoch 1336 :: Batch 0/1
Batch Loss = 0.0007309484141833952
1336, epoch_train_loss=0.0007309484141833952
Epoch 1337
Epoch 1337 :: Batch 0/1
Batch Loss = 0.0007309484141833922
1337, epoch_train_loss=0.0007309484141833922
Epoch 1338
Epoch 1338 :: Batch 0/1
Batch Loss = 0.0007309484141833889
1338, epoch_train_loss=0.0007309484141833889
Epoch 1339
Epoch 1339 :: Batch 0/1
Batch Loss = 0.0007309484141833856
1339, epoch_train_loss=0.0007309484141833856
Epoch 1340
Epoch 1340 :: Batch 0/1
Batch Loss = 0.0007309484141833825
1340, epoch_train_loss=0.0007309484141833825
Epoch 1341
Epoch 1341 :: Batch 0/1
Batch Loss = 0.0007309484141833793
1341, epoch_train_loss=0.0007309484141833793
Epoch 1342
Epoch 1342 :: Batch 0/1
Batch Loss = 0.000730948414183376
1342, epoch_train_loss=0.000730948414183376
Epoch 1343
Epoch 1343 :: Batch 0/1
Batch Loss = 0.0007309484141833729
1343, epoch_train_loss=0.0007309484141833729
Epoch 1344
Epoch 1344 :: Batch 0/1
Batch Loss = 0.0007309484141833696
1344, epoch_train_loss=0.0007309484141833696
Epoch 1345
Epoch 1345 :: Batch 0/1
Batch Loss = 0.0007309484141833665
1345, epoch_train_loss=0.0007309484141833665
Epoch 1346
Epoch 1346 :: Batch 0/1
Batch Loss = 0.0007309484141833631
1346, epoch_train_loss=0.0007309484141833631
Epoch 1347
Epoch 1347 :: Batch 0/1
Batch Loss = 0.00073094841418336
1347, epoch_train_loss=0.00073094841418336
Epoch 1348
Epoch 1348 :: Batch 0/1
Batch Loss = 0.0007309484141833567
1348, epoch_train_loss=0.0007309484141833567
Epoch 1349
Epoch 1349 :: Batch 0/1
Batch Loss = 0.0007309484141833534
1349, epoch_train_loss=0.0007309484141833534
Epoch 1350
Epoch 1350 :: Batch 0/1
Batch Loss = 0.0007309484141833503
1350, epoch_train_loss=0.0007309484141833503
Epoch 1351
Epoch 1351 :: Batch 0/1
Batch Loss = 0.000730948414183347
1351, epoch_train_loss=0.000730948414183347
Epoch 1352
Epoch 1352 :: Batch 0/1
Batch Loss = 0.0007309484141833439
1352, epoch_train_loss=0.0007309484141833439
Epoch 1353
Epoch 1353 :: Batch 0/1
Batch Loss = 0.0007309484141833405
1353, epoch_train_loss=0.0007309484141833405
Epoch 1354
Epoch 1354 :: Batch 0/1
Batch Loss = 0.0007309484141833374
1354, epoch_train_loss=0.0007309484141833374
Epoch 1355
Epoch 1355 :: Batch 0/1
Batch Loss = 0.000730948414183334
1355, epoch_train_loss=0.000730948414183334
Epoch 1356
Epoch 1356 :: Batch 0/1
Batch Loss = 0.0007309484141833308
1356, epoch_train_loss=0.0007309484141833308
Epoch 1357
Epoch 1357 :: Batch 0/1
Batch Loss = 0.0007309484141833276
1357, epoch_train_loss=0.0007309484141833276
Epoch 1358
Epoch 1358 :: Batch 0/1
Batch Loss = 0.0007309484141833244
1358, epoch_train_loss=0.0007309484141833244
Epoch 1359
Epoch 1359 :: Batch 0/1
Batch Loss = 0.0007309484141833211
1359, epoch_train_loss=0.0007309484141833211
Epoch 1360
Epoch 1360 :: Batch 0/1
Batch Loss = 0.0007309484141833179
1360, epoch_train_loss=0.0007309484141833179
Epoch 1361
Epoch 1361 :: Batch 0/1
Batch Loss = 0.0007309484141833146
1361, epoch_train_loss=0.0007309484141833146
Epoch 1362
Epoch 1362 :: Batch 0/1
Batch Loss = 0.0007309484141833114
1362, epoch_train_loss=0.0007309484141833114
Epoch 1363
Epoch 1363 :: Batch 0/1
Batch Loss = 0.0007309484141833081
1363, epoch_train_loss=0.0007309484141833081
Epoch 1364
Epoch 1364 :: Batch 0/1
Batch Loss = 0.0007309484141833048
1364, epoch_train_loss=0.0007309484141833048
Epoch 1365
Epoch 1365 :: Batch 0/1
Batch Loss = 0.0007309484141833016
1365, epoch_train_loss=0.0007309484141833016
Epoch 1366
Epoch 1366 :: Batch 0/1
Batch Loss = 0.0007309484141832984
1366, epoch_train_loss=0.0007309484141832984
Epoch 1367
Epoch 1367 :: Batch 0/1
Batch Loss = 0.0007309484141832951
1367, epoch_train_loss=0.0007309484141832951
Epoch 1368
Epoch 1368 :: Batch 0/1
Batch Loss = 0.0007309484141832919
1368, epoch_train_loss=0.0007309484141832919
Epoch 1369
Epoch 1369 :: Batch 0/1
Batch Loss = 0.0007309484141832886
1369, epoch_train_loss=0.0007309484141832886
Epoch 1370
Epoch 1370 :: Batch 0/1
Batch Loss = 0.0007309484141832854
1370, epoch_train_loss=0.0007309484141832854
Epoch 1371
Epoch 1371 :: Batch 0/1
Batch Loss = 0.000730948414183282
1371, epoch_train_loss=0.000730948414183282
Epoch 1372
Epoch 1372 :: Batch 0/1
Batch Loss = 0.0007309484141832787
1372, epoch_train_loss=0.0007309484141832787
Epoch 1373
Epoch 1373 :: Batch 0/1
Batch Loss = 0.0007309484141832756
1373, epoch_train_loss=0.0007309484141832756
Epoch 1374
Epoch 1374 :: Batch 0/1
Batch Loss = 0.0007309484141832722
1374, epoch_train_loss=0.0007309484141832722
Epoch 1375
Epoch 1375 :: Batch 0/1
Batch Loss = 0.000730948414183269
1375, epoch_train_loss=0.000730948414183269
Epoch 1376
Epoch 1376 :: Batch 0/1
Batch Loss = 0.0007309484141832657
1376, epoch_train_loss=0.0007309484141832657
Epoch 1377
Epoch 1377 :: Batch 0/1
Batch Loss = 0.0007309484141832624
1377, epoch_train_loss=0.0007309484141832624
Epoch 1378
Epoch 1378 :: Batch 0/1
Batch Loss = 0.000730948414183259
1378, epoch_train_loss=0.000730948414183259
Epoch 1379
Epoch 1379 :: Batch 0/1
Batch Loss = 0.0007309484141832558
1379, epoch_train_loss=0.0007309484141832558
Epoch 1380
Epoch 1380 :: Batch 0/1
Batch Loss = 0.0007309484141832525
1380, epoch_train_loss=0.0007309484141832525
Epoch 1381
Epoch 1381 :: Batch 0/1
Batch Loss = 0.0007309484141832491
1381, epoch_train_loss=0.0007309484141832491
Epoch 1382
Epoch 1382 :: Batch 0/1
Batch Loss = 0.0007309484141832458
1382, epoch_train_loss=0.0007309484141832458
Epoch 1383
Epoch 1383 :: Batch 0/1
Batch Loss = 0.0007309484141832428
1383, epoch_train_loss=0.0007309484141832428
Epoch 1384
Epoch 1384 :: Batch 0/1
Batch Loss = 0.0007309484141832394
1384, epoch_train_loss=0.0007309484141832394
Epoch 1385
Epoch 1385 :: Batch 0/1
Batch Loss = 0.000730948414183236
1385, epoch_train_loss=0.000730948414183236
Epoch 1386
Epoch 1386 :: Batch 0/1
Batch Loss = 0.0007309484141832328
1386, epoch_train_loss=0.0007309484141832328
Epoch 1387
Epoch 1387 :: Batch 0/1
Batch Loss = 0.0007309484141832294
1387, epoch_train_loss=0.0007309484141832294
Epoch 1388
Epoch 1388 :: Batch 0/1
Batch Loss = 0.0007309484141832262
1388, epoch_train_loss=0.0007309484141832262
Epoch 1389
Epoch 1389 :: Batch 0/1
Batch Loss = 0.0007309484141832228
1389, epoch_train_loss=0.0007309484141832228
Epoch 1390
Epoch 1390 :: Batch 0/1
Batch Loss = 0.0007309484141832196
1390, epoch_train_loss=0.0007309484141832196
Epoch 1391
Epoch 1391 :: Batch 0/1
Batch Loss = 0.0007309484141832161
1391, epoch_train_loss=0.0007309484141832161
Epoch 1392
Epoch 1392 :: Batch 0/1
Batch Loss = 0.0007309484141832129
1392, epoch_train_loss=0.0007309484141832129
Epoch 1393
Epoch 1393 :: Batch 0/1
Batch Loss = 0.0007309484141832096
1393, epoch_train_loss=0.0007309484141832096
Epoch 1394
Epoch 1394 :: Batch 0/1
Batch Loss = 0.0007309484141832062
1394, epoch_train_loss=0.0007309484141832062
Epoch 1395
Epoch 1395 :: Batch 0/1
Batch Loss = 0.0007309484141832029
1395, epoch_train_loss=0.0007309484141832029
Epoch 1396
Epoch 1396 :: Batch 0/1
Batch Loss = 0.0007309484141831995
1396, epoch_train_loss=0.0007309484141831995
Epoch 1397
Epoch 1397 :: Batch 0/1
Batch Loss = 0.0007309484141831963
1397, epoch_train_loss=0.0007309484141831963
Epoch 1398
Epoch 1398 :: Batch 0/1
Batch Loss = 0.000730948414183193
1398, epoch_train_loss=0.000730948414183193
Epoch 1399
Epoch 1399 :: Batch 0/1
Batch Loss = 0.0007309484141831897
1399, epoch_train_loss=0.0007309484141831897
Epoch 1400
Epoch 1400 :: Batch 0/1
Batch Loss = 0.0007309484141831864
1400, epoch_train_loss=0.0007309484141831864
Epoch 1401
Epoch 1401 :: Batch 0/1
Batch Loss = 0.000730948414183183
1401, epoch_train_loss=0.000730948414183183
Epoch 1402
Epoch 1402 :: Batch 0/1
Batch Loss = 0.0007309484141831797
1402, epoch_train_loss=0.0007309484141831797
Epoch 1403
Epoch 1403 :: Batch 0/1
Batch Loss = 0.0007309484141831763
1403, epoch_train_loss=0.0007309484141831763
Epoch 1404
Epoch 1404 :: Batch 0/1
Batch Loss = 0.0007309484141831729
1404, epoch_train_loss=0.0007309484141831729
Epoch 1405
Epoch 1405 :: Batch 0/1
Batch Loss = 0.0007309484141831696
1405, epoch_train_loss=0.0007309484141831696
Epoch 1406
Epoch 1406 :: Batch 0/1
Batch Loss = 0.0007309484141831662
1406, epoch_train_loss=0.0007309484141831662
Epoch 1407
Epoch 1407 :: Batch 0/1
Batch Loss = 0.0007309484141831628
1407, epoch_train_loss=0.0007309484141831628
Epoch 1408
Epoch 1408 :: Batch 0/1
Batch Loss = 0.0007309484141831595
1408, epoch_train_loss=0.0007309484141831595
Epoch 1409
Epoch 1409 :: Batch 0/1
Batch Loss = 0.0007309484141831562
1409, epoch_train_loss=0.0007309484141831562
Epoch 1410
Epoch 1410 :: Batch 0/1
Batch Loss = 0.0007309484141831529
1410, epoch_train_loss=0.0007309484141831529
Epoch 1411
Epoch 1411 :: Batch 0/1
Batch Loss = 0.0007309484141831495
1411, epoch_train_loss=0.0007309484141831495
Epoch 1412
Epoch 1412 :: Batch 0/1
Batch Loss = 0.0007309484141831461
1412, epoch_train_loss=0.0007309484141831461
Epoch 1413
Epoch 1413 :: Batch 0/1
Batch Loss = 0.0007309484141831428
1413, epoch_train_loss=0.0007309484141831428
Epoch 1414
Epoch 1414 :: Batch 0/1
Batch Loss = 0.0007309484141831394
1414, epoch_train_loss=0.0007309484141831394
Epoch 1415
Epoch 1415 :: Batch 0/1
Batch Loss = 0.000730948414183136
1415, epoch_train_loss=0.000730948414183136
Epoch 1416
Epoch 1416 :: Batch 0/1
Batch Loss = 0.0007309484141831327
1416, epoch_train_loss=0.0007309484141831327
Epoch 1417
Epoch 1417 :: Batch 0/1
Batch Loss = 0.0007309484141831293
1417, epoch_train_loss=0.0007309484141831293
Epoch 1418
Epoch 1418 :: Batch 0/1
Batch Loss = 0.0007309484141831259
1418, epoch_train_loss=0.0007309484141831259
Epoch 1419
Epoch 1419 :: Batch 0/1
Batch Loss = 0.0007309484141831225
1419, epoch_train_loss=0.0007309484141831225
Epoch 1420
Epoch 1420 :: Batch 0/1
Batch Loss = 0.0007309484141831192
1420, epoch_train_loss=0.0007309484141831192
Epoch 1421
Epoch 1421 :: Batch 0/1
Batch Loss = 0.0007309484141831158
1421, epoch_train_loss=0.0007309484141831158
Epoch 1422
Epoch 1422 :: Batch 0/1
Batch Loss = 0.0007309484141831124
1422, epoch_train_loss=0.0007309484141831124
Epoch 1423
Epoch 1423 :: Batch 0/1
Batch Loss = 0.0007309484141831091
1423, epoch_train_loss=0.0007309484141831091
Epoch 1424
Epoch 1424 :: Batch 0/1
Batch Loss = 0.0007309484141831057
1424, epoch_train_loss=0.0007309484141831057
Epoch 1425
Epoch 1425 :: Batch 0/1
Batch Loss = 0.0007309484141831025
1425, epoch_train_loss=0.0007309484141831025
Epoch 1426
Epoch 1426 :: Batch 0/1
Batch Loss = 0.0007309484141830991
1426, epoch_train_loss=0.0007309484141830991
Epoch 1427
Epoch 1427 :: Batch 0/1
Batch Loss = 0.0007309484141830955
1427, epoch_train_loss=0.0007309484141830955
Epoch 1428
Epoch 1428 :: Batch 0/1
Batch Loss = 0.0007309484141830923
1428, epoch_train_loss=0.0007309484141830923
Epoch 1429
Epoch 1429 :: Batch 0/1
Batch Loss = 0.0007309484141830887
1429, epoch_train_loss=0.0007309484141830887
Epoch 1430
Epoch 1430 :: Batch 0/1
Batch Loss = 0.0007309484141830853
1430, epoch_train_loss=0.0007309484141830853
Epoch 1431
Epoch 1431 :: Batch 0/1
Batch Loss = 0.000730948414183082
1431, epoch_train_loss=0.000730948414183082
Epoch 1432
Epoch 1432 :: Batch 0/1
Batch Loss = 0.0007309484141830787
1432, epoch_train_loss=0.0007309484141830787
Epoch 1433
Epoch 1433 :: Batch 0/1
Batch Loss = 0.0007309484141830754
1433, epoch_train_loss=0.0007309484141830754
Epoch 1434
Epoch 1434 :: Batch 0/1
Batch Loss = 0.000730948414183072
1434, epoch_train_loss=0.000730948414183072
Epoch 1435
Epoch 1435 :: Batch 0/1
Batch Loss = 0.0007309484141830683
1435, epoch_train_loss=0.0007309484141830683
Epoch 1436
Epoch 1436 :: Batch 0/1
Batch Loss = 0.0007309484141830649
1436, epoch_train_loss=0.0007309484141830649
Epoch 1437
Epoch 1437 :: Batch 0/1
Batch Loss = 0.0007309484141830616
1437, epoch_train_loss=0.0007309484141830616
Epoch 1438
Epoch 1438 :: Batch 0/1
Batch Loss = 0.0007309484141830583
1438, epoch_train_loss=0.0007309484141830583
Epoch 1439
Epoch 1439 :: Batch 0/1
Batch Loss = 0.0007309484141830548
1439, epoch_train_loss=0.0007309484141830548
Epoch 1440
Epoch 1440 :: Batch 0/1
Batch Loss = 0.0007309484141830514
1440, epoch_train_loss=0.0007309484141830514
Epoch 1441
Epoch 1441 :: Batch 0/1
Batch Loss = 0.0007309484141830479
1441, epoch_train_loss=0.0007309484141830479
Epoch 1442
Epoch 1442 :: Batch 0/1
Batch Loss = 0.0007309484141830446
1442, epoch_train_loss=0.0007309484141830446
Epoch 1443
Epoch 1443 :: Batch 0/1
Batch Loss = 0.0007309484141830411
1443, epoch_train_loss=0.0007309484141830411
Epoch 1444
Epoch 1444 :: Batch 0/1
Batch Loss = 0.0007309484141830376
1444, epoch_train_loss=0.0007309484141830376
Epoch 1445
Epoch 1445 :: Batch 0/1
Batch Loss = 0.0007309484141830343
1445, epoch_train_loss=0.0007309484141830343
Epoch 1446
Epoch 1446 :: Batch 0/1
Batch Loss = 0.0007309484141830308
1446, epoch_train_loss=0.0007309484141830308
Epoch 1447
Epoch 1447 :: Batch 0/1
Batch Loss = 0.0007309484141830273
1447, epoch_train_loss=0.0007309484141830273
Epoch 1448
Epoch 1448 :: Batch 0/1
Batch Loss = 0.000730948414183024
1448, epoch_train_loss=0.000730948414183024
Epoch 1449
Epoch 1449 :: Batch 0/1
Batch Loss = 0.0007309484141830206
1449, epoch_train_loss=0.0007309484141830206
Epoch 1450
Epoch 1450 :: Batch 0/1
Batch Loss = 0.0007309484141830171
1450, epoch_train_loss=0.0007309484141830171
Epoch 1451
Epoch 1451 :: Batch 0/1
Batch Loss = 0.0007309484141830137
1451, epoch_train_loss=0.0007309484141830137
Epoch 1452
Epoch 1452 :: Batch 0/1
Batch Loss = 0.0007309484141830102
1452, epoch_train_loss=0.0007309484141830102
Epoch 1453
Epoch 1453 :: Batch 0/1
Batch Loss = 0.0007309484141830067
1453, epoch_train_loss=0.0007309484141830067
Epoch 1454
Epoch 1454 :: Batch 0/1
Batch Loss = 0.0007309484141830034
1454, epoch_train_loss=0.0007309484141830034
Epoch 1455
Epoch 1455 :: Batch 0/1
Batch Loss = 0.000730948414183
1455, epoch_train_loss=0.000730948414183
Epoch 1456
Epoch 1456 :: Batch 0/1
Batch Loss = 0.0007309484141829965
1456, epoch_train_loss=0.0007309484141829965
Epoch 1457
Epoch 1457 :: Batch 0/1
Batch Loss = 0.0007309484141829931
1457, epoch_train_loss=0.0007309484141829931
Epoch 1458
Epoch 1458 :: Batch 0/1
Batch Loss = 0.0007309484141829896
1458, epoch_train_loss=0.0007309484141829896
Epoch 1459
Epoch 1459 :: Batch 0/1
Batch Loss = 0.0007309484141829861
1459, epoch_train_loss=0.0007309484141829861
Epoch 1460
Epoch 1460 :: Batch 0/1
Batch Loss = 0.0007309484141829827
1460, epoch_train_loss=0.0007309484141829827
Epoch 1461
Epoch 1461 :: Batch 0/1
Batch Loss = 0.0007309484141829792
1461, epoch_train_loss=0.0007309484141829792
Epoch 1462
Epoch 1462 :: Batch 0/1
Batch Loss = 0.0007309484141829758
1462, epoch_train_loss=0.0007309484141829758
Epoch 1463
Epoch 1463 :: Batch 0/1
Batch Loss = 0.0007309484141829724
1463, epoch_train_loss=0.0007309484141829724
Epoch 1464
Epoch 1464 :: Batch 0/1
Batch Loss = 0.0007309484141829688
1464, epoch_train_loss=0.0007309484141829688
Epoch 1465
Epoch 1465 :: Batch 0/1
Batch Loss = 0.0007309484141829654
1465, epoch_train_loss=0.0007309484141829654
Epoch 1466
Epoch 1466 :: Batch 0/1
Batch Loss = 0.0007309484141829618
1466, epoch_train_loss=0.0007309484141829618
Epoch 1467
Epoch 1467 :: Batch 0/1
Batch Loss = 0.0007309484141829584
1467, epoch_train_loss=0.0007309484141829584
Epoch 1468
Epoch 1468 :: Batch 0/1
Batch Loss = 0.0007309484141829549
1468, epoch_train_loss=0.0007309484141829549
Epoch 1469
Epoch 1469 :: Batch 0/1
Batch Loss = 0.0007309484141829515
1469, epoch_train_loss=0.0007309484141829515
Epoch 1470
Epoch 1470 :: Batch 0/1
Batch Loss = 0.000730948414182948
1470, epoch_train_loss=0.000730948414182948
Epoch 1471
Epoch 1471 :: Batch 0/1
Batch Loss = 0.0007309484141829445
1471, epoch_train_loss=0.0007309484141829445
Epoch 1472
Epoch 1472 :: Batch 0/1
Batch Loss = 0.000730948414182941
1472, epoch_train_loss=0.000730948414182941
Epoch 1473
Epoch 1473 :: Batch 0/1
Batch Loss = 0.0007309484141829375
1473, epoch_train_loss=0.0007309484141829375
Epoch 1474
Epoch 1474 :: Batch 0/1
Batch Loss = 0.0007309484141829341
1474, epoch_train_loss=0.0007309484141829341
Epoch 1475
Epoch 1475 :: Batch 0/1
Batch Loss = 0.0007309484141829307
1475, epoch_train_loss=0.0007309484141829307
Epoch 1476
Epoch 1476 :: Batch 0/1
Batch Loss = 0.0007309484141829271
1476, epoch_train_loss=0.0007309484141829271
Epoch 1477
Epoch 1477 :: Batch 0/1
Batch Loss = 0.0007309484141829236
1477, epoch_train_loss=0.0007309484141829236
Epoch 1478
Epoch 1478 :: Batch 0/1
Batch Loss = 0.0007309484141829201
1478, epoch_train_loss=0.0007309484141829201
Epoch 1479
Epoch 1479 :: Batch 0/1
Batch Loss = 0.0007309484141829165
1479, epoch_train_loss=0.0007309484141829165
Epoch 1480
Epoch 1480 :: Batch 0/1
Batch Loss = 0.0007309484141829132
1480, epoch_train_loss=0.0007309484141829132
Epoch 1481
Epoch 1481 :: Batch 0/1
Batch Loss = 0.0007309484141829097
1481, epoch_train_loss=0.0007309484141829097
Epoch 1482
Epoch 1482 :: Batch 0/1
Batch Loss = 0.000730948414182906
1482, epoch_train_loss=0.000730948414182906
Epoch 1483
Epoch 1483 :: Batch 0/1
Batch Loss = 0.0007309484141829026
1483, epoch_train_loss=0.0007309484141829026
Epoch 1484
Epoch 1484 :: Batch 0/1
Batch Loss = 0.0007309484141828991
1484, epoch_train_loss=0.0007309484141828991
Epoch 1485
Epoch 1485 :: Batch 0/1
Batch Loss = 0.0007309484141828956
1485, epoch_train_loss=0.0007309484141828956
Epoch 1486
Epoch 1486 :: Batch 0/1
Batch Loss = 0.0007309484141828921
1486, epoch_train_loss=0.0007309484141828921
Epoch 1487
Epoch 1487 :: Batch 0/1
Batch Loss = 0.0007309484141828887
1487, epoch_train_loss=0.0007309484141828887
Epoch 1488
Epoch 1488 :: Batch 0/1
Batch Loss = 0.0007309484141828851
1488, epoch_train_loss=0.0007309484141828851
Epoch 1489
Epoch 1489 :: Batch 0/1
Batch Loss = 0.0007309484141828815
1489, epoch_train_loss=0.0007309484141828815
Epoch 1490
Epoch 1490 :: Batch 0/1
Batch Loss = 0.000730948414182878
1490, epoch_train_loss=0.000730948414182878
Epoch 1491
Epoch 1491 :: Batch 0/1
Batch Loss = 0.0007309484141828746
1491, epoch_train_loss=0.0007309484141828746
Epoch 1492
Epoch 1492 :: Batch 0/1
Batch Loss = 0.000730948414182871
1492, epoch_train_loss=0.000730948414182871
Epoch 1493
Epoch 1493 :: Batch 0/1
Batch Loss = 0.0007309484141828675
1493, epoch_train_loss=0.0007309484141828675
Epoch 1494
Epoch 1494 :: Batch 0/1
Batch Loss = 0.0007309484141828639
1494, epoch_train_loss=0.0007309484141828639
Epoch 1495
Epoch 1495 :: Batch 0/1
Batch Loss = 0.0007309484141828605
1495, epoch_train_loss=0.0007309484141828605
Epoch 1496
Epoch 1496 :: Batch 0/1
Batch Loss = 0.0007309484141828568
1496, epoch_train_loss=0.0007309484141828568
Epoch 1497
Epoch 1497 :: Batch 0/1
Batch Loss = 0.0007309484141828532
1497, epoch_train_loss=0.0007309484141828532
Epoch 1498
Epoch 1498 :: Batch 0/1
Batch Loss = 0.0007309484141828497
1498, epoch_train_loss=0.0007309484141828497
Epoch 1499
Epoch 1499 :: Batch 0/1
Batch Loss = 0.0007309484141828463
1499, epoch_train_loss=0.0007309484141828463
Epoch 1500
Epoch 1500 :: Batch 0/1
Batch Loss = 0.0007309484141828427
1500, epoch_train_loss=0.0007309484141828427
Epoch 1501
Epoch 1501 :: Batch 0/1
Batch Loss = 0.0007309484141828392
1501, epoch_train_loss=0.0007309484141828392
Epoch 1502
Epoch 1502 :: Batch 0/1
Batch Loss = 0.0007309484141828356
1502, epoch_train_loss=0.0007309484141828356
Epoch 1503
Epoch 1503 :: Batch 0/1
Batch Loss = 0.0007309484141828322
1503, epoch_train_loss=0.0007309484141828322
Epoch 1504
Epoch 1504 :: Batch 0/1
Batch Loss = 0.0007309484141828285
1504, epoch_train_loss=0.0007309484141828285
Epoch 1505
Epoch 1505 :: Batch 0/1
Batch Loss = 0.0007309484141828249
1505, epoch_train_loss=0.0007309484141828249
Epoch 1506
Epoch 1506 :: Batch 0/1
Batch Loss = 0.0007309484141828213
1506, epoch_train_loss=0.0007309484141828213
Epoch 1507
Epoch 1507 :: Batch 0/1
Batch Loss = 0.000730948414182818
1507, epoch_train_loss=0.000730948414182818
Epoch 1508
Epoch 1508 :: Batch 0/1
Batch Loss = 0.0007309484141828143
1508, epoch_train_loss=0.0007309484141828143
Epoch 1509
Epoch 1509 :: Batch 0/1
Batch Loss = 0.0007309484141828108
1509, epoch_train_loss=0.0007309484141828108
Epoch 1510
Epoch 1510 :: Batch 0/1
Batch Loss = 0.0007309484141828072
1510, epoch_train_loss=0.0007309484141828072
Epoch 1511
Epoch 1511 :: Batch 0/1
Batch Loss = 0.0007309484141828035
1511, epoch_train_loss=0.0007309484141828035
Epoch 1512
Epoch 1512 :: Batch 0/1
Batch Loss = 0.0007309484141828
1512, epoch_train_loss=0.0007309484141828
Epoch 1513
Epoch 1513 :: Batch 0/1
Batch Loss = 0.0007309484141827965
1513, epoch_train_loss=0.0007309484141827965
Epoch 1514
Epoch 1514 :: Batch 0/1
Batch Loss = 0.0007309484141827928
1514, epoch_train_loss=0.0007309484141827928
Epoch 1515
Epoch 1515 :: Batch 0/1
Batch Loss = 0.0007309484141827894
1515, epoch_train_loss=0.0007309484141827894
Epoch 1516
Epoch 1516 :: Batch 0/1
Batch Loss = 0.0007309484141827859
1516, epoch_train_loss=0.0007309484141827859
Epoch 1517
Epoch 1517 :: Batch 0/1
Batch Loss = 0.0007309484141827822
1517, epoch_train_loss=0.0007309484141827822
Epoch 1518
Epoch 1518 :: Batch 0/1
Batch Loss = 0.0007309484141827786
1518, epoch_train_loss=0.0007309484141827786
Epoch 1519
Epoch 1519 :: Batch 0/1
Batch Loss = 0.000730948414182775
1519, epoch_train_loss=0.000730948414182775
Epoch 1520
Epoch 1520 :: Batch 0/1
Batch Loss = 0.0007309484141827714
1520, epoch_train_loss=0.0007309484141827714
Epoch 1521
Epoch 1521 :: Batch 0/1
Batch Loss = 0.0007309484141827679
1521, epoch_train_loss=0.0007309484141827679
Epoch 1522
Epoch 1522 :: Batch 0/1
Batch Loss = 0.0007309484141827643
1522, epoch_train_loss=0.0007309484141827643
Epoch 1523
Epoch 1523 :: Batch 0/1
Batch Loss = 0.0007309484141827606
1523, epoch_train_loss=0.0007309484141827606
Epoch 1524
Epoch 1524 :: Batch 0/1
Batch Loss = 0.000730948414182757
1524, epoch_train_loss=0.000730948414182757
Epoch 1525
Epoch 1525 :: Batch 0/1
Batch Loss = 0.0007309484141827535
1525, epoch_train_loss=0.0007309484141827535
Epoch 1526
Epoch 1526 :: Batch 0/1
Batch Loss = 0.0007309484141827499
1526, epoch_train_loss=0.0007309484141827499
Epoch 1527
Epoch 1527 :: Batch 0/1
Batch Loss = 0.0007309484141827463
1527, epoch_train_loss=0.0007309484141827463
Epoch 1528
Epoch 1528 :: Batch 0/1
Batch Loss = 0.0007309484141827427
1528, epoch_train_loss=0.0007309484141827427
Epoch 1529
Epoch 1529 :: Batch 0/1
Batch Loss = 0.000730948414182739
1529, epoch_train_loss=0.000730948414182739
Epoch 1530
Epoch 1530 :: Batch 0/1
Batch Loss = 0.0007309484141827355
1530, epoch_train_loss=0.0007309484141827355
Epoch 1531
Epoch 1531 :: Batch 0/1
Batch Loss = 0.0007309484141827319
1531, epoch_train_loss=0.0007309484141827319
Epoch 1532
Epoch 1532 :: Batch 0/1
Batch Loss = 0.0007309484141827283
1532, epoch_train_loss=0.0007309484141827283
Epoch 1533
Epoch 1533 :: Batch 0/1
Batch Loss = 0.0007309484141827247
1533, epoch_train_loss=0.0007309484141827247
Epoch 1534
Epoch 1534 :: Batch 0/1
Batch Loss = 0.000730948414182721
1534, epoch_train_loss=0.000730948414182721
Epoch 1535
Epoch 1535 :: Batch 0/1
Batch Loss = 0.0007309484141827175
1535, epoch_train_loss=0.0007309484141827175
Epoch 1536
Epoch 1536 :: Batch 0/1
Batch Loss = 0.0007309484141827138
1536, epoch_train_loss=0.0007309484141827138
Epoch 1537
Epoch 1537 :: Batch 0/1
Batch Loss = 0.0007309484141827103
1537, epoch_train_loss=0.0007309484141827103
Epoch 1538
Epoch 1538 :: Batch 0/1
Batch Loss = 0.0007309484141827067
1538, epoch_train_loss=0.0007309484141827067
Epoch 1539
Epoch 1539 :: Batch 0/1
Batch Loss = 0.0007309484141827031
1539, epoch_train_loss=0.0007309484141827031
Epoch 1540
Epoch 1540 :: Batch 0/1
Batch Loss = 0.0007309484141826993
1540, epoch_train_loss=0.0007309484141826993
Epoch 1541
Epoch 1541 :: Batch 0/1
Batch Loss = 0.0007309484141826958
1541, epoch_train_loss=0.0007309484141826958
Epoch 1542
Epoch 1542 :: Batch 0/1
Batch Loss = 0.0007309484141826921
1542, epoch_train_loss=0.0007309484141826921
Epoch 1543
Epoch 1543 :: Batch 0/1
Batch Loss = 0.0007309484141826885
1543, epoch_train_loss=0.0007309484141826885
Epoch 1544
Epoch 1544 :: Batch 0/1
Batch Loss = 0.0007309484141826848
1544, epoch_train_loss=0.0007309484141826848
Epoch 1545
Epoch 1545 :: Batch 0/1
Batch Loss = 0.0007309484141826811
1545, epoch_train_loss=0.0007309484141826811
Epoch 1546
Epoch 1546 :: Batch 0/1
Batch Loss = 0.0007309484141826776
1546, epoch_train_loss=0.0007309484141826776
Epoch 1547
Epoch 1547 :: Batch 0/1
Batch Loss = 0.000730948414182674
1547, epoch_train_loss=0.000730948414182674
Epoch 1548
Epoch 1548 :: Batch 0/1
Batch Loss = 0.0007309484141826702
1548, epoch_train_loss=0.0007309484141826702
Epoch 1549
Epoch 1549 :: Batch 0/1
Batch Loss = 0.0007309484141826666
1549, epoch_train_loss=0.0007309484141826666
Epoch 1550
Epoch 1550 :: Batch 0/1
Batch Loss = 0.000730948414182663
1550, epoch_train_loss=0.000730948414182663
Epoch 1551
Epoch 1551 :: Batch 0/1
Batch Loss = 0.0007309484141826593
1551, epoch_train_loss=0.0007309484141826593
Epoch 1552
Epoch 1552 :: Batch 0/1
Batch Loss = 0.0007309484141826557
1552, epoch_train_loss=0.0007309484141826557
Epoch 1553
Epoch 1553 :: Batch 0/1
Batch Loss = 0.000730948414182652
1553, epoch_train_loss=0.000730948414182652
Epoch 1554
Epoch 1554 :: Batch 0/1
Batch Loss = 0.0007309484141826484
1554, epoch_train_loss=0.0007309484141826484
Epoch 1555
Epoch 1555 :: Batch 0/1
Batch Loss = 0.0007309484141826448
1555, epoch_train_loss=0.0007309484141826448
Epoch 1556
Epoch 1556 :: Batch 0/1
Batch Loss = 0.0007309484141826411
1556, epoch_train_loss=0.0007309484141826411
Epoch 1557
Epoch 1557 :: Batch 0/1
Batch Loss = 0.0007309484141826373
1557, epoch_train_loss=0.0007309484141826373
Epoch 1558
Epoch 1558 :: Batch 0/1
Batch Loss = 0.0007309484141826338
1558, epoch_train_loss=0.0007309484141826338
Epoch 1559
Epoch 1559 :: Batch 0/1
Batch Loss = 0.0007309484141826301
1559, epoch_train_loss=0.0007309484141826301
Epoch 1560
Epoch 1560 :: Batch 0/1
Batch Loss = 0.0007309484141826264
1560, epoch_train_loss=0.0007309484141826264
Epoch 1561
Epoch 1561 :: Batch 0/1
Batch Loss = 0.0007309484141826227
1561, epoch_train_loss=0.0007309484141826227
Epoch 1562
Epoch 1562 :: Batch 0/1
Batch Loss = 0.000730948414182619
1562, epoch_train_loss=0.000730948414182619
Epoch 1563
Epoch 1563 :: Batch 0/1
Batch Loss = 0.0007309484141826153
1563, epoch_train_loss=0.0007309484141826153
Epoch 1564
Epoch 1564 :: Batch 0/1
Batch Loss = 0.0007309484141826117
1564, epoch_train_loss=0.0007309484141826117
Epoch 1565
Epoch 1565 :: Batch 0/1
Batch Loss = 0.000730948414182608
1565, epoch_train_loss=0.000730948414182608
Epoch 1566
Epoch 1566 :: Batch 0/1
Batch Loss = 0.0007309484141826043
1566, epoch_train_loss=0.0007309484141826043
Epoch 1567
Epoch 1567 :: Batch 0/1
Batch Loss = 0.0007309484141826007
1567, epoch_train_loss=0.0007309484141826007
Epoch 1568
Epoch 1568 :: Batch 0/1
Batch Loss = 0.0007309484141825969
1568, epoch_train_loss=0.0007309484141825969
Epoch 1569
Epoch 1569 :: Batch 0/1
Batch Loss = 0.0007309484141825932
1569, epoch_train_loss=0.0007309484141825932
Epoch 1570
Epoch 1570 :: Batch 0/1
Batch Loss = 0.0007309484141825896
1570, epoch_train_loss=0.0007309484141825896
Epoch 1571
Epoch 1571 :: Batch 0/1
Batch Loss = 0.0007309484141825859
1571, epoch_train_loss=0.0007309484141825859
Epoch 1572
Epoch 1572 :: Batch 0/1
Batch Loss = 0.0007309484141825823
1572, epoch_train_loss=0.0007309484141825823
Epoch 1573
Epoch 1573 :: Batch 0/1
Batch Loss = 0.0007309484141825784
1573, epoch_train_loss=0.0007309484141825784
Epoch 1574
Epoch 1574 :: Batch 0/1
Batch Loss = 0.0007309484141825748
1574, epoch_train_loss=0.0007309484141825748
Epoch 1575
Epoch 1575 :: Batch 0/1
Batch Loss = 0.0007309484141825711
1575, epoch_train_loss=0.0007309484141825711
Epoch 1576
Epoch 1576 :: Batch 0/1
Batch Loss = 0.0007309484141825674
1576, epoch_train_loss=0.0007309484141825674
Epoch 1577
Epoch 1577 :: Batch 0/1
Batch Loss = 0.0007309484141825637
1577, epoch_train_loss=0.0007309484141825637
Epoch 1578
Epoch 1578 :: Batch 0/1
Batch Loss = 0.00073094841418256
1578, epoch_train_loss=0.00073094841418256
Epoch 1579
Epoch 1579 :: Batch 0/1
Batch Loss = 0.0007309484141825563
1579, epoch_train_loss=0.0007309484141825563
Epoch 1580
Epoch 1580 :: Batch 0/1
Batch Loss = 0.0007309484141825525
1580, epoch_train_loss=0.0007309484141825525
Epoch 1581
Epoch 1581 :: Batch 0/1
Batch Loss = 0.0007309484141825489
1581, epoch_train_loss=0.0007309484141825489
Epoch 1582
Epoch 1582 :: Batch 0/1
Batch Loss = 0.0007309484141825452
1582, epoch_train_loss=0.0007309484141825452
Epoch 1583
Epoch 1583 :: Batch 0/1
Batch Loss = 0.0007309484141825415
1583, epoch_train_loss=0.0007309484141825415
Epoch 1584
Epoch 1584 :: Batch 0/1
Batch Loss = 0.0007309484141825376
1584, epoch_train_loss=0.0007309484141825376
Epoch 1585
Epoch 1585 :: Batch 0/1
Batch Loss = 0.000730948414182534
1585, epoch_train_loss=0.000730948414182534
Epoch 1586
Epoch 1586 :: Batch 0/1
Batch Loss = 0.0007309484141825302
1586, epoch_train_loss=0.0007309484141825302
Epoch 1587
Epoch 1587 :: Batch 0/1
Batch Loss = 0.0007309484141825265
1587, epoch_train_loss=0.0007309484141825265
Epoch 1588
Epoch 1588 :: Batch 0/1
Batch Loss = 0.0007309484141825227
1588, epoch_train_loss=0.0007309484141825227
Epoch 1589
Epoch 1589 :: Batch 0/1
Batch Loss = 0.0007309484141825192
1589, epoch_train_loss=0.0007309484141825192
Epoch 1590
Epoch 1590 :: Batch 0/1
Batch Loss = 0.0007309484141825154
1590, epoch_train_loss=0.0007309484141825154
Epoch 1591
Epoch 1591 :: Batch 0/1
Batch Loss = 0.0007309484141825115
1591, epoch_train_loss=0.0007309484141825115
Epoch 1592
Epoch 1592 :: Batch 0/1
Batch Loss = 0.0007309484141825079
1592, epoch_train_loss=0.0007309484141825079
Epoch 1593
Epoch 1593 :: Batch 0/1
Batch Loss = 0.0007309484141825042
1593, epoch_train_loss=0.0007309484141825042
Epoch 1594
Epoch 1594 :: Batch 0/1
Batch Loss = 0.0007309484141825004
1594, epoch_train_loss=0.0007309484141825004
Epoch 1595
Epoch 1595 :: Batch 0/1
Batch Loss = 0.0007309484141824966
1595, epoch_train_loss=0.0007309484141824966
Epoch 1596
Epoch 1596 :: Batch 0/1
Batch Loss = 0.000730948414182493
1596, epoch_train_loss=0.000730948414182493
Epoch 1597
Epoch 1597 :: Batch 0/1
Batch Loss = 0.0007309484141824891
1597, epoch_train_loss=0.0007309484141824891
Epoch 1598
Epoch 1598 :: Batch 0/1
Batch Loss = 0.0007309484141824854
1598, epoch_train_loss=0.0007309484141824854
Epoch 1599
Epoch 1599 :: Batch 0/1
Batch Loss = 0.0007309484141824816
1599, epoch_train_loss=0.0007309484141824816
Epoch 1600
Epoch 1600 :: Batch 0/1
Batch Loss = 0.0007309484141824778
1600, epoch_train_loss=0.0007309484141824778
Epoch 1601
Epoch 1601 :: Batch 0/1
Batch Loss = 0.000730948414182474
1601, epoch_train_loss=0.000730948414182474
Epoch 1602
Epoch 1602 :: Batch 0/1
Batch Loss = 0.0007309484141824705
1602, epoch_train_loss=0.0007309484141824705
Epoch 1603
Epoch 1603 :: Batch 0/1
Batch Loss = 0.0007309484141824666
1603, epoch_train_loss=0.0007309484141824666
Epoch 1604
Epoch 1604 :: Batch 0/1
Batch Loss = 0.0007309484141824628
1604, epoch_train_loss=0.0007309484141824628
Epoch 1605
Epoch 1605 :: Batch 0/1
Batch Loss = 0.0007309484141824591
1605, epoch_train_loss=0.0007309484141824591
Epoch 1606
Epoch 1606 :: Batch 0/1
Batch Loss = 0.0007309484141824554
1606, epoch_train_loss=0.0007309484141824554
Epoch 1607
Epoch 1607 :: Batch 0/1
Batch Loss = 0.0007309484141824515
1607, epoch_train_loss=0.0007309484141824515
Epoch 1608
Epoch 1608 :: Batch 0/1
Batch Loss = 0.0007309484141824477
1608, epoch_train_loss=0.0007309484141824477
Epoch 1609
Epoch 1609 :: Batch 0/1
Batch Loss = 0.0007309484141824439
1609, epoch_train_loss=0.0007309484141824439
Epoch 1610
Epoch 1610 :: Batch 0/1
Batch Loss = 0.0007309484141824402
1610, epoch_train_loss=0.0007309484141824402
Epoch 1611
Epoch 1611 :: Batch 0/1
Batch Loss = 0.0007309484141824364
1611, epoch_train_loss=0.0007309484141824364
Epoch 1612
Epoch 1612 :: Batch 0/1
Batch Loss = 0.0007309484141824325
1612, epoch_train_loss=0.0007309484141824325
Epoch 1613
Epoch 1613 :: Batch 0/1
Batch Loss = 0.0007309484141824288
1613, epoch_train_loss=0.0007309484141824288
Epoch 1614
Epoch 1614 :: Batch 0/1
Batch Loss = 0.0007309484141824252
1614, epoch_train_loss=0.0007309484141824252
Epoch 1615
Epoch 1615 :: Batch 0/1
Batch Loss = 0.0007309484141824213
1615, epoch_train_loss=0.0007309484141824213
Epoch 1616
Epoch 1616 :: Batch 0/1
Batch Loss = 0.0007309484141824175
1616, epoch_train_loss=0.0007309484141824175
Epoch 1617
Epoch 1617 :: Batch 0/1
Batch Loss = 0.0007309484141824137
1617, epoch_train_loss=0.0007309484141824137
Epoch 1618
Epoch 1618 :: Batch 0/1
Batch Loss = 0.00073094841418241
1618, epoch_train_loss=0.00073094841418241
Epoch 1619
Epoch 1619 :: Batch 0/1
Batch Loss = 0.0007309484141824062
1619, epoch_train_loss=0.0007309484141824062
Epoch 1620
Epoch 1620 :: Batch 0/1
Batch Loss = 0.0007309484141824024
1620, epoch_train_loss=0.0007309484141824024
Epoch 1621
Epoch 1621 :: Batch 0/1
Batch Loss = 0.0007309484141823985
1621, epoch_train_loss=0.0007309484141823985
Epoch 1622
Epoch 1622 :: Batch 0/1
Batch Loss = 0.0007309484141823947
1622, epoch_train_loss=0.0007309484141823947
Epoch 1623
Epoch 1623 :: Batch 0/1
Batch Loss = 0.0007309484141823908
1623, epoch_train_loss=0.0007309484141823908
Epoch 1624
Epoch 1624 :: Batch 0/1
Batch Loss = 0.000730948414182387
1624, epoch_train_loss=0.000730948414182387
Epoch 1625
Epoch 1625 :: Batch 0/1
Batch Loss = 0.0007309484141823833
1625, epoch_train_loss=0.0007309484141823833
Epoch 1626
Epoch 1626 :: Batch 0/1
Batch Loss = 0.0007309484141823793
1626, epoch_train_loss=0.0007309484141823793
Epoch 1627
Epoch 1627 :: Batch 0/1
Batch Loss = 0.0007309484141823757
1627, epoch_train_loss=0.0007309484141823757
Epoch 1628
Epoch 1628 :: Batch 0/1
Batch Loss = 0.0007309484141823719
1628, epoch_train_loss=0.0007309484141823719
Epoch 1629
Epoch 1629 :: Batch 0/1
Batch Loss = 0.000730948414182368
1629, epoch_train_loss=0.000730948414182368
Epoch 1630
Epoch 1630 :: Batch 0/1
Batch Loss = 0.0007309484141823642
1630, epoch_train_loss=0.0007309484141823642
Epoch 1631
Epoch 1631 :: Batch 0/1
Batch Loss = 0.0007309484141823604
1631, epoch_train_loss=0.0007309484141823604
Epoch 1632
Epoch 1632 :: Batch 0/1
Batch Loss = 0.0007309484141823565
1632, epoch_train_loss=0.0007309484141823565
Epoch 1633
Epoch 1633 :: Batch 0/1
Batch Loss = 0.0007309484141823527
1633, epoch_train_loss=0.0007309484141823527
Epoch 1634
Epoch 1634 :: Batch 0/1
Batch Loss = 0.0007309484141823488
1634, epoch_train_loss=0.0007309484141823488
Epoch 1635
Epoch 1635 :: Batch 0/1
Batch Loss = 0.000730948414182345
1635, epoch_train_loss=0.000730948414182345
Epoch 1636
Epoch 1636 :: Batch 0/1
Batch Loss = 0.0007309484141823412
1636, epoch_train_loss=0.0007309484141823412
Epoch 1637
Epoch 1637 :: Batch 0/1
Batch Loss = 0.0007309484141823373
1637, epoch_train_loss=0.0007309484141823373
Epoch 1638
Epoch 1638 :: Batch 0/1
Batch Loss = 0.0007309484141823335
1638, epoch_train_loss=0.0007309484141823335
Epoch 1639
Epoch 1639 :: Batch 0/1
Batch Loss = 0.0007309484141823296
1639, epoch_train_loss=0.0007309484141823296
Epoch 1640
Epoch 1640 :: Batch 0/1
Batch Loss = 0.0007309484141823258
1640, epoch_train_loss=0.0007309484141823258
Epoch 1641
Epoch 1641 :: Batch 0/1
Batch Loss = 0.000730948414182322
1641, epoch_train_loss=0.000730948414182322
Epoch 1642
Epoch 1642 :: Batch 0/1
Batch Loss = 0.0007309484141823181
1642, epoch_train_loss=0.0007309484141823181
Epoch 1643
Epoch 1643 :: Batch 0/1
Batch Loss = 0.0007309484141823143
1643, epoch_train_loss=0.0007309484141823143
Epoch 1644
Epoch 1644 :: Batch 0/1
Batch Loss = 0.0007309484141823104
1644, epoch_train_loss=0.0007309484141823104
Epoch 1645
Epoch 1645 :: Batch 0/1
Batch Loss = 0.0007309484141823067
1645, epoch_train_loss=0.0007309484141823067
Epoch 1646
Epoch 1646 :: Batch 0/1
Batch Loss = 0.0007309484141823029
1646, epoch_train_loss=0.0007309484141823029
Epoch 1647
Epoch 1647 :: Batch 0/1
Batch Loss = 0.0007309484141822988
1647, epoch_train_loss=0.0007309484141822988
Epoch 1648
Epoch 1648 :: Batch 0/1
Batch Loss = 0.000730948414182295
1648, epoch_train_loss=0.000730948414182295
Epoch 1649
Epoch 1649 :: Batch 0/1
Batch Loss = 0.000730948414182291
1649, epoch_train_loss=0.000730948414182291
Epoch 1650
Epoch 1650 :: Batch 0/1
Batch Loss = 0.0007309484141822872
1650, epoch_train_loss=0.0007309484141822872
Epoch 1651
Epoch 1651 :: Batch 0/1
Batch Loss = 0.0007309484141822834
1651, epoch_train_loss=0.0007309484141822834
Epoch 1652
Epoch 1652 :: Batch 0/1
Batch Loss = 0.0007309484141822795
1652, epoch_train_loss=0.0007309484141822795
Epoch 1653
Epoch 1653 :: Batch 0/1
Batch Loss = 0.0007309484141822758
1653, epoch_train_loss=0.0007309484141822758
Epoch 1654
Epoch 1654 :: Batch 0/1
Batch Loss = 0.0007309484141822717
1654, epoch_train_loss=0.0007309484141822717
Epoch 1655
Epoch 1655 :: Batch 0/1
Batch Loss = 0.000730948414182268
1655, epoch_train_loss=0.000730948414182268
Epoch 1656
Epoch 1656 :: Batch 0/1
Batch Loss = 0.000730948414182264
1656, epoch_train_loss=0.000730948414182264
Epoch 1657
Epoch 1657 :: Batch 0/1
Batch Loss = 0.0007309484141822601
1657, epoch_train_loss=0.0007309484141822601
Epoch 1658
Epoch 1658 :: Batch 0/1
Batch Loss = 0.0007309484141822563
1658, epoch_train_loss=0.0007309484141822563
Epoch 1659
Epoch 1659 :: Batch 0/1
Batch Loss = 0.0007309484141822524
1659, epoch_train_loss=0.0007309484141822524
Epoch 1660
Epoch 1660 :: Batch 0/1
Batch Loss = 0.0007309484141822485
1660, epoch_train_loss=0.0007309484141822485
Epoch 1661
Epoch 1661 :: Batch 0/1
Batch Loss = 0.0007309484141822445
1661, epoch_train_loss=0.0007309484141822445
Epoch 1662
Epoch 1662 :: Batch 0/1
Batch Loss = 0.0007309484141822407
1662, epoch_train_loss=0.0007309484141822407
Epoch 1663
Epoch 1663 :: Batch 0/1
Batch Loss = 0.0007309484141822368
1663, epoch_train_loss=0.0007309484141822368
Epoch 1664
Epoch 1664 :: Batch 0/1
Batch Loss = 0.0007309484141822329
1664, epoch_train_loss=0.0007309484141822329
Epoch 1665
Epoch 1665 :: Batch 0/1
Batch Loss = 0.0007309484141822289
1665, epoch_train_loss=0.0007309484141822289
Epoch 1666
Epoch 1666 :: Batch 0/1
Batch Loss = 0.0007309484141822251
1666, epoch_train_loss=0.0007309484141822251
Epoch 1667
Epoch 1667 :: Batch 0/1
Batch Loss = 0.0007309484141822213
1667, epoch_train_loss=0.0007309484141822213
Epoch 1668
Epoch 1668 :: Batch 0/1
Batch Loss = 0.0007309484141822173
1668, epoch_train_loss=0.0007309484141822173
Epoch 1669
Epoch 1669 :: Batch 0/1
Batch Loss = 0.0007309484141822134
1669, epoch_train_loss=0.0007309484141822134
Epoch 1670
Epoch 1670 :: Batch 0/1
Batch Loss = 0.0007309484141822095
1670, epoch_train_loss=0.0007309484141822095
Epoch 1671
Epoch 1671 :: Batch 0/1
Batch Loss = 0.0007309484141822057
1671, epoch_train_loss=0.0007309484141822057
Epoch 1672
Epoch 1672 :: Batch 0/1
Batch Loss = 0.0007309484141822016
1672, epoch_train_loss=0.0007309484141822016
Epoch 1673
Epoch 1673 :: Batch 0/1
Batch Loss = 0.0007309484141821978
1673, epoch_train_loss=0.0007309484141821978
Epoch 1674
Epoch 1674 :: Batch 0/1
Batch Loss = 0.0007309484141821938
1674, epoch_train_loss=0.0007309484141821938
Epoch 1675
Epoch 1675 :: Batch 0/1
Batch Loss = 0.00073094841418219
1675, epoch_train_loss=0.00073094841418219
Epoch 1676
Epoch 1676 :: Batch 0/1
Batch Loss = 0.000730948414182186
1676, epoch_train_loss=0.000730948414182186
Epoch 1677
Epoch 1677 :: Batch 0/1
Batch Loss = 0.0007309484141821822
1677, epoch_train_loss=0.0007309484141821822
Epoch 1678
Epoch 1678 :: Batch 0/1
Batch Loss = 0.0007309484141821781
1678, epoch_train_loss=0.0007309484141821781
Epoch 1679
Epoch 1679 :: Batch 0/1
Batch Loss = 0.0007309484141821743
1679, epoch_train_loss=0.0007309484141821743
Epoch 1680
Epoch 1680 :: Batch 0/1
Batch Loss = 0.0007309484141821704
1680, epoch_train_loss=0.0007309484141821704
Epoch 1681
Epoch 1681 :: Batch 0/1
Batch Loss = 0.0007309484141821664
1681, epoch_train_loss=0.0007309484141821664
Epoch 1682
Epoch 1682 :: Batch 0/1
Batch Loss = 0.0007309484141821625
1682, epoch_train_loss=0.0007309484141821625
Epoch 1683
Epoch 1683 :: Batch 0/1
Batch Loss = 0.0007309484141821584
1683, epoch_train_loss=0.0007309484141821584
Epoch 1684
Epoch 1684 :: Batch 0/1
Batch Loss = 0.0007309484141821545
1684, epoch_train_loss=0.0007309484141821545
Epoch 1685
Epoch 1685 :: Batch 0/1
Batch Loss = 0.0007309484141821505
1685, epoch_train_loss=0.0007309484141821505
Epoch 1686
Epoch 1686 :: Batch 0/1
Batch Loss = 0.0007309484141821467
1686, epoch_train_loss=0.0007309484141821467
Epoch 1687
Epoch 1687 :: Batch 0/1
Batch Loss = 0.0007309484141821426
1687, epoch_train_loss=0.0007309484141821426
Epoch 1688
Epoch 1688 :: Batch 0/1
Batch Loss = 0.0007309484141821388
1688, epoch_train_loss=0.0007309484141821388
Epoch 1689
Epoch 1689 :: Batch 0/1
Batch Loss = 0.0007309484141821348
1689, epoch_train_loss=0.0007309484141821348
Epoch 1690
Epoch 1690 :: Batch 0/1
Batch Loss = 0.0007309484141821309
1690, epoch_train_loss=0.0007309484141821309
Epoch 1691
Epoch 1691 :: Batch 0/1
Batch Loss = 0.0007309484141821268
1691, epoch_train_loss=0.0007309484141821268
Epoch 1692
Epoch 1692 :: Batch 0/1
Batch Loss = 0.000730948414182123
1692, epoch_train_loss=0.000730948414182123
Epoch 1693
Epoch 1693 :: Batch 0/1
Batch Loss = 0.0007309484141821189
1693, epoch_train_loss=0.0007309484141821189
Epoch 1694
Epoch 1694 :: Batch 0/1
Batch Loss = 0.0007309484141821151
1694, epoch_train_loss=0.0007309484141821151
Epoch 1695
Epoch 1695 :: Batch 0/1
Batch Loss = 0.000730948414182111
1695, epoch_train_loss=0.000730948414182111
Epoch 1696
Epoch 1696 :: Batch 0/1
Batch Loss = 0.0007309484141821072
1696, epoch_train_loss=0.0007309484141821072
Epoch 1697
Epoch 1697 :: Batch 0/1
Batch Loss = 0.000730948414182103
1697, epoch_train_loss=0.000730948414182103
Epoch 1698
Epoch 1698 :: Batch 0/1
Batch Loss = 0.0007309484141820992
1698, epoch_train_loss=0.0007309484141820992
Epoch 1699
Epoch 1699 :: Batch 0/1
Batch Loss = 0.0007309484141820951
1699, epoch_train_loss=0.0007309484141820951
Epoch 1700
Epoch 1700 :: Batch 0/1
Batch Loss = 0.000730948414182091
1700, epoch_train_loss=0.000730948414182091
Epoch 1701
Epoch 1701 :: Batch 0/1
Batch Loss = 0.0007309484141820872
1701, epoch_train_loss=0.0007309484141820872
Epoch 1702
Epoch 1702 :: Batch 0/1
Batch Loss = 0.0007309484141820831
1702, epoch_train_loss=0.0007309484141820831
Epoch 1703
Epoch 1703 :: Batch 0/1
Batch Loss = 0.0007309484141820793
1703, epoch_train_loss=0.0007309484141820793
Epoch 1704
Epoch 1704 :: Batch 0/1
Batch Loss = 0.0007309484141820752
1704, epoch_train_loss=0.0007309484141820752
Epoch 1705
Epoch 1705 :: Batch 0/1
Batch Loss = 0.0007309484141820712
1705, epoch_train_loss=0.0007309484141820712
Epoch 1706
Epoch 1706 :: Batch 0/1
Batch Loss = 0.0007309484141820672
1706, epoch_train_loss=0.0007309484141820672
Epoch 1707
Epoch 1707 :: Batch 0/1
Batch Loss = 0.0007309484141820632
1707, epoch_train_loss=0.0007309484141820632
Epoch 1708
Epoch 1708 :: Batch 0/1
Batch Loss = 0.0007309484141820591
1708, epoch_train_loss=0.0007309484141820591
Epoch 1709
Epoch 1709 :: Batch 0/1
Batch Loss = 0.0007309484141820553
1709, epoch_train_loss=0.0007309484141820553
Epoch 1710
Epoch 1710 :: Batch 0/1
Batch Loss = 0.0007309484141820512
1710, epoch_train_loss=0.0007309484141820512
Epoch 1711
Epoch 1711 :: Batch 0/1
Batch Loss = 0.0007309484141820472
1711, epoch_train_loss=0.0007309484141820472
Epoch 1712
Epoch 1712 :: Batch 0/1
Batch Loss = 0.0007309484141820432
1712, epoch_train_loss=0.0007309484141820432
Epoch 1713
Epoch 1713 :: Batch 0/1
Batch Loss = 0.0007309484141820393
1713, epoch_train_loss=0.0007309484141820393
Epoch 1714
Epoch 1714 :: Batch 0/1
Batch Loss = 0.0007309484141820352
1714, epoch_train_loss=0.0007309484141820352
Epoch 1715
Epoch 1715 :: Batch 0/1
Batch Loss = 0.000730948414182031
1715, epoch_train_loss=0.000730948414182031
Epoch 1716
Epoch 1716 :: Batch 0/1
Batch Loss = 0.0007309484141820273
1716, epoch_train_loss=0.0007309484141820273
Epoch 1717
Epoch 1717 :: Batch 0/1
Batch Loss = 0.0007309484141820231
1717, epoch_train_loss=0.0007309484141820231
Epoch 1718
Epoch 1718 :: Batch 0/1
Batch Loss = 0.0007309484141820191
1718, epoch_train_loss=0.0007309484141820191
Epoch 1719
Epoch 1719 :: Batch 0/1
Batch Loss = 0.000730948414182015
1719, epoch_train_loss=0.000730948414182015
Epoch 1720
Epoch 1720 :: Batch 0/1
Batch Loss = 0.0007309484141820112
1720, epoch_train_loss=0.0007309484141820112
Epoch 1721
Epoch 1721 :: Batch 0/1
Batch Loss = 0.0007309484141820071
1721, epoch_train_loss=0.0007309484141820071
Epoch 1722
Epoch 1722 :: Batch 0/1
Batch Loss = 0.0007309484141820031
1722, epoch_train_loss=0.0007309484141820031
Epoch 1723
Epoch 1723 :: Batch 0/1
Batch Loss = 0.000730948414181999
1723, epoch_train_loss=0.000730948414181999
Epoch 1724
Epoch 1724 :: Batch 0/1
Batch Loss = 0.0007309484141819948
1724, epoch_train_loss=0.0007309484141819948
Epoch 1725
Epoch 1725 :: Batch 0/1
Batch Loss = 0.000730948414181991
1725, epoch_train_loss=0.000730948414181991
Epoch 1726
Epoch 1726 :: Batch 0/1
Batch Loss = 0.0007309484141819869
1726, epoch_train_loss=0.0007309484141819869
Epoch 1727
Epoch 1727 :: Batch 0/1
Batch Loss = 0.0007309484141819829
1727, epoch_train_loss=0.0007309484141819829
Epoch 1728
Epoch 1728 :: Batch 0/1
Batch Loss = 0.0007309484141819788
1728, epoch_train_loss=0.0007309484141819788
Epoch 1729
Epoch 1729 :: Batch 0/1
Batch Loss = 0.0007309484141819748
1729, epoch_train_loss=0.0007309484141819748
Epoch 1730
Epoch 1730 :: Batch 0/1
Batch Loss = 0.0007309484141819708
1730, epoch_train_loss=0.0007309484141819708
Epoch 1731
Epoch 1731 :: Batch 0/1
Batch Loss = 0.0007309484141819668
1731, epoch_train_loss=0.0007309484141819668
Epoch 1732
Epoch 1732 :: Batch 0/1
Batch Loss = 0.0007309484141819627
1732, epoch_train_loss=0.0007309484141819627
Epoch 1733
Epoch 1733 :: Batch 0/1
Batch Loss = 0.0007309484141819586
1733, epoch_train_loss=0.0007309484141819586
Epoch 1734
Epoch 1734 :: Batch 0/1
Batch Loss = 0.0007309484141819546
1734, epoch_train_loss=0.0007309484141819546
Epoch 1735
Epoch 1735 :: Batch 0/1
Batch Loss = 0.0007309484141819505
1735, epoch_train_loss=0.0007309484141819505
Epoch 1736
Epoch 1736 :: Batch 0/1
Batch Loss = 0.0007309484141819465
1736, epoch_train_loss=0.0007309484141819465
Epoch 1737
Epoch 1737 :: Batch 0/1
Batch Loss = 0.0007309484141819424
1737, epoch_train_loss=0.0007309484141819424
Epoch 1738
Epoch 1738 :: Batch 0/1
Batch Loss = 0.0007309484141819382
1738, epoch_train_loss=0.0007309484141819382
Epoch 1739
Epoch 1739 :: Batch 0/1
Batch Loss = 0.0007309484141819342
1739, epoch_train_loss=0.0007309484141819342
Epoch 1740
Epoch 1740 :: Batch 0/1
Batch Loss = 0.0007309484141819301
1740, epoch_train_loss=0.0007309484141819301
Epoch 1741
Epoch 1741 :: Batch 0/1
Batch Loss = 0.0007309484141819261
1741, epoch_train_loss=0.0007309484141819261
Epoch 1742
Epoch 1742 :: Batch 0/1
Batch Loss = 0.000730948414181922
1742, epoch_train_loss=0.000730948414181922
Epoch 1743
Epoch 1743 :: Batch 0/1
Batch Loss = 0.0007309484141819179
1743, epoch_train_loss=0.0007309484141819179
Epoch 1744
Epoch 1744 :: Batch 0/1
Batch Loss = 0.0007309484141819138
1744, epoch_train_loss=0.0007309484141819138
Epoch 1745
Epoch 1745 :: Batch 0/1
Batch Loss = 0.0007309484141819097
1745, epoch_train_loss=0.0007309484141819097
Epoch 1746
Epoch 1746 :: Batch 0/1
Batch Loss = 0.0007309484141819057
1746, epoch_train_loss=0.0007309484141819057
Epoch 1747
Epoch 1747 :: Batch 0/1
Batch Loss = 0.0007309484141819016
1747, epoch_train_loss=0.0007309484141819016
Epoch 1748
Epoch 1748 :: Batch 0/1
Batch Loss = 0.0007309484141818975
1748, epoch_train_loss=0.0007309484141818975
Epoch 1749
Epoch 1749 :: Batch 0/1
Batch Loss = 0.0007309484141818935
1749, epoch_train_loss=0.0007309484141818935
Epoch 1750
Epoch 1750 :: Batch 0/1
Batch Loss = 0.0007309484141818893
1750, epoch_train_loss=0.0007309484141818893
Epoch 1751
Epoch 1751 :: Batch 0/1
Batch Loss = 0.0007309484141818853
1751, epoch_train_loss=0.0007309484141818853
Epoch 1752
Epoch 1752 :: Batch 0/1
Batch Loss = 0.0007309484141818812
1752, epoch_train_loss=0.0007309484141818812
Epoch 1753
Epoch 1753 :: Batch 0/1
Batch Loss = 0.0007309484141818771
1753, epoch_train_loss=0.0007309484141818771
Epoch 1754
Epoch 1754 :: Batch 0/1
Batch Loss = 0.0007309484141818731
1754, epoch_train_loss=0.0007309484141818731
Epoch 1755
Epoch 1755 :: Batch 0/1
Batch Loss = 0.0007309484141818689
1755, epoch_train_loss=0.0007309484141818689
Epoch 1756
Epoch 1756 :: Batch 0/1
Batch Loss = 0.0007309484141818646
1756, epoch_train_loss=0.0007309484141818646
Epoch 1757
Epoch 1757 :: Batch 0/1
Batch Loss = 0.0007309484141818607
1757, epoch_train_loss=0.0007309484141818607
Epoch 1758
Epoch 1758 :: Batch 0/1
Batch Loss = 0.0007309484141818565
1758, epoch_train_loss=0.0007309484141818565
Epoch 1759
Epoch 1759 :: Batch 0/1
Batch Loss = 0.0007309484141818525
1759, epoch_train_loss=0.0007309484141818525
Epoch 1760
Epoch 1760 :: Batch 0/1
Batch Loss = 0.0007309484141818484
1760, epoch_train_loss=0.0007309484141818484
Epoch 1761
Epoch 1761 :: Batch 0/1
Batch Loss = 0.0007309484141818441
1761, epoch_train_loss=0.0007309484141818441
Epoch 1762
Epoch 1762 :: Batch 0/1
Batch Loss = 0.0007309484141818401
1762, epoch_train_loss=0.0007309484141818401
Epoch 1763
Epoch 1763 :: Batch 0/1
Batch Loss = 0.0007309484141818359
1763, epoch_train_loss=0.0007309484141818359
Epoch 1764
Epoch 1764 :: Batch 0/1
Batch Loss = 0.0007309484141818318
1764, epoch_train_loss=0.0007309484141818318
Epoch 1765
Epoch 1765 :: Batch 0/1
Batch Loss = 0.0007309484141818278
1765, epoch_train_loss=0.0007309484141818278
Epoch 1766
Epoch 1766 :: Batch 0/1
Batch Loss = 0.0007309484141818236
1766, epoch_train_loss=0.0007309484141818236
Epoch 1767
Epoch 1767 :: Batch 0/1
Batch Loss = 0.0007309484141818194
1767, epoch_train_loss=0.0007309484141818194
Epoch 1768
Epoch 1768 :: Batch 0/1
Batch Loss = 0.0007309484141818153
1768, epoch_train_loss=0.0007309484141818153
Epoch 1769
Epoch 1769 :: Batch 0/1
Batch Loss = 0.0007309484141818112
1769, epoch_train_loss=0.0007309484141818112
Epoch 1770
Epoch 1770 :: Batch 0/1
Batch Loss = 0.0007309484141818069
1770, epoch_train_loss=0.0007309484141818069
Epoch 1771
Epoch 1771 :: Batch 0/1
Batch Loss = 0.0007309484141818029
1771, epoch_train_loss=0.0007309484141818029
Epoch 1772
Epoch 1772 :: Batch 0/1
Batch Loss = 0.0007309484141817988
1772, epoch_train_loss=0.0007309484141817988
Epoch 1773
Epoch 1773 :: Batch 0/1
Batch Loss = 0.0007309484141817946
1773, epoch_train_loss=0.0007309484141817946
Epoch 1774
Epoch 1774 :: Batch 0/1
Batch Loss = 0.0007309484141817906
1774, epoch_train_loss=0.0007309484141817906
Epoch 1775
Epoch 1775 :: Batch 0/1
Batch Loss = 0.0007309484141817862
1775, epoch_train_loss=0.0007309484141817862
Epoch 1776
Epoch 1776 :: Batch 0/1
Batch Loss = 0.0007309484141817821
1776, epoch_train_loss=0.0007309484141817821
Epoch 1777
Epoch 1777 :: Batch 0/1
Batch Loss = 0.0007309484141817781
1777, epoch_train_loss=0.0007309484141817781
Epoch 1778
Epoch 1778 :: Batch 0/1
Batch Loss = 0.0007309484141817739
1778, epoch_train_loss=0.0007309484141817739
Epoch 1779
Epoch 1779 :: Batch 0/1
Batch Loss = 0.0007309484141817696
1779, epoch_train_loss=0.0007309484141817696
Epoch 1780
Epoch 1780 :: Batch 0/1
Batch Loss = 0.0007309484141817656
1780, epoch_train_loss=0.0007309484141817656
Epoch 1781
Epoch 1781 :: Batch 0/1
Batch Loss = 0.0007309484141817614
1781, epoch_train_loss=0.0007309484141817614
Epoch 1782
Epoch 1782 :: Batch 0/1
Batch Loss = 0.0007309484141817572
1782, epoch_train_loss=0.0007309484141817572
Epoch 1783
Epoch 1783 :: Batch 0/1
Batch Loss = 0.0007309484141817531
1783, epoch_train_loss=0.0007309484141817531
Epoch 1784
Epoch 1784 :: Batch 0/1
Batch Loss = 0.0007309484141817488
1784, epoch_train_loss=0.0007309484141817488
Epoch 1785
Epoch 1785 :: Batch 0/1
Batch Loss = 0.0007309484141817447
1785, epoch_train_loss=0.0007309484141817447
Epoch 1786
Epoch 1786 :: Batch 0/1
Batch Loss = 0.0007309484141817405
1786, epoch_train_loss=0.0007309484141817405
Epoch 1787
Epoch 1787 :: Batch 0/1
Batch Loss = 0.0007309484141817364
1787, epoch_train_loss=0.0007309484141817364
Epoch 1788
Epoch 1788 :: Batch 0/1
Batch Loss = 0.0007309484141817321
1788, epoch_train_loss=0.0007309484141817321
Epoch 1789
Epoch 1789 :: Batch 0/1
Batch Loss = 0.0007309484141817279
1789, epoch_train_loss=0.0007309484141817279
Epoch 1790
Epoch 1790 :: Batch 0/1
Batch Loss = 0.0007309484141817239
1790, epoch_train_loss=0.0007309484141817239
Epoch 1791
Epoch 1791 :: Batch 0/1
Batch Loss = 0.0007309484141817196
1791, epoch_train_loss=0.0007309484141817196
Epoch 1792
Epoch 1792 :: Batch 0/1
Batch Loss = 0.0007309484141817153
1792, epoch_train_loss=0.0007309484141817153
Epoch 1793
Epoch 1793 :: Batch 0/1
Batch Loss = 0.0007309484141817113
1793, epoch_train_loss=0.0007309484141817113
Epoch 1794
Epoch 1794 :: Batch 0/1
Batch Loss = 0.0007309484141817071
1794, epoch_train_loss=0.0007309484141817071
Epoch 1795
Epoch 1795 :: Batch 0/1
Batch Loss = 0.0007309484141817028
1795, epoch_train_loss=0.0007309484141817028
Epoch 1796
Epoch 1796 :: Batch 0/1
Batch Loss = 0.0007309484141816986
1796, epoch_train_loss=0.0007309484141816986
Epoch 1797
Epoch 1797 :: Batch 0/1
Batch Loss = 0.0007309484141816944
1797, epoch_train_loss=0.0007309484141816944
Epoch 1798
Epoch 1798 :: Batch 0/1
Batch Loss = 0.0007309484141816903
1798, epoch_train_loss=0.0007309484141816903
Epoch 1799
Epoch 1799 :: Batch 0/1
Batch Loss = 0.000730948414181686
1799, epoch_train_loss=0.000730948414181686
Epoch 1800
Epoch 1800 :: Batch 0/1
Batch Loss = 0.0007309484141816818
1800, epoch_train_loss=0.0007309484141816818
Epoch 1801
Epoch 1801 :: Batch 0/1
Batch Loss = 0.0007309484141816776
1801, epoch_train_loss=0.0007309484141816776
Epoch 1802
Epoch 1802 :: Batch 0/1
Batch Loss = 0.0007309484141816734
1802, epoch_train_loss=0.0007309484141816734
Epoch 1803
Epoch 1803 :: Batch 0/1
Batch Loss = 0.0007309484141816692
1803, epoch_train_loss=0.0007309484141816692
Epoch 1804
Epoch 1804 :: Batch 0/1
Batch Loss = 0.0007309484141816649
1804, epoch_train_loss=0.0007309484141816649
Epoch 1805
Epoch 1805 :: Batch 0/1
Batch Loss = 0.0007309484141816607
1805, epoch_train_loss=0.0007309484141816607
Epoch 1806
Epoch 1806 :: Batch 0/1
Batch Loss = 0.0007309484141816565
1806, epoch_train_loss=0.0007309484141816565
Epoch 1807
Epoch 1807 :: Batch 0/1
Batch Loss = 0.0007309484141816523
1807, epoch_train_loss=0.0007309484141816523
Epoch 1808
Epoch 1808 :: Batch 0/1
Batch Loss = 0.0007309484141816481
1808, epoch_train_loss=0.0007309484141816481
Epoch 1809
Epoch 1809 :: Batch 0/1
Batch Loss = 0.0007309484141816438
1809, epoch_train_loss=0.0007309484141816438
Epoch 1810
Epoch 1810 :: Batch 0/1
Batch Loss = 0.0007309484141816397
1810, epoch_train_loss=0.0007309484141816397
Epoch 1811
Epoch 1811 :: Batch 0/1
Batch Loss = 0.0007309484141816354
1811, epoch_train_loss=0.0007309484141816354
Epoch 1812
Epoch 1812 :: Batch 0/1
Batch Loss = 0.0007309484141816311
1812, epoch_train_loss=0.0007309484141816311
Epoch 1813
Epoch 1813 :: Batch 0/1
Batch Loss = 0.000730948414181627
1813, epoch_train_loss=0.000730948414181627
Epoch 1814
Epoch 1814 :: Batch 0/1
Batch Loss = 0.0007309484141816226
1814, epoch_train_loss=0.0007309484141816226
Epoch 1815
Epoch 1815 :: Batch 0/1
Batch Loss = 0.0007309484141816184
1815, epoch_train_loss=0.0007309484141816184
Epoch 1816
Epoch 1816 :: Batch 0/1
Batch Loss = 0.0007309484141816142
1816, epoch_train_loss=0.0007309484141816142
Epoch 1817
Epoch 1817 :: Batch 0/1
Batch Loss = 0.0007309484141816099
1817, epoch_train_loss=0.0007309484141816099
Epoch 1818
Epoch 1818 :: Batch 0/1
Batch Loss = 0.0007309484141816056
1818, epoch_train_loss=0.0007309484141816056
Epoch 1819
Epoch 1819 :: Batch 0/1
Batch Loss = 0.0007309484141816015
1819, epoch_train_loss=0.0007309484141816015
Epoch 1820
Epoch 1820 :: Batch 0/1
Batch Loss = 0.0007309484141815971
1820, epoch_train_loss=0.0007309484141815971
Epoch 1821
Epoch 1821 :: Batch 0/1
Batch Loss = 0.0007309484141815928
1821, epoch_train_loss=0.0007309484141815928
Epoch 1822
Epoch 1822 :: Batch 0/1
Batch Loss = 0.0007309484141815886
1822, epoch_train_loss=0.0007309484141815886
Epoch 1823
Epoch 1823 :: Batch 0/1
Batch Loss = 0.0007309484141815844
1823, epoch_train_loss=0.0007309484141815844
Epoch 1824
Epoch 1824 :: Batch 0/1
Batch Loss = 0.00073094841418158
1824, epoch_train_loss=0.00073094841418158
Epoch 1825
Epoch 1825 :: Batch 0/1
Batch Loss = 0.0007309484141815759
1825, epoch_train_loss=0.0007309484141815759
Epoch 1826
Epoch 1826 :: Batch 0/1
Batch Loss = 0.0007309484141815716
1826, epoch_train_loss=0.0007309484141815716
Epoch 1827
Epoch 1827 :: Batch 0/1
Batch Loss = 0.0007309484141815672
1827, epoch_train_loss=0.0007309484141815672
Epoch 1828
Epoch 1828 :: Batch 0/1
Batch Loss = 0.0007309484141815631
1828, epoch_train_loss=0.0007309484141815631
Epoch 1829
Epoch 1829 :: Batch 0/1
Batch Loss = 0.0007309484141815588
1829, epoch_train_loss=0.0007309484141815588
Epoch 1830
Epoch 1830 :: Batch 0/1
Batch Loss = 0.0007309484141815545
1830, epoch_train_loss=0.0007309484141815545
Epoch 1831
Epoch 1831 :: Batch 0/1
Batch Loss = 0.0007309484141815502
1831, epoch_train_loss=0.0007309484141815502
Epoch 1832
Epoch 1832 :: Batch 0/1
Batch Loss = 0.000730948414181546
1832, epoch_train_loss=0.000730948414181546
Epoch 1833
Epoch 1833 :: Batch 0/1
Batch Loss = 0.0007309484141815416
1833, epoch_train_loss=0.0007309484141815416
Epoch 1834
Epoch 1834 :: Batch 0/1
Batch Loss = 0.0007309484141815373
1834, epoch_train_loss=0.0007309484141815373
Epoch 1835
Epoch 1835 :: Batch 0/1
Batch Loss = 0.0007309484141815331
1835, epoch_train_loss=0.0007309484141815331
Epoch 1836
Epoch 1836 :: Batch 0/1
Batch Loss = 0.0007309484141815287
1836, epoch_train_loss=0.0007309484141815287
Epoch 1837
Epoch 1837 :: Batch 0/1
Batch Loss = 0.0007309484141815245
1837, epoch_train_loss=0.0007309484141815245
Epoch 1838
Epoch 1838 :: Batch 0/1
Batch Loss = 0.0007309484141815202
1838, epoch_train_loss=0.0007309484141815202
Epoch 1839
Epoch 1839 :: Batch 0/1
Batch Loss = 0.0007309484141815158
1839, epoch_train_loss=0.0007309484141815158
Epoch 1840
Epoch 1840 :: Batch 0/1
Batch Loss = 0.0007309484141815115
1840, epoch_train_loss=0.0007309484141815115
Epoch 1841
Epoch 1841 :: Batch 0/1
Batch Loss = 0.0007309484141815073
1841, epoch_train_loss=0.0007309484141815073
Epoch 1842
Epoch 1842 :: Batch 0/1
Batch Loss = 0.000730948414181503
1842, epoch_train_loss=0.000730948414181503
Epoch 1843
Epoch 1843 :: Batch 0/1
Batch Loss = 0.0007309484141814987
1843, epoch_train_loss=0.0007309484141814987
Epoch 1844
Epoch 1844 :: Batch 0/1
Batch Loss = 0.0007309484141814944
1844, epoch_train_loss=0.0007309484141814944
Epoch 1845
Epoch 1845 :: Batch 0/1
Batch Loss = 0.00073094841418149
1845, epoch_train_loss=0.00073094841418149
Epoch 1846
Epoch 1846 :: Batch 0/1
Batch Loss = 0.0007309484141814857
1846, epoch_train_loss=0.0007309484141814857
Epoch 1847
Epoch 1847 :: Batch 0/1
Batch Loss = 0.0007309484141814815
1847, epoch_train_loss=0.0007309484141814815
Epoch 1848
Epoch 1848 :: Batch 0/1
Batch Loss = 0.0007309484141814771
1848, epoch_train_loss=0.0007309484141814771
Epoch 1849
Epoch 1849 :: Batch 0/1
Batch Loss = 0.0007309484141814728
1849, epoch_train_loss=0.0007309484141814728
Epoch 1850
Epoch 1850 :: Batch 0/1
Batch Loss = 0.0007309484141814685
1850, epoch_train_loss=0.0007309484141814685
Epoch 1851
Epoch 1851 :: Batch 0/1
Batch Loss = 0.0007309484141814641
1851, epoch_train_loss=0.0007309484141814641
Epoch 1852
Epoch 1852 :: Batch 0/1
Batch Loss = 0.0007309484141814598
1852, epoch_train_loss=0.0007309484141814598
Epoch 1853
Epoch 1853 :: Batch 0/1
Batch Loss = 0.0007309484141814556
1853, epoch_train_loss=0.0007309484141814556
Epoch 1854
Epoch 1854 :: Batch 0/1
Batch Loss = 0.0007309484141814511
1854, epoch_train_loss=0.0007309484141814511
Epoch 1855
Epoch 1855 :: Batch 0/1
Batch Loss = 0.0007309484141814468
1855, epoch_train_loss=0.0007309484141814468
Epoch 1856
Epoch 1856 :: Batch 0/1
Batch Loss = 0.0007309484141814424
1856, epoch_train_loss=0.0007309484141814424
Epoch 1857
Epoch 1857 :: Batch 0/1
Batch Loss = 0.000730948414181438
1857, epoch_train_loss=0.000730948414181438
Epoch 1858
Epoch 1858 :: Batch 0/1
Batch Loss = 0.0007309484141814337
1858, epoch_train_loss=0.0007309484141814337
Epoch 1859
Epoch 1859 :: Batch 0/1
Batch Loss = 0.0007309484141814294
1859, epoch_train_loss=0.0007309484141814294
Epoch 1860
Epoch 1860 :: Batch 0/1
Batch Loss = 0.0007309484141814251
1860, epoch_train_loss=0.0007309484141814251
Epoch 1861
Epoch 1861 :: Batch 0/1
Batch Loss = 0.0007309484141814208
1861, epoch_train_loss=0.0007309484141814208
Epoch 1862
Epoch 1862 :: Batch 0/1
Batch Loss = 0.0007309484141814164
1862, epoch_train_loss=0.0007309484141814164
Epoch 1863
Epoch 1863 :: Batch 0/1
Batch Loss = 0.0007309484141814119
1863, epoch_train_loss=0.0007309484141814119
Epoch 1864
Epoch 1864 :: Batch 0/1
Batch Loss = 0.0007309484141814076
1864, epoch_train_loss=0.0007309484141814076
Epoch 1865
Epoch 1865 :: Batch 0/1
Batch Loss = 0.0007309484141814032
1865, epoch_train_loss=0.0007309484141814032
Epoch 1866
Epoch 1866 :: Batch 0/1
Batch Loss = 0.000730948414181399
1866, epoch_train_loss=0.000730948414181399
Epoch 1867
Epoch 1867 :: Batch 0/1
Batch Loss = 0.0007309484141813946
1867, epoch_train_loss=0.0007309484141813946
Epoch 1868
Epoch 1868 :: Batch 0/1
Batch Loss = 0.0007309484141813902
1868, epoch_train_loss=0.0007309484141813902
Epoch 1869
Epoch 1869 :: Batch 0/1
Batch Loss = 0.0007309484141813857
1869, epoch_train_loss=0.0007309484141813857
Epoch 1870
Epoch 1870 :: Batch 0/1
Batch Loss = 0.0007309484141813814
1870, epoch_train_loss=0.0007309484141813814
Epoch 1871
Epoch 1871 :: Batch 0/1
Batch Loss = 0.0007309484141813771
1871, epoch_train_loss=0.0007309484141813771
Epoch 1872
Epoch 1872 :: Batch 0/1
Batch Loss = 0.0007309484141813728
1872, epoch_train_loss=0.0007309484141813728
Epoch 1873
Epoch 1873 :: Batch 0/1
Batch Loss = 0.0007309484141813682
1873, epoch_train_loss=0.0007309484141813682
Epoch 1874
Epoch 1874 :: Batch 0/1
Batch Loss = 0.0007309484141813639
1874, epoch_train_loss=0.0007309484141813639
Epoch 1875
Epoch 1875 :: Batch 0/1
Batch Loss = 0.0007309484141813596
1875, epoch_train_loss=0.0007309484141813596
Epoch 1876
Epoch 1876 :: Batch 0/1
Batch Loss = 0.0007309484141813552
1876, epoch_train_loss=0.0007309484141813552
Epoch 1877
Epoch 1877 :: Batch 0/1
Batch Loss = 0.0007309484141813507
1877, epoch_train_loss=0.0007309484141813507
Epoch 1878
Epoch 1878 :: Batch 0/1
Batch Loss = 0.0007309484141813464
1878, epoch_train_loss=0.0007309484141813464
Epoch 1879
Epoch 1879 :: Batch 0/1
Batch Loss = 0.0007309484141813419
1879, epoch_train_loss=0.0007309484141813419
Epoch 1880
Epoch 1880 :: Batch 0/1
Batch Loss = 0.0007309484141813375
1880, epoch_train_loss=0.0007309484141813375
Epoch 1881
Epoch 1881 :: Batch 0/1
Batch Loss = 0.0007309484141813333
1881, epoch_train_loss=0.0007309484141813333
Epoch 1882
Epoch 1882 :: Batch 0/1
Batch Loss = 0.0007309484141813288
1882, epoch_train_loss=0.0007309484141813288
Epoch 1883
Epoch 1883 :: Batch 0/1
Batch Loss = 0.0007309484141813244
1883, epoch_train_loss=0.0007309484141813244
Epoch 1884
Epoch 1884 :: Batch 0/1
Batch Loss = 0.0007309484141813199
1884, epoch_train_loss=0.0007309484141813199
Epoch 1885
Epoch 1885 :: Batch 0/1
Batch Loss = 0.0007309484141813156
1885, epoch_train_loss=0.0007309484141813156
Epoch 1886
Epoch 1886 :: Batch 0/1
Batch Loss = 0.0007309484141813111
1886, epoch_train_loss=0.0007309484141813111
Epoch 1887
Epoch 1887 :: Batch 0/1
Batch Loss = 0.0007309484141813067
1887, epoch_train_loss=0.0007309484141813067
Epoch 1888
Epoch 1888 :: Batch 0/1
Batch Loss = 0.0007309484141813022
1888, epoch_train_loss=0.0007309484141813022
Epoch 1889
Epoch 1889 :: Batch 0/1
Batch Loss = 0.0007309484141812979
1889, epoch_train_loss=0.0007309484141812979
Epoch 1890
Epoch 1890 :: Batch 0/1
Batch Loss = 0.0007309484141812934
1890, epoch_train_loss=0.0007309484141812934
Epoch 1891
Epoch 1891 :: Batch 0/1
Batch Loss = 0.0007309484141812891
1891, epoch_train_loss=0.0007309484141812891
Epoch 1892
Epoch 1892 :: Batch 0/1
Batch Loss = 0.0007309484141812845
1892, epoch_train_loss=0.0007309484141812845
Epoch 1893
Epoch 1893 :: Batch 0/1
Batch Loss = 0.0007309484141812802
1893, epoch_train_loss=0.0007309484141812802
Epoch 1894
Epoch 1894 :: Batch 0/1
Batch Loss = 0.0007309484141812757
1894, epoch_train_loss=0.0007309484141812757
Epoch 1895
Epoch 1895 :: Batch 0/1
Batch Loss = 0.0007309484141812713
1895, epoch_train_loss=0.0007309484141812713
Epoch 1896
Epoch 1896 :: Batch 0/1
Batch Loss = 0.0007309484141812669
1896, epoch_train_loss=0.0007309484141812669
Epoch 1897
Epoch 1897 :: Batch 0/1
Batch Loss = 0.0007309484141812625
1897, epoch_train_loss=0.0007309484141812625
Epoch 1898
Epoch 1898 :: Batch 0/1
Batch Loss = 0.0007309484141812579
1898, epoch_train_loss=0.0007309484141812579
Epoch 1899
Epoch 1899 :: Batch 0/1
Batch Loss = 0.0007309484141812536
1899, epoch_train_loss=0.0007309484141812536
Epoch 1900
Epoch 1900 :: Batch 0/1
Batch Loss = 0.000730948414181249
1900, epoch_train_loss=0.000730948414181249
Epoch 1901
Epoch 1901 :: Batch 0/1
Batch Loss = 0.0007309484141812447
1901, epoch_train_loss=0.0007309484141812447
Epoch 1902
Epoch 1902 :: Batch 0/1
Batch Loss = 0.0007309484141812401
1902, epoch_train_loss=0.0007309484141812401
Epoch 1903
Epoch 1903 :: Batch 0/1
Batch Loss = 0.0007309484141812358
1903, epoch_train_loss=0.0007309484141812358
Epoch 1904
Epoch 1904 :: Batch 0/1
Batch Loss = 0.0007309484141812312
1904, epoch_train_loss=0.0007309484141812312
Epoch 1905
Epoch 1905 :: Batch 0/1
Batch Loss = 0.0007309484141812267
1905, epoch_train_loss=0.0007309484141812267
Epoch 1906
Epoch 1906 :: Batch 0/1
Batch Loss = 0.0007309484141812224
1906, epoch_train_loss=0.0007309484141812224
Epoch 1907
Epoch 1907 :: Batch 0/1
Batch Loss = 0.0007309484141812179
1907, epoch_train_loss=0.0007309484141812179
Epoch 1908
Epoch 1908 :: Batch 0/1
Batch Loss = 0.0007309484141812136
1908, epoch_train_loss=0.0007309484141812136
Epoch 1909
Epoch 1909 :: Batch 0/1
Batch Loss = 0.000730948414181209
1909, epoch_train_loss=0.000730948414181209
Epoch 1910
Epoch 1910 :: Batch 0/1
Batch Loss = 0.0007309484141812045
1910, epoch_train_loss=0.0007309484141812045
Epoch 1911
Epoch 1911 :: Batch 0/1
Batch Loss = 0.0007309484141812001
1911, epoch_train_loss=0.0007309484141812001
Epoch 1912
Epoch 1912 :: Batch 0/1
Batch Loss = 0.0007309484141811956
1912, epoch_train_loss=0.0007309484141811956
Epoch 1913
Epoch 1913 :: Batch 0/1
Batch Loss = 0.0007309484141811911
1913, epoch_train_loss=0.0007309484141811911
Epoch 1914
Epoch 1914 :: Batch 0/1
Batch Loss = 0.0007309484141811867
1914, epoch_train_loss=0.0007309484141811867
Epoch 1915
Epoch 1915 :: Batch 0/1
Batch Loss = 0.0007309484141811821
1915, epoch_train_loss=0.0007309484141811821
Epoch 1916
Epoch 1916 :: Batch 0/1
Batch Loss = 0.0007309484141811777
1916, epoch_train_loss=0.0007309484141811777
Epoch 1917
Epoch 1917 :: Batch 0/1
Batch Loss = 0.0007309484141811731
1917, epoch_train_loss=0.0007309484141811731
Epoch 1918
Epoch 1918 :: Batch 0/1
Batch Loss = 0.0007309484141811687
1918, epoch_train_loss=0.0007309484141811687
Epoch 1919
Epoch 1919 :: Batch 0/1
Batch Loss = 0.0007309484141811641
1919, epoch_train_loss=0.0007309484141811641
Epoch 1920
Epoch 1920 :: Batch 0/1
Batch Loss = 0.0007309484141811597
1920, epoch_train_loss=0.0007309484141811597
Epoch 1921
Epoch 1921 :: Batch 0/1
Batch Loss = 0.0007309484141811551
1921, epoch_train_loss=0.0007309484141811551
Epoch 1922
Epoch 1922 :: Batch 0/1
Batch Loss = 0.0007309484141811507
1922, epoch_train_loss=0.0007309484141811507
Epoch 1923
Epoch 1923 :: Batch 0/1
Batch Loss = 0.0007309484141811461
1923, epoch_train_loss=0.0007309484141811461
Epoch 1924
Epoch 1924 :: Batch 0/1
Batch Loss = 0.0007309484141811417
1924, epoch_train_loss=0.0007309484141811417
Epoch 1925
Epoch 1925 :: Batch 0/1
Batch Loss = 0.0007309484141811371
1925, epoch_train_loss=0.0007309484141811371
Epoch 1926
Epoch 1926 :: Batch 0/1
Batch Loss = 0.0007309484141811327
1926, epoch_train_loss=0.0007309484141811327
Epoch 1927
Epoch 1927 :: Batch 0/1
Batch Loss = 0.0007309484141811281
1927, epoch_train_loss=0.0007309484141811281
Epoch 1928
Epoch 1928 :: Batch 0/1
Batch Loss = 0.0007309484141811236
1928, epoch_train_loss=0.0007309484141811236
Epoch 1929
Epoch 1929 :: Batch 0/1
Batch Loss = 0.0007309484141811191
1929, epoch_train_loss=0.0007309484141811191
Epoch 1930
Epoch 1930 :: Batch 0/1
Batch Loss = 0.0007309484141811146
1930, epoch_train_loss=0.0007309484141811146
Epoch 1931
Epoch 1931 :: Batch 0/1
Batch Loss = 0.00073094841418111
1931, epoch_train_loss=0.00073094841418111
Epoch 1932
Epoch 1932 :: Batch 0/1
Batch Loss = 0.0007309484141811055
1932, epoch_train_loss=0.0007309484141811055
Epoch 1933
Epoch 1933 :: Batch 0/1
Batch Loss = 0.000730948414181101
1933, epoch_train_loss=0.000730948414181101
Epoch 1934
Epoch 1934 :: Batch 0/1
Batch Loss = 0.0007309484141810965
1934, epoch_train_loss=0.0007309484141810965
Epoch 1935
Epoch 1935 :: Batch 0/1
Batch Loss = 0.0007309484141810919
1935, epoch_train_loss=0.0007309484141810919
Epoch 1936
Epoch 1936 :: Batch 0/1
Batch Loss = 0.0007309484141810875
1936, epoch_train_loss=0.0007309484141810875
Epoch 1937
Epoch 1937 :: Batch 0/1
Batch Loss = 0.0007309484141810829
1937, epoch_train_loss=0.0007309484141810829
Epoch 1938
Epoch 1938 :: Batch 0/1
Batch Loss = 0.0007309484141810784
1938, epoch_train_loss=0.0007309484141810784
Epoch 1939
Epoch 1939 :: Batch 0/1
Batch Loss = 0.0007309484141810738
1939, epoch_train_loss=0.0007309484141810738
Epoch 1940
Epoch 1940 :: Batch 0/1
Batch Loss = 0.0007309484141810693
1940, epoch_train_loss=0.0007309484141810693
Epoch 1941
Epoch 1941 :: Batch 0/1
Batch Loss = 0.0007309484141810647
1941, epoch_train_loss=0.0007309484141810647
Epoch 1942
Epoch 1942 :: Batch 0/1
Batch Loss = 0.0007309484141810601
1942, epoch_train_loss=0.0007309484141810601
Epoch 1943
Epoch 1943 :: Batch 0/1
Batch Loss = 0.0007309484141810556
1943, epoch_train_loss=0.0007309484141810556
Epoch 1944
Epoch 1944 :: Batch 0/1
Batch Loss = 0.0007309484141810511
1944, epoch_train_loss=0.0007309484141810511
Epoch 1945
Epoch 1945 :: Batch 0/1
Batch Loss = 0.0007309484141810465
1945, epoch_train_loss=0.0007309484141810465
Epoch 1946
Epoch 1946 :: Batch 0/1
Batch Loss = 0.0007309484141810419
1946, epoch_train_loss=0.0007309484141810419
Epoch 1947
Epoch 1947 :: Batch 0/1
Batch Loss = 0.0007309484141810374
1947, epoch_train_loss=0.0007309484141810374
Epoch 1948
Epoch 1948 :: Batch 0/1
Batch Loss = 0.0007309484141810328
1948, epoch_train_loss=0.0007309484141810328
Epoch 1949
Epoch 1949 :: Batch 0/1
Batch Loss = 0.0007309484141810283
1949, epoch_train_loss=0.0007309484141810283
Epoch 1950
Epoch 1950 :: Batch 0/1
Batch Loss = 0.0007309484141810237
1950, epoch_train_loss=0.0007309484141810237
Epoch 1951
Epoch 1951 :: Batch 0/1
Batch Loss = 0.0007309484141810192
1951, epoch_train_loss=0.0007309484141810192
Epoch 1952
Epoch 1952 :: Batch 0/1
Batch Loss = 0.0007309484141810146
1952, epoch_train_loss=0.0007309484141810146
Epoch 1953
Epoch 1953 :: Batch 0/1
Batch Loss = 0.0007309484141810101
1953, epoch_train_loss=0.0007309484141810101
Epoch 1954
Epoch 1954 :: Batch 0/1
Batch Loss = 0.0007309484141810055
1954, epoch_train_loss=0.0007309484141810055
Epoch 1955
Epoch 1955 :: Batch 0/1
Batch Loss = 0.0007309484141810008
1955, epoch_train_loss=0.0007309484141810008
Epoch 1956
Epoch 1956 :: Batch 0/1
Batch Loss = 0.0007309484141809963
1956, epoch_train_loss=0.0007309484141809963
Epoch 1957
Epoch 1957 :: Batch 0/1
Batch Loss = 0.0007309484141809917
1957, epoch_train_loss=0.0007309484141809917
Epoch 1958
Epoch 1958 :: Batch 0/1
Batch Loss = 0.000730948414180987
1958, epoch_train_loss=0.000730948414180987
Epoch 1959
Epoch 1959 :: Batch 0/1
Batch Loss = 0.0007309484141809826
1959, epoch_train_loss=0.0007309484141809826
Epoch 1960
Epoch 1960 :: Batch 0/1
Batch Loss = 0.0007309484141809779
1960, epoch_train_loss=0.0007309484141809779
Epoch 1961
Epoch 1961 :: Batch 0/1
Batch Loss = 0.0007309484141809733
1961, epoch_train_loss=0.0007309484141809733
Epoch 1962
Epoch 1962 :: Batch 0/1
Batch Loss = 0.0007309484141809686
1962, epoch_train_loss=0.0007309484141809686
Epoch 1963
Epoch 1963 :: Batch 0/1
Batch Loss = 0.0007309484141809641
1963, epoch_train_loss=0.0007309484141809641
Epoch 1964
Epoch 1964 :: Batch 0/1
Batch Loss = 0.0007309484141809595
1964, epoch_train_loss=0.0007309484141809595
Epoch 1965
Epoch 1965 :: Batch 0/1
Batch Loss = 0.0007309484141809549
1965, epoch_train_loss=0.0007309484141809549
Epoch 1966
Epoch 1966 :: Batch 0/1
Batch Loss = 0.0007309484141809503
1966, epoch_train_loss=0.0007309484141809503
Epoch 1967
Epoch 1967 :: Batch 0/1
Batch Loss = 0.0007309484141809457
1967, epoch_train_loss=0.0007309484141809457
Epoch 1968
Epoch 1968 :: Batch 0/1
Batch Loss = 0.0007309484141809411
1968, epoch_train_loss=0.0007309484141809411
Epoch 1969
Epoch 1969 :: Batch 0/1
Batch Loss = 0.0007309484141809365
1969, epoch_train_loss=0.0007309484141809365
Epoch 1970
Epoch 1970 :: Batch 0/1
Batch Loss = 0.0007309484141809319
1970, epoch_train_loss=0.0007309484141809319
Epoch 1971
Epoch 1971 :: Batch 0/1
Batch Loss = 0.0007309484141809273
1971, epoch_train_loss=0.0007309484141809273
Epoch 1972
Epoch 1972 :: Batch 0/1
Batch Loss = 0.0007309484141809227
1972, epoch_train_loss=0.0007309484141809227
Epoch 1973
Epoch 1973 :: Batch 0/1
Batch Loss = 0.0007309484141809181
1973, epoch_train_loss=0.0007309484141809181
Epoch 1974
Epoch 1974 :: Batch 0/1
Batch Loss = 0.0007309484141809133
1974, epoch_train_loss=0.0007309484141809133
Epoch 1975
Epoch 1975 :: Batch 0/1
Batch Loss = 0.0007309484141809087
1975, epoch_train_loss=0.0007309484141809087
Epoch 1976
Epoch 1976 :: Batch 0/1
Batch Loss = 0.0007309484141809041
1976, epoch_train_loss=0.0007309484141809041
Epoch 1977
Epoch 1977 :: Batch 0/1
Batch Loss = 0.0007309484141808994
1977, epoch_train_loss=0.0007309484141808994
Epoch 1978
Epoch 1978 :: Batch 0/1
Batch Loss = 0.0007309484141808948
1978, epoch_train_loss=0.0007309484141808948
Epoch 1979
Epoch 1979 :: Batch 0/1
Batch Loss = 0.0007309484141808903
1979, epoch_train_loss=0.0007309484141808903
Epoch 1980
Epoch 1980 :: Batch 0/1
Batch Loss = 0.0007309484141808855
1980, epoch_train_loss=0.0007309484141808855
Epoch 1981
Epoch 1981 :: Batch 0/1
Batch Loss = 0.0007309484141808809
1981, epoch_train_loss=0.0007309484141808809
Epoch 1982
Epoch 1982 :: Batch 0/1
Batch Loss = 0.0007309484141808764
1982, epoch_train_loss=0.0007309484141808764
Epoch 1983
Epoch 1983 :: Batch 0/1
Batch Loss = 0.0007309484141808715
1983, epoch_train_loss=0.0007309484141808715
Epoch 1984
Epoch 1984 :: Batch 0/1
Batch Loss = 0.0007309484141808669
1984, epoch_train_loss=0.0007309484141808669
Epoch 1985
Epoch 1985 :: Batch 0/1
Batch Loss = 0.0007309484141808622
1985, epoch_train_loss=0.0007309484141808622
Epoch 1986
Epoch 1986 :: Batch 0/1
Batch Loss = 0.0007309484141808576
1986, epoch_train_loss=0.0007309484141808576
Epoch 1987
Epoch 1987 :: Batch 0/1
Batch Loss = 0.0007309484141808531
1987, epoch_train_loss=0.0007309484141808531
Epoch 1988
Epoch 1988 :: Batch 0/1
Batch Loss = 0.0007309484141808483
1988, epoch_train_loss=0.0007309484141808483
Epoch 1989
Epoch 1989 :: Batch 0/1
Batch Loss = 0.0007309484141808437
1989, epoch_train_loss=0.0007309484141808437
Epoch 1990
Epoch 1990 :: Batch 0/1
Batch Loss = 0.000730948414180839
1990, epoch_train_loss=0.000730948414180839
Epoch 1991
Epoch 1991 :: Batch 0/1
Batch Loss = 0.0007309484141808344
1991, epoch_train_loss=0.0007309484141808344
Epoch 1992
Epoch 1992 :: Batch 0/1
Batch Loss = 0.0007309484141808296
1992, epoch_train_loss=0.0007309484141808296
Epoch 1993
Epoch 1993 :: Batch 0/1
Batch Loss = 0.000730948414180825
1993, epoch_train_loss=0.000730948414180825
Epoch 1994
Epoch 1994 :: Batch 0/1
Batch Loss = 0.0007309484141808202
1994, epoch_train_loss=0.0007309484141808202
Epoch 1995
Epoch 1995 :: Batch 0/1
Batch Loss = 0.0007309484141808157
1995, epoch_train_loss=0.0007309484141808157
Epoch 1996
Epoch 1996 :: Batch 0/1
Batch Loss = 0.0007309484141808109
1996, epoch_train_loss=0.0007309484141808109
Epoch 1997
Epoch 1997 :: Batch 0/1
Batch Loss = 0.0007309484141808063
1997, epoch_train_loss=0.0007309484141808063
Epoch 1998
Epoch 1998 :: Batch 0/1
Batch Loss = 0.0007309484141808016
1998, epoch_train_loss=0.0007309484141808016
Epoch 1999
Epoch 1999 :: Batch 0/1
Batch Loss = 0.0007309484141807969
1999, epoch_train_loss=0.0007309484141807969
Epoch 2000
Epoch 2000 :: Batch 0/1
Batch Loss = 0.0007309484141807921
2000, epoch_train_loss=0.0007309484141807921
Epoch 2001
Epoch 2001 :: Batch 0/1
Batch Loss = 0.0007309484141807875
2001, epoch_train_loss=0.0007309484141807875
Epoch 2002
Epoch 2002 :: Batch 0/1
Batch Loss = 0.0007309484141807828
2002, epoch_train_loss=0.0007309484141807828
Epoch 2003
Epoch 2003 :: Batch 0/1
Batch Loss = 0.0007309484141807781
2003, epoch_train_loss=0.0007309484141807781
Epoch 2004
Epoch 2004 :: Batch 0/1
Batch Loss = 0.0007309484141807735
2004, epoch_train_loss=0.0007309484141807735
Epoch 2005
Epoch 2005 :: Batch 0/1
Batch Loss = 0.0007309484141807686
2005, epoch_train_loss=0.0007309484141807686
Epoch 2006
Epoch 2006 :: Batch 0/1
Batch Loss = 0.0007309484141807639
2006, epoch_train_loss=0.0007309484141807639
Epoch 2007
Epoch 2007 :: Batch 0/1
Batch Loss = 0.0007309484141807593
2007, epoch_train_loss=0.0007309484141807593
Epoch 2008
Epoch 2008 :: Batch 0/1
Batch Loss = 0.0007309484141807545
2008, epoch_train_loss=0.0007309484141807545
Epoch 2009
Epoch 2009 :: Batch 0/1
Batch Loss = 0.0007309484141807498
2009, epoch_train_loss=0.0007309484141807498
Epoch 2010
Epoch 2010 :: Batch 0/1
Batch Loss = 0.0007309484141807452
2010, epoch_train_loss=0.0007309484141807452
Epoch 2011
Epoch 2011 :: Batch 0/1
Batch Loss = 0.0007309484141807405
2011, epoch_train_loss=0.0007309484141807405
Epoch 2012
Epoch 2012 :: Batch 0/1
Batch Loss = 0.0007309484141807356
2012, epoch_train_loss=0.0007309484141807356
Epoch 2013
Epoch 2013 :: Batch 0/1
Batch Loss = 0.000730948414180731
2013, epoch_train_loss=0.000730948414180731
Epoch 2014
Epoch 2014 :: Batch 0/1
Batch Loss = 0.0007309484141807262
2014, epoch_train_loss=0.0007309484141807262
Epoch 2015
Epoch 2015 :: Batch 0/1
Batch Loss = 0.0007309484141807215
2015, epoch_train_loss=0.0007309484141807215
Epoch 2016
Epoch 2016 :: Batch 0/1
Batch Loss = 0.0007309484141807169
2016, epoch_train_loss=0.0007309484141807169
Epoch 2017
Epoch 2017 :: Batch 0/1
Batch Loss = 0.000730948414180712
2017, epoch_train_loss=0.000730948414180712
Epoch 2018
Epoch 2018 :: Batch 0/1
Batch Loss = 0.0007309484141807072
2018, epoch_train_loss=0.0007309484141807072
Epoch 2019
Epoch 2019 :: Batch 0/1
Batch Loss = 0.0007309484141807026
2019, epoch_train_loss=0.0007309484141807026
Epoch 2020
Epoch 2020 :: Batch 0/1
Batch Loss = 0.0007309484141806979
2020, epoch_train_loss=0.0007309484141806979
Epoch 2021
Epoch 2021 :: Batch 0/1
Batch Loss = 0.0007309484141806931
2021, epoch_train_loss=0.0007309484141806931
Epoch 2022
Epoch 2022 :: Batch 0/1
Batch Loss = 0.0007309484141806883
2022, epoch_train_loss=0.0007309484141806883
Epoch 2023
Epoch 2023 :: Batch 0/1
Batch Loss = 0.0007309484141806835
2023, epoch_train_loss=0.0007309484141806835
Epoch 2024
Epoch 2024 :: Batch 0/1
Batch Loss = 0.0007309484141806787
2024, epoch_train_loss=0.0007309484141806787
Epoch 2025
Epoch 2025 :: Batch 0/1
Batch Loss = 0.0007309484141806742
2025, epoch_train_loss=0.0007309484141806742
Epoch 2026
Epoch 2026 :: Batch 0/1
Batch Loss = 0.0007309484141806694
2026, epoch_train_loss=0.0007309484141806694
Epoch 2027
Epoch 2027 :: Batch 0/1
Batch Loss = 0.0007309484141806645
2027, epoch_train_loss=0.0007309484141806645
Epoch 2028
Epoch 2028 :: Batch 0/1
Batch Loss = 0.0007309484141806597
2028, epoch_train_loss=0.0007309484141806597
Epoch 2029
Epoch 2029 :: Batch 0/1
Batch Loss = 0.000730948414180655
2029, epoch_train_loss=0.000730948414180655
Epoch 2030
Epoch 2030 :: Batch 0/1
Batch Loss = 0.0007309484141806503
2030, epoch_train_loss=0.0007309484141806503
Epoch 2031
Epoch 2031 :: Batch 0/1
Batch Loss = 0.0007309484141806455
2031, epoch_train_loss=0.0007309484141806455
Epoch 2032
Epoch 2032 :: Batch 0/1
Batch Loss = 0.0007309484141806407
2032, epoch_train_loss=0.0007309484141806407
Epoch 2033
Epoch 2033 :: Batch 0/1
Batch Loss = 0.0007309484141806359
2033, epoch_train_loss=0.0007309484141806359
Epoch 2034
Epoch 2034 :: Batch 0/1
Batch Loss = 0.0007309484141806312
2034, epoch_train_loss=0.0007309484141806312
Epoch 2035
Epoch 2035 :: Batch 0/1
Batch Loss = 0.0007309484141806265
2035, epoch_train_loss=0.0007309484141806265
Epoch 2036
Epoch 2036 :: Batch 0/1
Batch Loss = 0.0007309484141806217
2036, epoch_train_loss=0.0007309484141806217
Epoch 2037
Epoch 2037 :: Batch 0/1
Batch Loss = 0.0007309484141806168
2037, epoch_train_loss=0.0007309484141806168
Epoch 2038
Epoch 2038 :: Batch 0/1
Batch Loss = 0.000730948414180612
2038, epoch_train_loss=0.000730948414180612
Epoch 2039
Epoch 2039 :: Batch 0/1
Batch Loss = 0.0007309484141806073
2039, epoch_train_loss=0.0007309484141806073
Epoch 2040
Epoch 2040 :: Batch 0/1
Batch Loss = 0.0007309484141806025
2040, epoch_train_loss=0.0007309484141806025
Epoch 2041
Epoch 2041 :: Batch 0/1
Batch Loss = 0.0007309484141805976
2041, epoch_train_loss=0.0007309484141805976
Epoch 2042
Epoch 2042 :: Batch 0/1
Batch Loss = 0.0007309484141805929
2042, epoch_train_loss=0.0007309484141805929
Epoch 2043
Epoch 2043 :: Batch 0/1
Batch Loss = 0.0007309484141805881
2043, epoch_train_loss=0.0007309484141805881
Epoch 2044
Epoch 2044 :: Batch 0/1
Batch Loss = 0.0007309484141805833
2044, epoch_train_loss=0.0007309484141805833
Epoch 2045
Epoch 2045 :: Batch 0/1
Batch Loss = 0.0007309484141805784
2045, epoch_train_loss=0.0007309484141805784
Epoch 2046
Epoch 2046 :: Batch 0/1
Batch Loss = 0.0007309484141805737
2046, epoch_train_loss=0.0007309484141805737
Epoch 2047
Epoch 2047 :: Batch 0/1
Batch Loss = 0.0007309484141805689
2047, epoch_train_loss=0.0007309484141805689
Epoch 2048
Epoch 2048 :: Batch 0/1
Batch Loss = 0.0007309484141805641
2048, epoch_train_loss=0.0007309484141805641
Epoch 2049
Epoch 2049 :: Batch 0/1
Batch Loss = 0.0007309484141805591
2049, epoch_train_loss=0.0007309484141805591
Epoch 2050
Epoch 2050 :: Batch 0/1
Batch Loss = 0.0007309484141805544
2050, epoch_train_loss=0.0007309484141805544
Epoch 2051
Epoch 2051 :: Batch 0/1
Batch Loss = 0.0007309484141805496
2051, epoch_train_loss=0.0007309484141805496
Epoch 2052
Epoch 2052 :: Batch 0/1
Batch Loss = 0.0007309484141805448
2052, epoch_train_loss=0.0007309484141805448
Epoch 2053
Epoch 2053 :: Batch 0/1
Batch Loss = 0.0007309484141805399
2053, epoch_train_loss=0.0007309484141805399
Epoch 2054
Epoch 2054 :: Batch 0/1
Batch Loss = 0.0007309484141805351
2054, epoch_train_loss=0.0007309484141805351
Epoch 2055
Epoch 2055 :: Batch 0/1
Batch Loss = 0.0007309484141805303
2055, epoch_train_loss=0.0007309484141805303
Epoch 2056
Epoch 2056 :: Batch 0/1
Batch Loss = 0.0007309484141805254
2056, epoch_train_loss=0.0007309484141805254
Epoch 2057
Epoch 2057 :: Batch 0/1
Batch Loss = 0.0007309484141805206
2057, epoch_train_loss=0.0007309484141805206
Epoch 2058
Epoch 2058 :: Batch 0/1
Batch Loss = 0.0007309484141805159
2058, epoch_train_loss=0.0007309484141805159
Epoch 2059
Epoch 2059 :: Batch 0/1
Batch Loss = 0.0007309484141805109
2059, epoch_train_loss=0.0007309484141805109
Epoch 2060
Epoch 2060 :: Batch 0/1
Batch Loss = 0.000730948414180506
2060, epoch_train_loss=0.000730948414180506
Epoch 2061
Epoch 2061 :: Batch 0/1
Batch Loss = 0.0007309484141805012
2061, epoch_train_loss=0.0007309484141805012
Epoch 2062
Epoch 2062 :: Batch 0/1
Batch Loss = 0.0007309484141804964
2062, epoch_train_loss=0.0007309484141804964
Epoch 2063
Epoch 2063 :: Batch 0/1
Batch Loss = 0.0007309484141804915
2063, epoch_train_loss=0.0007309484141804915
Epoch 2064
Epoch 2064 :: Batch 0/1
Batch Loss = 0.0007309484141804866
2064, epoch_train_loss=0.0007309484141804866
Epoch 2065
Epoch 2065 :: Batch 0/1
Batch Loss = 0.0007309484141804818
2065, epoch_train_loss=0.0007309484141804818
Epoch 2066
Epoch 2066 :: Batch 0/1
Batch Loss = 0.0007309484141804771
2066, epoch_train_loss=0.0007309484141804771
Epoch 2067
Epoch 2067 :: Batch 0/1
Batch Loss = 0.0007309484141804721
2067, epoch_train_loss=0.0007309484141804721
Epoch 2068
Epoch 2068 :: Batch 0/1
Batch Loss = 0.0007309484141804673
2068, epoch_train_loss=0.0007309484141804673
Epoch 2069
Epoch 2069 :: Batch 0/1
Batch Loss = 0.0007309484141804624
2069, epoch_train_loss=0.0007309484141804624
Epoch 2070
Epoch 2070 :: Batch 0/1
Batch Loss = 0.0007309484141804574
2070, epoch_train_loss=0.0007309484141804574
Epoch 2071
Epoch 2071 :: Batch 0/1
Batch Loss = 0.0007309484141804526
2071, epoch_train_loss=0.0007309484141804526
Epoch 2072
Epoch 2072 :: Batch 0/1
Batch Loss = 0.0007309484141804478
2072, epoch_train_loss=0.0007309484141804478
Epoch 2073
Epoch 2073 :: Batch 0/1
Batch Loss = 0.000730948414180443
2073, epoch_train_loss=0.000730948414180443
Epoch 2074
Epoch 2074 :: Batch 0/1
Batch Loss = 0.0007309484141804379
2074, epoch_train_loss=0.0007309484141804379
Epoch 2075
Epoch 2075 :: Batch 0/1
Batch Loss = 0.0007309484141804332
2075, epoch_train_loss=0.0007309484141804332
Epoch 2076
Epoch 2076 :: Batch 0/1
Batch Loss = 0.0007309484141804281
2076, epoch_train_loss=0.0007309484141804281
Epoch 2077
Epoch 2077 :: Batch 0/1
Batch Loss = 0.0007309484141804233
2077, epoch_train_loss=0.0007309484141804233
Epoch 2078
Epoch 2078 :: Batch 0/1
Batch Loss = 0.0007309484141804185
2078, epoch_train_loss=0.0007309484141804185
Epoch 2079
Epoch 2079 :: Batch 0/1
Batch Loss = 0.0007309484141804134
2079, epoch_train_loss=0.0007309484141804134
Epoch 2080
Epoch 2080 :: Batch 0/1
Batch Loss = 0.0007309484141804086
2080, epoch_train_loss=0.0007309484141804086
Epoch 2081
Epoch 2081 :: Batch 0/1
Batch Loss = 0.0007309484141804038
2081, epoch_train_loss=0.0007309484141804038
Epoch 2082
Epoch 2082 :: Batch 0/1
Batch Loss = 0.0007309484141803989
2082, epoch_train_loss=0.0007309484141803989
Epoch 2083
Epoch 2083 :: Batch 0/1
Batch Loss = 0.0007309484141803939
2083, epoch_train_loss=0.0007309484141803939
Epoch 2084
Epoch 2084 :: Batch 0/1
Batch Loss = 0.000730948414180389
2084, epoch_train_loss=0.000730948414180389
Epoch 2085
Epoch 2085 :: Batch 0/1
Batch Loss = 0.0007309484141803843
2085, epoch_train_loss=0.0007309484141803843
Epoch 2086
Epoch 2086 :: Batch 0/1
Batch Loss = 0.0007309484141803792
2086, epoch_train_loss=0.0007309484141803792
Epoch 2087
Epoch 2087 :: Batch 0/1
Batch Loss = 0.0007309484141803744
2087, epoch_train_loss=0.0007309484141803744
Epoch 2088
Epoch 2088 :: Batch 0/1
Batch Loss = 0.0007309484141803693
2088, epoch_train_loss=0.0007309484141803693
Epoch 2089
Epoch 2089 :: Batch 0/1
Batch Loss = 0.0007309484141803645
2089, epoch_train_loss=0.0007309484141803645
Epoch 2090
Epoch 2090 :: Batch 0/1
Batch Loss = 0.0007309484141803595
2090, epoch_train_loss=0.0007309484141803595
Epoch 2091
Epoch 2091 :: Batch 0/1
Batch Loss = 0.0007309484141803548
2091, epoch_train_loss=0.0007309484141803548
Epoch 2092
Epoch 2092 :: Batch 0/1
Batch Loss = 0.0007309484141803497
2092, epoch_train_loss=0.0007309484141803497
Epoch 2093
Epoch 2093 :: Batch 0/1
Batch Loss = 0.0007309484141803448
2093, epoch_train_loss=0.0007309484141803448
Epoch 2094
Epoch 2094 :: Batch 0/1
Batch Loss = 0.0007309484141803398
2094, epoch_train_loss=0.0007309484141803398
Epoch 2095
Epoch 2095 :: Batch 0/1
Batch Loss = 0.0007309484141803349
2095, epoch_train_loss=0.0007309484141803349
Epoch 2096
Epoch 2096 :: Batch 0/1
Batch Loss = 0.00073094841418033
2096, epoch_train_loss=0.00073094841418033
Epoch 2097
Epoch 2097 :: Batch 0/1
Batch Loss = 0.000730948414180325
2097, epoch_train_loss=0.000730948414180325
Epoch 2098
Epoch 2098 :: Batch 0/1
Batch Loss = 0.00073094841418032
2098, epoch_train_loss=0.00073094841418032
Epoch 2099
Epoch 2099 :: Batch 0/1
Batch Loss = 0.0007309484141803152
2099, epoch_train_loss=0.0007309484141803152
Epoch 2100
Epoch 2100 :: Batch 0/1
Batch Loss = 0.0007309484141803101
2100, epoch_train_loss=0.0007309484141803101
Epoch 2101
Epoch 2101 :: Batch 0/1
Batch Loss = 0.0007309484141803053
2101, epoch_train_loss=0.0007309484141803053
Epoch 2102
Epoch 2102 :: Batch 0/1
Batch Loss = 0.0007309484141803002
2102, epoch_train_loss=0.0007309484141803002
Epoch 2103
Epoch 2103 :: Batch 0/1
Batch Loss = 0.0007309484141802952
2103, epoch_train_loss=0.0007309484141802952
Epoch 2104
Epoch 2104 :: Batch 0/1
Batch Loss = 0.0007309484141802904
2104, epoch_train_loss=0.0007309484141802904
Epoch 2105
Epoch 2105 :: Batch 0/1
Batch Loss = 0.0007309484141802854
2105, epoch_train_loss=0.0007309484141802854
Epoch 2106
Epoch 2106 :: Batch 0/1
Batch Loss = 0.0007309484141802805
2106, epoch_train_loss=0.0007309484141802805
Epoch 2107
Epoch 2107 :: Batch 0/1
Batch Loss = 0.0007309484141802756
2107, epoch_train_loss=0.0007309484141802756
Epoch 2108
Epoch 2108 :: Batch 0/1
Batch Loss = 0.0007309484141802705
2108, epoch_train_loss=0.0007309484141802705
Epoch 2109
Epoch 2109 :: Batch 0/1
Batch Loss = 0.0007309484141802655
2109, epoch_train_loss=0.0007309484141802655
Epoch 2110
Epoch 2110 :: Batch 0/1
Batch Loss = 0.0007309484141802604
2110, epoch_train_loss=0.0007309484141802604
Epoch 2111
Epoch 2111 :: Batch 0/1
Batch Loss = 0.0007309484141802557
2111, epoch_train_loss=0.0007309484141802557
Epoch 2112
Epoch 2112 :: Batch 0/1
Batch Loss = 0.0007309484141802507
2112, epoch_train_loss=0.0007309484141802507
Epoch 2113
Epoch 2113 :: Batch 0/1
Batch Loss = 0.0007309484141802456
2113, epoch_train_loss=0.0007309484141802456
Epoch 2114
Epoch 2114 :: Batch 0/1
Batch Loss = 0.0007309484141802407
2114, epoch_train_loss=0.0007309484141802407
Epoch 2115
Epoch 2115 :: Batch 0/1
Batch Loss = 0.0007309484141802356
2115, epoch_train_loss=0.0007309484141802356
Epoch 2116
Epoch 2116 :: Batch 0/1
Batch Loss = 0.0007309484141802307
2116, epoch_train_loss=0.0007309484141802307
Epoch 2117
Epoch 2117 :: Batch 0/1
Batch Loss = 0.0007309484141802256
2117, epoch_train_loss=0.0007309484141802256
Epoch 2118
Epoch 2118 :: Batch 0/1
Batch Loss = 0.0007309484141802206
2118, epoch_train_loss=0.0007309484141802206
Epoch 2119
Epoch 2119 :: Batch 0/1
Batch Loss = 0.0007309484141802157
2119, epoch_train_loss=0.0007309484141802157
Epoch 2120
Epoch 2120 :: Batch 0/1
Batch Loss = 0.0007309484141802107
2120, epoch_train_loss=0.0007309484141802107
Epoch 2121
Epoch 2121 :: Batch 0/1
Batch Loss = 0.0007309484141802058
2121, epoch_train_loss=0.0007309484141802058
Epoch 2122
Epoch 2122 :: Batch 0/1
Batch Loss = 0.0007309484141802007
2122, epoch_train_loss=0.0007309484141802007
Epoch 2123
Epoch 2123 :: Batch 0/1
Batch Loss = 0.0007309484141801957
2123, epoch_train_loss=0.0007309484141801957
Epoch 2124
Epoch 2124 :: Batch 0/1
Batch Loss = 0.0007309484141801907
2124, epoch_train_loss=0.0007309484141801907
Epoch 2125
Epoch 2125 :: Batch 0/1
Batch Loss = 0.0007309484141801856
2125, epoch_train_loss=0.0007309484141801856
Epoch 2126
Epoch 2126 :: Batch 0/1
Batch Loss = 0.0007309484141801807
2126, epoch_train_loss=0.0007309484141801807
Epoch 2127
Epoch 2127 :: Batch 0/1
Batch Loss = 0.0007309484141801757
2127, epoch_train_loss=0.0007309484141801757
Epoch 2128
Epoch 2128 :: Batch 0/1
Batch Loss = 0.0007309484141801707
2128, epoch_train_loss=0.0007309484141801707
Epoch 2129
Epoch 2129 :: Batch 0/1
Batch Loss = 0.0007309484141801655
2129, epoch_train_loss=0.0007309484141801655
Epoch 2130
Epoch 2130 :: Batch 0/1
Batch Loss = 0.0007309484141801606
2130, epoch_train_loss=0.0007309484141801606
Epoch 2131
Epoch 2131 :: Batch 0/1
Batch Loss = 0.0007309484141801555
2131, epoch_train_loss=0.0007309484141801555
Epoch 2132
Epoch 2132 :: Batch 0/1
Batch Loss = 0.0007309484141801506
2132, epoch_train_loss=0.0007309484141801506
Epoch 2133
Epoch 2133 :: Batch 0/1
Batch Loss = 0.0007309484141801455
2133, epoch_train_loss=0.0007309484141801455
Epoch 2134
Epoch 2134 :: Batch 0/1
Batch Loss = 0.0007309484141801404
2134, epoch_train_loss=0.0007309484141801404
Epoch 2135
Epoch 2135 :: Batch 0/1
Batch Loss = 0.0007309484141801354
2135, epoch_train_loss=0.0007309484141801354
Epoch 2136
Epoch 2136 :: Batch 0/1
Batch Loss = 0.0007309484141801303
2136, epoch_train_loss=0.0007309484141801303
Epoch 2137
Epoch 2137 :: Batch 0/1
Batch Loss = 0.0007309484141801253
2137, epoch_train_loss=0.0007309484141801253
Epoch 2138
Epoch 2138 :: Batch 0/1
Batch Loss = 0.0007309484141801201
2138, epoch_train_loss=0.0007309484141801201
Epoch 2139
Epoch 2139 :: Batch 0/1
Batch Loss = 0.0007309484141801152
2139, epoch_train_loss=0.0007309484141801152
Epoch 2140
Epoch 2140 :: Batch 0/1
Batch Loss = 0.0007309484141801101
2140, epoch_train_loss=0.0007309484141801101
Epoch 2141
Epoch 2141 :: Batch 0/1
Batch Loss = 0.0007309484141801051
2141, epoch_train_loss=0.0007309484141801051
Epoch 2142
Epoch 2142 :: Batch 0/1
Batch Loss = 0.0007309484141801
2142, epoch_train_loss=0.0007309484141801
Epoch 2143
Epoch 2143 :: Batch 0/1
Batch Loss = 0.000730948414180095
2143, epoch_train_loss=0.000730948414180095
Epoch 2144
Epoch 2144 :: Batch 0/1
Batch Loss = 0.0007309484141800899
2144, epoch_train_loss=0.0007309484141800899
Epoch 2145
Epoch 2145 :: Batch 0/1
Batch Loss = 0.0007309484141800849
2145, epoch_train_loss=0.0007309484141800849
Epoch 2146
Epoch 2146 :: Batch 0/1
Batch Loss = 0.0007309484141800797
2146, epoch_train_loss=0.0007309484141800797
Epoch 2147
Epoch 2147 :: Batch 0/1
Batch Loss = 0.0007309484141800747
2147, epoch_train_loss=0.0007309484141800747
Epoch 2148
Epoch 2148 :: Batch 0/1
Batch Loss = 0.0007309484141800695
2148, epoch_train_loss=0.0007309484141800695
Epoch 2149
Epoch 2149 :: Batch 0/1
Batch Loss = 0.0007309484141800645
2149, epoch_train_loss=0.0007309484141800645
Epoch 2150
Epoch 2150 :: Batch 0/1
Batch Loss = 0.0007309484141800595
2150, epoch_train_loss=0.0007309484141800595
Epoch 2151
Epoch 2151 :: Batch 0/1
Batch Loss = 0.0007309484141800544
2151, epoch_train_loss=0.0007309484141800544
Epoch 2152
Epoch 2152 :: Batch 0/1
Batch Loss = 0.0007309484141800495
2152, epoch_train_loss=0.0007309484141800495
Epoch 2153
Epoch 2153 :: Batch 0/1
Batch Loss = 0.0007309484141800442
2153, epoch_train_loss=0.0007309484141800442
Epoch 2154
Epoch 2154 :: Batch 0/1
Batch Loss = 0.0007309484141800393
2154, epoch_train_loss=0.0007309484141800393
Epoch 2155
Epoch 2155 :: Batch 0/1
Batch Loss = 0.0007309484141800341
2155, epoch_train_loss=0.0007309484141800341
Epoch 2156
Epoch 2156 :: Batch 0/1
Batch Loss = 0.0007309484141800291
2156, epoch_train_loss=0.0007309484141800291
Epoch 2157
Epoch 2157 :: Batch 0/1
Batch Loss = 0.000730948414180024
2157, epoch_train_loss=0.000730948414180024
Epoch 2158
Epoch 2158 :: Batch 0/1
Batch Loss = 0.0007309484141800188
2158, epoch_train_loss=0.0007309484141800188
Epoch 2159
Epoch 2159 :: Batch 0/1
Batch Loss = 0.0007309484141800137
2159, epoch_train_loss=0.0007309484141800137
Epoch 2160
Epoch 2160 :: Batch 0/1
Batch Loss = 0.0007309484141800087
2160, epoch_train_loss=0.0007309484141800087
Epoch 2161
Epoch 2161 :: Batch 0/1
Batch Loss = 0.0007309484141800035
2161, epoch_train_loss=0.0007309484141800035
Epoch 2162
Epoch 2162 :: Batch 0/1
Batch Loss = 0.0007309484141799983
2162, epoch_train_loss=0.0007309484141799983
Epoch 2163
Epoch 2163 :: Batch 0/1
Batch Loss = 0.0007309484141799933
2163, epoch_train_loss=0.0007309484141799933
Epoch 2164
Epoch 2164 :: Batch 0/1
Batch Loss = 0.000730948414179988
2164, epoch_train_loss=0.000730948414179988
Epoch 2165
Epoch 2165 :: Batch 0/1
Batch Loss = 0.000730948414179983
2165, epoch_train_loss=0.000730948414179983
Epoch 2166
Epoch 2166 :: Batch 0/1
Batch Loss = 0.0007309484141799779
2166, epoch_train_loss=0.0007309484141799779
Epoch 2167
Epoch 2167 :: Batch 0/1
Batch Loss = 0.0007309484141799727
2167, epoch_train_loss=0.0007309484141799727
Epoch 2168
Epoch 2168 :: Batch 0/1
Batch Loss = 0.0007309484141799676
2168, epoch_train_loss=0.0007309484141799676
Epoch 2169
Epoch 2169 :: Batch 0/1
Batch Loss = 0.0007309484141799625
2169, epoch_train_loss=0.0007309484141799625
Epoch 2170
Epoch 2170 :: Batch 0/1
Batch Loss = 0.0007309484141799574
2170, epoch_train_loss=0.0007309484141799574
Epoch 2171
Epoch 2171 :: Batch 0/1
Batch Loss = 0.0007309484141799523
2171, epoch_train_loss=0.0007309484141799523
Epoch 2172
Epoch 2172 :: Batch 0/1
Batch Loss = 0.000730948414179947
2172, epoch_train_loss=0.000730948414179947
Epoch 2173
Epoch 2173 :: Batch 0/1
Batch Loss = 0.000730948414179942
2173, epoch_train_loss=0.000730948414179942
Epoch 2174
Epoch 2174 :: Batch 0/1
Batch Loss = 0.0007309484141799367
2174, epoch_train_loss=0.0007309484141799367
Epoch 2175
Epoch 2175 :: Batch 0/1
Batch Loss = 0.0007309484141799317
2175, epoch_train_loss=0.0007309484141799317
Epoch 2176
Epoch 2176 :: Batch 0/1
Batch Loss = 0.0007309484141799266
2176, epoch_train_loss=0.0007309484141799266
Epoch 2177
Epoch 2177 :: Batch 0/1
Batch Loss = 0.0007309484141799215
2177, epoch_train_loss=0.0007309484141799215
Epoch 2178
Epoch 2178 :: Batch 0/1
Batch Loss = 0.0007309484141799163
2178, epoch_train_loss=0.0007309484141799163
Epoch 2179
Epoch 2179 :: Batch 0/1
Batch Loss = 0.000730948414179911
2179, epoch_train_loss=0.000730948414179911
Epoch 2180
Epoch 2180 :: Batch 0/1
Batch Loss = 0.000730948414179906
2180, epoch_train_loss=0.000730948414179906
Epoch 2181
Epoch 2181 :: Batch 0/1
Batch Loss = 0.0007309484141799007
2181, epoch_train_loss=0.0007309484141799007
Epoch 2182
Epoch 2182 :: Batch 0/1
Batch Loss = 0.0007309484141798957
2182, epoch_train_loss=0.0007309484141798957
Epoch 2183
Epoch 2183 :: Batch 0/1
Batch Loss = 0.0007309484141798904
2183, epoch_train_loss=0.0007309484141798904
Epoch 2184
Epoch 2184 :: Batch 0/1
Batch Loss = 0.0007309484141798853
2184, epoch_train_loss=0.0007309484141798853
Epoch 2185
Epoch 2185 :: Batch 0/1
Batch Loss = 0.0007309484141798801
2185, epoch_train_loss=0.0007309484141798801
Epoch 2186
Epoch 2186 :: Batch 0/1
Batch Loss = 0.0007309484141798749
2186, epoch_train_loss=0.0007309484141798749
Epoch 2187
Epoch 2187 :: Batch 0/1
Batch Loss = 0.0007309484141798698
2187, epoch_train_loss=0.0007309484141798698
Epoch 2188
Epoch 2188 :: Batch 0/1
Batch Loss = 0.0007309484141798645
2188, epoch_train_loss=0.0007309484141798645
Epoch 2189
Epoch 2189 :: Batch 0/1
Batch Loss = 0.0007309484141798594
2189, epoch_train_loss=0.0007309484141798594
Epoch 2190
Epoch 2190 :: Batch 0/1
Batch Loss = 0.0007309484141798542
2190, epoch_train_loss=0.0007309484141798542
Epoch 2191
Epoch 2191 :: Batch 0/1
Batch Loss = 0.0007309484141798489
2191, epoch_train_loss=0.0007309484141798489
Epoch 2192
Epoch 2192 :: Batch 0/1
Batch Loss = 0.0007309484141798438
2192, epoch_train_loss=0.0007309484141798438
Epoch 2193
Epoch 2193 :: Batch 0/1
Batch Loss = 0.0007309484141798386
2193, epoch_train_loss=0.0007309484141798386
Epoch 2194
Epoch 2194 :: Batch 0/1
Batch Loss = 0.0007309484141798334
2194, epoch_train_loss=0.0007309484141798334
Epoch 2195
Epoch 2195 :: Batch 0/1
Batch Loss = 0.0007309484141798283
2195, epoch_train_loss=0.0007309484141798283
Epoch 2196
Epoch 2196 :: Batch 0/1
Batch Loss = 0.0007309484141798231
2196, epoch_train_loss=0.0007309484141798231
Epoch 2197
Epoch 2197 :: Batch 0/1
Batch Loss = 0.0007309484141798178
2197, epoch_train_loss=0.0007309484141798178
Epoch 2198
Epoch 2198 :: Batch 0/1
Batch Loss = 0.0007309484141798126
2198, epoch_train_loss=0.0007309484141798126
Epoch 2199
Epoch 2199 :: Batch 0/1
Batch Loss = 0.0007309484141798073
2199, epoch_train_loss=0.0007309484141798073
Epoch 2200
Epoch 2200 :: Batch 0/1
Batch Loss = 0.0007309484141798021
2200, epoch_train_loss=0.0007309484141798021
Epoch 2201
Epoch 2201 :: Batch 0/1
Batch Loss = 0.0007309484141797968
2201, epoch_train_loss=0.0007309484141797968
Epoch 2202
Epoch 2202 :: Batch 0/1
Batch Loss = 0.0007309484141797918
2202, epoch_train_loss=0.0007309484141797918
Epoch 2203
Epoch 2203 :: Batch 0/1
Batch Loss = 0.0007309484141797865
2203, epoch_train_loss=0.0007309484141797865
Epoch 2204
Epoch 2204 :: Batch 0/1
Batch Loss = 0.0007309484141797813
2204, epoch_train_loss=0.0007309484141797813
Epoch 2205
Epoch 2205 :: Batch 0/1
Batch Loss = 0.000730948414179776
2205, epoch_train_loss=0.000730948414179776
Epoch 2206
Epoch 2206 :: Batch 0/1
Batch Loss = 0.0007309484141797708
2206, epoch_train_loss=0.0007309484141797708
Epoch 2207
Epoch 2207 :: Batch 0/1
Batch Loss = 0.0007309484141797656
2207, epoch_train_loss=0.0007309484141797656
Epoch 2208
Epoch 2208 :: Batch 0/1
Batch Loss = 0.0007309484141797604
2208, epoch_train_loss=0.0007309484141797604
Epoch 2209
Epoch 2209 :: Batch 0/1
Batch Loss = 0.0007309484141797552
2209, epoch_train_loss=0.0007309484141797552
Epoch 2210
Epoch 2210 :: Batch 0/1
Batch Loss = 0.0007309484141797499
2210, epoch_train_loss=0.0007309484141797499
Epoch 2211
Epoch 2211 :: Batch 0/1
Batch Loss = 0.0007309484141797447
2211, epoch_train_loss=0.0007309484141797447
Epoch 2212
Epoch 2212 :: Batch 0/1
Batch Loss = 0.0007309484141797395
2212, epoch_train_loss=0.0007309484141797395
Epoch 2213
Epoch 2213 :: Batch 0/1
Batch Loss = 0.0007309484141797342
2213, epoch_train_loss=0.0007309484141797342
Epoch 2214
Epoch 2214 :: Batch 0/1
Batch Loss = 0.0007309484141797289
2214, epoch_train_loss=0.0007309484141797289
Epoch 2215
Epoch 2215 :: Batch 0/1
Batch Loss = 0.0007309484141797238
2215, epoch_train_loss=0.0007309484141797238
Epoch 2216
Epoch 2216 :: Batch 0/1
Batch Loss = 0.0007309484141797184
2216, epoch_train_loss=0.0007309484141797184
Epoch 2217
Epoch 2217 :: Batch 0/1
Batch Loss = 0.0007309484141797131
2217, epoch_train_loss=0.0007309484141797131
Epoch 2218
Epoch 2218 :: Batch 0/1
Batch Loss = 0.0007309484141797079
2218, epoch_train_loss=0.0007309484141797079
Epoch 2219
Epoch 2219 :: Batch 0/1
Batch Loss = 0.0007309484141797026
2219, epoch_train_loss=0.0007309484141797026
Epoch 2220
Epoch 2220 :: Batch 0/1
Batch Loss = 0.0007309484141796973
2220, epoch_train_loss=0.0007309484141796973
Epoch 2221
Epoch 2221 :: Batch 0/1
Batch Loss = 0.0007309484141796921
2221, epoch_train_loss=0.0007309484141796921
Epoch 2222
Epoch 2222 :: Batch 0/1
Batch Loss = 0.0007309484141796868
2222, epoch_train_loss=0.0007309484141796868
Epoch 2223
Epoch 2223 :: Batch 0/1
Batch Loss = 0.0007309484141796815
2223, epoch_train_loss=0.0007309484141796815
Epoch 2224
Epoch 2224 :: Batch 0/1
Batch Loss = 0.0007309484141796763
2224, epoch_train_loss=0.0007309484141796763
Epoch 2225
Epoch 2225 :: Batch 0/1
Batch Loss = 0.000730948414179671
2225, epoch_train_loss=0.000730948414179671
Epoch 2226
Epoch 2226 :: Batch 0/1
Batch Loss = 0.0007309484141796656
2226, epoch_train_loss=0.0007309484141796656
Epoch 2227
Epoch 2227 :: Batch 0/1
Batch Loss = 0.0007309484141796604
2227, epoch_train_loss=0.0007309484141796604
Epoch 2228
Epoch 2228 :: Batch 0/1
Batch Loss = 0.0007309484141796551
2228, epoch_train_loss=0.0007309484141796551
Epoch 2229
Epoch 2229 :: Batch 0/1
Batch Loss = 0.0007309484141796498
2229, epoch_train_loss=0.0007309484141796498
Epoch 2230
Epoch 2230 :: Batch 0/1
Batch Loss = 0.0007309484141796446
2230, epoch_train_loss=0.0007309484141796446
Epoch 2231
Epoch 2231 :: Batch 0/1
Batch Loss = 0.0007309484141796392
2231, epoch_train_loss=0.0007309484141796392
Epoch 2232
Epoch 2232 :: Batch 0/1
Batch Loss = 0.000730948414179634
2232, epoch_train_loss=0.000730948414179634
Epoch 2233
Epoch 2233 :: Batch 0/1
Batch Loss = 0.0007309484141796287
2233, epoch_train_loss=0.0007309484141796287
Epoch 2234
Epoch 2234 :: Batch 0/1
Batch Loss = 0.0007309484141796235
2234, epoch_train_loss=0.0007309484141796235
Epoch 2235
Epoch 2235 :: Batch 0/1
Batch Loss = 0.0007309484141796179
2235, epoch_train_loss=0.0007309484141796179
Epoch 2236
Epoch 2236 :: Batch 0/1
Batch Loss = 0.0007309484141796127
2236, epoch_train_loss=0.0007309484141796127
Epoch 2237
Epoch 2237 :: Batch 0/1
Batch Loss = 0.0007309484141796074
2237, epoch_train_loss=0.0007309484141796074
Epoch 2238
Epoch 2238 :: Batch 0/1
Batch Loss = 0.0007309484141796021
2238, epoch_train_loss=0.0007309484141796021
Epoch 2239
Epoch 2239 :: Batch 0/1
Batch Loss = 0.0007309484141795969
2239, epoch_train_loss=0.0007309484141795969
Epoch 2240
Epoch 2240 :: Batch 0/1
Batch Loss = 0.0007309484141795915
2240, epoch_train_loss=0.0007309484141795915
Epoch 2241
Epoch 2241 :: Batch 0/1
Batch Loss = 0.0007309484141795862
2241, epoch_train_loss=0.0007309484141795862
Epoch 2242
Epoch 2242 :: Batch 0/1
Batch Loss = 0.0007309484141795808
2242, epoch_train_loss=0.0007309484141795808
Epoch 2243
Epoch 2243 :: Batch 0/1
Batch Loss = 0.0007309484141795755
2243, epoch_train_loss=0.0007309484141795755
Epoch 2244
Epoch 2244 :: Batch 0/1
Batch Loss = 0.0007309484141795701
2244, epoch_train_loss=0.0007309484141795701
Epoch 2245
Epoch 2245 :: Batch 0/1
Batch Loss = 0.0007309484141795648
2245, epoch_train_loss=0.0007309484141795648
Epoch 2246
Epoch 2246 :: Batch 0/1
Batch Loss = 0.0007309484141795595
2246, epoch_train_loss=0.0007309484141795595
Epoch 2247
Epoch 2247 :: Batch 0/1
Batch Loss = 0.0007309484141795542
2247, epoch_train_loss=0.0007309484141795542
Epoch 2248
Epoch 2248 :: Batch 0/1
Batch Loss = 0.0007309484141795488
2248, epoch_train_loss=0.0007309484141795488
Epoch 2249
Epoch 2249 :: Batch 0/1
Batch Loss = 0.0007309484141795433
2249, epoch_train_loss=0.0007309484141795433
Epoch 2250
Epoch 2250 :: Batch 0/1
Batch Loss = 0.0007309484141795381
2250, epoch_train_loss=0.0007309484141795381
Epoch 2251
Epoch 2251 :: Batch 0/1
Batch Loss = 0.0007309484141795327
2251, epoch_train_loss=0.0007309484141795327
Epoch 2252
Epoch 2252 :: Batch 0/1
Batch Loss = 0.0007309484141795274
2252, epoch_train_loss=0.0007309484141795274
Epoch 2253
Epoch 2253 :: Batch 0/1
Batch Loss = 0.000730948414179522
2253, epoch_train_loss=0.000730948414179522
Epoch 2254
Epoch 2254 :: Batch 0/1
Batch Loss = 0.0007309484141795168
2254, epoch_train_loss=0.0007309484141795168
Epoch 2255
Epoch 2255 :: Batch 0/1
Batch Loss = 0.0007309484141795114
2255, epoch_train_loss=0.0007309484141795114
Epoch 2256
Epoch 2256 :: Batch 0/1
Batch Loss = 0.0007309484141795059
2256, epoch_train_loss=0.0007309484141795059
Epoch 2257
Epoch 2257 :: Batch 0/1
Batch Loss = 0.0007309484141795007
2257, epoch_train_loss=0.0007309484141795007
Epoch 2258
Epoch 2258 :: Batch 0/1
Batch Loss = 0.0007309484141794952
2258, epoch_train_loss=0.0007309484141794952
Epoch 2259
Epoch 2259 :: Batch 0/1
Batch Loss = 0.0007309484141794899
2259, epoch_train_loss=0.0007309484141794899
Epoch 2260
Epoch 2260 :: Batch 0/1
Batch Loss = 0.0007309484141794844
2260, epoch_train_loss=0.0007309484141794844
Epoch 2261
Epoch 2261 :: Batch 0/1
Batch Loss = 0.000730948414179479
2261, epoch_train_loss=0.000730948414179479
Epoch 2262
Epoch 2262 :: Batch 0/1
Batch Loss = 0.0007309484141794737
2262, epoch_train_loss=0.0007309484141794737
Epoch 2263
Epoch 2263 :: Batch 0/1
Batch Loss = 0.0007309484141794683
2263, epoch_train_loss=0.0007309484141794683
Epoch 2264
Epoch 2264 :: Batch 0/1
Batch Loss = 0.0007309484141794629
2264, epoch_train_loss=0.0007309484141794629
Epoch 2265
Epoch 2265 :: Batch 0/1
Batch Loss = 0.0007309484141794575
2265, epoch_train_loss=0.0007309484141794575
Epoch 2266
Epoch 2266 :: Batch 0/1
Batch Loss = 0.0007309484141794522
2266, epoch_train_loss=0.0007309484141794522
Epoch 2267
Epoch 2267 :: Batch 0/1
Batch Loss = 0.0007309484141794467
2267, epoch_train_loss=0.0007309484141794467
Epoch 2268
Epoch 2268 :: Batch 0/1
Batch Loss = 0.0007309484141794413
2268, epoch_train_loss=0.0007309484141794413
Epoch 2269
Epoch 2269 :: Batch 0/1
Batch Loss = 0.0007309484141794359
2269, epoch_train_loss=0.0007309484141794359
Epoch 2270
Epoch 2270 :: Batch 0/1
Batch Loss = 0.0007309484141794304
2270, epoch_train_loss=0.0007309484141794304
Epoch 2271
Epoch 2271 :: Batch 0/1
Batch Loss = 0.0007309484141794252
2271, epoch_train_loss=0.0007309484141794252
Epoch 2272
Epoch 2272 :: Batch 0/1
Batch Loss = 0.0007309484141794196
2272, epoch_train_loss=0.0007309484141794196
Epoch 2273
Epoch 2273 :: Batch 0/1
Batch Loss = 0.0007309484141794143
2273, epoch_train_loss=0.0007309484141794143
Epoch 2274
Epoch 2274 :: Batch 0/1
Batch Loss = 0.0007309484141794088
2274, epoch_train_loss=0.0007309484141794088
Epoch 2275
Epoch 2275 :: Batch 0/1
Batch Loss = 0.0007309484141794036
2275, epoch_train_loss=0.0007309484141794036
Epoch 2276
Epoch 2276 :: Batch 0/1
Batch Loss = 0.0007309484141793981
2276, epoch_train_loss=0.0007309484141793981
Epoch 2277
Epoch 2277 :: Batch 0/1
Batch Loss = 0.0007309484141793926
2277, epoch_train_loss=0.0007309484141793926
Epoch 2278
Epoch 2278 :: Batch 0/1
Batch Loss = 0.0007309484141793872
2278, epoch_train_loss=0.0007309484141793872
Epoch 2279
Epoch 2279 :: Batch 0/1
Batch Loss = 0.0007309484141793817
2279, epoch_train_loss=0.0007309484141793817
Epoch 2280
Epoch 2280 :: Batch 0/1
Batch Loss = 0.0007309484141793764
2280, epoch_train_loss=0.0007309484141793764
Epoch 2281
Epoch 2281 :: Batch 0/1
Batch Loss = 0.000730948414179371
2281, epoch_train_loss=0.000730948414179371
Epoch 2282
Epoch 2282 :: Batch 0/1
Batch Loss = 0.0007309484141793654
2282, epoch_train_loss=0.0007309484141793654
Epoch 2283
Epoch 2283 :: Batch 0/1
Batch Loss = 0.00073094841417936
2283, epoch_train_loss=0.00073094841417936
Epoch 2284
Epoch 2284 :: Batch 0/1
Batch Loss = 0.0007309484141793546
2284, epoch_train_loss=0.0007309484141793546
Epoch 2285
Epoch 2285 :: Batch 0/1
Batch Loss = 0.0007309484141793492
2285, epoch_train_loss=0.0007309484141793492
Epoch 2286
Epoch 2286 :: Batch 0/1
Batch Loss = 0.0007309484141793437
2286, epoch_train_loss=0.0007309484141793437
Epoch 2287
Epoch 2287 :: Batch 0/1
Batch Loss = 0.0007309484141793382
2287, epoch_train_loss=0.0007309484141793382
Epoch 2288
Epoch 2288 :: Batch 0/1
Batch Loss = 0.0007309484141793328
2288, epoch_train_loss=0.0007309484141793328
Epoch 2289
Epoch 2289 :: Batch 0/1
Batch Loss = 0.0007309484141793273
2289, epoch_train_loss=0.0007309484141793273
Epoch 2290
Epoch 2290 :: Batch 0/1
Batch Loss = 0.0007309484141793217
2290, epoch_train_loss=0.0007309484141793217
Epoch 2291
Epoch 2291 :: Batch 0/1
Batch Loss = 0.0007309484141793164
2291, epoch_train_loss=0.0007309484141793164
Epoch 2292
Epoch 2292 :: Batch 0/1
Batch Loss = 0.0007309484141793109
2292, epoch_train_loss=0.0007309484141793109
Epoch 2293
Epoch 2293 :: Batch 0/1
Batch Loss = 0.0007309484141793055
2293, epoch_train_loss=0.0007309484141793055
Epoch 2294
Epoch 2294 :: Batch 0/1
Batch Loss = 0.0007309484141792999
2294, epoch_train_loss=0.0007309484141792999
Epoch 2295
Epoch 2295 :: Batch 0/1
Batch Loss = 0.0007309484141792944
2295, epoch_train_loss=0.0007309484141792944
Epoch 2296
Epoch 2296 :: Batch 0/1
Batch Loss = 0.0007309484141792889
2296, epoch_train_loss=0.0007309484141792889
Epoch 2297
Epoch 2297 :: Batch 0/1
Batch Loss = 0.0007309484141792836
2297, epoch_train_loss=0.0007309484141792836
Epoch 2298
Epoch 2298 :: Batch 0/1
Batch Loss = 0.0007309484141792781
2298, epoch_train_loss=0.0007309484141792781
Epoch 2299
Epoch 2299 :: Batch 0/1
Batch Loss = 0.0007309484141792726
2299, epoch_train_loss=0.0007309484141792726
Epoch 2300
Epoch 2300 :: Batch 0/1
Batch Loss = 0.0007309484141792671
2300, epoch_train_loss=0.0007309484141792671
Epoch 2301
Epoch 2301 :: Batch 0/1
Batch Loss = 0.0007309484141792616
2301, epoch_train_loss=0.0007309484141792616
Epoch 2302
Epoch 2302 :: Batch 0/1
Batch Loss = 0.0007309484141792561
2302, epoch_train_loss=0.0007309484141792561
Epoch 2303
Epoch 2303 :: Batch 0/1
Batch Loss = 0.0007309484141792507
2303, epoch_train_loss=0.0007309484141792507
Epoch 2304
Epoch 2304 :: Batch 0/1
Batch Loss = 0.0007309484141792451
2304, epoch_train_loss=0.0007309484141792451
Epoch 2305
Epoch 2305 :: Batch 0/1
Batch Loss = 0.0007309484141792398
2305, epoch_train_loss=0.0007309484141792398
Epoch 2306
Epoch 2306 :: Batch 0/1
Batch Loss = 0.0007309484141792341
2306, epoch_train_loss=0.0007309484141792341
Epoch 2307
Epoch 2307 :: Batch 0/1
Batch Loss = 0.0007309484141792286
2307, epoch_train_loss=0.0007309484141792286
Epoch 2308
Epoch 2308 :: Batch 0/1
Batch Loss = 0.0007309484141792232
2308, epoch_train_loss=0.0007309484141792232
Epoch 2309
Epoch 2309 :: Batch 0/1
Batch Loss = 0.0007309484141792177
2309, epoch_train_loss=0.0007309484141792177
Epoch 2310
Epoch 2310 :: Batch 0/1
Batch Loss = 0.0007309484141792122
2310, epoch_train_loss=0.0007309484141792122
Epoch 2311
Epoch 2311 :: Batch 0/1
Batch Loss = 0.0007309484141792066
2311, epoch_train_loss=0.0007309484141792066
Epoch 2312
Epoch 2312 :: Batch 0/1
Batch Loss = 0.0007309484141792011
2312, epoch_train_loss=0.0007309484141792011
Epoch 2313
Epoch 2313 :: Batch 0/1
Batch Loss = 0.0007309484141791955
2313, epoch_train_loss=0.0007309484141791955
Epoch 2314
Epoch 2314 :: Batch 0/1
Batch Loss = 0.0007309484141791901
2314, epoch_train_loss=0.0007309484141791901
Epoch 2315
Epoch 2315 :: Batch 0/1
Batch Loss = 0.0007309484141791846
2315, epoch_train_loss=0.0007309484141791846
Epoch 2316
Epoch 2316 :: Batch 0/1
Batch Loss = 0.0007309484141791789
2316, epoch_train_loss=0.0007309484141791789
Epoch 2317
Epoch 2317 :: Batch 0/1
Batch Loss = 0.0007309484141791734
2317, epoch_train_loss=0.0007309484141791734
Epoch 2318
Epoch 2318 :: Batch 0/1
Batch Loss = 0.0007309484141791678
2318, epoch_train_loss=0.0007309484141791678
Epoch 2319
Epoch 2319 :: Batch 0/1
Batch Loss = 0.0007309484141791622
2319, epoch_train_loss=0.0007309484141791622
Epoch 2320
Epoch 2320 :: Batch 0/1
Batch Loss = 0.0007309484141791568
2320, epoch_train_loss=0.0007309484141791568
Epoch 2321
Epoch 2321 :: Batch 0/1
Batch Loss = 0.0007309484141791513
2321, epoch_train_loss=0.0007309484141791513
Epoch 2322
Epoch 2322 :: Batch 0/1
Batch Loss = 0.0007309484141791457
2322, epoch_train_loss=0.0007309484141791457
Epoch 2323
Epoch 2323 :: Batch 0/1
Batch Loss = 0.0007309484141791402
2323, epoch_train_loss=0.0007309484141791402
Epoch 2324
Epoch 2324 :: Batch 0/1
Batch Loss = 0.0007309484141791346
2324, epoch_train_loss=0.0007309484141791346
Epoch 2325
Epoch 2325 :: Batch 0/1
Batch Loss = 0.000730948414179129
2325, epoch_train_loss=0.000730948414179129
Epoch 2326
Epoch 2326 :: Batch 0/1
Batch Loss = 0.0007309484141791235
2326, epoch_train_loss=0.0007309484141791235
Epoch 2327
Epoch 2327 :: Batch 0/1
Batch Loss = 0.0007309484141791179
2327, epoch_train_loss=0.0007309484141791179
Epoch 2328
Epoch 2328 :: Batch 0/1
Batch Loss = 0.0007309484141791123
2328, epoch_train_loss=0.0007309484141791123
Epoch 2329
Epoch 2329 :: Batch 0/1
Batch Loss = 0.0007309484141791066
2329, epoch_train_loss=0.0007309484141791066
Epoch 2330
Epoch 2330 :: Batch 0/1
Batch Loss = 0.0007309484141791011
2330, epoch_train_loss=0.0007309484141791011
Epoch 2331
Epoch 2331 :: Batch 0/1
Batch Loss = 0.0007309484141790956
2331, epoch_train_loss=0.0007309484141790956
Epoch 2332
Epoch 2332 :: Batch 0/1
Batch Loss = 0.0007309484141790901
2332, epoch_train_loss=0.0007309484141790901
Epoch 2333
Epoch 2333 :: Batch 0/1
Batch Loss = 0.0007309484141790844
2333, epoch_train_loss=0.0007309484141790844
Epoch 2334
Epoch 2334 :: Batch 0/1
Batch Loss = 0.0007309484141790789
2334, epoch_train_loss=0.0007309484141790789
Epoch 2335
Epoch 2335 :: Batch 0/1
Batch Loss = 0.0007309484141790732
2335, epoch_train_loss=0.0007309484141790732
Epoch 2336
Epoch 2336 :: Batch 0/1
Batch Loss = 0.0007309484141790677
2336, epoch_train_loss=0.0007309484141790677
Epoch 2337
Epoch 2337 :: Batch 0/1
Batch Loss = 0.0007309484141790621
2337, epoch_train_loss=0.0007309484141790621
Epoch 2338
Epoch 2338 :: Batch 0/1
Batch Loss = 0.0007309484141790565
2338, epoch_train_loss=0.0007309484141790565
Epoch 2339
Epoch 2339 :: Batch 0/1
Batch Loss = 0.0007309484141790509
2339, epoch_train_loss=0.0007309484141790509
Epoch 2340
Epoch 2340 :: Batch 0/1
Batch Loss = 0.0007309484141790454
2340, epoch_train_loss=0.0007309484141790454
Epoch 2341
Epoch 2341 :: Batch 0/1
Batch Loss = 0.0007309484141790397
2341, epoch_train_loss=0.0007309484141790397
Epoch 2342
Epoch 2342 :: Batch 0/1
Batch Loss = 0.0007309484141790341
2342, epoch_train_loss=0.0007309484141790341
Epoch 2343
Epoch 2343 :: Batch 0/1
Batch Loss = 0.0007309484141790285
2343, epoch_train_loss=0.0007309484141790285
Epoch 2344
Epoch 2344 :: Batch 0/1
Batch Loss = 0.0007309484141790228
2344, epoch_train_loss=0.0007309484141790228
Epoch 2345
Epoch 2345 :: Batch 0/1
Batch Loss = 0.0007309484141790173
2345, epoch_train_loss=0.0007309484141790173
Epoch 2346
Epoch 2346 :: Batch 0/1
Batch Loss = 0.0007309484141790117
2346, epoch_train_loss=0.0007309484141790117
Epoch 2347
Epoch 2347 :: Batch 0/1
Batch Loss = 0.000730948414179006
2347, epoch_train_loss=0.000730948414179006
Epoch 2348
Epoch 2348 :: Batch 0/1
Batch Loss = 0.0007309484141790004
2348, epoch_train_loss=0.0007309484141790004
Epoch 2349
Epoch 2349 :: Batch 0/1
Batch Loss = 0.0007309484141789947
2349, epoch_train_loss=0.0007309484141789947
Epoch 2350
Epoch 2350 :: Batch 0/1
Batch Loss = 0.0007309484141789891
2350, epoch_train_loss=0.0007309484141789891
Epoch 2351
Epoch 2351 :: Batch 0/1
Batch Loss = 0.0007309484141789835
2351, epoch_train_loss=0.0007309484141789835
Epoch 2352
Epoch 2352 :: Batch 0/1
Batch Loss = 0.0007309484141789778
2352, epoch_train_loss=0.0007309484141789778
Epoch 2353
Epoch 2353 :: Batch 0/1
Batch Loss = 0.0007309484141789724
2353, epoch_train_loss=0.0007309484141789724
Epoch 2354
Epoch 2354 :: Batch 0/1
Batch Loss = 0.0007309484141789666
2354, epoch_train_loss=0.0007309484141789666
Epoch 2355
Epoch 2355 :: Batch 0/1
Batch Loss = 0.0007309484141789608
2355, epoch_train_loss=0.0007309484141789608
Epoch 2356
Epoch 2356 :: Batch 0/1
Batch Loss = 0.0007309484141789553
2356, epoch_train_loss=0.0007309484141789553
Epoch 2357
Epoch 2357 :: Batch 0/1
Batch Loss = 0.0007309484141789496
2357, epoch_train_loss=0.0007309484141789496
Epoch 2358
Epoch 2358 :: Batch 0/1
Batch Loss = 0.0007309484141789441
2358, epoch_train_loss=0.0007309484141789441
Epoch 2359
Epoch 2359 :: Batch 0/1
Batch Loss = 0.0007309484141789385
2359, epoch_train_loss=0.0007309484141789385
Epoch 2360
Epoch 2360 :: Batch 0/1
Batch Loss = 0.0007309484141789326
2360, epoch_train_loss=0.0007309484141789326
Epoch 2361
Epoch 2361 :: Batch 0/1
Batch Loss = 0.000730948414178927
2361, epoch_train_loss=0.000730948414178927
Epoch 2362
Epoch 2362 :: Batch 0/1
Batch Loss = 0.0007309484141789212
2362, epoch_train_loss=0.0007309484141789212
Epoch 2363
Epoch 2363 :: Batch 0/1
Batch Loss = 0.0007309484141789157
2363, epoch_train_loss=0.0007309484141789157
Epoch 2364
Epoch 2364 :: Batch 0/1
Batch Loss = 0.00073094841417891
2364, epoch_train_loss=0.00073094841417891
Epoch 2365
Epoch 2365 :: Batch 0/1
Batch Loss = 0.0007309484141789043
2365, epoch_train_loss=0.0007309484141789043
Epoch 2366
Epoch 2366 :: Batch 0/1
Batch Loss = 0.0007309484141788987
2366, epoch_train_loss=0.0007309484141788987
Epoch 2367
Epoch 2367 :: Batch 0/1
Batch Loss = 0.0007309484141788929
2367, epoch_train_loss=0.0007309484141788929
Epoch 2368
Epoch 2368 :: Batch 0/1
Batch Loss = 0.0007309484141788872
2368, epoch_train_loss=0.0007309484141788872
Epoch 2369
Epoch 2369 :: Batch 0/1
Batch Loss = 0.0007309484141788817
2369, epoch_train_loss=0.0007309484141788817
Epoch 2370
Epoch 2370 :: Batch 0/1
Batch Loss = 0.0007309484141788759
2370, epoch_train_loss=0.0007309484141788759
Epoch 2371
Epoch 2371 :: Batch 0/1
Batch Loss = 0.0007309484141788703
2371, epoch_train_loss=0.0007309484141788703
Epoch 2372
Epoch 2372 :: Batch 0/1
Batch Loss = 0.0007309484141788645
2372, epoch_train_loss=0.0007309484141788645
Epoch 2373
Epoch 2373 :: Batch 0/1
Batch Loss = 0.0007309484141788589
2373, epoch_train_loss=0.0007309484141788589
Epoch 2374
Epoch 2374 :: Batch 0/1
Batch Loss = 0.0007309484141788531
2374, epoch_train_loss=0.0007309484141788531
Epoch 2375
Epoch 2375 :: Batch 0/1
Batch Loss = 0.0007309484141788474
2375, epoch_train_loss=0.0007309484141788474
Epoch 2376
Epoch 2376 :: Batch 0/1
Batch Loss = 0.0007309484141788418
2376, epoch_train_loss=0.0007309484141788418
Epoch 2377
Epoch 2377 :: Batch 0/1
Batch Loss = 0.0007309484141788361
2377, epoch_train_loss=0.0007309484141788361
Epoch 2378
Epoch 2378 :: Batch 0/1
Batch Loss = 0.0007309484141788304
2378, epoch_train_loss=0.0007309484141788304
Epoch 2379
Epoch 2379 :: Batch 0/1
Batch Loss = 0.0007309484141788246
2379, epoch_train_loss=0.0007309484141788246
Epoch 2380
Epoch 2380 :: Batch 0/1
Batch Loss = 0.0007309484141788189
2380, epoch_train_loss=0.0007309484141788189
Epoch 2381
Epoch 2381 :: Batch 0/1
Batch Loss = 0.0007309484141788132
2381, epoch_train_loss=0.0007309484141788132
Epoch 2382
Epoch 2382 :: Batch 0/1
Batch Loss = 0.0007309484141788075
2382, epoch_train_loss=0.0007309484141788075
Epoch 2383
Epoch 2383 :: Batch 0/1
Batch Loss = 0.0007309484141788019
2383, epoch_train_loss=0.0007309484141788019
Epoch 2384
Epoch 2384 :: Batch 0/1
Batch Loss = 0.0007309484141787961
2384, epoch_train_loss=0.0007309484141787961
Epoch 2385
Epoch 2385 :: Batch 0/1
Batch Loss = 0.0007309484141787904
2385, epoch_train_loss=0.0007309484141787904
Epoch 2386
Epoch 2386 :: Batch 0/1
Batch Loss = 0.0007309484141787846
2386, epoch_train_loss=0.0007309484141787846
Epoch 2387
Epoch 2387 :: Batch 0/1
Batch Loss = 0.0007309484141787788
2387, epoch_train_loss=0.0007309484141787788
Epoch 2388
Epoch 2388 :: Batch 0/1
Batch Loss = 0.0007309484141787731
2388, epoch_train_loss=0.0007309484141787731
Epoch 2389
Epoch 2389 :: Batch 0/1
Batch Loss = 0.0007309484141787674
2389, epoch_train_loss=0.0007309484141787674
Epoch 2390
Epoch 2390 :: Batch 0/1
Batch Loss = 0.0007309484141787615
2390, epoch_train_loss=0.0007309484141787615
Epoch 2391
Epoch 2391 :: Batch 0/1
Batch Loss = 0.0007309484141787558
2391, epoch_train_loss=0.0007309484141787558
Epoch 2392
Epoch 2392 :: Batch 0/1
Batch Loss = 0.00073094841417875
2392, epoch_train_loss=0.00073094841417875
Epoch 2393
Epoch 2393 :: Batch 0/1
Batch Loss = 0.0007309484141787444
2393, epoch_train_loss=0.0007309484141787444
Epoch 2394
Epoch 2394 :: Batch 0/1
Batch Loss = 0.0007309484141787387
2394, epoch_train_loss=0.0007309484141787387
Epoch 2395
Epoch 2395 :: Batch 0/1
Batch Loss = 0.0007309484141787329
2395, epoch_train_loss=0.0007309484141787329
Epoch 2396
Epoch 2396 :: Batch 0/1
Batch Loss = 0.0007309484141787272
2396, epoch_train_loss=0.0007309484141787272
Epoch 2397
Epoch 2397 :: Batch 0/1
Batch Loss = 0.0007309484141787213
2397, epoch_train_loss=0.0007309484141787213
Epoch 2398
Epoch 2398 :: Batch 0/1
Batch Loss = 0.0007309484141787154
2398, epoch_train_loss=0.0007309484141787154
Epoch 2399
Epoch 2399 :: Batch 0/1
Batch Loss = 0.0007309484141787097
2399, epoch_train_loss=0.0007309484141787097
Epoch 2400
Epoch 2400 :: Batch 0/1
Batch Loss = 0.000730948414178704
2400, epoch_train_loss=0.000730948414178704
Epoch 2401
Epoch 2401 :: Batch 0/1
Batch Loss = 0.0007309484141786982
2401, epoch_train_loss=0.0007309484141786982
Epoch 2402
Epoch 2402 :: Batch 0/1
Batch Loss = 0.0007309484141786925
2402, epoch_train_loss=0.0007309484141786925
Epoch 2403
Epoch 2403 :: Batch 0/1
Batch Loss = 0.0007309484141786867
2403, epoch_train_loss=0.0007309484141786867
Epoch 2404
Epoch 2404 :: Batch 0/1
Batch Loss = 0.000730948414178681
2404, epoch_train_loss=0.000730948414178681
Epoch 2405
Epoch 2405 :: Batch 0/1
Batch Loss = 0.0007309484141786751
2405, epoch_train_loss=0.0007309484141786751
Epoch 2406
Epoch 2406 :: Batch 0/1
Batch Loss = 0.0007309484141786694
2406, epoch_train_loss=0.0007309484141786694
Epoch 2407
Epoch 2407 :: Batch 0/1
Batch Loss = 0.0007309484141786634
2407, epoch_train_loss=0.0007309484141786634
Epoch 2408
Epoch 2408 :: Batch 0/1
Batch Loss = 0.0007309484141786577
2408, epoch_train_loss=0.0007309484141786577
Epoch 2409
Epoch 2409 :: Batch 0/1
Batch Loss = 0.0007309484141786519
2409, epoch_train_loss=0.0007309484141786519
Epoch 2410
Epoch 2410 :: Batch 0/1
Batch Loss = 0.0007309484141786461
2410, epoch_train_loss=0.0007309484141786461
Epoch 2411
Epoch 2411 :: Batch 0/1
Batch Loss = 0.0007309484141786403
2411, epoch_train_loss=0.0007309484141786403
Epoch 2412
Epoch 2412 :: Batch 0/1
Batch Loss = 0.0007309484141786345
2412, epoch_train_loss=0.0007309484141786345
Epoch 2413
Epoch 2413 :: Batch 0/1
Batch Loss = 0.0007309484141786287
2413, epoch_train_loss=0.0007309484141786287
Epoch 2414
Epoch 2414 :: Batch 0/1
Batch Loss = 0.0007309484141786229
2414, epoch_train_loss=0.0007309484141786229
Epoch 2415
Epoch 2415 :: Batch 0/1
Batch Loss = 0.000730948414178617
2415, epoch_train_loss=0.000730948414178617
Epoch 2416
Epoch 2416 :: Batch 0/1
Batch Loss = 0.0007309484141786113
2416, epoch_train_loss=0.0007309484141786113
Epoch 2417
Epoch 2417 :: Batch 0/1
Batch Loss = 0.0007309484141786054
2417, epoch_train_loss=0.0007309484141786054
Epoch 2418
Epoch 2418 :: Batch 0/1
Batch Loss = 0.0007309484141785995
2418, epoch_train_loss=0.0007309484141785995
Epoch 2419
Epoch 2419 :: Batch 0/1
Batch Loss = 0.0007309484141785937
2419, epoch_train_loss=0.0007309484141785937
Epoch 2420
Epoch 2420 :: Batch 0/1
Batch Loss = 0.000730948414178588
2420, epoch_train_loss=0.000730948414178588
Epoch 2421
Epoch 2421 :: Batch 0/1
Batch Loss = 0.0007309484141785822
2421, epoch_train_loss=0.0007309484141785822
Epoch 2422
Epoch 2422 :: Batch 0/1
Batch Loss = 0.0007309484141785761
2422, epoch_train_loss=0.0007309484141785761
Epoch 2423
Epoch 2423 :: Batch 0/1
Batch Loss = 0.0007309484141785704
2423, epoch_train_loss=0.0007309484141785704
Epoch 2424
Epoch 2424 :: Batch 0/1
Batch Loss = 0.0007309484141785645
2424, epoch_train_loss=0.0007309484141785645
Epoch 2425
Epoch 2425 :: Batch 0/1
Batch Loss = 0.0007309484141785587
2425, epoch_train_loss=0.0007309484141785587
Epoch 2426
Epoch 2426 :: Batch 0/1
Batch Loss = 0.0007309484141785529
2426, epoch_train_loss=0.0007309484141785529
Epoch 2427
Epoch 2427 :: Batch 0/1
Batch Loss = 0.0007309484141785469
2427, epoch_train_loss=0.0007309484141785469
Epoch 2428
Epoch 2428 :: Batch 0/1
Batch Loss = 0.0007309484141785411
2428, epoch_train_loss=0.0007309484141785411
Epoch 2429
Epoch 2429 :: Batch 0/1
Batch Loss = 0.0007309484141785353
2429, epoch_train_loss=0.0007309484141785353
Epoch 2430
Epoch 2430 :: Batch 0/1
Batch Loss = 0.0007309484141785294
2430, epoch_train_loss=0.0007309484141785294
Epoch 2431
Epoch 2431 :: Batch 0/1
Batch Loss = 0.0007309484141785237
2431, epoch_train_loss=0.0007309484141785237
Epoch 2432
Epoch 2432 :: Batch 0/1
Batch Loss = 0.0007309484141785177
2432, epoch_train_loss=0.0007309484141785177
Epoch 2433
Epoch 2433 :: Batch 0/1
Batch Loss = 0.0007309484141785118
2433, epoch_train_loss=0.0007309484141785118
Epoch 2434
Epoch 2434 :: Batch 0/1
Batch Loss = 0.0007309484141785059
2434, epoch_train_loss=0.0007309484141785059
Epoch 2435
Epoch 2435 :: Batch 0/1
Batch Loss = 0.0007309484141785
2435, epoch_train_loss=0.0007309484141785
Epoch 2436
Epoch 2436 :: Batch 0/1
Batch Loss = 0.0007309484141784942
2436, epoch_train_loss=0.0007309484141784942
Epoch 2437
Epoch 2437 :: Batch 0/1
Batch Loss = 0.0007309484141784884
2437, epoch_train_loss=0.0007309484141784884
Epoch 2438
Epoch 2438 :: Batch 0/1
Batch Loss = 0.0007309484141784823
2438, epoch_train_loss=0.0007309484141784823
Epoch 2439
Epoch 2439 :: Batch 0/1
Batch Loss = 0.0007309484141784765
2439, epoch_train_loss=0.0007309484141784765
Epoch 2440
Epoch 2440 :: Batch 0/1
Batch Loss = 0.0007309484141784706
2440, epoch_train_loss=0.0007309484141784706
Epoch 2441
Epoch 2441 :: Batch 0/1
Batch Loss = 0.0007309484141784648
2441, epoch_train_loss=0.0007309484141784648
Epoch 2442
Epoch 2442 :: Batch 0/1
Batch Loss = 0.0007309484141784588
2442, epoch_train_loss=0.0007309484141784588
Epoch 2443
Epoch 2443 :: Batch 0/1
Batch Loss = 0.0007309484141784529
2443, epoch_train_loss=0.0007309484141784529
Epoch 2444
Epoch 2444 :: Batch 0/1
Batch Loss = 0.000730948414178447
2444, epoch_train_loss=0.000730948414178447
Epoch 2445
Epoch 2445 :: Batch 0/1
Batch Loss = 0.0007309484141784411
2445, epoch_train_loss=0.0007309484141784411
Epoch 2446
Epoch 2446 :: Batch 0/1
Batch Loss = 0.0007309484141784352
2446, epoch_train_loss=0.0007309484141784352
Epoch 2447
Epoch 2447 :: Batch 0/1
Batch Loss = 0.0007309484141784294
2447, epoch_train_loss=0.0007309484141784294
Epoch 2448
Epoch 2448 :: Batch 0/1
Batch Loss = 0.0007309484141784234
2448, epoch_train_loss=0.0007309484141784234
Epoch 2449
Epoch 2449 :: Batch 0/1
Batch Loss = 0.0007309484141784175
2449, epoch_train_loss=0.0007309484141784175
Epoch 2450
Epoch 2450 :: Batch 0/1
Batch Loss = 0.0007309484141784117
2450, epoch_train_loss=0.0007309484141784117
Epoch 2451
Epoch 2451 :: Batch 0/1
Batch Loss = 0.0007309484141784057
2451, epoch_train_loss=0.0007309484141784057
Epoch 2452
Epoch 2452 :: Batch 0/1
Batch Loss = 0.0007309484141783996
2452, epoch_train_loss=0.0007309484141783996
Epoch 2453
Epoch 2453 :: Batch 0/1
Batch Loss = 0.0007309484141783938
2453, epoch_train_loss=0.0007309484141783938
Epoch 2454
Epoch 2454 :: Batch 0/1
Batch Loss = 0.0007309484141783879
2454, epoch_train_loss=0.0007309484141783879
Epoch 2455
Epoch 2455 :: Batch 0/1
Batch Loss = 0.000730948414178382
2455, epoch_train_loss=0.000730948414178382
Epoch 2456
Epoch 2456 :: Batch 0/1
Batch Loss = 0.0007309484141783759
2456, epoch_train_loss=0.0007309484141783759
Epoch 2457
Epoch 2457 :: Batch 0/1
Batch Loss = 0.0007309484141783699
2457, epoch_train_loss=0.0007309484141783699
Epoch 2458
Epoch 2458 :: Batch 0/1
Batch Loss = 0.0007309484141783642
2458, epoch_train_loss=0.0007309484141783642
Epoch 2459
Epoch 2459 :: Batch 0/1
Batch Loss = 0.0007309484141783582
2459, epoch_train_loss=0.0007309484141783582
Epoch 2460
Epoch 2460 :: Batch 0/1
Batch Loss = 0.0007309484141783521
2460, epoch_train_loss=0.0007309484141783521
Epoch 2461
Epoch 2461 :: Batch 0/1
Batch Loss = 0.0007309484141783462
2461, epoch_train_loss=0.0007309484141783462
Epoch 2462
Epoch 2462 :: Batch 0/1
Batch Loss = 0.0007309484141783403
2462, epoch_train_loss=0.0007309484141783403
Epoch 2463
Epoch 2463 :: Batch 0/1
Batch Loss = 0.0007309484141783342
2463, epoch_train_loss=0.0007309484141783342
Epoch 2464
Epoch 2464 :: Batch 0/1
Batch Loss = 0.0007309484141783284
2464, epoch_train_loss=0.0007309484141783284
Epoch 2465
Epoch 2465 :: Batch 0/1
Batch Loss = 0.0007309484141783223
2465, epoch_train_loss=0.0007309484141783223
Epoch 2466
Epoch 2466 :: Batch 0/1
Batch Loss = 0.0007309484141783165
2466, epoch_train_loss=0.0007309484141783165
Epoch 2467
Epoch 2467 :: Batch 0/1
Batch Loss = 0.0007309484141783104
2467, epoch_train_loss=0.0007309484141783104
Epoch 2468
Epoch 2468 :: Batch 0/1
Batch Loss = 0.0007309484141783044
2468, epoch_train_loss=0.0007309484141783044
Epoch 2469
Epoch 2469 :: Batch 0/1
Batch Loss = 0.0007309484141782985
2469, epoch_train_loss=0.0007309484141782985
Epoch 2470
Epoch 2470 :: Batch 0/1
Batch Loss = 0.0007309484141782924
2470, epoch_train_loss=0.0007309484141782924
Epoch 2471
Epoch 2471 :: Batch 0/1
Batch Loss = 0.0007309484141782864
2471, epoch_train_loss=0.0007309484141782864
Epoch 2472
Epoch 2472 :: Batch 0/1
Batch Loss = 0.0007309484141782805
2472, epoch_train_loss=0.0007309484141782805
Epoch 2473
Epoch 2473 :: Batch 0/1
Batch Loss = 0.0007309484141782745
2473, epoch_train_loss=0.0007309484141782745
Epoch 2474
Epoch 2474 :: Batch 0/1
Batch Loss = 0.0007309484141782684
2474, epoch_train_loss=0.0007309484141782684
Epoch 2475
Epoch 2475 :: Batch 0/1
Batch Loss = 0.0007309484141782626
2475, epoch_train_loss=0.0007309484141782626
Epoch 2476
Epoch 2476 :: Batch 0/1
Batch Loss = 0.0007309484141782565
2476, epoch_train_loss=0.0007309484141782565
Epoch 2477
Epoch 2477 :: Batch 0/1
Batch Loss = 0.0007309484141782504
2477, epoch_train_loss=0.0007309484141782504
Epoch 2478
Epoch 2478 :: Batch 0/1
Batch Loss = 0.0007309484141782445
2478, epoch_train_loss=0.0007309484141782445
Epoch 2479
Epoch 2479 :: Batch 0/1
Batch Loss = 0.0007309484141782385
2479, epoch_train_loss=0.0007309484141782385
Epoch 2480
Epoch 2480 :: Batch 0/1
Batch Loss = 0.0007309484141782324
2480, epoch_train_loss=0.0007309484141782324
Epoch 2481
Epoch 2481 :: Batch 0/1
Batch Loss = 0.0007309484141782265
2481, epoch_train_loss=0.0007309484141782265
Epoch 2482
Epoch 2482 :: Batch 0/1
Batch Loss = 0.0007309484141782205
2482, epoch_train_loss=0.0007309484141782205
Epoch 2483
Epoch 2483 :: Batch 0/1
Batch Loss = 0.0007309484141782145
2483, epoch_train_loss=0.0007309484141782145
Epoch 2484
Epoch 2484 :: Batch 0/1
Batch Loss = 0.0007309484141782084
2484, epoch_train_loss=0.0007309484141782084
Epoch 2485
Epoch 2485 :: Batch 0/1
Batch Loss = 0.0007309484141782024
2485, epoch_train_loss=0.0007309484141782024
Epoch 2486
Epoch 2486 :: Batch 0/1
Batch Loss = 0.0007309484141781962
2486, epoch_train_loss=0.0007309484141781962
Epoch 2487
Epoch 2487 :: Batch 0/1
Batch Loss = 0.0007309484141781903
2487, epoch_train_loss=0.0007309484141781903
Epoch 2488
Epoch 2488 :: Batch 0/1
Batch Loss = 0.0007309484141781843
2488, epoch_train_loss=0.0007309484141781843
Epoch 2489
Epoch 2489 :: Batch 0/1
Batch Loss = 0.0007309484141781783
2489, epoch_train_loss=0.0007309484141781783
Epoch 2490
Epoch 2490 :: Batch 0/1
Batch Loss = 0.0007309484141781722
2490, epoch_train_loss=0.0007309484141781722
Epoch 2491
Epoch 2491 :: Batch 0/1
Batch Loss = 0.0007309484141781662
2491, epoch_train_loss=0.0007309484141781662
Epoch 2492
Epoch 2492 :: Batch 0/1
Batch Loss = 0.00073094841417816
2492, epoch_train_loss=0.00073094841417816
Epoch 2493
Epoch 2493 :: Batch 0/1
Batch Loss = 0.000730948414178154
2493, epoch_train_loss=0.000730948414178154
Epoch 2494
Epoch 2494 :: Batch 0/1
Batch Loss = 0.0007309484141781481
2494, epoch_train_loss=0.0007309484141781481
Epoch 2495
Epoch 2495 :: Batch 0/1
Batch Loss = 0.0007309484141781418
2495, epoch_train_loss=0.0007309484141781418
Epoch 2496
Epoch 2496 :: Batch 0/1
Batch Loss = 0.0007309484141781358
2496, epoch_train_loss=0.0007309484141781358
Epoch 2497
Epoch 2497 :: Batch 0/1
Batch Loss = 0.0007309484141781299
2497, epoch_train_loss=0.0007309484141781299
Epoch 2498
Epoch 2498 :: Batch 0/1
Batch Loss = 0.0007309484141781238
2498, epoch_train_loss=0.0007309484141781238
Epoch 2499
Epoch 2499 :: Batch 0/1
Batch Loss = 0.0007309484141781177
2499, epoch_train_loss=0.0007309484141781177
